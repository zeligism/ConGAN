{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConsistentGAN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/ConGAN/blob/main/ConsistentGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxx3Jy_8qsPE"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFx20xTNkpQ",
        "outputId": "ddafd4ef-145b-45c6-edce-220f3b3843bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QNzdq01hSb"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlF68ff2K8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_Qrpq7z3iJ"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import log2\n",
        "from pprint import pformat\n",
        "from collections import defaultdict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDduLe1Qkd9"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRxrufxw1cm"
      },
      "source": [
        "### Report Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmEyNG58w2kJ"
      },
      "source": [
        "def plot_lines(losses_dict, filename=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots the losses of the discriminator and the generator.\n",
        "\n",
        "    Args:\n",
        "        filename: The plot's filename. If None, plot won't be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(title)\n",
        "    for label, losses in losses_dict.items():\n",
        "        plt.plot(losses, label=label)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.legend()\n",
        "    \n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def create_progress_animation(frames, filename):\n",
        "    \"\"\"\n",
        "    Creates a video of the progress of the generator on a fixed latent vector.\n",
        "\n",
        "    Args:\n",
        "        filename: The animation's filename.\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    ims = [[plt.imshow(img.permute(1,2,0), animated=True)]\n",
        "           for img in frames]\n",
        "    ani = animation.ArtistAnimation(fig, ims, blit=True)\n",
        "    \n",
        "    ani.save(filename)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def generate_grid(generator, latent):\n",
        "    \"\"\"\n",
        "    Check generator's output on latent vectors and return it.\n",
        "\n",
        "    Args:\n",
        "        generator: The generator.\n",
        "        latent: Latent vector from which an image grid will be generated.\n",
        "\n",
        "    Returns:\n",
        "        A grid of images generated by `generator` from `latent`.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(latent).detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(fake.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzwGurc1qOx"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhc2oS53G4e"
      },
      "source": [
        "## PyTorch Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU7HFc6t5N8w"
      },
      "source": [
        "### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHPo8w13JmH"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding half the size of features,\n",
        "    e.g. if input is [in_channels, 64, 64], output will be [out_channels, 32, 32].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.conv = nn.utils.spectral_norm(self.conv)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.LeakyReLU(0.2, inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding double the size of features,\n",
        "    e.g. if input is [in_channels, 32, 32], output will be [out_channels, 64, 64].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.convT = nn.utils.spectral_norm(self.convT)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.ReLU(inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convT(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=16,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,\n",
        "                 D_block=ConvBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        using_grad_penalty = gan_type in (\"gan-gp\", \"wgan-gp\")\n",
        "        output_sigmoid = output_sigmoid and gan_type in (\"gan\", \"gan-gp\")\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm and not using_grad_penalty,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Input layer\n",
        "        self.input_layer = D_block(image_channels, features[0], **block_config)\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            D_block(in_features, out_features, **block_config)\n",
        "            for in_features, out_features in zip(features, features[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer (feature_size = 3, 4, or 5 -> 1)\n",
        "        if fully_convolutional:\n",
        "            self.output_layer = nn.Sequential(\n",
        "                nn.Conv2d(features[-1], num_latents, latent_kernel, bias=False),\n",
        "                nn.Flatten(),\n",
        "            )\n",
        "        else:\n",
        "            self.output_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(features[-1] * latent_kernel**2, num_latents, bias=False)\n",
        "            )\n",
        "\n",
        "        # Add sigmoid activation if using regular GAN loss\n",
        "        self.output_activation = nn.Sigmoid() if output_sigmoid else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        if self.output_activation:\n",
        "            x = self.output_activation(x)\n",
        "        # Remove H and W dimensions, infer channels dim (remove if 1)\n",
        "        x = x.view(x.size(0), -1).squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 G_block=ConvTBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Reverse order of image sizes and features for generator\n",
        "        image_sizes = image_sizes[::-1]\n",
        "        features = features[::-1]\n",
        "\n",
        "        # Input layer\n",
        "        if fully_convolutional:\n",
        "            self.input_layer = G_block(num_latents, features[0], kernel_size=latent_kernel,\n",
        "                                       stride=1, padding=0, **block_config)\n",
        "        else:\n",
        "            self.input_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(num_latents, features[0] * image_sizes[0]**2, bias=False),\n",
        "                View(features[0], image_sizes[0], image_sizes[0])\n",
        "            )\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            G_block(in_features, out_features, kernel_size=4+(expected_size%2), **block_config)\n",
        "            for in_features, out_features, expected_size in zip(features, features[1:], image_sizes[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.ConvTranspose2d(features[-1], image_channels, kernel_size=4+(image_size%2),\n",
        "                                               stride=2, padding=1, bias=False)\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add H and W dimensions, infer channels dim (add if none)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = self.output_activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    \"\"\"Deep Convolutional Generative Adversarial Network\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 D_num_features=64,\n",
        "                 G_num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,):\n",
        "        \"\"\"\n",
        "        Initializes DCGAN.\n",
        "\n",
        "        Args:\n",
        "            num_latents: Number of latent factors.\n",
        "            num_features: Number of features in the convolutions.\n",
        "            image_channels: Number of channels in the input image.\n",
        "            image_size: Size (i.e. height or width) of image.\n",
        "            gan_type: Type of GAN (e.g. \"gan\" or \"wgan-gp\").\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_latents = num_latents\n",
        "        self.D_num_features = D_num_features\n",
        "        self.G_num_features = G_num_features\n",
        "        self.image_channels = image_channels\n",
        "        self.image_size = image_size\n",
        "        self.feature_multiplier = feature_multiplier\n",
        "        self.gan_type = gan_type\n",
        "        self.fully_convolutional = fully_convolutional\n",
        "        self.activation = activation\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.use_spectralnorm = use_spectralnorm\n",
        "\n",
        "        D_params = {\n",
        "            \"num_latents\": 1,  # XXX\n",
        "            \"num_features\": D_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "            \"output_sigmoid\": output_sigmoid,\n",
        "        }\n",
        "        G_params = {\n",
        "            \"num_latents\": num_latents,\n",
        "            \"num_features\": G_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": True,\n",
        "            \"use_spectralnorm\": False,  # XXX\n",
        "        }\n",
        "\n",
        "        self.D = DCGAN_Discriminator(**D_params)\n",
        "        self.G = DCGAN_Generator(**G_params)\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape, including_batch=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.including_batch = including_batch\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.including_batch:\n",
        "            return x.view(*self.shape)\n",
        "        else:\n",
        "            return x.view(x.size(0), *self.shape)\n",
        "\n",
        "class ChannelNoise(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel noise injection module.\n",
        "    Adds a linearly transformed noise to a convolution layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, std=0.02):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise_size = [x.size()[0], 1, *x.size()[2:]]  # single channel\n",
        "        noise = self.std * torch.randn(noise_size).to(x)\n",
        "\n",
        "        return x + self.scale * noise"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYujBEzC7EOO"
      },
      "source": [
        "### SimSiam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YcNut27F-v"
      },
      "source": [
        "class SimSiam(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a SimSiam model.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 2048)\n",
        "        pred_dim: hidden dimension of the predictor (default: 512)\n",
        "        \"\"\"\n",
        "        super(SimSiam, self).__init__()\n",
        "\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQcvNDLQ5niT"
      },
      "source": [
        "### ConsistentGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeUqwjQ95mMV"
      },
      "source": [
        "class ConsistentGAN(nn.Module):\n",
        "    def __init__(self, repr_dim, latent_dim,\n",
        "                 D_batchnorm=True, image_size=64, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        # Make D's architecture kinda similar to predictor\n",
        "        D_hidden_dim = repr_dim // 10\n",
        "        if D_batchnorm:\n",
        "            self.D = nn.Sequential(nn.Linear(repr_dim, D_hidden_dim, bias=False),\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(D_hidden_dim, D_hidden_dim, bias=False),\n",
        "                                   nn.BatchNorm1d(D_hidden_dim),\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(D_hidden_dim, 1),\n",
        "                                   nn.Sigmoid())\n",
        "        else:\n",
        "            self.D = nn.Sequential(nn.Linear(repr_dim, D_hidden_dim, bias=False),\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(D_hidden_dim, D_hidden_dim, bias=False),\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(D_hidden_dim, 1),\n",
        "                                   nn.Sigmoid())\n",
        "\n",
        "\n",
        "        # Same for generator (latent -> representations)\n",
        "        G_hidden_dim = repr_dim // 10\n",
        "        self.G = nn.Sequential(nn.Linear(latent_dim, G_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(G_hidden_dim),\n",
        "                               nn.LeakyReLU(0.2, inplace=True),\n",
        "                               nn.Linear(G_hidden_dim, G_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(G_hidden_dim),\n",
        "                               nn.LeakyReLU(0.2, inplace=True),\n",
        "                               nn.Linear(G_hidden_dim, G_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(G_hidden_dim),\n",
        "                               nn.LeakyReLU(0.2, inplace=True),\n",
        "                               nn.Linear(G_hidden_dim, G_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(G_hidden_dim),\n",
        "                               nn.LeakyReLU(0.2, inplace=True),\n",
        "                               nn.Linear(G_hidden_dim, G_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(G_hidden_dim),\n",
        "                               nn.LeakyReLU(0.2, inplace=True),\n",
        "                               nn.Linear(G_hidden_dim, G_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(G_hidden_dim),\n",
        "                               nn.LeakyReLU(0.2, inplace=True),\n",
        "                               nn.Linear(G_hidden_dim, repr_dim, bias=False),\n",
        "                               nn.BatchNorm1d(repr_dim, affine=False),\n",
        "                               Normalize2()\n",
        "                               )\n",
        "\n",
        "        # Encodes x to context @XXX\n",
        "        ctx_dim = 256\n",
        "        self.ctx_encoder = DCGAN_Discriminator(num_latents=ctx_dim, image_size=image_size)\n",
        "\n",
        "        # Projections to decoding space\n",
        "        # Decodes representation + context projection to an image\n",
        "        num_latents = 512\n",
        "        self.repr_proj = nn.Sequential(nn.Linear(repr_dim, num_latents // 2), nn.Sigmoid())\n",
        "        self.ctx_proj = nn.Sequential(nn.Linear(ctx_dim, num_latents // 2), nn.Sigmoid())\n",
        "        self.decoder = DCGAN_Generator(num_latents=num_latents, image_size=image_size)\n",
        "\n",
        "        # To check progress of G\n",
        "        self.fixed_latent = self.sample_latent(8*8)\n",
        "    \n",
        "    # XXX temp function\n",
        "    def proj(self, repr, ctx, return_all=False):\n",
        "        repr_proj = self.repr_proj(repr)\n",
        "        ctx_proj = self.ctx_proj(ctx)\n",
        "        proj = torch.cat([repr_proj, ctx_proj], dim=1)\n",
        "        if return_all:\n",
        "            return proj, repr_proj, ctx_proj\n",
        "        else:\n",
        "            return proj\n",
        "\n",
        "    def sample_latent(self, batch_size):\n",
        "        latent_size = [batch_size, self.latent_dim]\n",
        "        latent = torch.randn(latent_size)\n",
        "        return latent\n",
        "\n",
        "\n",
        "class Normalize2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.normalize(x, p=2, dim=1)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEuurkcmLLd3"
      },
      "source": [
        "### Latent Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTlMYVgLN5E"
      },
      "source": [
        "class LatentTransform(nn.Module):\n",
        "    def __init__(self, repr_dim, latent_dim, hidden_dim, full_transform=True, noop=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.full_transform = full_transform\n",
        "        self.noop = noop\n",
        "\n",
        "        if self.noop:\n",
        "            self.output_dim = self.latent_dim * 2\n",
        "            return\n",
        "        elif self.full_transform:\n",
        "            self.input_dim = self.repr_dim + self.latent_dim\n",
        "            self.output_dim = self.hidden_dim\n",
        "        else:\n",
        "            self.input_dim = self.repr_dim\n",
        "            self.output_dim = self.hidden_dim + self.latent_dim\n",
        "\n",
        "        self.transform = nn.Linear(self.input_dim, self.hidden_dim, bias=False)\n",
        "    \n",
        "    def forward(self, repr, noise):\n",
        "        if self.noop:\n",
        "            return torch.cat([noise, torch.randn_like(noise)], dim=1)\n",
        "\n",
        "        # assuming latent is concat as [repr,noise] XXX\n",
        "        if self.full_transform:\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "            latent = self.transform(latent)\n",
        "        else:\n",
        "            repr = self.transform(repr)\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "\n",
        "        return latent\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRivPV9BwFk"
      },
      "source": [
        "# Training v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rpQp2E9rE5"
      },
      "source": [
        "### Imports and globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51zFNn509xLz"
      },
      "source": [
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "GANSIAM_DIR = \"/content/drive/My Drive/gansiam/\"\n",
        "SIMSIAM_PATH = os.path.join(GANSIAM_DIR, \"pretrained_batch256.tar\")\n",
        "TINYIMAGENET_DIR = \"tiny-imagenet-200\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9X_JYE2Vwxd"
      },
      "source": [
        "### Download Tiny Imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "559H2an_V03M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0d988e-1f7b-4641-af7b-09170813d023"
      },
      "source": [
        "%%bash\n",
        "if [[ -d  \"tiny-imagenet-200\" ]]; then\n",
        "    echo \"Tiny Imagenet exists.\"\n",
        "else\n",
        "    wget -q \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "    unzip -qq \"tiny-imagenet-200.zip\" && rm \"tiny-imagenet-200.zip\"\n",
        "    echo \"Downloaded Tiny Imagenet.\"\n",
        "fi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Tiny Imagenet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwyRrBEGq9jh"
      },
      "source": [
        "### Utility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlbiU7QhrETa"
      },
      "source": [
        "#### GAN Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-TnvLE0q-1U"
      },
      "source": [
        "def get_D_loss(gan_type=\"gan\"):\n",
        "    if gan_type in (\"gan\", \"gan-gp\"):\n",
        "        return D_loss_GAN\n",
        "    elif gan_type in (\"wgan\", \"wgan-gp\"):\n",
        "        return D_loss_WGAN\n",
        "    else:\n",
        "        raise ValueError(f\"gan_type {gan_type} not supported\")\n",
        "\n",
        "\n",
        "def get_G_loss(gan_type=\"gan\"):\n",
        "    if gan_type in (\"gan\", \"gan-gp\"):\n",
        "        return G_loss_GAN\n",
        "    elif gan_type in (\"wgan\", \"wgan-gp\"):\n",
        "        return G_loss_WGAN\n",
        "    else:\n",
        "        raise ValueError(f\"gan_type {gan_type} not supported\")\n",
        "\n",
        "\n",
        "def D_loss_GAN(D_real, D_fake, label_smoothing=True):\n",
        "    \n",
        "    # Create (noisy) real and fake labels XXX\n",
        "    if label_smoothing:\n",
        "        real_label = 0.7 + 0.5 * torch.rand_like(D_real)\n",
        "    else:\n",
        "        real_label = torch.ones_like(D_real) - 0.1\n",
        "    fake_label = torch.zeros_like(D_fake)\n",
        "\n",
        "    # Calculate binary cross entropy loss\n",
        "    D_loss_real = F.binary_cross_entropy(D_real, real_label)\n",
        "    D_loss_fake = F.binary_cross_entropy(D_fake, fake_label)\n",
        "\n",
        "    # Loss is: - log(D(x)) - log(1 - D(x_g)),\n",
        "    # which is equiv. to maximizing: log(D(x)) + log(1 - D(x_g))\n",
        "    D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "    return D_loss.mean()\n",
        "\n",
        "\n",
        "def D_loss_WGAN(D_real, D_fake):\n",
        "\n",
        "    # Maximize: D(x) - D(x_g) - const * (|| grad of D(x_i) wrt x_i || - 1)^2,\n",
        "    # where x_i <- eps * x + (1 - eps) * x_g, and eps ~ rand(0,1)\n",
        "    D_loss = -1 * (D_real - D_fake)\n",
        "\n",
        "    return D_loss.mean()\n",
        "\n",
        "\n",
        "def G_loss_GAN(D_fake):\n",
        "\n",
        "    # Calculate binary cross entropy loss with a fake binary label\n",
        "    fake_label = torch.zeros_like(D_fake)\n",
        "\n",
        "    # Loss is: -log(D(G(z))), which is equiv. to minimizing log(1-D(G(z)))\n",
        "    # We use this loss vs. the original one for stability only.\n",
        "    G_loss = F.binary_cross_entropy(D_fake, 1 - fake_label)\n",
        "\n",
        "    return G_loss.mean()\n",
        "\n",
        "\n",
        "def G_loss_WGAN(D_fake):\n",
        "\n",
        "    # Minimize: -D(G(z))\n",
        "    G_loss = -D_fake\n",
        "    \n",
        "    return G_loss.mean()\n",
        "\n",
        "\n",
        "def interpolate(real, fake):\n",
        "    eps_size = [1] * len(real.size())\n",
        "    eps_size[0] = real.size(0)\n",
        "    eps = torch.rand(eps_size).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "\n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_x, x, torch.ones_like(D_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esZGRUlerHNX"
      },
      "source": [
        "#### Data Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-K3c9WlrJDD"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "import random\n",
        "\n",
        "\n",
        "class TwoCropsTransform:\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        q = self.base_transform(x)\n",
        "        k = self.base_transform(x)\n",
        "        return [q, k]\n",
        "\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
        "\n",
        "    def __init__(self, sigma=[.1, 2.]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyzHmINsryyh"
      },
      "source": [
        "#### Train Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8KJUUeWr1dI"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    filename = os.path.join(GANSIAM_DIR, \"results\", filename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, init_lr, epoch, args):\n",
        "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
        "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
        "            param_group['lr'] = init_lr\n",
        "        else:\n",
        "            param_group['lr'] = cur_lr\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbo7T6blPVTc"
      },
      "source": [
        "### Load pre-trained SimSiam model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr8clgi_AzY",
        "outputId": "3685e56e-3798-4929-b573-fe8f8b3ae50b"
      },
      "source": [
        "checkpoint = torch.load(SIMSIAM_PATH, map_location=\"cuda:0\")\n",
        "# remove 'module.' from dict keys\n",
        "model_dict = OrderedDict((k[7:], v) for k, v in checkpoint[\"state_dict\"].items())\n",
        "\n",
        "# Load model\n",
        "simsiam = SimSiam(models.__dict__[\"resnet50\"])\n",
        "simsiam.load_state_dict(model_dict)\n",
        "#print(simsiam)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckB_xSVX8kB"
      },
      "source": [
        "# Training v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nouxldrYb0r"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUP5vn8OX--p"
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.data = TINYIMAGENET_DIR  # used for training Tiny ImageNet\n",
        "        self.load = False\n",
        "        self.workers = 2\n",
        "        self.epochs = 100\n",
        "        self.batch_size = 256\n",
        "        self.D_lr = 2e-4\n",
        "        self.G_lr = 2e-4\n",
        "        self.latent_transform_lr = self.G_lr\n",
        "        self.lr_decay = 0.01\n",
        "        self.betas = (0.5, 0.9)\n",
        "        self.print_freq = 10\n",
        "        self.seed = None\n",
        "        self.gpu = 0\n",
        "\n",
        "        # SimSiam (don't change if loading pre-trained)\n",
        "        self.dim = 2048\n",
        "        self.pred_dim = 512\n",
        "\n",
        "        # GAN\n",
        "        self.gan_type = \"gan\"  # ignore this\n",
        "        self.wgan = False  # if False, use spectral norm\n",
        "        self.repr_dim = self.dim  # don't change\n",
        "        self.latent_dim = 128\n",
        "        self.num_features = 64\n",
        "        self.D_iters = 5\n",
        "        self.grad_penalty = 10.  # 0 if wgan is False\n",
        "        self.grad_center = 1.  # not important\n",
        "        self.generate_grid_interval = 100\n",
        "\n",
        "        # make noise proportional to sd(data)\n",
        "        self.im_noise = 1e-3  # image sd is about 1.0\n",
        "        self.repr_noise = 1e-6  # repr sd is about 0.001\n",
        "        \n",
        "        self.repr_consistency = 0.01\n",
        "\n",
        "\n",
        "GENERATED_GRIDS = []\n",
        "IMAGE_SIZE = 64\n",
        "args = Args()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xihRlU0PYhiJ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW_P-JfeYiOe",
        "outputId": "298c9de4-fdab-47e2-a395-690cb6ad030d"
      },
      "source": [
        "# image normalization\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "inv_normalize = transforms.Normalize(\n",
        "   mean= [-m/s for m, s in zip(mean, std)],\n",
        "   std= [1/s for s in std]\n",
        ")\n",
        "\n",
        "augmentation = [\n",
        "    #transforms.RandomResizedCrop(IMAGE_SIZE),\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "# MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "_augmentation = [\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.2, 1.)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "DATASET = \"CIFAR10\"\n",
        "\n",
        "if DATASET == \"MNIST\":\n",
        "    augmentation = [transforms.Grayscale(3)] + augmentation\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=os.path.join(GANSIAM_DIR, \"mnist/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CelebA\":\n",
        "    train_dataset = datasets.CelebA(\n",
        "        root=os.path.join(GANSIAM_DIR, \"celeba\"), download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CIFAR10\":\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=os.path.join(GANSIAM_DIR, \"cifar10/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "        #transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "elif DATASET == \"Tiny Imagenet\":\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "        transform=transforms.Compose(augmentation))\n",
        "else:\n",
        "    raise Exception(f\"Dataset '{DATASET}' not found\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=args.workers, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Z4Ke6DYkDg"
      },
      "source": [
        "## Model + Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLiHFvBimb3"
      },
      "source": [
        "def D_criterion_NS(D_real, D_fake):\n",
        "    d_loss = F.softplus(-D_real) + F.softplus(D_fake)\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_NS(D_fake):\n",
        "    return F.softplus(-D_fake).mean()\n",
        "\n",
        "def D_criterion_LS(D_real, D_fake):\n",
        "    d_loss = 0.5 * (D_real - torch.ones_like(D_real))**2 + 0.5 * (D_fake)**2\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_LS(D_fake):\n",
        "    gen_loss = 0.5 * (D_fake - torch.ones_like(D_fake))**2\n",
        "    return gen_loss.mean()\n",
        "\n",
        "def D_criterion_hinge(D_real, D_fake):\n",
        "    return torch.mean(F.relu(1. - D_real)) + torch.mean(F.relu(1. + D_fake))\n",
        "\n",
        "def G_criterion_hinge(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def D_criterion_wasserstein(D_real, D_fake):\n",
        "    return torch.mean(D_fake - D_real)\n",
        "\n",
        "def G_criterion_wasserstein(D_fake):\n",
        "    return -torch.mean(D_fake)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rO_MvGzYldx",
        "outputId": "90d37bfa-f5c4-47cc-ea7b-f77721ac0173"
      },
      "source": [
        "if args.seed is not None:\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.set_device(args.gpu)\n",
        "\n",
        "latent_transform = LatentTransform(repr_dim=args.repr_dim,\n",
        "                                   latent_dim=args.latent_dim,\n",
        "                                   hidden_dim=args.latent_dim,\n",
        "                                   full_transform=False,\n",
        "                                   #noop=True,\n",
        "                                   )\n",
        "\n",
        "model = DCGAN(num_latents=latent_transform.output_dim,\n",
        "              image_size=IMAGE_SIZE,\n",
        "              gan_type=args.gan_type,  # doesn't make a difference\n",
        "              use_batchnorm=False,  # for D only\n",
        "              output_sigmoid=False,  # for D only\n",
        "              use_spectralnorm=not args.wgan,\n",
        "              )\n",
        "\n",
        "latent_transform = latent_transform.cuda(args.gpu)\n",
        "model = model.cuda(args.gpu)\n",
        "simsiam = simsiam.cuda(args.gpu)\n",
        "\n",
        "print(\"Num of params in lf:\", sum(map(torch.numel, latent_transform.parameters())))\n",
        "print(\"Num of params in D:\", sum(map(torch.numel, model.D.parameters())))\n",
        "print(\"Num of params in G:\", sum(map(torch.numel, model.G.parameters())))\n",
        "\n",
        "# Define D and G loss functions\n",
        "if args.wgan:\n",
        "    args.grad_penalty = 10.\n",
        "    D_criterion = D_criterion_wasserstein\n",
        "    G_criterion = G_criterion_wasserstein\n",
        "else:\n",
        "    args.grad_penalty = 0.\n",
        "    D_criterion = D_criterion_LS\n",
        "    G_criterion = G_criterion_LS\n",
        "\n",
        "# Optimizers\n",
        "D_optimizer = torch.optim.Adam(\n",
        "    model.D.parameters(),\n",
        "    args.D_lr, betas=args.betas)\n",
        "\n",
        "G_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.G.parameters()},\n",
        "     {\"params\": latent_transform.parameters(), \"lr\": args.latent_transform_lr}],\n",
        "     args.G_lr, betas=args.betas)\n",
        "\n",
        "D_sched = torch.optim.lr_scheduler.ExponentialLR(D_optimizer, 1. - args.lr_decay)\n",
        "G_sched = torch.optim.lr_scheduler.ExponentialLR(G_optimizer, 1. - args.lr_decay)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if args.load:\n",
        "    model.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/model.pth.tar\"))\n",
        "    latent_transform.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\"))\n",
        "    D_sched.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/D_sched.pth.tar\"))\n",
        "    G_sched.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/G_sched.pth.tar\"))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of params in lf: 262144\n",
            "Num of params in D: 2763776\n",
            "Num of params in G: 4854656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTqwby4cX0i",
        "outputId": "8a8cda36-9b20-4677-e530-e583b46eaa91"
      },
      "source": [
        "print(latent_transform)\n",
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentTransform(\n",
            "  (transform): Linear(in_features=2048, out_features=128, bias=False)\n",
            ")\n",
            "DCGAN(\n",
            "  (D): DCGAN_Discriminator(\n",
            "    (input_layer): ConvBlock(\n",
            "      (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (main_layers): Sequential(\n",
            "      (0): ConvBlock(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "      (1): ConvBlock(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "      (2): ConvBlock(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Sequential(\n",
            "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "  )\n",
            "  (G): DCGAN_Generator(\n",
            "    (input_layer): ConvTBlock(\n",
            "      (convT): ConvTranspose2d(256, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (main_layers): Sequential(\n",
            "      (0): ConvTBlock(\n",
            "        (convT): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvTBlock(\n",
            "        (convT): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvTBlock(\n",
            "        (convT): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (output_layer): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (output_activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeDicP6QZNQ2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA8BoUEjNrlR"
      },
      "source": [
        "def sample_latent(num_samples):\n",
        "    return torch.randn(num_samples, args.latent_dim)\n",
        "\n",
        "def check_G_progress(G):\n",
        "    with torch.no_grad():\n",
        "        z = latent_transform(fixed_repr, fixed_noise)\n",
        "        fake_progress = G(z)\n",
        "    im_grid = torch.cat([fixed_x, fake_progress], dim=0)\n",
        "    grid = vutils.make_grid(im_grid.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "    return grid"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj9x-2fNtnp"
      },
      "source": [
        "# Sample a global latent for reuse\n",
        "fixed_x, _ = next(iter(train_loader))\n",
        "fixed_x = fixed_x[:32].cuda(args.gpu)\n",
        "with torch.no_grad():\n",
        "    fixed_repr = simsiam.encoder(fixed_x)\n",
        "    fixed_repr = F.normalize(fixed_repr)\n",
        "fixed_noise = sample_latent(32).cuda(args.gpu)\n",
        "fixed_latent = torch.cat([fixed_repr, fixed_noise], dim=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7gU4I8OZOer"
      },
      "source": [
        "def train(train_loader, model, simsiam,\n",
        "          D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    D_on_reals = AverageMeter('D(real)', ':.4f')\n",
        "    D_on_fakes = AverageMeter('D(fake)', ':.4f')\n",
        "    D_grads = AverageMeter('grad(D)', ':.4f')\n",
        "    repr_losses = AverageMeter('repr loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time,\n",
        "         D_on_reals, D_on_fakes, D_grads, repr_losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    D_grad_penalty = torch.zeros(1).cuda(args.gpu)\n",
        "    repr_loss = torch.zeros(1).cuda(args.gpu)\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        x = x.cuda(args.gpu, non_blocking=True)\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # compute output and loss\n",
        "        with torch.no_grad():\n",
        "            repr = simsiam.encoder(x)\n",
        "            repr = F.normalize(repr + args.repr_noise * torch.randn_like(repr))\n",
        "\n",
        "        ### train GAN\n",
        "        #for _ in range(args.D_iters):\n",
        "        if (i+1) % (args.D_iters+1) > 0:\n",
        "            # Add noise to real sample\n",
        "            real = x + args.im_noise * torch.randn_like(x)\n",
        "\n",
        "            # Sample from generator\n",
        "            with torch.no_grad():\n",
        "                noise = sample_latent(batch_size).cuda(args.gpu)\n",
        "                z = latent_transform(repr, noise)\n",
        "                fake = model.G(z)\n",
        "                # Add noise to fake sample as well\n",
        "                fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "\n",
        "            # Classify real and fake data\n",
        "            D_real = model.D(real)\n",
        "            D_fake = model.D(fake)\n",
        "\n",
        "            # Calculate loss\n",
        "            D_loss = D_criterion(D_real, D_fake)\n",
        "            # Gradient penalty\n",
        "            if args.grad_penalty != 0.:\n",
        "                D_grad_penalty = simple_gradient_penalty(\n",
        "                    model.D, interpolate(real, fake), center=args.grad_center)\n",
        "                D_loss += args.grad_penalty * D_grad_penalty\n",
        "\n",
        "            # Calculate gradient and minimize\n",
        "            D_optimizer.zero_grad()\n",
        "            D_loss.backward()\n",
        "            D_optimizer.step()\n",
        "\n",
        "            # Save data\n",
        "            D_on_reals.update(D_real.mean().item(), batch_size)\n",
        "            D_on_fakes.update(D_fake.mean().item(), batch_size)\n",
        "            D_grads.update(D_grad_penalty.mean().item(), batch_size)\n",
        "\n",
        "        else:\n",
        "            # Sample from generator\n",
        "            noise = sample_latent(batch_size).cuda(args.gpu)\n",
        "            z = latent_transform(repr, noise)\n",
        "            fake = model.G(z)\n",
        "            fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "            # Classify fake images\n",
        "            D_fake = model.D(fake)\n",
        "            # Calculate loss\n",
        "            G_loss = G_criterion(D_fake)\n",
        "            if args.repr_consistency != 0.:\n",
        "                # Representation consistency loss\n",
        "                fake_repr = simsiam.encoder(fake)\n",
        "                repr_loss = -F.cosine_similarity(fake_repr, repr).mean()\n",
        "            # Calculate gradient and minimize\n",
        "            G_optimizer.zero_grad()\n",
        "            (G_loss + args.repr_consistency * repr_loss).backward()\n",
        "            G_optimizer.step()\n",
        "\n",
        "            # Save data\n",
        "            D_on_fakes.update(D_fake.mean().item(), batch_size)\n",
        "            repr_losses.update(repr_loss.mean().item(), batch_size)\n",
        "\n",
        "        # Check generator's progress by recording its output on a fixed input\n",
        "        if i % args.generate_grid_interval == 0:\n",
        "            grid = check_G_progress(model.G)\n",
        "            GENERATED_GRIDS.append(grid)\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.display(i)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24ES94Re55W"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDMPwe-ae6q-"
      },
      "source": [
        "def save():\n",
        "    torch.save({'state_dict': model.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/model.pth.tar\")\n",
        "    torch.save({'state_dict': latent_transform.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")\n",
        "    torch.save({'state_dict': D_sched.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/D_sched.pth.tar\")\n",
        "    torch.save({'state_dict': G_sched.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/G_sched.pth.tar\")\n",
        "\n",
        "def save_vid():\n",
        "    vidname = f\"grids_per_{args.generate_grid_interval}_iters.mp4\"\n",
        "    vidname = os.path.join(GANSIAM_DIR, \"results\", \"progress\", vidname)\n",
        "    create_progress_animation(GENERATED_GRIDS, vidname)\n",
        "\n",
        "def show_sample(x, num_samples=16, show_x=False):\n",
        "    x = x.cuda(args.gpu)[:num_samples]\n",
        "    if show_x:\n",
        "        x_grid = vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4)\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(x_grid.permute(1,2,0))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = sample_latent(num_samples).cuda(args.gpu)\n",
        "        repr = simsiam.encoder(x)\n",
        "        repr = F.normalize(repr)\n",
        "        z = latent_transform(repr, noise)\n",
        "        x_fake = model.G(z)\n",
        "    im_grid = vutils.make_grid(x_fake.cpu(), padding=2, nrow=4, normalize=True, range=(-1,1))\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(im_grid.permute(1,2,0))\n",
        "\n",
        "def run(epochs):\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, simsiam,\n",
        "            D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\n",
        "\n",
        "        D_sched.step()\n",
        "        G_sched.step()\n",
        "\n",
        "        # Check G's progress evey epoch by generating an image\n",
        "        grid = check_G_progress(model.G)\n",
        "        imname = f'{GANSIAM_DIR}/results/progress/grid_{epoch:04d}.png'\n",
        "        plt.imsave(imname, grid.permute(1,2,0).numpy())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            save()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNNZfXWe5Rr",
        "outputId": "4095a907-5931-4d0e-dd5d-43057fd4041d"
      },
      "source": [
        "run(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  1.299 ( 1.299)\tData  0.183 ( 0.183)\tD(real) 0.0925 (0.0925)\tD(fake) 0.0659 (0.0659)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [0][ 10/195]\tTime  0.147 ( 0.374)\tData  0.000 ( 0.017)\tD(real) 1.0362 (0.7898)\tD(fake) 0.0363 (0.1317)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0129 (0.0129)\n",
            "Epoch: [0][ 20/195]\tTime  0.147 ( 0.282)\tData  0.000 ( 0.009)\tD(real) 1.1437 (0.8232)\tD(fake) 0.1136 (0.0906)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0287 (-0.0074)\n",
            "Epoch: [0][ 30/195]\tTime  0.147 ( 0.249)\tData  0.000 ( 0.006)\tD(real) 0.8515 (0.8355)\tD(fake) 0.1230 (0.0655)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0163 (-0.0146)\n",
            "Epoch: [0][ 40/195]\tTime  0.151 ( 0.228)\tData  0.000 ( 0.005)\tD(real) 1.0378 (0.8597)\tD(fake) 0.0229 (0.0513)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0170 (-0.0093)\n",
            "Epoch: [0][ 50/195]\tTime  0.147 ( 0.219)\tData  0.000 ( 0.004)\tD(real) 1.0460 (0.8732)\tD(fake) -0.0205 (0.0441)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0508 (-0.0127)\n",
            "Epoch: [0][ 60/195]\tTime  0.147 ( 0.212)\tData  0.000 ( 0.003)\tD(real) 0.9292 (0.8670)\tD(fake) 0.0285 (0.0366)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0433 (-0.0247)\n",
            "Epoch: [0][ 70/195]\tTime  0.147 ( 0.206)\tData  0.000 ( 0.003)\tD(real) 0.9163 (0.8787)\tD(fake) -0.0019 (0.0322)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0370 (-0.0258)\n",
            "Epoch: [0][ 80/195]\tTime  0.150 ( 0.202)\tData  0.000 ( 0.002)\tD(real) 0.9684 (0.8860)\tD(fake) 0.0154 (0.0295)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0591 (-0.0302)\n",
            "Epoch: [0][ 90/195]\tTime  0.149 ( 0.200)\tData  0.000 ( 0.002)\tD(real) 0.8029 (0.8869)\tD(fake) 0.0092 (0.0260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0888 (-0.0474)\n",
            "Epoch: [0][100/195]\tTime  0.159 ( 0.196)\tData  0.000 ( 0.002)\tD(real) 0.9364 (0.8926)\tD(fake) -0.0021 (0.0238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3564 (-0.0667)\n",
            "Epoch: [0][110/195]\tTime  0.149 ( 0.195)\tData  0.000 ( 0.002)\tD(real) 0.5716 (0.8951)\tD(fake) -0.0529 (0.0226)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4754 (-0.1068)\n",
            "Epoch: [0][120/195]\tTime  0.148 ( 0.194)\tData  0.000 ( 0.002)\tD(real) 0.8946 (0.8966)\tD(fake) 0.0546 (0.0211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4995 (-0.1482)\n",
            "Epoch: [0][130/195]\tTime  0.149 ( 0.192)\tData  0.000 ( 0.002)\tD(real) 0.8849 (0.9000)\tD(fake) -0.0040 (0.0192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5692 (-0.1682)\n",
            "Epoch: [0][140/195]\tTime  0.148 ( 0.191)\tData  0.000 ( 0.002)\tD(real) 0.7431 (0.9027)\tD(fake) -0.0170 (0.0189)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5556 (-0.2006)\n",
            "Epoch: [0][150/195]\tTime  0.152 ( 0.190)\tData  0.000 ( 0.001)\tD(real) 1.0829 (0.9057)\tD(fake) 0.0476 (0.0178)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5671 (-0.2322)\n",
            "Epoch: [0][160/195]\tTime  0.148 ( 0.188)\tData  0.000 ( 0.001)\tD(real) 0.9485 (0.9077)\tD(fake) -0.0083 (0.0172)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6301 (-0.2475)\n",
            "Epoch: [0][170/195]\tTime  0.148 ( 0.188)\tData  0.000 ( 0.001)\tD(real) 1.0176 (0.9096)\tD(fake) 0.0180 (0.0166)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6143 (-0.2717)\n",
            "Epoch: [0][180/195]\tTime  0.149 ( 0.187)\tData  0.000 ( 0.001)\tD(real) 1.0956 (0.9118)\tD(fake) 0.2237 (0.0170)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6065 (-0.2931)\n",
            "Epoch: [0][190/195]\tTime  0.151 ( 0.186)\tData  0.000 ( 0.001)\tD(real) 1.0004 (0.9131)\tD(fake) -0.0073 (0.0154)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6140 (-0.3035)\n",
            "Epoch: [1][  0/195]\tTime  0.381 ( 0.381)\tData  0.201 ( 0.201)\tD(real) 1.1361 (1.1361)\tD(fake) 0.0067 (0.0067)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [1][ 10/195]\tTime  0.147 ( 0.185)\tData  0.000 ( 0.019)\tD(real) 0.9593 (0.9588)\tD(fake) -0.0124 (0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6433 (-0.6433)\n",
            "Epoch: [1][ 20/195]\tTime  0.147 ( 0.182)\tData  0.000 ( 0.010)\tD(real) 0.8760 (0.9374)\tD(fake) -0.0716 (0.0081)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6181 (-0.6558)\n",
            "Epoch: [1][ 30/195]\tTime  0.151 ( 0.181)\tData  0.000 ( 0.007)\tD(real) 0.9974 (0.9430)\tD(fake) 0.0300 (0.0062)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6784 (-0.6572)\n",
            "Epoch: [1][ 40/195]\tTime  0.152 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 0.9382 (0.9436)\tD(fake) -0.0260 (0.0054)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6395 (-0.6542)\n",
            "Epoch: [1][ 50/195]\tTime  0.150 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 0.7735 (0.9432)\tD(fake) -0.0197 (0.0069)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6644 (-0.6499)\n",
            "Epoch: [1][ 60/195]\tTime  0.151 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0035 (0.9459)\tD(fake) 0.3070 (0.0108)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6431 (-0.6486)\n",
            "Epoch: [1][ 70/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9853 (0.9434)\tD(fake) -0.0071 (0.0076)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6488 (-0.6486)\n",
            "Epoch: [1][ 80/195]\tTime  0.146 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.0874 (0.9444)\tD(fake) -0.0465 (0.0077)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6269 (-0.6468)\n",
            "Epoch: [1][ 90/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 1.0153 (0.9448)\tD(fake) 0.5080 (0.0127)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6608 (-0.6485)\n",
            "Epoch: [1][100/195]\tTime  0.160 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9464 (0.9406)\tD(fake) 0.0060 (0.0096)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6363 (-0.6477)\n",
            "Epoch: [1][110/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9957 (0.9425)\tD(fake) -0.0098 (0.0101)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6100 (-0.6462)\n",
            "Epoch: [1][120/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8242 (0.9424)\tD(fake) 0.0362 (0.0095)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6753 (-0.6469)\n",
            "Epoch: [1][130/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.9322 (0.9418)\tD(fake) -0.0255 (0.0094)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6915 (-0.6490)\n",
            "Epoch: [1][140/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.9965 (0.9430)\tD(fake) 0.0079 (0.0098)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6682 (-0.6505)\n",
            "Epoch: [1][150/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8654 (0.9403)\tD(fake) -0.0044 (0.0112)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5769 (-0.6473)\n",
            "Epoch: [1][160/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.9297 (0.9413)\tD(fake) 0.0038 (0.0115)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6922 (-0.6490)\n",
            "Epoch: [1][170/195]\tTime  0.146 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8783 (0.9409)\tD(fake) 0.0153 (0.0121)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6241 (-0.6490)\n",
            "Epoch: [1][180/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0752 (0.9420)\tD(fake) 0.1652 (0.0132)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6469 (-0.6466)\n",
            "Epoch: [1][190/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.9904 (0.9412)\tD(fake) -0.0006 (0.0127)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6181 (-0.6456)\n",
            "Epoch: [2][  0/195]\tTime  0.354 ( 0.354)\tData  0.186 ( 0.186)\tD(real) 0.8650 (0.8650)\tD(fake) -0.0234 (-0.0234)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [2][ 10/195]\tTime  0.148 ( 0.182)\tData  0.000 ( 0.017)\tD(real) 0.9701 (0.9413)\tD(fake) -0.0072 (0.0061)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6291 (-0.6291)\n",
            "Epoch: [2][ 20/195]\tTime  0.147 ( 0.181)\tData  0.000 ( 0.009)\tD(real) 1.0379 (0.9461)\tD(fake) 0.0151 (0.0114)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.7010 (-0.6763)\n",
            "Epoch: [2][ 30/195]\tTime  0.150 ( 0.181)\tData  0.000 ( 0.006)\tD(real) 0.8761 (0.9439)\tD(fake) 0.0196 (0.0117)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6387 (-0.6503)\n",
            "Epoch: [2][ 40/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 0.8524 (0.9447)\tD(fake) -0.0187 (0.0116)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6515 (-0.6505)\n",
            "Epoch: [2][ 50/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.004)\tD(real) 0.9184 (0.9433)\tD(fake) 0.0093 (0.0131)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.7108 (-0.6447)\n",
            "Epoch: [2][ 60/195]\tTime  0.154 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.9191 (0.9446)\tD(fake) 0.0984 (0.0143)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6098 (-0.6435)\n",
            "Epoch: [2][ 70/195]\tTime  0.153 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9277 (0.9428)\tD(fake) -0.0000 (0.0161)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5792 (-0.6376)\n",
            "Epoch: [2][ 80/195]\tTime  0.147 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 1.1096 (0.9451)\tD(fake) 0.0199 (0.0189)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6426 (-0.6387)\n",
            "Epoch: [2][ 90/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 1.0181 (0.9439)\tD(fake) 0.2111 (0.0209)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6737 (-0.6424)\n",
            "Epoch: [2][100/195]\tTime  0.158 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8804 (0.9427)\tD(fake) -0.0034 (0.0198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6378 (-0.6421)\n",
            "Epoch: [2][110/195]\tTime  0.153 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9029 (0.9424)\tD(fake) 0.0178 (0.0200)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6880 (-0.6437)\n",
            "Epoch: [2][120/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0178 (0.9437)\tD(fake) 0.0893 (0.0207)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6098 (-0.6422)\n",
            "Epoch: [2][130/195]\tTime  0.151 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.8762 (0.9432)\tD(fake) -0.0117 (0.0200)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5613 (-0.6383)\n",
            "Epoch: [2][140/195]\tTime  0.147 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0486 (0.9424)\tD(fake) 0.0432 (0.0234)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5371 (-0.6356)\n",
            "Epoch: [2][150/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.8571 (0.9421)\tD(fake) 0.1118 (0.0243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.7239 (-0.6403)\n",
            "Epoch: [2][160/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.1439 (0.9436)\tD(fake) 0.0579 (0.0243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6735 (-0.6416)\n",
            "Epoch: [2][170/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.8724 (0.9406)\tD(fake) 0.0175 (0.0249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6737 (-0.6434)\n",
            "Epoch: [2][180/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.8386 (0.9415)\tD(fake) 0.0376 (0.0245)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6830 (-0.6401)\n",
            "Epoch: [2][190/195]\tTime  0.147 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8021 (0.9417)\tD(fake) -0.0114 (0.0241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6489 (-0.6404)\n",
            "Epoch: [3][  0/195]\tTime  0.365 ( 0.365)\tData  0.191 ( 0.191)\tD(real) 1.0305 (1.0305)\tD(fake) 0.0320 (0.0320)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [3][ 10/195]\tTime  0.149 ( 0.184)\tData  0.000 ( 0.018)\tD(real) 1.0345 (0.9614)\tD(fake) 0.0245 (0.0232)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6049 (-0.6049)\n",
            "Epoch: [3][ 20/195]\tTime  0.150 ( 0.182)\tData  0.000 ( 0.009)\tD(real) 0.9544 (0.9439)\tD(fake) 0.0285 (0.0231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6300 (-0.6247)\n",
            "Epoch: [3][ 30/195]\tTime  0.148 ( 0.181)\tData  0.000 ( 0.006)\tD(real) 0.9387 (0.9454)\tD(fake) 0.0862 (0.0247)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3844 (-0.5833)\n",
            "Epoch: [3][ 40/195]\tTime  0.152 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 1.0447 (0.9475)\tD(fake) 0.0392 (0.0216)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6171 (-0.5890)\n",
            "Epoch: [3][ 50/195]\tTime  0.150 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0470 (0.9456)\tD(fake) 0.0125 (0.0217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5026 (-0.5851)\n",
            "Epoch: [3][ 60/195]\tTime  0.146 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.9132 (0.9444)\tD(fake) 0.1197 (0.0240)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6985 (-0.6019)\n",
            "Epoch: [3][ 70/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9779 (0.9424)\tD(fake) 0.0144 (0.0262)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5779 (-0.5997)\n",
            "Epoch: [3][ 80/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.0858 (0.9418)\tD(fake) 0.0845 (0.0291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6133 (-0.6033)\n",
            "Epoch: [3][ 90/195]\tTime  0.153 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9249 (0.9405)\tD(fake) 0.1092 (0.0301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6601 (-0.6092)\n",
            "Epoch: [3][100/195]\tTime  0.157 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8585 (0.9406)\tD(fake) 0.0061 (0.0293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4708 (-0.6005)\n",
            "Epoch: [3][110/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9385 (0.9394)\tD(fake) 0.0269 (0.0313)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6517 (-0.6041)\n",
            "Epoch: [3][120/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9316 (0.9398)\tD(fake) 0.1205 (0.0327)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6320 (-0.5958)\n",
            "Epoch: [3][130/195]\tTime  0.151 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9063 (0.9386)\tD(fake) 0.0253 (0.0331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4210 (-0.5875)\n",
            "Epoch: [3][140/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0397 (0.9381)\tD(fake) 0.0349 (0.0350)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5605 (-0.5861)\n",
            "Epoch: [3][150/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0550 (0.9383)\tD(fake) 0.2647 (0.0364)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5603 (-0.5875)\n",
            "Epoch: [3][160/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.9608 (0.9365)\tD(fake) 0.0182 (0.0359)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4988 (-0.5841)\n",
            "Epoch: [3][170/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0102 (0.9363)\tD(fake) 0.0358 (0.0364)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6381 (-0.5843)\n",
            "Epoch: [3][180/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0893 (0.9365)\tD(fake) 0.2372 (0.0367)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6874 (-0.5894)\n",
            "Epoch: [3][190/195]\tTime  0.154 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.9593 (0.9353)\tD(fake) -0.0003 (0.0359)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6540 (-0.5915)\n",
            "Epoch: [4][  0/195]\tTime  0.383 ( 0.383)\tData  0.190 ( 0.190)\tD(real) 0.9655 (0.9655)\tD(fake) 0.0231 (0.0231)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [4][ 10/195]\tTime  0.149 ( 0.185)\tData  0.000 ( 0.018)\tD(real) 0.8939 (0.9384)\tD(fake) 0.0031 (0.0251)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6443 (-0.6443)\n",
            "Epoch: [4][ 20/195]\tTime  0.150 ( 0.183)\tData  0.000 ( 0.009)\tD(real) 1.0122 (0.9375)\tD(fake) 0.0118 (0.0335)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6291 (-0.6475)\n",
            "Epoch: [4][ 30/195]\tTime  0.151 ( 0.182)\tData  0.000 ( 0.006)\tD(real) 0.9283 (0.9356)\tD(fake) 0.1428 (0.0362)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6634 (-0.6518)\n",
            "Epoch: [4][ 40/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 0.9287 (0.9334)\tD(fake) 0.0016 (0.0338)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6772 (-0.6561)\n",
            "Epoch: [4][ 50/195]\tTime  0.149 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 0.9501 (0.9317)\tD(fake) 0.0406 (0.0399)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6116 (-0.6483)\n",
            "Epoch: [4][ 60/195]\tTime  0.147 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.8892 (0.9329)\tD(fake) 0.1490 (0.0401)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4856 (-0.6301)\n",
            "Epoch: [4][ 70/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9510 (0.9311)\tD(fake) 0.0074 (0.0403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6263 (-0.6297)\n",
            "Epoch: [4][ 80/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9485 (0.9294)\tD(fake) 0.0089 (0.0423)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6391 (-0.5990)\n",
            "Epoch: [4][ 90/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9531 (0.9310)\tD(fake) 0.1420 (0.0427)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5491 (-0.5977)\n",
            "Epoch: [4][100/195]\tTime  0.157 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0978 (0.9333)\tD(fake) 0.0890 (0.0416)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6139 (-0.5987)\n",
            "Epoch: [4][110/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0853 (0.9313)\tD(fake) 0.0811 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5892 (-0.6005)\n",
            "Epoch: [4][120/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8702 (0.9300)\tD(fake) 0.1638 (0.0431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6505 (-0.6013)\n",
            "Epoch: [4][130/195]\tTime  0.153 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 1.1479 (0.9312)\tD(fake) 0.1510 (0.0434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5194 (-0.5974)\n",
            "Epoch: [4][140/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9399 (0.9290)\tD(fake) 0.0167 (0.0435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5824 (-0.5923)\n",
            "Epoch: [4][150/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9146 (0.9302)\tD(fake) 0.1222 (0.0436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6075 (-0.5799)\n",
            "Epoch: [4][160/195]\tTime  0.150 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0546 (0.9317)\tD(fake) 0.0787 (0.0423)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6004 (-0.5807)\n",
            "Epoch: [4][170/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0608 (0.9317)\tD(fake) 0.0261 (0.0413)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6076 (-0.5813)\n",
            "Epoch: [4][180/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9792 (0.9319)\tD(fake) 0.1396 (0.0413)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6206 (-0.5831)\n",
            "Epoch: [4][190/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0615 (0.9325)\tD(fake) 0.0889 (0.0406)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5763 (-0.5828)\n",
            "Epoch: [5][  0/195]\tTime  0.385 ( 0.385)\tData  0.197 ( 0.197)\tD(real) 0.8222 (0.8222)\tD(fake) -0.0214 (-0.0214)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [5][ 10/195]\tTime  0.153 ( 0.186)\tData  0.000 ( 0.018)\tD(real) 0.8744 (0.9303)\tD(fake) -0.0128 (0.0308)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6120 (-0.6120)\n",
            "Epoch: [5][ 20/195]\tTime  0.151 ( 0.183)\tData  0.000 ( 0.010)\tD(real) 1.0334 (0.9331)\tD(fake) 0.0465 (0.0443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5685 (-0.4711)\n",
            "Epoch: [5][ 30/195]\tTime  0.152 ( 0.183)\tData  0.000 ( 0.007)\tD(real) 0.9620 (0.9346)\tD(fake) 0.1458 (0.0456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4871 (-0.4999)\n",
            "Epoch: [5][ 40/195]\tTime  0.150 ( 0.178)\tData  0.000 ( 0.005)\tD(real) 0.8318 (0.9321)\tD(fake) -0.0166 (0.0429)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5567 (-0.5094)\n",
            "Epoch: [5][ 50/195]\tTime  0.149 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 0.9301 (0.9343)\tD(fake) -0.0128 (0.0420)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5916 (-0.5192)\n",
            "Epoch: [5][ 60/195]\tTime  0.150 ( 0.179)\tData  0.000 ( 0.003)\tD(real) 0.8975 (0.9331)\tD(fake) 0.1229 (0.0426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6203 (-0.5473)\n",
            "Epoch: [5][ 70/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.8574 (0.9352)\tD(fake) 0.0010 (0.0400)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6945 (-0.5606)\n",
            "Epoch: [5][ 80/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.9642 (0.9352)\tD(fake) 0.0013 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6051 (-0.5727)\n",
            "Epoch: [5][ 90/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9516 (0.9369)\tD(fake) 0.1479 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4073 (-0.5643)\n",
            "Epoch: [5][100/195]\tTime  0.158 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9884 (0.9370)\tD(fake) 0.0401 (0.0409)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5913 (-0.5660)\n",
            "Epoch: [5][110/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.1110 (0.9381)\tD(fake) 0.0315 (0.0410)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.5478)\n",
            "Epoch: [5][120/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9221 (0.9368)\tD(fake) 0.1284 (0.0411)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5223 (-0.5465)\n",
            "Epoch: [5][130/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0524 (0.9382)\tD(fake) 0.0451 (0.0401)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4832 (-0.5435)\n",
            "Epoch: [5][140/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0383 (0.9385)\tD(fake) 0.0423 (0.0400)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5751 (-0.5481)\n",
            "Epoch: [5][150/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9453 (0.9381)\tD(fake) 0.1473 (0.0403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6235 (-0.5505)\n",
            "Epoch: [5][160/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8230 (0.9372)\tD(fake) -0.0373 (0.0403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5294 (-0.5497)\n",
            "Epoch: [5][170/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0514 (0.9378)\tD(fake) 0.0283 (0.0410)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6127 (-0.5533)\n",
            "Epoch: [5][180/195]\tTime  0.152 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.8033 (0.9375)\tD(fake) 0.0720 (0.0402)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6262 (-0.5541)\n",
            "Epoch: [5][190/195]\tTime  0.146 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0786 (0.9385)\tD(fake) 0.0924 (0.0401)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5253 (-0.5532)\n",
            "Epoch: [6][  0/195]\tTime  0.380 ( 0.380)\tData  0.199 ( 0.199)\tD(real) 0.8883 (0.8883)\tD(fake) -0.0319 (-0.0319)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [6][ 10/195]\tTime  0.147 ( 0.184)\tData  0.000 ( 0.018)\tD(real) 1.0104 (0.9407)\tD(fake) 0.0628 (0.0241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4769 (-0.4769)\n",
            "Epoch: [6][ 20/195]\tTime  0.151 ( 0.183)\tData  0.000 ( 0.010)\tD(real) 0.9187 (0.9325)\tD(fake) 0.0021 (0.0425)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4943 (-0.4890)\n",
            "Epoch: [6][ 30/195]\tTime  0.149 ( 0.182)\tData  0.000 ( 0.007)\tD(real) 0.9648 (0.9374)\tD(fake) 0.1412 (0.0433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5663 (-0.4853)\n",
            "Epoch: [6][ 40/195]\tTime  0.151 ( 0.178)\tData  0.000 ( 0.005)\tD(real) 1.0722 (0.9393)\tD(fake) 0.0465 (0.0397)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5303 (-0.4928)\n",
            "Epoch: [6][ 50/195]\tTime  0.150 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0218 (0.9359)\tD(fake) 0.1185 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5427 (-0.4943)\n",
            "Epoch: [6][ 60/195]\tTime  0.148 ( 0.179)\tData  0.000 ( 0.004)\tD(real) 0.9898 (0.9356)\tD(fake) 0.1680 (0.0435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4869 (-0.4881)\n",
            "Epoch: [6][ 70/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.8868 (0.9339)\tD(fake) -0.0035 (0.0438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.6016 (-0.4985)\n",
            "Epoch: [6][ 80/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.9421 (0.9329)\tD(fake) 0.0083 (0.0457)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5137 (-0.4995)\n",
            "Epoch: [6][ 90/195]\tTime  0.152 ( 0.178)\tData  0.000 ( 0.002)\tD(real) 0.9685 (0.9346)\tD(fake) 0.1723 (0.0461)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4959 (-0.4937)\n",
            "Epoch: [6][100/195]\tTime  0.164 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9276 (0.9353)\tD(fake) 0.0055 (0.0435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3899 (-0.4873)\n",
            "Epoch: [6][110/195]\tTime  0.151 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 1.0585 (0.9365)\tD(fake) 0.0222 (0.0433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4710 (-0.4883)\n",
            "Epoch: [6][120/195]\tTime  0.151 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9523 (0.9369)\tD(fake) 0.1507 (0.0428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5804 (-0.4951)\n",
            "Epoch: [6][130/195]\tTime  0.152 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0446 (0.9377)\tD(fake) 0.0552 (0.0416)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5152 (-0.4960)\n",
            "Epoch: [6][140/195]\tTime  0.152 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 1.0112 (0.9372)\tD(fake) 0.0262 (0.0415)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5071 (-0.4953)\n",
            "Epoch: [6][150/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 1.0131 (0.9371)\tD(fake) 0.2755 (0.0426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5168 (-0.4976)\n",
            "Epoch: [6][160/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9134 (0.9353)\tD(fake) -0.0008 (0.0428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5706 (-0.5004)\n",
            "Epoch: [6][170/195]\tTime  0.147 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9863 (0.9349)\tD(fake) 0.0338 (0.0436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4197 (-0.4970)\n",
            "Epoch: [6][180/195]\tTime  0.147 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0207 (0.9357)\tD(fake) 0.1647 (0.0443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3592 (-0.4912)\n",
            "Epoch: [6][190/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9063 (0.9355)\tD(fake) 0.0029 (0.0436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4460 (-0.4897)\n",
            "Epoch: [7][  0/195]\tTime  0.364 ( 0.364)\tData  0.190 ( 0.190)\tD(real) 0.9726 (0.9726)\tD(fake) -0.0167 (-0.0167)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [7][ 10/195]\tTime  0.149 ( 0.185)\tData  0.000 ( 0.018)\tD(real) 1.0344 (0.9527)\tD(fake) 0.0619 (0.0215)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5964 (-0.5964)\n",
            "Epoch: [7][ 20/195]\tTime  0.148 ( 0.183)\tData  0.000 ( 0.009)\tD(real) 1.1613 (0.9548)\tD(fake) 0.0393 (0.0280)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4676 (-0.4845)\n",
            "Epoch: [7][ 30/195]\tTime  0.148 ( 0.181)\tData  0.000 ( 0.006)\tD(real) 0.9239 (0.9411)\tD(fake) 0.1670 (0.0350)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5454 (-0.5027)\n",
            "Epoch: [7][ 40/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 0.9975 (0.9430)\tD(fake) 0.0370 (0.0342)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5257 (-0.5065)\n",
            "Epoch: [7][ 50/195]\tTime  0.151 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0286 (0.9433)\tD(fake) 0.0300 (0.0368)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5228 (-0.5174)\n",
            "Epoch: [7][ 60/195]\tTime  0.148 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.9971 (0.9431)\tD(fake) 0.1748 (0.0373)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.5456 (-0.5189)\n",
            "Epoch: [7][ 70/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9886 (0.9418)\tD(fake) 0.0144 (0.0371)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4343 (-0.5112)\n",
            "Epoch: [7][ 80/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.1321 (0.9415)\tD(fake) 0.0884 (0.0393)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3689 (-0.5052)\n",
            "Epoch: [7][ 90/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9532 (0.9389)\tD(fake) 0.1505 (0.0409)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3358 (-0.4963)\n",
            "Epoch: [7][100/195]\tTime  0.160 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9083 (0.9394)\tD(fake) -0.0023 (0.0404)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3973 (-0.4901)\n",
            "Epoch: [7][110/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9732 (0.9391)\tD(fake) 0.0359 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3978 (-0.4822)\n",
            "Epoch: [7][120/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.8256 (0.9380)\tD(fake) 0.1218 (0.0428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3741 (-0.4716)\n",
            "Epoch: [7][130/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9767 (0.9386)\tD(fake) 0.0192 (0.0431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3436 (-0.4655)\n",
            "Epoch: [7][140/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.1833 (0.9399)\tD(fake) 0.1005 (0.0437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3136 (-0.4516)\n",
            "Epoch: [7][150/195]\tTime  0.154 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9292 (0.9376)\tD(fake) 0.1699 (0.0452)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1925 (-0.4341)\n",
            "Epoch: [7][160/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.9608 (0.9379)\tD(fake) 0.0352 (0.0450)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.4280 (-0.4339)\n",
            "Epoch: [7][170/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0425 (0.9383)\tD(fake) 0.0447 (0.0451)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2836 (-0.4244)\n",
            "Epoch: [7][180/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.8365 (0.9384)\tD(fake) 0.0625 (0.0442)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3456 (-0.4162)\n",
            "Epoch: [7][190/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0022 (0.9388)\tD(fake) 0.0373 (0.0446)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2589 (-0.4111)\n",
            "Epoch: [8][  0/195]\tTime  0.374 ( 0.374)\tData  0.189 ( 0.189)\tD(real) 0.9649 (0.9649)\tD(fake) 0.0216 (0.0216)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [8][ 10/195]\tTime  0.148 ( 0.184)\tData  0.000 ( 0.017)\tD(real) 0.8693 (0.9379)\tD(fake) 0.0025 (0.0304)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3311 (-0.3311)\n",
            "Epoch: [8][ 20/195]\tTime  0.150 ( 0.182)\tData  0.000 ( 0.009)\tD(real) 1.0246 (0.9403)\tD(fake) 0.0331 (0.0464)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2469 (-0.2662)\n",
            "Epoch: [8][ 30/195]\tTime  0.150 ( 0.181)\tData  0.000 ( 0.006)\tD(real) 0.9619 (0.9383)\tD(fake) 0.2008 (0.0519)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2286 (-0.2641)\n",
            "Epoch: [8][ 40/195]\tTime  0.152 ( 0.178)\tData  0.000 ( 0.005)\tD(real) 0.9966 (0.9379)\tD(fake) 0.0770 (0.0487)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0954 (-0.2360)\n",
            "Epoch: [8][ 50/195]\tTime  0.152 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0436 (0.9388)\tD(fake) 0.0330 (0.0501)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2364 (-0.2386)\n",
            "Epoch: [8][ 60/195]\tTime  0.148 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.8569 (0.9379)\tD(fake) 0.1011 (0.0487)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2443 (-0.2356)\n",
            "Epoch: [8][ 70/195]\tTime  0.151 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.8520 (0.9370)\tD(fake) -0.0182 (0.0491)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1801 (-0.2306)\n",
            "Epoch: [8][ 80/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.0256 (0.9376)\tD(fake) 0.0566 (0.0512)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.2281)\n",
            "Epoch: [8][ 90/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.6990 (0.9365)\tD(fake) 0.0483 (0.0509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1185 (-0.2138)\n",
            "Epoch: [8][100/195]\tTime  0.160 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9091 (0.9344)\tD(fake) 0.0009 (0.0529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1710 (-0.2111)\n",
            "Epoch: [8][110/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9570 (0.9349)\tD(fake) 0.0518 (0.0528)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0987 (-0.2014)\n",
            "Epoch: [8][120/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9597 (0.9359)\tD(fake) 0.1402 (0.0525)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2770 (-0.2022)\n",
            "Epoch: [8][130/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.7975 (0.9358)\tD(fake) -0.0267 (0.0513)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1538 (-0.1999)\n",
            "Epoch: [8][140/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9160 (0.9354)\tD(fake) 0.0057 (0.0535)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1002 (-0.1982)\n",
            "Epoch: [8][150/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8732 (0.9358)\tD(fake) 0.0700 (0.0534)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0795 (-0.1882)\n",
            "Epoch: [8][160/195]\tTime  0.146 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8575 (0.9363)\tD(fake) -0.0058 (0.0529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1245 (-0.1858)\n",
            "Epoch: [8][170/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0061 (0.9371)\tD(fake) 0.0435 (0.0524)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1216 (-0.1832)\n",
            "Epoch: [8][180/195]\tTime  0.151 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0134 (0.9372)\tD(fake) 0.1523 (0.0529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0714 (-0.1788)\n",
            "Epoch: [8][190/195]\tTime  0.150 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8311 (0.9362)\tD(fake) 0.0300 (0.0534)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2294 (-0.1804)\n",
            "Epoch: [9][  0/195]\tTime  0.380 ( 0.380)\tData  0.190 ( 0.190)\tD(real) 0.9586 (0.9586)\tD(fake) 0.0283 (0.0283)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [9][ 10/195]\tTime  0.148 ( 0.185)\tData  0.000 ( 0.018)\tD(real) 0.8672 (0.9339)\tD(fake) 0.0247 (0.0522)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1235 (-0.1235)\n",
            "Epoch: [9][ 20/195]\tTime  0.150 ( 0.182)\tData  0.000 ( 0.009)\tD(real) 1.0167 (0.9383)\tD(fake) 0.0456 (0.0534)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1511 (-0.1584)\n",
            "Epoch: [9][ 30/195]\tTime  0.147 ( 0.181)\tData  0.000 ( 0.006)\tD(real) 1.0473 (0.9386)\tD(fake) 0.2371 (0.0601)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1777 (-0.1767)\n",
            "Epoch: [9][ 40/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.005)\tD(real) 0.9619 (0.9355)\tD(fake) 0.0277 (0.0572)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1458 (-0.1715)\n",
            "Epoch: [9][ 50/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.004)\tD(real) 0.9156 (0.9315)\tD(fake) 0.0022 (0.0584)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1522 (-0.1678)\n",
            "Epoch: [9][ 60/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.9918 (0.9358)\tD(fake) 0.1656 (0.0573)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1272 (-0.1646)\n",
            "Epoch: [9][ 70/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9731 (0.9356)\tD(fake) 0.0673 (0.0545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2071 (-0.1685)\n",
            "Epoch: [9][ 80/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 1.0783 (0.9383)\tD(fake) 0.0469 (0.0522)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2445 (-0.1773)\n",
            "Epoch: [9][ 90/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0312 (0.9384)\tD(fake) 0.1632 (0.0511)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2523 (-0.1848)\n",
            "Epoch: [9][100/195]\tTime  0.158 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.9173 (0.9385)\tD(fake) 0.0095 (0.0488)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2137 (-0.1866)\n",
            "Epoch: [9][110/195]\tTime  0.151 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 1.0782 (0.9399)\tD(fake) 0.0757 (0.0480)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2492 (-0.1875)\n",
            "Epoch: [9][120/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9273 (0.9398)\tD(fake) 0.1368 (0.0475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2678 (-0.1974)\n",
            "Epoch: [9][130/195]\tTime  0.151 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.8006 (0.9382)\tD(fake) 0.0229 (0.0464)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3263 (-0.2035)\n",
            "Epoch: [9][140/195]\tTime  0.150 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 0.9792 (0.9383)\tD(fake) 0.0273 (0.0485)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3417 (-0.2132)\n",
            "Epoch: [9][150/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9794 (0.9388)\tD(fake) 0.1724 (0.0493)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3281 (-0.2253)\n",
            "Epoch: [9][160/195]\tTime  0.152 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8401 (0.9383)\tD(fake) -0.0063 (0.0486)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2584 (-0.2266)\n",
            "Epoch: [9][170/195]\tTime  0.151 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0613 (0.9388)\tD(fake) 0.0231 (0.0492)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3243 (-0.2329)\n",
            "Epoch: [9][180/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.9920 (0.9393)\tD(fake) 0.1611 (0.0492)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3799 (-0.2412)\n",
            "Epoch: [9][190/195]\tTime  0.150 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8655 (0.9389)\tD(fake) -0.0189 (0.0488)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3226 (-0.2438)\n",
            "Epoch: [10][  0/195]\tTime  0.383 ( 0.383)\tData  0.193 ( 0.193)\tD(real) 1.0349 (1.0349)\tD(fake) 0.0206 (0.0206)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [10][ 10/195]\tTime  0.153 ( 0.186)\tData  0.000 ( 0.018)\tD(real) 0.9391 (0.9549)\tD(fake) 0.0329 (0.0301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3069 (-0.3069)\n",
            "Epoch: [10][ 20/195]\tTime  0.147 ( 0.183)\tData  0.000 ( 0.009)\tD(real) 1.0099 (0.9500)\tD(fake) 0.0297 (0.0368)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2840 (-0.3128)\n",
            "Epoch: [10][ 30/195]\tTime  0.147 ( 0.182)\tData  0.000 ( 0.007)\tD(real) 1.0121 (0.9509)\tD(fake) 0.1460 (0.0408)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3242 (-0.3097)\n",
            "Epoch: [10][ 40/195]\tTime  0.146 ( 0.178)\tData  0.000 ( 0.005)\tD(real) 0.8864 (0.9472)\tD(fake) 0.0224 (0.0387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2627 (-0.3019)\n",
            "Epoch: [10][ 50/195]\tTime  0.148 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0023 (0.9452)\tD(fake) 0.0437 (0.0437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2199 (-0.2841)\n",
            "Epoch: [10][ 60/195]\tTime  0.150 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.9910 (0.9463)\tD(fake) 0.1895 (0.0463)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2782 (-0.2854)\n",
            "Epoch: [10][ 70/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.003)\tD(real) 0.9898 (0.9457)\tD(fake) 0.0393 (0.0457)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2437 (-0.2816)\n",
            "Epoch: [10][ 80/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.0658 (0.9465)\tD(fake) 0.0654 (0.0444)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2385 (-0.2775)\n",
            "Epoch: [10][ 90/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9516 (0.9462)\tD(fake) 0.1292 (0.0438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2605 (-0.2700)\n",
            "Epoch: [10][100/195]\tTime  0.157 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9652 (0.9458)\tD(fake) 0.0312 (0.0429)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2589 (-0.2693)\n",
            "Epoch: [10][110/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0599 (0.9461)\tD(fake) 0.0464 (0.0435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2346 (-0.2629)\n",
            "Epoch: [10][120/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.8343 (0.9451)\tD(fake) 0.0862 (0.0434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.2547)\n",
            "Epoch: [10][130/195]\tTime  0.147 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9963 (0.9454)\tD(fake) 0.0395 (0.0430)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1807 (-0.2512)\n",
            "Epoch: [10][140/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.1342 (0.9468)\tD(fake) 0.0523 (0.0426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1997 (-0.2471)\n",
            "Epoch: [10][150/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0066 (0.9462)\tD(fake) 0.1337 (0.0425)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.2395)\n",
            "Epoch: [10][160/195]\tTime  0.152 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 0.8628 (0.9461)\tD(fake) -0.0332 (0.0412)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2445 (-0.2397)\n",
            "Epoch: [10][170/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9941 (0.9465)\tD(fake) 0.0304 (0.0415)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.2330)\n",
            "Epoch: [10][180/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0373 (0.9470)\tD(fake) 0.1735 (0.0419)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1557 (-0.2301)\n",
            "Epoch: [10][190/195]\tTime  0.152 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0092 (0.9468)\tD(fake) 0.0302 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.2279)\n",
            "Epoch: [11][  0/195]\tTime  0.374 ( 0.374)\tData  0.202 ( 0.202)\tD(real) 0.9679 (0.9679)\tD(fake) 0.0164 (0.0164)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [11][ 10/195]\tTime  0.148 ( 0.184)\tData  0.000 ( 0.019)\tD(real) 0.9164 (0.9528)\tD(fake) -0.0196 (0.0337)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1786 (-0.1786)\n",
            "Epoch: [11][ 20/195]\tTime  0.149 ( 0.182)\tData  0.000 ( 0.010)\tD(real) 0.9603 (0.9467)\tD(fake) 0.0206 (0.0418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1048 (-0.1494)\n",
            "Epoch: [11][ 30/195]\tTime  0.148 ( 0.182)\tData  0.000 ( 0.007)\tD(real) 0.9828 (0.9454)\tD(fake) 0.1521 (0.0505)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2647 (-0.2005)\n",
            "Epoch: [11][ 40/195]\tTime  0.149 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 0.9133 (0.9447)\tD(fake) -0.0086 (0.0486)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3302 (-0.2221)\n",
            "Epoch: [11][ 50/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.004)\tD(real) 0.9665 (0.9449)\tD(fake) -0.0041 (0.0481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2582 (-0.2239)\n",
            "Epoch: [11][ 60/195]\tTime  0.148 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 0.9581 (0.9444)\tD(fake) 0.1140 (0.0495)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.3113 (-0.2277)\n",
            "Epoch: [11][ 70/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.0436 (0.9468)\tD(fake) 0.0798 (0.0471)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2630 (-0.2309)\n",
            "Epoch: [11][ 80/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 1.1034 (0.9478)\tD(fake) 0.0739 (0.0456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2082 (-0.2301)\n",
            "Epoch: [11][ 90/195]\tTime  0.151 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9626 (0.9463)\tD(fake) 0.1491 (0.0458)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1938 (-0.2286)\n",
            "Epoch: [11][100/195]\tTime  0.157 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9605 (0.9456)\tD(fake) 0.1222 (0.0445)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2531 (-0.2301)\n",
            "Epoch: [11][110/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0263 (0.9460)\tD(fake) 0.0408 (0.0452)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1148 (-0.2211)\n",
            "Epoch: [11][120/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9384 (0.9462)\tD(fake) 0.1427 (0.0451)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1990 (-0.2183)\n",
            "Epoch: [11][130/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9409 (0.9465)\tD(fake) 0.0156 (0.0440)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0834 (-0.2119)\n",
            "Epoch: [11][140/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0696 (0.9470)\tD(fake) 0.0279 (0.0445)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1479 (-0.2070)\n",
            "Epoch: [11][150/195]\tTime  0.151 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9192 (0.9465)\tD(fake) 0.1511 (0.0449)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1862 (-0.2100)\n",
            "Epoch: [11][160/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.002)\tD(real) 1.0071 (0.9466)\tD(fake) 0.0754 (0.0442)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2050 (-0.2098)\n",
            "Epoch: [11][170/195]\tTime  0.151 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9948 (0.9467)\tD(fake) 0.0060 (0.0443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0857 (-0.2041)\n",
            "Epoch: [11][180/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.7957 (0.9466)\tD(fake) 0.0786 (0.0441)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1329 (-0.1987)\n",
            "Epoch: [11][190/195]\tTime  0.149 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0304 (0.9476)\tD(fake) 0.0948 (0.0434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1331 (-0.1966)\n",
            "Epoch: [12][  0/195]\tTime  0.391 ( 0.391)\tData  0.194 ( 0.194)\tD(real) 0.9633 (0.9633)\tD(fake) 0.0117 (0.0117)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [12][ 10/195]\tTime  0.148 ( 0.185)\tData  0.000 ( 0.018)\tD(real) 0.8962 (0.9410)\tD(fake) 0.0874 (0.0183)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1534)\n",
            "Epoch: [12][ 20/195]\tTime  0.151 ( 0.182)\tData  0.000 ( 0.010)\tD(real) 0.9345 (0.9458)\tD(fake) 0.0074 (0.0378)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1863 (-0.1465)\n",
            "Epoch: [12][ 30/195]\tTime  0.151 ( 0.181)\tData  0.000 ( 0.007)\tD(real) 0.8661 (0.9478)\tD(fake) 0.0841 (0.0380)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2335 (-0.1719)\n",
            "Epoch: [12][ 40/195]\tTime  0.148 ( 0.177)\tData  0.000 ( 0.005)\tD(real) 1.0691 (0.9523)\tD(fake) 0.0908 (0.0365)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2366 (-0.1827)\n",
            "Epoch: [12][ 50/195]\tTime  0.152 ( 0.178)\tData  0.000 ( 0.004)\tD(real) 1.0158 (0.9498)\tD(fake) 0.0574 (0.0388)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2129 (-0.1853)\n",
            "Epoch: [12][ 60/195]\tTime  0.150 ( 0.178)\tData  0.000 ( 0.003)\tD(real) 0.8549 (0.9495)\tD(fake) 0.0897 (0.0380)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2089 (-0.1844)\n",
            "Epoch: [12][ 70/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.8505 (0.9471)\tD(fake) 0.0115 (0.0385)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1537 (-0.1816)\n",
            "Epoch: [12][ 80/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.003)\tD(real) 0.9421 (0.9474)\tD(fake) 0.0192 (0.0424)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1866 (-0.1824)\n",
            "Epoch: [12][ 90/195]\tTime  0.150 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 0.9676 (0.9477)\tD(fake) 0.1821 (0.0449)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2431 (-0.1860)\n",
            "Epoch: [12][100/195]\tTime  0.160 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9104 (0.9464)\tD(fake) 0.0322 (0.0456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2106 (-0.1876)\n",
            "Epoch: [12][110/195]\tTime  0.146 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9760 (0.9467)\tD(fake) 0.0330 (0.0470)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2676 (-0.1934)\n",
            "Epoch: [12][120/195]\tTime  0.147 ( 0.177)\tData  0.000 ( 0.002)\tD(real) 1.0261 (0.9469)\tD(fake) 0.1939 (0.0482)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2310 (-0.1961)\n",
            "Epoch: [12][130/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 0.9930 (0.9465)\tD(fake) 0.0264 (0.0485)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1838 (-0.1955)\n",
            "Epoch: [12][140/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.1484 (0.9475)\tD(fake) 0.1484 (0.0488)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1825 (-0.1960)\n",
            "Epoch: [12][150/195]\tTime  0.149 ( 0.176)\tData  0.000 ( 0.002)\tD(real) 1.0045 (0.9462)\tD(fake) 0.1537 (0.0505)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2651 (-0.2008)\n",
            "Epoch: [12][160/195]\tTime  0.147 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0435 (0.9464)\tD(fake) 0.0741 (0.0510)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1995)\n",
            "Epoch: [12][170/195]\tTime  0.148 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 1.0488 (0.9460)\tD(fake) 0.0778 (0.0512)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1382 (-0.1987)\n",
            "Epoch: [12][180/195]\tTime  0.150 ( 0.176)\tData  0.000 ( 0.001)\tD(real) 0.9526 (0.9459)\tD(fake) 0.1284 (0.0514)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2192 (-0.1996)\n",
            "Epoch: [12][190/195]\tTime  0.148 ( 0.175)\tData  0.000 ( 0.001)\tD(real) 1.0559 (0.9463)\tD(fake) 0.0660 (0.0512)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2671 (-0.2018)\n",
            "Epoch: [13][  0/195]\tTime  0.370 ( 0.370)\tData  0.194 ( 0.194)\tD(real) 0.8785 (0.8785)\tD(fake) -0.0302 (-0.0302)\tgrad(D) 0.0000 (0.0000)\trepr loss 0.0000 (0.0000)\n",
            "Epoch: [13][ 10/195]\tTime  0.150 ( 0.185)\tData  0.000 ( 0.018)\tD(real) 1.0135 (0.9486)\tD(fake) 0.0963 (0.0423)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.2514 (-0.2514)\n",
            "Epoch: [13][ 20/195]\tTime  0.150 ( 0.183)\tData  0.000 ( 0.010)\tD(real) 0.8978 (0.9394)\tD(fake) 0.0622 (0.0582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1923 (-0.2496)\n",
            "Epoch: [13][ 30/195]\tTime  0.151 ( 0.182)\tData  0.000 ( 0.007)\tD(real) 0.9295 (0.9397)\tD(fake) 0.1238 (0.0684)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1843 (-0.2378)\n",
            "Epoch: [13][ 40/195]\tTime  0.152 ( 0.178)\tData  0.000 ( 0.005)\tD(real) 0.8447 (0.9405)\tD(fake) -0.0100 (0.0637)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.2260)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-p4wAlbftUb"
      },
      "source": [
        "run(15)\n",
        "save_vid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUGjJ-6Pf3xE"
      },
      "source": [
        "run(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhsj8_owgDSl"
      },
      "source": [
        "run(15)\n",
        "save_vid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxlmBIutPfw"
      },
      "source": [
        "args.repr_consistency = 0.1\n",
        "run(30)\n",
        "save_vid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iepY_Go7tf7Y"
      },
      "source": [
        "run(30)\n",
        "save_vid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5V-0_k5tpiW"
      },
      "source": [
        "run(30)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdIo707ZyUic"
      },
      "source": [
        "run(30)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMSlrEvie7Pa"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvYdbtKQe_2-"
      },
      "source": [
        "%matplotlib inline\n",
        "x, _ = next(iter(train_loader))\n",
        "show_sample(x, show_x=True)\n",
        "show_sample(x)\n",
        "show_sample(x)\n",
        "show_sample(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gfx3T5m2wah"
      },
      "source": [
        "save_vid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5P0BestcMER"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}