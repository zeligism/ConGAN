{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConsistentGAN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce15db1308cf4137a2651c8dfe89f3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8703519d345d4810b176a58f12e00af3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9442ab6eda044d92a55b12aadd92a654",
              "IPY_MODEL_2444b40302af4c889a2ae77e7c01a3b3",
              "IPY_MODEL_5b87e2d7c84e41d390d9b563c688a7b7"
            ]
          }
        },
        "8703519d345d4810b176a58f12e00af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9442ab6eda044d92a55b12aadd92a654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28ea9c3081944102a13d7b6d3857eeb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d822e29f9bde48b69ed5d7190fb60cef"
          }
        },
        "2444b40302af4c889a2ae77e7c01a3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecef038dece54a0ab78ad42ac9512dea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b8dbe767bb9460bba2e7b209d16fdf8"
          }
        },
        "5b87e2d7c84e41d390d9b563c688a7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a11c43e1ef24e8a9a6bbbac57f00baa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [01:07&lt;00:00, 67.24s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68328d286f264b8a9af2596a229ddb0a"
          }
        },
        "28ea9c3081944102a13d7b6d3857eeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d822e29f9bde48b69ed5d7190fb60cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecef038dece54a0ab78ad42ac9512dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b8dbe767bb9460bba2e7b209d16fdf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a11c43e1ef24e8a9a6bbbac57f00baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68328d286f264b8a9af2596a229ddb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d80138f64466454e9e4b082a2ca9ae2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2435793fc4104ff28dd4f7331d190de7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1670c2b447a4f4aa3a90cf43063099c",
              "IPY_MODEL_57845f65f9ed4616a94a8705c24a5633",
              "IPY_MODEL_c2a0baa293da4d80882a040cc2213d05"
            ]
          }
        },
        "2435793fc4104ff28dd4f7331d190de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1670c2b447a4f4aa3a90cf43063099c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94b490b78049466e9841e8d19375bab3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81ec79b2732541c68192101ea5ed93c5"
          }
        },
        "57845f65f9ed4616a94a8705c24a5633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe4dc33999b2426cb90c315f0132315f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 781,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 79,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27db98ab6d5540b98eacbc5533566cee"
          }
        },
        "c2a0baa293da4d80882a040cc2213d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e40ed04938fd43c4806e148878ebd31b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 79/781 [01:07&lt;09:55,  1.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_168e2b0a3f9846aaa4da5fa989d4ee43"
          }
        },
        "94b490b78049466e9841e8d19375bab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81ec79b2732541c68192101ea5ed93c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe4dc33999b2426cb90c315f0132315f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27db98ab6d5540b98eacbc5533566cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e40ed04938fd43c4806e148878ebd31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "168e2b0a3f9846aaa4da5fa989d4ee43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/ConGAN/blob/main/ConsistentGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxx3Jy_8qsPE"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFx20xTNkpQ",
        "outputId": "d15b4218-cfdd-41ab-96fb-3601a17bae19"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QNzdq01hSb"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlF68ff2K8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_Qrpq7z3iJ"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import log2\n",
        "from pprint import pformat\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDduLe1Qkd9"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRxrufxw1cm"
      },
      "source": [
        "### Report Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmEyNG58w2kJ"
      },
      "source": [
        "def plot_lines(losses_dict, filename=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots the losses of the discriminator and the generator.\n",
        "\n",
        "    Args:\n",
        "        filename: The plot's filename. If None, plot won't be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(title)\n",
        "    for label, losses in losses_dict.items():\n",
        "        plt.plot(losses, label=label)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.legend()\n",
        "    \n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def create_progress_animation(frames, filename):\n",
        "    \"\"\"\n",
        "    Creates a video of the progress of the generator on a fixed latent vector.\n",
        "\n",
        "    Args:\n",
        "        filename: The animation's filename.\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    ims = [[plt.imshow(img.permute(1,2,0), animated=True)]\n",
        "           for img in frames]\n",
        "    ani = animation.ArtistAnimation(fig, ims, blit=True)\n",
        "    \n",
        "    ani.save(filename)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def generate_grid(generator, latent):\n",
        "    \"\"\"\n",
        "    Check generator's output on latent vectors and return it.\n",
        "\n",
        "    Args:\n",
        "        generator: The generator.\n",
        "        latent: Latent vector from which an image grid will be generated.\n",
        "\n",
        "    Returns:\n",
        "        A grid of images generated by `generator` from `latent`.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(latent).detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(fake.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzwGurc1qOx"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhc2oS53G4e"
      },
      "source": [
        "## PyTorch Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU7HFc6t5N8w"
      },
      "source": [
        "### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHPo8w13JmH"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding half the size of features,\n",
        "    e.g. if input is [in_channels, 64, 64], output will be [out_channels, 32, 32].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.conv = nn.utils.parametrizations.spectral_norm(self.conv)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.LeakyReLU(0.2, inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding double the size of features,\n",
        "    e.g. if input is [in_channels, 32, 32], output will be [out_channels, 64, 64].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.convT = nn.utils.parametrizations.spectral_norm(self.convT)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.ReLU(inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convT(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=16,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,\n",
        "                 D_block=ConvBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        using_grad_penalty = gan_type in (\"gan-gp\", \"wgan-gp\")\n",
        "        output_sigmoid = output_sigmoid and gan_type in (\"gan\", \"gan-gp\")\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm and not using_grad_penalty,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Input layer\n",
        "        self.input_layer = D_block(image_channels, features[0], **block_config)\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            D_block(in_features, out_features, **block_config)\n",
        "            for in_features, out_features in zip(features, features[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer (feature_size = 3, 4, or 5 -> 1)\n",
        "        if fully_convolutional:\n",
        "            conv = nn.Conv2d(features[-1], num_latents, latent_kernel, bias=False)\n",
        "            if use_spectralnorm:\n",
        "                conv = nn.utils.parametrizations.spectral_norm(conv)\n",
        "            self.output_layer = nn.Sequential(conv, nn.Flatten())\n",
        "        else:\n",
        "            linear = nn.Linear(features[-1] * latent_kernel**2, num_latents, bias=False)\n",
        "            if use_spectralnorm:\n",
        "                linear = nn.utils.parametrizations.spectral_norm(linear)\n",
        "            self.output_layer = nn.Sequential(nn.Flatten(), linear)\n",
        "        \n",
        "        self.hidden_dim = features[-1] * latent_kernel**2\n",
        "\n",
        "        # Add sigmoid activation if using regular GAN loss\n",
        "        self.output_activation = nn.Sigmoid() if output_sigmoid else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        if self.output_activation:\n",
        "            x = self.output_activation(x)\n",
        "        # Remove H and W dimensions, infer channels dim (remove if 1)\n",
        "        x = x.view(x.size(0), -1).squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 G_block=ConvTBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Reverse order of image sizes and features for generator\n",
        "        image_sizes = image_sizes[::-1]\n",
        "        features = features[::-1]\n",
        "\n",
        "        # Input layer\n",
        "        if fully_convolutional:\n",
        "            self.input_layer = G_block(num_latents, features[0], kernel_size=latent_kernel,\n",
        "                                       stride=1, padding=0, **block_config)\n",
        "        else:\n",
        "            self.input_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(num_latents, features[0] * image_sizes[0]**2, bias=False),\n",
        "                View(features[0], image_sizes[0], image_sizes[0])\n",
        "            )\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            G_block(in_features, out_features, kernel_size=4+(expected_size%2), **block_config)\n",
        "            for in_features, out_features, expected_size in zip(features, features[1:], image_sizes[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.ConvTranspose2d(features[-1], image_channels, kernel_size=4+(image_size%2),\n",
        "                                               stride=2, padding=1, bias=False)\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add H and W dimensions, infer channels dim (add if none)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = self.output_activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    \"\"\"Deep Convolutional Generative Adversarial Network\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 D_num_features=64,\n",
        "                 G_num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,):\n",
        "        \"\"\"\n",
        "        Initializes DCGAN.\n",
        "\n",
        "        Args:\n",
        "            num_latents: Number of latent factors.\n",
        "            num_features: Number of features in the convolutions.\n",
        "            image_channels: Number of channels in the input image.\n",
        "            image_size: Size (i.e. height or width) of image.\n",
        "            gan_type: Type of GAN (e.g. \"gan\" or \"wgan-gp\").\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_latents = num_latents\n",
        "        self.D_num_features = D_num_features\n",
        "        self.G_num_features = G_num_features\n",
        "        self.image_channels = image_channels\n",
        "        self.image_size = image_size\n",
        "        self.feature_multiplier = feature_multiplier\n",
        "        self.gan_type = gan_type\n",
        "        self.fully_convolutional = fully_convolutional\n",
        "        self.activation = activation\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.use_spectralnorm = use_spectralnorm\n",
        "\n",
        "        D_params = {\n",
        "            \"num_latents\": 1,  # XXX\n",
        "            \"num_features\": D_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "            \"output_sigmoid\": output_sigmoid,\n",
        "        }\n",
        "        G_params = {\n",
        "            \"num_latents\": num_latents,\n",
        "            \"num_features\": G_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": True,\n",
        "            \"use_spectralnorm\": False,  # XXX\n",
        "        }\n",
        "\n",
        "        self.D = DCGAN_Discriminator(**D_params)\n",
        "        self.G = DCGAN_Generator(**G_params)\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape, including_batch=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.including_batch = including_batch\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.including_batch:\n",
        "            return x.view(*self.shape)\n",
        "        else:\n",
        "            return x.view(x.size(0), *self.shape)\n",
        "\n",
        "class ChannelNoise(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel noise injection module.\n",
        "    Adds a linearly transformed noise to a convolution layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, std=0.02):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise_size = [x.size()[0], 1, *x.size()[2:]]  # single channel\n",
        "        noise = self.std * torch.randn(noise_size).to(x)\n",
        "\n",
        "        return x + self.scale * noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSPvaklIYvwT"
      },
      "source": [
        "### Third-party modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9B8z4ZY4oX"
      },
      "source": [
        "#### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLNQ90KUY_Is"
      },
      "source": [
        "class ConditionalBatchNorm2d(nn.Module):\n",
        "  def __init__(self, num_features, repr_dim):\n",
        "    super().__init__()\n",
        "    self.num_features = num_features\n",
        "    self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
        "    self.embed = nn.Linear(repr_dim, num_features * 2)\n",
        "    self.embed.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
        "    self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    out = self.bn(x)\n",
        "    gamma, beta = self.embed(y).chunk(2, 1)\n",
        "    out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
        "    return out\n",
        "\n",
        "\n",
        "#https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class SNDCGAN_Generator(nn.Module):\n",
        "    def __init__(self, z_dim, image_size=32, num_features=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(z_dim, 8*num_features, 4, stride=1)\n",
        "        self.bn1 = ConditionalBatchNorm2d(8*num_features, repr_dim)\n",
        "        self.conv2 = nn.ConvTranspose2d(8*num_features, 4*num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn2 = ConditionalBatchNorm2d(4*num_features, repr_dim)\n",
        "        self.conv3 = nn.ConvTranspose2d(4*num_features, 2*num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn3 = ConditionalBatchNorm2d(2*num_features, repr_dim)\n",
        "        self.conv4 = nn.ConvTranspose2d(2*num_features, num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn4 = ConditionalBatchNorm2d(num_features, repr_dim)\n",
        "\n",
        "        if image_size == 64:\n",
        "            self.conv5 = nn.ConvTranspose2d(num_features, num_features//2, 4, stride=2, padding=(1,1))\n",
        "            self.bn5 = ConditionalBatchNorm2d(num_features//2, repr_dim)\n",
        "            self.final_conv = nn.ConvTranspose2d(num_features//2, channels, 3, stride=1, padding=(1,1))\n",
        "        else:\n",
        "            self.conv5 = None\n",
        "            self.bn5 = None\n",
        "            self.final_conv = nn.ConvTranspose2d(num_features, channels, 3, stride=1, padding=(1,1))\n",
        "\n",
        "        self.block_activation = nn.ReLU()\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, z, repr=None):\n",
        "        h = z.view(-1, self.z_dim, 1, 1)\n",
        "        h = self.block_activation(self.bn1(self.conv1(h), repr))\n",
        "        h = self.block_activation(self.bn2(self.conv2(h), repr))\n",
        "        h = self.block_activation(self.bn3(self.conv3(h), repr))\n",
        "        h = self.block_activation(self.bn4(self.conv4(h), repr))\n",
        "        if self.conv5 is not None:\n",
        "            h = self.block_activation(self.bn5(self.conv5(h), repr))\n",
        "        return self.output_activation(self.final_conv(h))\n",
        "\n",
        "class SNDCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self, image_size=32, num_features=64, channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(channels, num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(num_features, num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(num_features, 2*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(2*num_features, 2*num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(2*num_features, 4*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(4*num_features, 4*num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(4*num_features, 8*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "\n",
        "        if image_size == 64:\n",
        "            self.from64 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(8*num_features, 8*num_features, 3, stride=2, padding=(1,1))),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                spectral_norm(nn.Conv2d(8*num_features, 16*num_features, 3, stride=1, padding=(1,1))),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "            )\n",
        "            self.hidden_dim = 4*4 * 16*num_features\n",
        "        else:\n",
        "            self.from64 = None\n",
        "            self.hidden_dim = 4*4 * 8*num_features\n",
        "\n",
        "        self.fc = spectral_norm(nn.Linear(self.hidden_dim, 1))\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.main(x)\n",
        "        if self.from64 is not None:\n",
        "            h = self.from64(h)\n",
        "        h = h.flatten(start_dim=1)\n",
        "        out = self.fc(h).squeeze(1)\n",
        "        if return_h:\n",
        "            return out, h\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class SNDCGAN(nn.Module):\n",
        "    def __init__(self, num_latents, image_size=32,\n",
        "                 D_num_features=64, G_num_features=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNDCGAN_Discriminator(channels=channels,\n",
        "                                       image_size=image_size,\n",
        "                                       num_features=D_num_features)\n",
        "        self.G = SNDCGAN_Generator(num_latents, channels=channels,\n",
        "                                   image_size=image_size,\n",
        "                                   num_features=G_num_features,\n",
        "                                   repr_dim=repr_dim)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiu_Ri-XY6yy"
      },
      "source": [
        "#### ResNet GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjWBbXzdlSF"
      },
      "source": [
        "# https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model_resnet.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class ResBlockGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, repr_dim=None):\n",
        "        super(ResBlockGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            self.conv1,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            self.conv2\n",
        "            )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "class ResBlockGeneratorConditional(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, repr_dim=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.bn1 = ConditionalBatchNorm2d(in_channels, repr_dim)\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.bn2 = ConditionalBatchNorm2d(out_channels, repr_dim)\n",
        "\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x, repr):\n",
        "        h = F.relu(self.bn1(x, repr))\n",
        "        h = self.conv1(self.upsample(h))\n",
        "        h = F.relu(self.bn2(h, repr))\n",
        "        h = self.conv2(h)\n",
        "        return self.bypass(x) + h\n",
        "\n",
        "\n",
        "class ResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        if stride == 1:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2)\n",
        "                )\n",
        "        else:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "                )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "\n",
        "            self.bypass_conv = nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)\n",
        "            nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "            self.bypass = nn.Sequential(\n",
        "                spectral_norm(self.bypass_conv),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            )\n",
        "            # if in_channels == out_channels:\n",
        "            #     self.bypass = nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            # else:\n",
        "            #     self.bypass = nn.Sequential(\n",
        "            #         spectral_norm(nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)),\n",
        "            #         nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            #     )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "# special ResBlock just for the first layer of the discriminator\n",
        "class FirstResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(FirstResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        self.bypass_conv = nn.Conv2d(in_channels, out_channels, 1, 1, padding=0)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "        # we don't want to apply ReLU activation to raw image before convolution transformation.\n",
        "        self.model = nn.Sequential(\n",
        "            spectral_norm(self.conv1),\n",
        "            nn.ReLU(),\n",
        "            spectral_norm(self.conv2),\n",
        "            nn.AvgPool2d(2)\n",
        "            )\n",
        "        self.bypass = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            spectral_norm(self.bypass_conv),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "\n",
        "class SNResNetGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, num_features=128, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * num_features)\n",
        "        self.final = nn.Conv2d(num_features, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            nn.BatchNorm2d(num_features),\n",
        "            nn.ReLU(),\n",
        "            self.final,\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(self.dense(z).view(-1, self.num_features, 4, 4))\n",
        "\n",
        "class SNResNetGeneratorConditional(nn.Module):\n",
        "    def __init__(self, z_dim, num_features=128, image_size=32, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * num_features)\n",
        "        self.final = nn.Conv2d(num_features, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.block1 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        self.block2 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        self.block3 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        if image_size == 64:\n",
        "            self.block4 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        else:\n",
        "            self.block4 = None\n",
        "        self.bn = ConditionalBatchNorm2d(num_features, repr_dim)\n",
        "\n",
        "    def forward(self, z, repr):\n",
        "        h = self.dense(z).view(-1, self.num_features, 4, 4)\n",
        "        h = self.block1(h, repr)\n",
        "        h = self.block2(h, repr)\n",
        "        h = self.block3(h, repr)\n",
        "        if self.block4 is not None:\n",
        "            h = self.block4(h, repr)\n",
        "        h = F.relu(self.bn(h, repr))\n",
        "        out = F.tanh(self.final(h))\n",
        "        return out\n",
        "\n",
        "\n",
        "class SNResNetDiscriminator(nn.Module):\n",
        "    def __init__(self, num_features=128, image_size=32, channels=3):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.hidden_dim = num_features\n",
        "        if image_size == 64:\n",
        "            self.hidden_dim *= 4\n",
        "\n",
        "        self.model = [\n",
        "                FirstResBlockDiscriminator(channels, num_features, stride=2),\n",
        "                ResBlockDiscriminator(num_features, num_features, stride=2),\n",
        "                ResBlockDiscriminator(num_features, num_features),\n",
        "                ResBlockDiscriminator(num_features, num_features),\n",
        "        ]\n",
        "        if image_size == 64:\n",
        "            self.model += [ResBlockDiscriminator(num_features, num_features)]\n",
        "        self.model += [nn.ReLU(), nn.AvgPool2d(8)]\n",
        "        self.model = nn.Sequential(*self.model)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
        "        nn.init.xavier_uniform_(self.fc.weight.data, 1.)\n",
        "        self.fc = spectral_norm(self.fc)\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.model(x)\n",
        "        h = h.view(-1, self.hidden_dim)\n",
        "        if return_h:\n",
        "            return self.fc(h), h\n",
        "        else:\n",
        "            return self.fc(h)\n",
        "\n",
        "\n",
        "class SNResNetGAN(nn.Module):\n",
        "    def __init__(self, num_latents,\n",
        "                 D_num_features=128, G_num_features=128,\n",
        "                 image_size=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNResNetDiscriminator(num_features=D_num_features,\n",
        "                                       image_size=image_size,\n",
        "                                       channels=channels)\n",
        "        self.G = SNResNetGeneratorConditional(num_latents,\n",
        "                                              num_features=G_num_features,\n",
        "                                              image_size=image_size,\n",
        "                                              channels=channels,\n",
        "                                              repr_dim=repr_dim)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYujBEzC7EOO"
      },
      "source": [
        "#### SimSiam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YcNut27F-v"
      },
      "source": [
        "class SimSiam(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a SimSiam model.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 2048)\n",
        "        pred_dim: hidden dimension of the predictor (default: 512)\n",
        "        \"\"\"\n",
        "        super(SimSiam, self).__init__()\n",
        "\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEuurkcmLLd3"
      },
      "source": [
        "### Latent Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTlMYVgLN5E"
      },
      "source": [
        "class LatentTransform(nn.Module):\n",
        "    def __init__(self, repr_dim, latent_dim, hidden_dim, full_transform=True, noop=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.full_transform = full_transform\n",
        "        self.noop = noop\n",
        "\n",
        "        if self.noop:\n",
        "            self.output_dim = self.latent_dim\n",
        "            return\n",
        "        elif self.full_transform:\n",
        "            self.input_dim = self.repr_dim + self.latent_dim\n",
        "            self.output_dim = self.hidden_dim\n",
        "        else:\n",
        "            self.input_dim = self.repr_dim\n",
        "            self.output_dim = self.hidden_dim + self.latent_dim\n",
        "\n",
        "        self.transform = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "    \n",
        "    def forward(self, repr, noise):\n",
        "        if self.noop:\n",
        "            return noise\n",
        "\n",
        "        # assuming latent is concat as [repr,noise] XXX\n",
        "        if self.full_transform:\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "            latent = self.transform(latent)\n",
        "        else:\n",
        "            repr = self.transform(repr)\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "\n",
        "        return latent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRivPV9BwFk"
      },
      "source": [
        "# Training v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rpQp2E9rE5"
      },
      "source": [
        "### Imports and globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51zFNn509xLz"
      },
      "source": [
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "GANSIAM_DIR = \"/content/drive/My Drive/gansiam\"\n",
        "SIMSIAM_PATH = os.path.join(GANSIAM_DIR, \"pretrained_batch256.tar\")\n",
        "TINYIMAGENET_DIR = \"tiny-imagenet-200\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9X_JYE2Vwxd"
      },
      "source": [
        "### Download Tiny Imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "559H2an_V03M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976b7c3a-8692-4b40-ffd4-61930b194167"
      },
      "source": [
        "%%bash\n",
        "if [[ -d  \"tiny-imagenet-200\" ]]; then\n",
        "    echo \"Tiny Imagenet exists.\"\n",
        "else\n",
        "    wget -q \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "    unzip -qq \"tiny-imagenet-200.zip\" && rm \"tiny-imagenet-200.zip\"\n",
        "    echo \"Downloaded Tiny Imagenet.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Tiny Imagenet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbo7T6blPVTc"
      },
      "source": [
        "### Load pre-trained SimSiam model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyzHmINsryyh"
      },
      "source": [
        "#### SimSiam Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8KJUUeWr1dI"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "import random\n",
        "\n",
        "\n",
        "class TwoCropsTransform:\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        q = self.base_transform(x)\n",
        "        k = self.base_transform(x)\n",
        "        return [q, k]\n",
        "\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
        "\n",
        "    def __init__(self, sigma=[.1, 2.]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr8clgi_AzY",
        "outputId": "391cedd9-2d53-48ce-c112-8122cec4fbbf"
      },
      "source": [
        "checkpoint = torch.load(SIMSIAM_PATH, map_location=\"cuda:0\")\n",
        "# remove 'module.' from dict keys\n",
        "model_dict = OrderedDict((k[7:], v) for k, v in checkpoint[\"state_dict\"].items())\n",
        "\n",
        "# Load model\n",
        "simsiam = SimSiam(models.__dict__[\"resnet50\"])\n",
        "simsiam.load_state_dict(model_dict)\n",
        "#print(simsiam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckB_xSVX8kB"
      },
      "source": [
        "# Training v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nouxldrYb0r"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUP5vn8OX--p"
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.load = True\n",
        "        self.print_freq = 10\n",
        "        self.seed = None\n",
        "        self.gpu = 0\n",
        "        self.workers = 2\n",
        "        self.epochs = 100\n",
        "\n",
        "        ### lr is about 2e-4 for batch size of 64\n",
        "        # we scale according to our choice of batch size\n",
        "        self.batch_size = 128\n",
        "        self.D_lr = 1e-3 * (self.batch_size / 256)\n",
        "        self.G_lr = 1e-3 * (self.batch_size / 256)\n",
        "        self.Q_lr = self.D_lr\n",
        "        self.latent_transform_lr = self.G_lr\n",
        "        self.lr_decay = 0.02\n",
        "        #self.betas = (0.5, 0.999)\n",
        "        self.betas = (0., 0.9)\n",
        "\n",
        "        # SimSiam (_don't change_ if loading pre-trained)\n",
        "        self.dim = 2048\n",
        "        self.pred_dim = 512\n",
        "\n",
        "        # GAN\n",
        "        self.repr_dim = self.dim  # don't change\n",
        "        self.latent_full_transform = False\n",
        "        self.latent_noise_dim = 512\n",
        "        self.latent_hidden_dim = 512  # dim of transform output\n",
        "        self.Q_hidden_dim = 512\n",
        "        self.num_features = 64\n",
        "        self.D_iters = 5\n",
        "\n",
        "        self.gan_type = \"gan\"  # ignore this\n",
        "        self.resnetgan = True  # overrides wgan when True\n",
        "        self.wgan = False  # if False, use spectral norm\n",
        "        self.grad_penalty = 0.  # 0 if wgan is False\n",
        "        self.grad_center = 1.  # not important\n",
        "\n",
        "        self.generate_grid_interval = 50\n",
        "\n",
        "        # make noise proportional to sd(data)\n",
        "        self.im_noise = 1e-2  # image sd is about 1.0\n",
        "        self.repr_noise = 1e-5  # repr sd is about 1e-3\n",
        "\n",
        "        # Start small, increase later\n",
        "        self.G_consistency = 1.\n",
        "        self.D_consistency = 1.\n",
        "\n",
        "\n",
        "GENERATED_GRIDS = []\n",
        "IMAGE_SIZE = 64\n",
        "DATASET = \"Tiny ImageNet\"\n",
        "#DATASET = \"CIFAR10\"\n",
        "args = Args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xihRlU0PYhiJ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW_P-JfeYiOe"
      },
      "source": [
        "# image normalization\n",
        "mean = [0.5]\n",
        "std = [0.5]\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "inv_normalize = transforms.Normalize(\n",
        "   mean= [-m/s for m, s in zip(mean, std)],\n",
        "   std= [1/s for s in std]\n",
        ")\n",
        "\n",
        "augmentation = [\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "# MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "_augmentation = [\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.2, 1.)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "if DATASET == \"MNIST\":\n",
        "    augmentation = [transforms.Grayscale(3)] + augmentation\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=os.path.join(GANSIAM_DIR, \"mnist/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CelebA\":\n",
        "    train_dataset = datasets.CelebA(\n",
        "        root=os.path.join(GANSIAM_DIR, \"celeba\"), download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CIFAR10\":\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=os.path.join(GANSIAM_DIR, \"cifar10/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "        #transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "elif DATASET == \"Tiny ImageNet\":\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "        transform=transforms.Compose(augmentation))\n",
        "else:\n",
        "    raise Exception(f\"Dataset '{DATASET}' not found\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=args.workers, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQ0_BfjmAHf"
      },
      "source": [
        "### Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLiHFvBimb3"
      },
      "source": [
        "def D_criterion_NS(D_real, D_fake):\n",
        "    d_loss = F.softplus(-D_real) + F.softplus(D_fake)\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_NS(D_fake):\n",
        "    return F.softplus(-D_fake).mean()\n",
        "\n",
        "def D_criterion_LS(D_real, D_fake):\n",
        "    d_loss = 0.5 * (D_real - torch.ones_like(D_real))**2 + 0.5 * (D_fake)**2\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_LS(D_fake):\n",
        "    gen_loss = 0.5 * (D_fake - torch.ones_like(D_fake))**2\n",
        "    return gen_loss.mean()\n",
        "\n",
        "def D_criterion_hinge(D_real, D_fake):\n",
        "    return torch.mean(F.relu(1. - D_real)) + torch.mean(F.relu(1. + D_fake))\n",
        "\n",
        "def G_criterion_hinge(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def D_criterion_wasserstein(D_real, D_fake):\n",
        "    return torch.mean(D_fake - D_real)\n",
        "\n",
        "def G_criterion_wasserstein(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def interpolate(real, fake, eps=None):\n",
        "    if eps is None:\n",
        "        eps_size = [1] * len(real.size())\n",
        "        eps_size[0] = real.size(0)\n",
        "        eps = torch.rand(eps_size).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "    \n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_x, x, torch.ones_like(D_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n",
        "\n",
        "def lerp(x1, x2, t=None):\n",
        "    return interpolate(x1, x2, t)\n",
        "\n",
        "def slerp(x1, x2, t=None):\n",
        "    if t is None:\n",
        "        t = torch.rand(x1.size(0)).to(x1)\n",
        "    # assuming normalized x and x2\n",
        "    omega = torch.acos((x1*x2).sum(1))\n",
        "    so = torch.sin(omega)\n",
        "    res = (torch.sin((1.-t)*omega) / so).unsqueeze(1) * x1 \\\n",
        "        + (torch.sin(t*omega) / so).unsqueeze(1) * x2\n",
        "    return res\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Z4Ke6DYkDg"
      },
      "source": [
        "## Model + Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rO_MvGzYldx",
        "outputId": "6b33989f-d173-4e60-81de-a689108461dd"
      },
      "source": [
        "if args.seed is not None:\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.set_device(args.gpu)\n",
        "\n",
        "latent_transform = LatentTransform(repr_dim=args.repr_dim,\n",
        "                                   latent_dim=args.latent_noise_dim,\n",
        "                                   hidden_dim=args.latent_hidden_dim,\n",
        "                                   full_transform=args.latent_full_transform,\n",
        "                                   )\n",
        "\n",
        "model = DCGAN(num_latents=latent_transform.output_dim,\n",
        "              image_size=IMAGE_SIZE,\n",
        "              gan_type=args.gan_type,  # doesn't make a difference\n",
        "              D_num_features=args.num_features,\n",
        "              G_num_features=args.num_features,\n",
        "              use_batchnorm=False,  # for D only\n",
        "              output_sigmoid=False,  # for D only\n",
        "              use_spectralnorm=not args.wgan,  # for spectral norm, use the below model\n",
        "              )\n",
        "\n",
        "\n",
        "if not args.wgan:\n",
        "    model = SNDCGAN(num_latents=latent_transform.output_dim,\n",
        "                    image_size=IMAGE_SIZE,\n",
        "                    D_num_features=args.num_features//(IMAGE_SIZE//32),\n",
        "                    G_num_features=args.num_features,\n",
        "                    repr_dim=args.repr_dim)\n",
        "if args.resnetgan:\n",
        "    model = SNResNetGAN(num_latents=latent_transform.output_dim,\n",
        "                        image_size=IMAGE_SIZE,\n",
        "                        D_num_features=args.num_features*2,\n",
        "                        G_num_features=args.num_features*2,\n",
        "                        repr_dim=args.repr_dim)\n",
        "\n",
        "Q_hidden_dim = args.Q_hidden_dim\n",
        "Q = nn.Sequential(nn.Linear(model.D.hidden_dim, Q_hidden_dim, bias=False),\n",
        "                    nn.Linear(Q_hidden_dim, args.repr_dim))\n",
        "\n",
        "model = model.cuda(args.gpu)\n",
        "Q = Q.cuda(args.gpu)\n",
        "latent_transform = latent_transform.cuda(args.gpu)\n",
        "simsiam = simsiam.cuda(args.gpu)\n",
        "\n",
        "print(\"Num of params in D:\", sum(map(torch.numel, model.D.parameters())))\n",
        "print(\"Num of params in G:\", sum(map(torch.numel, model.G.parameters())))\n",
        "print(\"Num of params in Q:\", sum(map(torch.numel, Q.parameters())))\n",
        "print(\"Num of params in L:\", sum(map(torch.numel, latent_transform.parameters())))\n",
        "\n",
        "# Define D and G loss functions\n",
        "D_criterion = D_criterion_hinge\n",
        "G_criterion = G_criterion_hinge\n",
        "\n",
        "# Optimizers\n",
        "G_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.G.parameters()},\n",
        "     {\"params\": latent_transform.parameters(), \"lr\": args.latent_transform_lr}],\n",
        "     args.G_lr, betas=args.betas)\n",
        "D_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.D.parameters(), \"lr\": args.D_lr},\n",
        "     {\"params\": Q.parameters(), \"lr\": args.Q_lr}],\n",
        "     args.Q_lr, betas=args.betas)\n",
        "\n",
        "D_sched = torch.optim.lr_scheduler.ExponentialLR(D_optimizer, 1. - args.lr_decay)\n",
        "G_sched = torch.optim.lr_scheduler.ExponentialLR(G_optimizer, 1. - args.lr_decay)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if args.load:\n",
        "    print(\"Loading...\")\n",
        "    model.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/model.pth.tar\")[\"state_dict\"])\n",
        "    latent_transform.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")[\"state_dict\"])\n",
        "    Q.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/Q.pth.tar\")[\"state_dict\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of params in D: 1349377\n",
            "Num of params in G: 8004227\n",
            "Num of params in Q: 1312768\n",
            "Num of params in L: 1049088\n",
            "Loading...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTqwby4cX0i",
        "outputId": "c191fa65-cb94-4486-9e56-5ede9039c46a"
      },
      "source": [
        "print(model)\n",
        "print(Q)\n",
        "print(latent_transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SNResNetGAN(\n",
            "  (D): SNResNetDiscriminator(\n",
            "    (model): Sequential(\n",
            "      (0): FirstResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass_conv): ParametrizedConv2d(\n",
            "          3, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ParametrizedConv2d(\n",
            "            3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1): ReLU()\n",
            "          (2): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): ParametrizedConv2d(\n",
            "            3, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass): Sequential(\n",
            "          (0): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass_conv): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (3): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (4): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (5): ReLU()\n",
            "      (6): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "    )\n",
            "    (fc): ParametrizedLinear(\n",
            "      in_features=512, out_features=1, bias=True\n",
            "      (parametrizations): ModuleDict(\n",
            "        (weight): ParametrizationList(\n",
            "          (0): _SpectralNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (G): SNResNetGeneratorConditional(\n",
            "    (dense): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "    (final): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (block1): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block2): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block3): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block4): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (bn): ConditionalBatchNorm2d(\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=512, out_features=512, bias=False)\n",
            "  (1): Linear(in_features=512, out_features=2048, bias=True)\n",
            ")\n",
            "LatentTransform(\n",
            "  (transform): Linear(in_features=2048, out_features=512, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeDicP6QZNQ2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj9x-2fNtnp"
      },
      "source": [
        "def sample_noise(num_samples):\n",
        "    return torch.randn(num_samples, args.latent_noise_dim)\n",
        "\n",
        "def get_repr(img):\n",
        "    with torch.no_grad():\n",
        "        repr = simsiam.encoder(img)\n",
        "        repr = repr + args.repr_noise * torch.randn_like(repr)\n",
        "    return repr\n",
        "\n",
        "def sample_G(repr):\n",
        "    noise = sample_noise(repr.size(0)).cuda(args.gpu)\n",
        "    z = latent_transform(repr, noise)\n",
        "    fake = model.G(z, repr)\n",
        "    fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "    return fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEVERm6alJt6"
      },
      "source": [
        "# Sample a global latent for reuse\n",
        "fixed_x, _ = next(iter(train_loader))\n",
        "fixed_x = fixed_x[:32].cuda(args.gpu)\n",
        "fixed_repr = get_repr(fixed_x)\n",
        "fixed_noise = sample_noise(32).cuda(args.gpu)\n",
        "\n",
        "def check_G_progress(G):\n",
        "    with torch.no_grad():\n",
        "        z = latent_transform(fixed_repr, fixed_noise)\n",
        "        fake_progress = G(z, fixed_repr)\n",
        "    im_grid = torch.cat([fixed_x, fake_progress], dim=0)\n",
        "    grid = vutils.make_grid(im_grid.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "    return grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7gU4I8OZOer"
      },
      "source": [
        "def train(train_loader, model, simsiam,\n",
        "          D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    D_on_reals = AverageMeter('D(real)', ':.4f')\n",
        "    D_on_fakes1 = AverageMeter('D(fake)1', ':.4f')\n",
        "    D_on_fakes2 = AverageMeter('D(fake)2', ':.4f')\n",
        "    D_grads = AverageMeter('grad(D)', ':.4f')\n",
        "    G_repr_losses = AverageMeter('G repr loss', ':.4f')\n",
        "    D_repr_losses = AverageMeter('D repr loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time,\n",
        "         D_on_reals, D_on_fakes1, D_on_fakes2, D_grads, G_repr_losses, D_repr_losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    \n",
        "    # Create dataset sampler\n",
        "    data_iter = iter(enumerate(train_loader))\n",
        "    batch_idx = [0]  # just an ugly hack\n",
        "    def sample_data():\n",
        "        i, (x, y) = next(data_iter)\n",
        "        batch_idx[0] = i\n",
        "        x = x.cuda(args.gpu, non_blocking=True)\n",
        "        real = x + args.im_noise * torch.randn_like(x)\n",
        "        return real\n",
        "    \n",
        "    def sample_repr():\n",
        "        # (1) Sample a random representation from a prior distribution\n",
        "        #repr = 1e-2*torch.rand(args.batch_size, args.repr_dim).cuda(args.gpu)\n",
        "        #repr = torch.randn(args.batch_size, args.repr_dim).cuda(args.gpu)\n",
        "\n",
        "        # (2) Sample a real represenation (best so far)\n",
        "        repr = get_repr(sample_data())\n",
        "\n",
        "        # (3) Sample an interpolated represenation\n",
        "        \"\"\"\n",
        "        real1, real2 = sample_data(), sample_data()\n",
        "        repr1, repr2 = get_repr(real1), get_repr(real2)\n",
        "        repr = lerp(repr1, repr2)\n",
        "        #repr = slerp(repr1, repr2)\n",
        "        \"\"\"\n",
        "        \n",
        "        return repr\n",
        "\n",
        "    end = time.time()\n",
        "    # Train until data_iter is exhausted\n",
        "    try:\n",
        "        i = -1\n",
        "        while True:\n",
        "            i += 1\n",
        "            # measure data loading time\n",
        "            data_time.update(time.time() - end)\n",
        "\n",
        "            ### Train generator\n",
        "            # Sample data and get representation\n",
        "            repr = sample_repr()\n",
        "            # Sample from generator given repr\n",
        "            fake = sample_G(repr)\n",
        "            # Classify fake data\n",
        "            D_fake, h_fake = model.D(fake, return_h=True)\n",
        "            # Calculate adversarial loss\n",
        "            G_loss = G_criterion(D_fake)\n",
        "            # Calculate consistency loss\n",
        "            if args.G_consistency != 0.:\n",
        "                fake_repr = simsiam.encoder(fake)\n",
        "                G_repr_loss = -F.cosine_similarity(fake_repr, repr).mean()\n",
        "                G_repr_losses.update(G_repr_loss.mean().item(), args.batch_size)\n",
        "                G_loss = G_loss + args.G_consistency * G_repr_loss\n",
        "            if args.D_consistency != 0.:\n",
        "                D_repr_loss = -F.cosine_similarity(Q(h_fake), repr).mean()\n",
        "                D_repr_losses.update(D_repr_loss.mean().item(), args.batch_size)\n",
        "                G_loss = G_loss + args.D_consistency * D_repr_loss\n",
        "            # Calculate gradient and minimize\n",
        "            G_optimizer.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_optimizer.step()\n",
        "            # Update average\n",
        "            D_on_fakes1.update(D_fake.mean().item(), args.batch_size)\n",
        "\n",
        "            ### Train discriminator\n",
        "            for _ in range(args.D_iters):\n",
        "                # Sample data and get representation\n",
        "                real = sample_data()\n",
        "                repr = sample_repr()\n",
        "                # Sample from generator given repr\n",
        "                with torch.no_grad():\n",
        "                    fake = sample_G(repr)\n",
        "                # Classify real and fake data\n",
        "                D_real, h_real = model.D(real, return_h=True)\n",
        "                D_fake, h_fake = model.D(fake, return_h=True)\n",
        "                # Calculate loss\n",
        "                D_loss = D_criterion(D_real, D_fake)\n",
        "                # Gradient penalty\n",
        "                if args.grad_penalty != 0.:\n",
        "                    D_grad_penalty = simple_gradient_penalty(\n",
        "                        model.D, interpolate(real, fake), center=args.grad_center)\n",
        "                    D_loss = D_loss + args.grad_penalty * D_grad_penalty\n",
        "                    D_grads.update(D_grad_penalty.mean().item(), args.batch_size)\n",
        "                # Calculate consistency loss\n",
        "                if args.D_consistency != 0.:\n",
        "                    real_repr = simsiam.encoder(real)\n",
        "                    D_repr_loss_real = -F.cosine_similarity(Q(h_real), real_repr).mean()\n",
        "                    D_repr_loss_fake = -F.cosine_similarity(Q(h_fake), repr).mean()\n",
        "                    D_repr_loss = 0.5 * (D_repr_loss_real + D_repr_loss_fake)\n",
        "                    D_repr_losses.update(D_repr_loss.mean().item(), args.batch_size)\n",
        "                    D_loss = D_loss + args.D_consistency * D_repr_loss\n",
        "                # Calculate gradient and minimize\n",
        "                D_optimizer.zero_grad()\n",
        "                D_loss.backward()\n",
        "                D_optimizer.step()\n",
        "                # Update average\n",
        "                D_on_reals.update(D_real.mean().item(), args.batch_size)\n",
        "                D_on_fakes2.update(D_fake.mean().item(), args.batch_size)\n",
        "\n",
        "            # Check generator's progress by recording its output on a fixed input\n",
        "            if i % args.generate_grid_interval == 0:\n",
        "                grid = check_G_progress(model.G)\n",
        "                GENERATED_GRIDS.append(grid)\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.display(batch_idx[0])\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "    \n",
        "    except StopIteration:\n",
        "        progress.display(batch_idx[0])\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24ES94Re55W"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDMPwe-ae6q-"
      },
      "source": [
        "def save():\n",
        "    torch.save({'state_dict': model.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/model.pth.tar\")\n",
        "    torch.save({'state_dict': latent_transform.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")\n",
        "    torch.save({'state_dict': Q.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/Q.pth.tar\")\n",
        "\n",
        "def save_vid():\n",
        "    vidname = f\"grids_per_{args.generate_grid_interval}_iters.mp4\"\n",
        "    vidname = os.path.join(GANSIAM_DIR, \"results\", \"progress\", vidname)\n",
        "    create_progress_animation(GENERATED_GRIDS, vidname)\n",
        "\n",
        "def run(epochs):\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, simsiam,\n",
        "            D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\n",
        "        D_sched.step()\n",
        "        G_sched.step()\n",
        "\n",
        "        # Check G's progress evey epoch by generating an image\n",
        "        grid = check_G_progress(model.G)\n",
        "        imname = f'{GANSIAM_DIR}/results/progress/grid_{epoch:04d}.png'\n",
        "        plt.imsave(imname, grid.permute(1,2,0).numpy())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            save()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qjya-BRT_cJ"
      },
      "source": [
        "epochs_per_cell = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNNZfXWe5Rr",
        "outputId": "4910d019-b377-452d-b7fe-8dc4eb25171c"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.9214 (0.5884)\tD(fake)1 -0.6305 (-0.6305)\tD(fake)2 -1.3782 (-0.5423)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5117 (-0.5117)\tD repr loss -0.4199 (-0.4486)\n",
            "Epoch: [0][120/781]\tTime  2.500 ( 2.532)\tData  0.000 ( 0.000)\tD(real) -0.0724 (0.4182)\tD(fake)1 -1.0012 (-0.5836)\tD(fake)2 -0.9563 (-0.4552)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5470 (-0.5448)\tD repr loss -0.4955 (-0.4927)\n",
            "Epoch: [0][230/781]\tTime  2.487 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 0.1449 (0.3843)\tD(fake)1 -1.4193 (-0.4382)\tD(fake)2 -0.6095 (-0.4084)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4894 (-0.5393)\tD repr loss -0.4671 (-0.4811)\n",
            "Epoch: [0][340/781]\tTime  2.533 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.4442 (0.3724)\tD(fake)1 0.6592 (-0.3680)\tD(fake)2 -0.4093 (-0.4020)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5399 (-0.5355)\tD repr loss -0.5127 (-0.4844)\n",
            "Epoch: [0][450/781]\tTime  2.513 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.1844 (0.3613)\tD(fake)1 0.2272 (-0.4720)\tD(fake)2 0.2527 (-0.4103)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4783 (-0.5334)\tD repr loss -0.4686 (-0.4845)\n",
            "Epoch: [0][560/781]\tTime  2.558 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 1.9251 (0.3702)\tD(fake)1 -0.3201 (-0.5074)\tD(fake)2 0.7332 (-0.4163)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5483 (-0.5372)\tD repr loss -0.4978 (-0.4870)\n",
            "Epoch: [0][670/781]\tTime  2.538 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.8068 (0.3762)\tD(fake)1 -0.2747 (-0.6031)\tD(fake)2 0.3970 (-0.4294)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5738 (-0.5244)\tD repr loss -0.4771 (-0.4869)\n",
            "Epoch: [0][780/781]\tTime  2.487 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 0.7731 (0.3764)\tD(fake)1 0.1649 (-0.5755)\tD(fake)2 -0.4316 (-0.4348)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5006 (-0.5284)\tD repr loss -0.4807 (-0.4889)\n",
            "Epoch: [0][780/781]\tTime  2.467 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 0.7731 (0.3764)\tD(fake)1 0.1649 (-0.5755)\tD(fake)2 -0.4316 (-0.4348)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5006 (-0.5284)\tD repr loss -0.4807 (-0.4889)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.0755 (0.4594)\tD(fake)1 -0.7667 (-0.7667)\tD(fake)2 0.0028 (-0.5249)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4810 (-0.4810)\tD repr loss -0.4508 (-0.4931)\n",
            "Epoch: [1][120/781]\tTime  2.534 ( 2.521)\tData  0.000 ( 0.000)\tD(real) 0.5436 (0.4692)\tD(fake)1 0.3834 (-0.5130)\tD(fake)2 -0.3858 (-0.4694)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5467 (-0.5344)\tD repr loss -0.5275 (-0.4785)\n",
            "Epoch: [1][230/781]\tTime  2.505 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 1.7880 (0.4719)\tD(fake)1 -0.0441 (-0.5226)\tD(fake)2 0.3636 (-0.4486)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5300 (-0.5378)\tD repr loss -0.3018 (-0.4859)\n",
            "Epoch: [1][340/781]\tTime  2.515 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.9297 (0.4725)\tD(fake)1 0.1878 (-0.5406)\tD(fake)2 -1.0350 (-0.4661)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6076 (-0.5446)\tD repr loss -0.2627 (-0.4922)\n",
            "Epoch: [1][450/781]\tTime  2.517 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 3.0344 (0.5013)\tD(fake)1 -0.4123 (-0.4510)\tD(fake)2 1.9463 (-0.4405)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4226 (-0.5388)\tD repr loss -0.4860 (-0.4898)\n",
            "Epoch: [1][560/781]\tTime  2.449 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.4855 (0.4982)\tD(fake)1 -0.0296 (-0.4077)\tD(fake)2 0.3274 (-0.4389)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5819 (-0.5401)\tD repr loss -0.4824 (-0.4932)\n",
            "Epoch: [1][670/781]\tTime  2.474 ( 2.507)\tData  0.000 ( 0.000)\tD(real) -0.3850 (0.4941)\tD(fake)1 -1.2546 (-0.4308)\tD(fake)2 -1.2726 (-0.4467)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5955 (-0.5386)\tD repr loss -0.4867 (-0.4960)\n",
            "Epoch: [1][780/781]\tTime  2.530 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.7080 (0.5006)\tD(fake)1 0.0771 (-0.4367)\tD(fake)2 -0.4873 (-0.4464)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6295 (-0.5354)\tD repr loss -0.4811 (-0.4966)\n",
            "Epoch: [1][780/781]\tTime  2.462 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.7080 (0.5006)\tD(fake)1 0.0771 (-0.4367)\tD(fake)2 -0.4873 (-0.4464)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6295 (-0.5354)\tD repr loss -0.4811 (-0.4966)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.2390 (0.5171)\tD(fake)1 -0.4676 (-0.4676)\tD(fake)2 -0.1017 (-0.4673)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5753 (-0.5753)\tD repr loss -0.4493 (-0.4979)\n",
            "Epoch: [2][120/781]\tTime  2.529 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 1.4736 (0.5133)\tD(fake)1 -0.8327 (-0.6776)\tD(fake)2 0.0486 (-0.5313)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1456 (-0.4546)\tD repr loss -0.5037 (-0.5018)\n",
            "Epoch: [2][230/781]\tTime  2.524 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 1.1902 (0.5075)\tD(fake)1 0.2812 (-0.6794)\tD(fake)2 -0.0799 (-0.5230)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5967 (-0.4966)\tD repr loss -0.4770 (-0.5041)\n",
            "Epoch: [2][340/781]\tTime  2.541 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 2.0586 (0.5184)\tD(fake)1 -1.2237 (-0.6660)\tD(fake)2 1.0423 (-0.5143)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5496 (-0.5082)\tD repr loss -0.4463 (-0.5041)\n",
            "Epoch: [2][450/781]\tTime  2.468 ( 2.506)\tData  0.000 ( 0.000)\tD(real) 0.5321 (0.5086)\tD(fake)1 -0.9985 (-0.6491)\tD(fake)2 -2.1340 (-0.5244)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5677 (-0.5172)\tD repr loss -0.2908 (-0.5051)\n",
            "Epoch: [2][560/781]\tTime  2.528 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 2.2435 (0.5211)\tD(fake)1 -0.3421 (-0.6111)\tD(fake)2 1.2096 (-0.5095)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5606 (-0.5223)\tD repr loss -0.3739 (-0.5058)\n",
            "Epoch: [2][670/781]\tTime  2.524 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 0.6597 (0.5102)\tD(fake)1 -1.4242 (-0.6233)\tD(fake)2 -0.6961 (-0.5135)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5466 (-0.5227)\tD repr loss -0.5040 (-0.5063)\n",
            "Epoch: [2][780/781]\tTime  2.516 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.6228 (0.5223)\tD(fake)1 -0.3295 (-0.6478)\tD(fake)2 -0.0343 (-0.5132)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5949 (-0.5213)\tD repr loss -0.4325 (-0.5053)\n",
            "Epoch: [2][780/781]\tTime  2.485 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.6228 (0.5223)\tD(fake)1 -0.3295 (-0.6478)\tD(fake)2 -0.0343 (-0.5132)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5949 (-0.5213)\tD repr loss -0.4325 (-0.5053)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.3865 (0.1877)\tD(fake)1 -2.1491 (-2.1491)\tD(fake)2 -0.6679 (-0.7398)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5231 (-0.5231)\tD repr loss -0.5084 (-0.4833)\n",
            "Epoch: [3][120/781]\tTime  2.524 ( 2.523)\tData  0.000 ( 0.000)\tD(real) 1.8633 (0.5418)\tD(fake)1 -1.6044 (-0.8385)\tD(fake)2 0.5532 (-0.5317)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1167 (-0.4721)\tD repr loss -0.3988 (-0.4944)\n",
            "Epoch: [3][230/781]\tTime  2.503 ( 2.517)\tData  0.000 ( 0.000)\tD(real) 1.5691 (0.5611)\tD(fake)1 0.1449 (-0.7741)\tD(fake)2 -0.4528 (-0.5429)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5809 (-0.5111)\tD repr loss -0.4195 (-0.5024)\n",
            "Epoch: [3][340/781]\tTime  2.510 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.5426 (0.5418)\tD(fake)1 0.0299 (-0.6863)\tD(fake)2 -0.4862 (-0.5502)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5580 (-0.5080)\tD repr loss -0.5161 (-0.5042)\n",
            "Epoch: [3][450/781]\tTime  2.511 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 1.7628 (0.5473)\tD(fake)1 -1.5198 (-0.6733)\tD(fake)2 -0.3287 (-0.5470)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6036 (-0.5248)\tD repr loss -0.4463 (-0.5068)\n",
            "Epoch: [3][560/781]\tTime  2.526 ( 2.508)\tData  0.000 ( 0.000)\tD(real) -0.3189 (0.5448)\tD(fake)1 -1.1211 (-0.6767)\tD(fake)2 -1.0322 (-0.5366)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5723 (-0.5323)\tD repr loss -0.4433 (-0.5082)\n",
            "Epoch: [3][670/781]\tTime  2.480 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 0.6963 (0.5442)\tD(fake)1 -1.2099 (-0.6697)\tD(fake)2 -0.3104 (-0.5322)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2832 (-0.5324)\tD repr loss -0.5053 (-0.5087)\n",
            "Epoch: [3][780/781]\tTime  2.512 ( 2.507)\tData  0.000 ( 0.000)\tD(real) -0.1836 (0.5477)\tD(fake)1 -1.2238 (-0.6350)\tD(fake)2 -1.1607 (-0.5315)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5843 (-0.5351)\tD repr loss -0.4650 (-0.5085)\n",
            "Epoch: [3][780/781]\tTime  2.453 ( 2.507)\tData  0.000 ( 0.000)\tD(real) -0.1836 (0.5477)\tD(fake)1 -1.2238 (-0.6350)\tD(fake)2 -1.1607 (-0.5315)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5843 (-0.5351)\tD repr loss -0.4650 (-0.5085)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.2116 (0.6347)\tD(fake)1 -0.5962 (-0.5962)\tD(fake)2 -0.0119 (-0.5478)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5749 (-0.5749)\tD repr loss -0.4781 (-0.5412)\n",
            "Epoch: [4][120/781]\tTime  2.537 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.1457 (0.5779)\tD(fake)1 1.0917 (-0.5512)\tD(fake)2 -0.7034 (-0.5403)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5614 (-0.5494)\tD repr loss -0.4989 (-0.5280)\n",
            "Epoch: [4][230/781]\tTime  2.503 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.0339 (0.5862)\tD(fake)1 -1.0764 (-0.6439)\tD(fake)2 -1.0665 (-0.5460)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5160 (-0.5578)\tD repr loss -0.4572 (-0.5261)\n",
            "Epoch: [4][340/781]\tTime  2.523 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 1.0859 (0.6049)\tD(fake)1 -0.1279 (-0.6309)\tD(fake)2 -0.2757 (-0.5421)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5645 (-0.5477)\tD repr loss -0.5123 (-0.5200)\n",
            "Epoch: [4][450/781]\tTime  2.505 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 1.3332 (0.6029)\tD(fake)1 -0.0287 (-0.6231)\tD(fake)2 -0.1789 (-0.5385)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5967 (-0.5339)\tD repr loss -0.4953 (-0.5187)\n",
            "Epoch: [4][560/781]\tTime  2.531 ( 2.506)\tData  0.000 ( 0.000)\tD(real) 0.1942 (0.5875)\tD(fake)1 -1.3513 (-0.6756)\tD(fake)2 -1.0032 (-0.5494)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3967 (-0.5322)\tD repr loss -0.5101 (-0.5173)\n",
            "Epoch: [4][670/781]\tTime  2.514 ( 2.506)\tData  0.000 ( 0.000)\tD(real) -0.4409 (0.5843)\tD(fake)1 -1.2187 (-0.6980)\tD(fake)2 -1.4901 (-0.5586)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5615 (-0.5290)\tD repr loss -0.5204 (-0.5172)\n",
            "Epoch: [4][780/781]\tTime  2.520 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.6936 (0.5831)\tD(fake)1 0.0159 (-0.6638)\tD(fake)2 -0.4643 (-0.5629)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6168 (-0.5286)\tD repr loss -0.5258 (-0.5183)\n",
            "Epoch: [4][780/781]\tTime  2.514 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.6936 (0.5831)\tD(fake)1 0.0159 (-0.6638)\tD(fake)2 -0.4643 (-0.5629)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6168 (-0.5286)\tD repr loss -0.5258 (-0.5183)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.3644 (0.4647)\tD(fake)1 -0.8140 (-0.8140)\tD(fake)2 -0.8793 (-0.5731)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3691 (-0.3691)\tD repr loss -0.4334 (-0.4672)\n",
            "Epoch: [5][120/781]\tTime  2.505 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 0.7126 (0.5368)\tD(fake)1 -0.2519 (-0.6230)\tD(fake)2 -0.4113 (-0.5620)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4210 (-0.4662)\tD repr loss -0.5680 (-0.5048)\n",
            "Epoch: [5][230/781]\tTime  2.489 ( 2.517)\tData  0.000 ( 0.000)\tD(real) 1.8573 (0.5730)\tD(fake)1 -0.0403 (-0.6099)\tD(fake)2 0.2922 (-0.5515)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5041 (-0.5165)\tD repr loss -0.5376 (-0.5126)\n",
            "Epoch: [5][340/781]\tTime  2.511 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 0.6329 (0.5832)\tD(fake)1 -1.1389 (-0.6538)\tD(fake)2 -0.2401 (-0.5583)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6144 (-0.5293)\tD repr loss -0.5160 (-0.5132)\n",
            "Epoch: [5][450/781]\tTime  2.513 ( 2.512)\tData  0.000 ( 0.000)\tD(real) -0.0595 (0.5881)\tD(fake)1 -1.1952 (-0.6199)\tD(fake)2 -1.0396 (-0.5568)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5801 (-0.5293)\tD repr loss -0.5067 (-0.5135)\n",
            "Epoch: [5][560/781]\tTime  2.530 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.2921 (0.5805)\tD(fake)1 -1.0477 (-0.6047)\tD(fake)2 -1.2138 (-0.5538)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4703 (-0.5334)\tD repr loss -0.5531 (-0.5168)\n",
            "Epoch: [5][670/781]\tTime  2.521 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 1.0332 (0.5805)\tD(fake)1 -0.2135 (-0.6089)\tD(fake)2 -0.3778 (-0.5538)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5258 (-0.5365)\tD repr loss -0.4883 (-0.5179)\n",
            "Epoch: [5][780/781]\tTime  2.524 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 0.5632 (0.5815)\tD(fake)1 -1.4028 (-0.6358)\tD(fake)2 -0.8474 (-0.5571)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6431 (-0.5373)\tD repr loss -0.5087 (-0.5169)\n",
            "Epoch: [5][780/781]\tTime  2.503 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 0.5632 (0.5815)\tD(fake)1 -1.4028 (-0.6358)\tD(fake)2 -0.8474 (-0.5571)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6431 (-0.5373)\tD repr loss -0.5087 (-0.5169)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.4740 (0.5737)\tD(fake)1 -0.3235 (-0.3235)\tD(fake)2 -0.7291 (-0.5418)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6059 (-0.6059)\tD repr loss -0.4195 (-0.5168)\n",
            "Epoch: [6][120/781]\tTime  2.533 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 1.8321 (0.6168)\tD(fake)1 -0.3864 (-0.6495)\tD(fake)2 0.2079 (-0.5061)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4447 (-0.5040)\tD repr loss -0.5009 (-0.5089)\n",
            "Epoch: [6][230/781]\tTime  2.532 ( 2.526)\tData  0.000 ( 0.000)\tD(real) -0.1458 (0.6579)\tD(fake)1 -1.4112 (-0.7192)\tD(fake)2 -1.2954 (-0.5663)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5736 (-0.4978)\tD repr loss -0.4744 (-0.5105)\n",
            "Epoch: [6][340/781]\tTime  2.519 ( 2.518)\tData  0.000 ( 0.000)\tD(real) 0.6032 (0.6418)\tD(fake)1 -0.5457 (-0.7270)\tD(fake)2 -0.5965 (-0.5774)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5836 (-0.5265)\tD repr loss -0.5367 (-0.5174)\n",
            "Epoch: [6][450/781]\tTime  2.454 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.5518 (0.6387)\tD(fake)1 0.0261 (-0.6681)\tD(fake)2 -0.8455 (-0.5831)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5921 (-0.5303)\tD repr loss -0.4762 (-0.5186)\n",
            "Epoch: [6][560/781]\tTime  2.506 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.0217 (0.6253)\tD(fake)1 -0.9944 (-0.6667)\tD(fake)2 -0.9776 (-0.5829)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4561 (-0.5306)\tD repr loss -0.5514 (-0.5192)\n",
            "Epoch: [6][670/781]\tTime  2.538 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 1.2086 (0.6350)\tD(fake)1 -0.2644 (-0.6316)\tD(fake)2 -0.0786 (-0.5777)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5934 (-0.5301)\tD repr loss -0.4682 (-0.5173)\n",
            "Epoch: [6][780/781]\tTime  2.464 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.7272 (0.6250)\tD(fake)1 -1.2520 (-0.6191)\tD(fake)2 -0.4145 (-0.5752)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5873 (-0.5274)\tD repr loss -0.5427 (-0.5167)\n",
            "Epoch: [6][780/781]\tTime  2.484 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.7272 (0.6250)\tD(fake)1 -1.2520 (-0.6191)\tD(fake)2 -0.4145 (-0.5752)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5873 (-0.5274)\tD repr loss -0.5427 (-0.5167)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 2.5981 (0.9868)\tD(fake)1 -0.9575 (-0.9575)\tD(fake)2 1.0462 (-0.4858)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5126 (-0.5126)\tD repr loss -0.4131 (-0.4982)\n",
            "Epoch: [7][120/781]\tTime  2.467 ( 2.517)\tData  0.000 ( 0.000)\tD(real) -0.4750 (0.6934)\tD(fake)1 -0.4986 (-0.7904)\tD(fake)2 -1.2860 (-0.6233)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5586 (-0.5502)\tD repr loss -0.4590 (-0.5126)\n",
            "Epoch: [7][230/781]\tTime  2.506 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 0.1355 (0.6756)\tD(fake)1 -1.0621 (-0.7709)\tD(fake)2 -1.1460 (-0.6050)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5461 (-0.5338)\tD repr loss -0.4919 (-0.5119)\n",
            "Epoch: [7][340/781]\tTime  2.469 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.3887 (0.6533)\tD(fake)1 -0.7936 (-0.6972)\tD(fake)2 -0.7239 (-0.5983)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6803 (-0.5444)\tD repr loss -0.5749 (-0.5170)\n",
            "Epoch: [7][450/781]\tTime  2.480 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.1710 (0.6590)\tD(fake)1 -0.9530 (-0.6636)\tD(fake)2 -1.2479 (-0.5880)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3954 (-0.5337)\tD repr loss -0.4878 (-0.5162)\n",
            "Epoch: [7][560/781]\tTime  2.468 ( 2.503)\tData  0.000 ( 0.000)\tD(real) 1.2863 (0.6538)\tD(fake)1 -0.0763 (-0.5623)\tD(fake)2 -0.2910 (-0.5889)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5634 (-0.5384)\tD repr loss -0.4950 (-0.5179)\n",
            "Epoch: [7][670/781]\tTime  2.511 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.9099 (0.6496)\tD(fake)1 0.4958 (-0.5643)\tD(fake)2 -0.5840 (-0.5886)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5687 (-0.5392)\tD repr loss -0.5254 (-0.5167)\n",
            "Epoch: [7][780/781]\tTime  2.536 ( 2.502)\tData  0.000 ( 0.000)\tD(real) -0.3459 (0.6509)\tD(fake)1 0.4464 (-0.5453)\tD(fake)2 -1.3014 (-0.5955)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5640 (-0.5435)\tD repr loss -0.4669 (-0.5157)\n",
            "Epoch: [7][780/781]\tTime  2.494 ( 2.502)\tData  0.000 ( 0.000)\tD(real) -0.3459 (0.6509)\tD(fake)1 0.4464 (-0.5453)\tD(fake)2 -1.3014 (-0.5955)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5640 (-0.5435)\tD repr loss -0.4669 (-0.5157)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.1782 (0.7103)\tD(fake)1 -0.4540 (-0.4540)\tD(fake)2 -0.1695 (-0.5230)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5976 (-0.5976)\tD repr loss -0.5365 (-0.5368)\n",
            "Epoch: [8][120/781]\tTime  2.513 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.4780 (0.6769)\tD(fake)1 -1.1744 (-0.5872)\tD(fake)2 -0.8228 (-0.6090)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5745 (-0.5365)\tD repr loss -0.4605 (-0.5268)\n",
            "Epoch: [8][230/781]\tTime  2.484 ( 2.497)\tData  0.000 ( 0.000)\tD(real) -0.0293 (0.6509)\tD(fake)1 -1.0719 (-0.6704)\tD(fake)2 -1.0138 (-0.6086)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5891 (-0.5261)\tD repr loss -0.5238 (-0.5201)\n",
            "Epoch: [8][340/781]\tTime  2.468 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 1.4204 (0.6613)\tD(fake)1 -0.5136 (-0.6742)\tD(fake)2 0.1869 (-0.6004)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6045 (-0.5248)\tD repr loss -0.4460 (-0.5196)\n",
            "Epoch: [8][450/781]\tTime  2.518 ( 2.486)\tData  0.000 ( 0.000)\tD(real) 1.0010 (0.6591)\tD(fake)1 -0.0623 (-0.6847)\tD(fake)2 -0.6473 (-0.6023)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6418 (-0.5300)\tD repr loss -0.5458 (-0.5212)\n",
            "Epoch: [8][560/781]\tTime  2.495 ( 2.487)\tData  0.000 ( 0.000)\tD(real) 1.6870 (0.6742)\tD(fake)1 0.2752 (-0.5942)\tD(fake)2 0.2410 (-0.5983)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5791 (-0.5323)\tD repr loss -0.4709 (-0.5195)\n",
            "Epoch: [8][670/781]\tTime  2.514 ( 2.489)\tData  0.000 ( 0.000)\tD(real) 1.3377 (0.6692)\tD(fake)1 0.2824 (-0.6028)\tD(fake)2 -0.0949 (-0.6020)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6429 (-0.5312)\tD repr loss -0.4893 (-0.5185)\n",
            "Epoch: [8][780/781]\tTime  2.497 ( 2.491)\tData  0.000 ( 0.000)\tD(real) -0.6589 (0.6640)\tD(fake)1 -1.3572 (-0.6237)\tD(fake)2 -1.5555 (-0.6068)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4957 (-0.5357)\tD repr loss -0.5177 (-0.5212)\n",
            "Epoch: [8][780/781]\tTime  2.464 ( 2.491)\tData  0.000 ( 0.000)\tD(real) -0.6589 (0.6640)\tD(fake)1 -1.3572 (-0.6237)\tD(fake)2 -1.5555 (-0.6068)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4957 (-0.5357)\tD repr loss -0.5177 (-0.5212)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.3481 (0.6512)\tD(fake)1 -0.6656 (-0.6656)\tD(fake)2 -1.1373 (-0.6695)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5629 (-0.5629)\tD repr loss -0.5262 (-0.5574)\n",
            "Epoch: [9][120/781]\tTime  2.510 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 0.0051 (0.6208)\tD(fake)1 -1.2014 (-0.5788)\tD(fake)2 -1.0819 (-0.6326)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5568 (-0.5693)\tD repr loss -0.5251 (-0.5263)\n",
            "Epoch: [9][230/781]\tTime  2.535 ( 2.520)\tData  0.000 ( 0.000)\tD(real) -0.1857 (0.6557)\tD(fake)1 -0.3229 (-0.4341)\tD(fake)2 -1.3001 (-0.6382)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4755 (-0.5563)\tD repr loss -0.4505 (-0.5215)\n",
            "Epoch: [9][340/781]\tTime  2.515 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.3422 (0.6691)\tD(fake)1 -0.4145 (-0.4900)\tD(fake)2 -1.2325 (-0.6322)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5932 (-0.5480)\tD repr loss -0.3877 (-0.5212)\n",
            "Epoch: [9][450/781]\tTime  2.522 ( 2.505)\tData  0.000 ( 0.000)\tD(real) -0.1816 (0.6796)\tD(fake)1 -1.3926 (-0.4941)\tD(fake)2 -1.7566 (-0.6307)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5421 (-0.5507)\tD repr loss -0.3142 (-0.5196)\n",
            "Epoch: [9][560/781]\tTime  2.540 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.0097 (0.6805)\tD(fake)1 -1.0293 (-0.4307)\tD(fake)2 -1.2401 (-0.6246)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6195 (-0.5542)\tD repr loss -0.5588 (-0.5203)\n",
            "Epoch: [9][670/781]\tTime  2.521 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.2603 (0.6699)\tD(fake)1 -0.8005 (-0.4627)\tD(fake)2 -1.1696 (-0.6207)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4398 (-0.5598)\tD repr loss -0.4647 (-0.5222)\n",
            "Epoch: [9][780/781]\tTime  2.504 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 1.1848 (0.6733)\tD(fake)1 -0.5159 (-0.5268)\tD(fake)2 -0.3036 (-0.6216)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4568 (-0.5539)\tD repr loss -0.4940 (-0.5224)\n",
            "Epoch: [9][780/781]\tTime  2.490 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 1.1848 (0.6733)\tD(fake)1 -0.5159 (-0.5268)\tD(fake)2 -0.3036 (-0.6216)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4568 (-0.5539)\tD repr loss -0.4940 (-0.5224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-p4wAlbftUb",
        "outputId": "ec7ceeed-5d18-4f3f-baf1-c9f3e03eea52"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.2748 (0.5970)\tD(fake)1 -1.1453 (-1.1453)\tD(fake)2 -1.1746 (-0.6681)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2819 (-0.2819)\tD repr loss -0.4366 (-0.4899)\n",
            "Epoch: [0][120/781]\tTime  2.536 ( 2.524)\tData  0.000 ( 0.000)\tD(real) -0.2054 (0.6796)\tD(fake)1 -1.1218 (-0.6563)\tD(fake)2 -1.3197 (-0.6149)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5735 (-0.5321)\tD repr loss -0.5284 (-0.5252)\n",
            "Epoch: [0][230/781]\tTime  2.472 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 0.0427 (0.6598)\tD(fake)1 -1.0912 (-0.7282)\tD(fake)2 -1.1268 (-0.6252)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4428 (-0.4714)\tD repr loss -0.4841 (-0.5177)\n",
            "Epoch: [0][340/781]\tTime  2.539 ( 2.503)\tData  0.000 ( 0.000)\tD(real) -0.2452 (0.6544)\tD(fake)1 -1.3988 (-0.6768)\tD(fake)2 -1.3617 (-0.6208)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6118 (-0.5090)\tD repr loss -0.4970 (-0.5250)\n",
            "Epoch: [0][450/781]\tTime  2.526 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.2930 (0.6699)\tD(fake)1 0.1181 (-0.6811)\tD(fake)2 -0.3905 (-0.6219)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5778 (-0.5015)\tD repr loss -0.5313 (-0.5229)\n",
            "Epoch: [0][560/781]\tTime  2.475 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.1738 (0.6765)\tD(fake)1 -0.0189 (-0.6659)\tD(fake)2 -1.0071 (-0.6234)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5479 (-0.5138)\tD repr loss -0.5401 (-0.5247)\n",
            "Epoch: [0][670/781]\tTime  2.509 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 0.0459 (0.6709)\tD(fake)1 -1.8477 (-0.6719)\tD(fake)2 -1.1887 (-0.6236)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5759 (-0.5151)\tD repr loss -0.5061 (-0.5242)\n",
            "Epoch: [0][780/781]\tTime  2.521 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 1.3782 (0.6691)\tD(fake)1 -0.0293 (-0.6721)\tD(fake)2 -0.1944 (-0.6228)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5911 (-0.5194)\tD repr loss -0.5466 (-0.5249)\n",
            "Epoch: [0][780/781]\tTime  2.504 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 1.3782 (0.6691)\tD(fake)1 -0.0293 (-0.6721)\tD(fake)2 -0.1944 (-0.6228)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5911 (-0.5194)\tD repr loss -0.5466 (-0.5249)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 2.3959 (1.1391)\tD(fake)1 -1.1868 (-1.1868)\tD(fake)2 0.5265 (-0.5841)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6369 (-0.6369)\tD repr loss -0.4609 (-0.5233)\n",
            "Epoch: [1][120/781]\tTime  2.483 ( 2.519)\tData  0.000 ( 0.000)\tD(real) -0.3110 (0.7614)\tD(fake)1 -1.3752 (-0.9521)\tD(fake)2 -1.0797 (-0.6423)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6023 (-0.5916)\tD repr loss -0.5307 (-0.5197)\n",
            "Epoch: [1][230/781]\tTime  2.524 ( 2.518)\tData  0.000 ( 0.000)\tD(real) 1.0760 (0.7444)\tD(fake)1 -0.1348 (-0.8635)\tD(fake)2 -0.4053 (-0.6347)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5329 (-0.5672)\tD repr loss -0.4590 (-0.5230)\n",
            "Epoch: [1][340/781]\tTime  2.458 ( 2.514)\tData  0.000 ( 0.000)\tD(real) -0.0966 (0.7333)\tD(fake)1 -1.2260 (-0.8401)\tD(fake)2 -1.0441 (-0.6254)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5983 (-0.5628)\tD repr loss -0.5377 (-0.5229)\n",
            "Epoch: [1][450/781]\tTime  2.487 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.4810 (0.7263)\tD(fake)1 0.0784 (-0.7800)\tD(fake)2 -0.2042 (-0.6296)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4725 (-0.5598)\tD repr loss -0.4603 (-0.5254)\n",
            "Epoch: [1][560/781]\tTime  2.504 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.1626 (0.7176)\tD(fake)1 -1.4521 (-0.7653)\tD(fake)2 -0.4317 (-0.6281)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3654 (-0.5595)\tD repr loss -0.5203 (-0.5258)\n",
            "Epoch: [1][670/781]\tTime  2.521 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.2821 (0.7232)\tD(fake)1 -1.0399 (-0.7282)\tD(fake)2 0.0090 (-0.6309)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4008 (-0.5531)\tD repr loss -0.4805 (-0.5251)\n",
            "Epoch: [1][780/781]\tTime  2.464 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 1.4739 (0.7109)\tD(fake)1 -0.0451 (-0.7293)\tD(fake)2 -0.2025 (-0.6298)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5764 (-0.5515)\tD repr loss -0.4146 (-0.5263)\n",
            "Epoch: [1][780/781]\tTime  2.493 ( 2.504)\tData  0.000 ( 0.000)\tD(real) 1.4739 (0.7109)\tD(fake)1 -0.0451 (-0.7293)\tD(fake)2 -0.2025 (-0.6298)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5764 (-0.5515)\tD repr loss -0.4146 (-0.5263)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.0031 (0.5763)\tD(fake)1 -1.6888 (-1.6888)\tD(fake)2 -1.2785 (-0.8254)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3711 (-0.3711)\tD repr loss -0.5299 (-0.5146)\n",
            "Epoch: [2][120/781]\tTime  2.453 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.6681 (0.7310)\tD(fake)1 -0.0670 (-0.4665)\tD(fake)2 0.0008 (-0.6309)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6517 (-0.4960)\tD repr loss -0.4209 (-0.5200)\n",
            "Epoch: [2][230/781]\tTime  2.530 ( 2.495)\tData  0.000 ( 0.000)\tD(real) -0.0357 (0.7227)\tD(fake)1 -0.7057 (-0.5383)\tD(fake)2 -1.1824 (-0.6640)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5011 (-0.5210)\tD repr loss -0.4836 (-0.5226)\n",
            "Epoch: [2][340/781]\tTime  2.467 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.0326 (0.7398)\tD(fake)1 -1.1855 (-0.6494)\tD(fake)2 -1.1745 (-0.6556)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5935 (-0.5401)\tD repr loss -0.5075 (-0.5268)\n",
            "Epoch: [2][450/781]\tTime  2.510 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 0.8466 (0.7405)\tD(fake)1 -1.3275 (-0.7042)\tD(fake)2 -0.6790 (-0.6539)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5869 (-0.5505)\tD repr loss -0.4944 (-0.5292)\n",
            "Epoch: [2][560/781]\tTime  2.505 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 2.1047 (0.7524)\tD(fake)1 -0.0819 (-0.7250)\tD(fake)2 0.3056 (-0.6524)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6428 (-0.5553)\tD repr loss -0.5413 (-0.5306)\n",
            "Epoch: [2][670/781]\tTime  2.521 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.6401 (0.7443)\tD(fake)1 -0.1985 (-0.7127)\tD(fake)2 -0.5820 (-0.6567)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5939 (-0.5563)\tD repr loss -0.4910 (-0.5326)\n",
            "Epoch: [2][780/781]\tTime  2.525 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.9606 (0.7476)\tD(fake)1 -0.5964 (-0.7067)\tD(fake)2 -0.3513 (-0.6536)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6577 (-0.5542)\tD repr loss -0.5201 (-0.5330)\n",
            "Epoch: [2][780/781]\tTime  2.474 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.9606 (0.7476)\tD(fake)1 -0.5964 (-0.7067)\tD(fake)2 -0.3513 (-0.6536)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6577 (-0.5542)\tD repr loss -0.5201 (-0.5330)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.4795 (0.7218)\tD(fake)1 -0.9979 (-0.9979)\tD(fake)2 -0.9809 (-0.6842)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5717 (-0.5717)\tD repr loss -0.5086 (-0.5444)\n",
            "Epoch: [3][120/781]\tTime  2.509 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 1.4064 (0.7884)\tD(fake)1 -0.1203 (-0.6557)\tD(fake)2 -0.1780 (-0.6395)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.7116 (-0.6098)\tD repr loss -0.4868 (-0.5373)\n",
            "Epoch: [3][230/781]\tTime  2.456 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.6662 (0.7850)\tD(fake)1 -0.2736 (-0.6868)\tD(fake)2 -0.7505 (-0.6520)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6249 (-0.5897)\tD repr loss -0.5182 (-0.5333)\n",
            "Epoch: [3][340/781]\tTime  2.516 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 1.0253 (0.7801)\tD(fake)1 -0.1190 (-0.6648)\tD(fake)2 -0.5506 (-0.6467)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4449 (-0.5716)\tD repr loss -0.4673 (-0.5318)\n",
            "Epoch: [3][450/781]\tTime  2.512 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.0045 (0.7588)\tD(fake)1 -1.1753 (-0.6848)\tD(fake)2 -1.3318 (-0.6494)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5171 (-0.5651)\tD repr loss -0.3323 (-0.5324)\n",
            "Epoch: [3][560/781]\tTime  2.467 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.3370 (0.7500)\tD(fake)1 -1.0311 (-0.6724)\tD(fake)2 -0.9611 (-0.6513)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6334 (-0.5608)\tD repr loss -0.5074 (-0.5306)\n",
            "Epoch: [3][670/781]\tTime  2.469 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.2618 (0.7519)\tD(fake)1 -1.0178 (-0.7039)\tD(fake)2 -1.6507 (-0.6537)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5625 (-0.5632)\tD repr loss -0.3706 (-0.5312)\n",
            "Epoch: [3][780/781]\tTime  2.535 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.2173 (0.7502)\tD(fake)1 -0.2012 (-0.6646)\tD(fake)2 -0.9609 (-0.6477)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5058 (-0.5655)\tD repr loss -0.5593 (-0.5312)\n",
            "Epoch: [3][780/781]\tTime  2.497 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 0.2173 (0.7502)\tD(fake)1 -0.2012 (-0.6646)\tD(fake)2 -0.9609 (-0.6477)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5058 (-0.5655)\tD repr loss -0.5593 (-0.5312)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.6570 (0.7906)\tD(fake)1 -0.1695 (-0.1695)\tD(fake)2 -0.1459 (-0.5660)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6356 (-0.6356)\tD repr loss -0.4703 (-0.5522)\n",
            "Epoch: [4][120/781]\tTime  2.455 ( 2.497)\tData  0.000 ( 0.000)\tD(real) 2.3004 (0.7271)\tD(fake)1 0.4666 (-0.7331)\tD(fake)2 1.0009 (-0.6516)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5540 (-0.5538)\tD repr loss -0.5374 (-0.5389)\n",
            "Epoch: [4][230/781]\tTime  2.518 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 0.7243 (0.7404)\tD(fake)1 -1.1592 (-0.6509)\tD(fake)2 -0.7897 (-0.6556)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6559 (-0.5668)\tD repr loss -0.5370 (-0.5418)\n",
            "Epoch: [4][340/781]\tTime  2.519 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.3026 (0.7593)\tD(fake)1 -0.3492 (-0.6859)\tD(fake)2 -0.2709 (-0.6578)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5481 (-0.5420)\tD repr loss -0.5177 (-0.5354)\n",
            "Epoch: [4][450/781]\tTime  2.536 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.3210 (0.7524)\tD(fake)1 -1.2989 (-0.6941)\tD(fake)2 -1.0206 (-0.6563)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6041 (-0.5485)\tD repr loss -0.5377 (-0.5370)\n",
            "Epoch: [4][560/781]\tTime  2.509 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 1.4370 (0.7625)\tD(fake)1 -0.0597 (-0.6690)\tD(fake)2 -0.3815 (-0.6569)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5856 (-0.5520)\tD repr loss -0.5161 (-0.5358)\n",
            "Epoch: [4][670/781]\tTime  2.518 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.4485 (0.7517)\tD(fake)1 -0.3505 (-0.6695)\tD(fake)2 -0.7708 (-0.6617)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5142 (-0.5539)\tD repr loss -0.5846 (-0.5342)\n",
            "Epoch: [4][780/781]\tTime  2.529 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.7533 (0.7534)\tD(fake)1 0.0732 (-0.6891)\tD(fake)2 -0.9397 (-0.6625)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4936 (-0.5561)\tD repr loss -0.5470 (-0.5335)\n",
            "Epoch: [4][780/781]\tTime  2.485 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.7533 (0.7534)\tD(fake)1 0.0732 (-0.6891)\tD(fake)2 -0.9397 (-0.6625)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4936 (-0.5561)\tD repr loss -0.5470 (-0.5335)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.5824 (0.6535)\tD(fake)1 -0.3838 (-0.3838)\tD(fake)2 0.1144 (-0.5885)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4817 (-0.4817)\tD repr loss -0.5554 (-0.4983)\n",
            "Epoch: [5][120/781]\tTime  2.504 ( 2.526)\tData  0.000 ( 0.000)\tD(real) 1.8635 (0.7198)\tD(fake)1 -0.3644 (-0.6990)\tD(fake)2 0.2827 (-0.6628)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6589 (-0.5739)\tD repr loss -0.5535 (-0.5356)\n",
            "Epoch: [5][230/781]\tTime  2.533 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.0597 (0.7223)\tD(fake)1 -0.1859 (-0.7098)\tD(fake)2 -0.6309 (-0.6793)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5796 (-0.5678)\tD repr loss -0.5294 (-0.5412)\n",
            "Epoch: [5][340/781]\tTime  2.545 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.5227 (0.7329)\tD(fake)1 0.0505 (-0.6953)\tD(fake)2 -0.7046 (-0.6778)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6308 (-0.5760)\tD repr loss -0.4332 (-0.5443)\n",
            "Epoch: [5][450/781]\tTime  2.545 ( 2.513)\tData  0.000 ( 0.000)\tD(real) -0.5163 (0.7405)\tD(fake)1 -1.1251 (-0.7134)\tD(fake)2 -1.4912 (-0.6836)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5908 (-0.5700)\tD repr loss -0.5256 (-0.5432)\n",
            "Epoch: [5][560/781]\tTime  2.550 ( 2.514)\tData  0.000 ( 0.000)\tD(real) -0.1643 (0.7597)\tD(fake)1 -1.0491 (-0.7220)\tD(fake)2 -1.1848 (-0.6779)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6186 (-0.5663)\tD repr loss -0.5520 (-0.5404)\n",
            "Epoch: [5][670/781]\tTime  2.483 ( 2.513)\tData  0.000 ( 0.000)\tD(real) -0.7061 (0.7719)\tD(fake)1 -1.0386 (-0.7292)\tD(fake)2 -1.7249 (-0.6797)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6078 (-0.5633)\tD repr loss -0.3287 (-0.5375)\n",
            "Epoch: [5][780/781]\tTime  2.528 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.2117 (0.7674)\tD(fake)1 -0.7334 (-0.6738)\tD(fake)2 -1.2392 (-0.6740)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5716 (-0.5637)\tD repr loss -0.5886 (-0.5365)\n",
            "Epoch: [5][780/781]\tTime  2.515 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.2117 (0.7674)\tD(fake)1 -0.7334 (-0.6738)\tD(fake)2 -1.2392 (-0.6740)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5716 (-0.5637)\tD repr loss -0.5886 (-0.5365)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.7800 (0.9048)\tD(fake)1 -0.5706 (-0.5706)\tD(fake)2 0.0620 (-0.5820)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5640 (-0.5640)\tD repr loss -0.5326 (-0.5592)\n",
            "Epoch: [6][120/781]\tTime  2.526 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 1.6332 (0.8379)\tD(fake)1 -1.0988 (-0.8654)\tD(fake)2 -0.3423 (-0.6704)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5791 (-0.5678)\tD repr loss -0.5469 (-0.5313)\n",
            "Epoch: [6][230/781]\tTime  2.534 ( 2.511)\tData  0.000 ( 0.000)\tD(real) -0.4049 (0.8043)\tD(fake)1 -1.2567 (-0.8930)\tD(fake)2 -1.4515 (-0.6885)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6238 (-0.5660)\tD repr loss -0.4955 (-0.5335)\n",
            "Epoch: [6][340/781]\tTime  2.509 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.4592 (0.8025)\tD(fake)1 -1.1310 (-0.8546)\tD(fake)2 -1.0616 (-0.6893)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6022 (-0.5648)\tD repr loss -0.4839 (-0.5352)\n",
            "Epoch: [6][450/781]\tTime  2.477 ( 2.513)\tData  0.000 ( 0.000)\tD(real) -0.4443 (0.8151)\tD(fake)1 -0.5424 (-0.8135)\tD(fake)2 -1.4652 (-0.6902)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4843 (-0.5607)\tD repr loss -0.5057 (-0.5356)\n",
            "Epoch: [6][560/781]\tTime  2.518 ( 2.512)\tData  0.000 ( 0.000)\tD(real) -0.3662 (0.8080)\tD(fake)1 -1.4424 (-0.7884)\tD(fake)2 -1.4236 (-0.6890)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5870 (-0.5639)\tD repr loss -0.5303 (-0.5335)\n",
            "Epoch: [6][670/781]\tTime  2.525 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.1671 (0.7947)\tD(fake)1 -1.3202 (-0.7783)\tD(fake)2 -1.1317 (-0.6881)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5757 (-0.5666)\tD repr loss -0.5312 (-0.5354)\n",
            "Epoch: [6][780/781]\tTime  2.505 ( 2.511)\tData  0.000 ( 0.000)\tD(real) -0.2238 (0.7918)\tD(fake)1 -1.0690 (-0.7545)\tD(fake)2 -1.2687 (-0.6800)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5834 (-0.5673)\tD repr loss -0.5094 (-0.5371)\n",
            "Epoch: [6][780/781]\tTime  2.480 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.2238 (0.7918)\tD(fake)1 -1.0690 (-0.7545)\tD(fake)2 -1.2687 (-0.6800)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5834 (-0.5673)\tD repr loss -0.5094 (-0.5371)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.3485 (0.8113)\tD(fake)1 -0.3034 (-0.3034)\tD(fake)2 -0.3806 (-0.6246)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5536 (-0.5536)\tD repr loss -0.5759 (-0.5612)\n",
            "Epoch: [7][120/781]\tTime  2.512 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 0.9131 (0.7753)\tD(fake)1 1.0759 (-0.4875)\tD(fake)2 -0.6210 (-0.6438)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5765 (-0.5704)\tD repr loss -0.5262 (-0.5341)\n",
            "Epoch: [7][230/781]\tTime  2.521 ( 2.506)\tData  0.000 ( 0.000)\tD(real) -0.5072 (0.7388)\tD(fake)1 -1.4383 (-0.6171)\tD(fake)2 -1.2652 (-0.6609)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6204 (-0.5599)\tD repr loss -0.5346 (-0.5340)\n",
            "Epoch: [7][340/781]\tTime  2.519 ( 2.500)\tData  0.000 ( 0.000)\tD(real) 1.8412 (0.7507)\tD(fake)1 -0.2130 (-0.6223)\tD(fake)2 -0.0945 (-0.6595)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5997 (-0.5741)\tD repr loss -0.5064 (-0.5413)\n",
            "Epoch: [7][450/781]\tTime  2.435 ( 2.501)\tData  0.000 ( 0.000)\tD(real) -0.0127 (0.7597)\tD(fake)1 -1.1841 (-0.6603)\tD(fake)2 -1.2588 (-0.6637)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5440 (-0.5769)\tD repr loss -0.5263 (-0.5424)\n",
            "Epoch: [7][560/781]\tTime  2.499 ( 2.502)\tData  0.000 ( 0.000)\tD(real) -0.6623 (0.7664)\tD(fake)1 -1.2633 (-0.6348)\tD(fake)2 -1.5762 (-0.6566)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2693 (-0.5691)\tD repr loss -0.5372 (-0.5409)\n",
            "Epoch: [7][670/781]\tTime  2.542 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 0.9696 (0.7706)\tD(fake)1 -0.3433 (-0.6410)\tD(fake)2 -0.4541 (-0.6628)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5033 (-0.5692)\tD repr loss -0.3922 (-0.5418)\n",
            "Epoch: [7][780/781]\tTime  2.487 ( 2.502)\tData  0.000 ( 0.000)\tD(real) 0.3683 (0.7772)\tD(fake)1 -1.3296 (-0.6329)\tD(fake)2 -1.0187 (-0.6563)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4592 (-0.5641)\tD repr loss -0.5266 (-0.5393)\n",
            "Epoch: [7][780/781]\tTime  2.469 ( 2.501)\tData  0.000 ( 0.000)\tD(real) 0.3683 (0.7772)\tD(fake)1 -1.3296 (-0.6329)\tD(fake)2 -1.0187 (-0.6563)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4592 (-0.5641)\tD repr loss -0.5266 (-0.5393)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.7752 (0.9406)\tD(fake)1 -0.5503 (-0.5503)\tD(fake)2 0.0182 (-0.6170)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5644 (-0.5644)\tD repr loss -0.5587 (-0.5663)\n",
            "Epoch: [8][120/781]\tTime  2.534 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 0.2427 (0.7874)\tD(fake)1 -0.1665 (-0.6763)\tD(fake)2 -1.0241 (-0.7141)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5484 (-0.5746)\tD repr loss -0.5332 (-0.5474)\n",
            "Epoch: [8][230/781]\tTime  2.482 ( 2.520)\tData  0.000 ( 0.000)\tD(real) -0.1243 (0.7827)\tD(fake)1 -0.4999 (-0.7291)\tD(fake)2 -1.3552 (-0.6847)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5816 (-0.5655)\tD repr loss -0.4908 (-0.5426)\n",
            "Epoch: [8][340/781]\tTime  2.519 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.5173 (0.7742)\tD(fake)1 -1.4714 (-0.6513)\tD(fake)2 -1.0136 (-0.6860)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4919 (-0.5593)\tD repr loss -0.5146 (-0.5396)\n",
            "Epoch: [8][450/781]\tTime  2.456 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 0.0015 (0.7650)\tD(fake)1 -0.8974 (-0.6524)\tD(fake)2 -1.3506 (-0.6790)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5852 (-0.5527)\tD repr loss -0.3992 (-0.5380)\n",
            "Epoch: [8][560/781]\tTime  2.461 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 0.1722 (0.7639)\tD(fake)1 -1.5061 (-0.6754)\tD(fake)2 -1.1256 (-0.6801)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6137 (-0.5591)\tD repr loss -0.5281 (-0.5379)\n",
            "Epoch: [8][670/781]\tTime  2.525 ( 2.507)\tData  0.000 ( 0.000)\tD(real) 0.9715 (0.7623)\tD(fake)1 -0.0873 (-0.6461)\tD(fake)2 -0.5271 (-0.6848)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6510 (-0.5643)\tD repr loss -0.5590 (-0.5388)\n",
            "Epoch: [8][780/781]\tTime  2.474 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.8438 (0.7737)\tD(fake)1 -1.7485 (-0.6790)\tD(fake)2 -0.5385 (-0.6833)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5417 (-0.5682)\tD repr loss -0.5324 (-0.5385)\n",
            "Epoch: [8][780/781]\tTime  2.505 ( 2.505)\tData  0.000 ( 0.000)\tD(real) 0.8438 (0.7737)\tD(fake)1 -1.7485 (-0.6790)\tD(fake)2 -0.5385 (-0.6833)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5417 (-0.5682)\tD repr loss -0.5324 (-0.5385)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.8851 (0.9808)\tD(fake)1 -0.7488 (-0.7488)\tD(fake)2 -0.6659 (-0.7574)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5612 (-0.5612)\tD repr loss -0.5183 (-0.5303)\n",
            "Epoch: [9][120/781]\tTime  2.540 ( 2.523)\tData  0.000 ( 0.000)\tD(real) 1.0778 (0.8068)\tD(fake)1 -1.2019 (-0.7947)\tD(fake)2 -0.4944 (-0.6841)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4040 (-0.5553)\tD repr loss -0.4924 (-0.5440)\n",
            "Epoch: [9][230/781]\tTime  2.487 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 1.3703 (0.8118)\tD(fake)1 -0.1074 (-0.6988)\tD(fake)2 -0.3029 (-0.6837)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4058 (-0.5484)\tD repr loss -0.4948 (-0.5383)\n",
            "Epoch: [9][340/781]\tTime  2.514 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.3231 (0.8183)\tD(fake)1 -0.3508 (-0.7982)\tD(fake)2 -0.3802 (-0.6934)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6192 (-0.5524)\tD repr loss -0.5154 (-0.5379)\n",
            "Epoch: [9][450/781]\tTime  2.490 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 0.4361 (0.8244)\tD(fake)1 -0.2402 (-0.7637)\tD(fake)2 -1.1309 (-0.6991)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4947 (-0.5487)\tD repr loss -0.5339 (-0.5368)\n",
            "Epoch: [9][560/781]\tTime  2.506 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.8902 (0.8343)\tD(fake)1 -1.2016 (-0.7940)\tD(fake)2 0.3010 (-0.6962)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6330 (-0.5498)\tD repr loss -0.5148 (-0.5359)\n",
            "Epoch: [9][670/781]\tTime  2.483 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.1611 (0.8252)\tD(fake)1 -1.2133 (-0.7872)\tD(fake)2 -0.3140 (-0.6931)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6258 (-0.5583)\tD repr loss -0.4782 (-0.5371)\n",
            "Epoch: [9][780/781]\tTime  2.514 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.5747 (0.8215)\tD(fake)1 0.2008 (-0.7289)\tD(fake)2 -0.9374 (-0.6901)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6071 (-0.5554)\tD repr loss -0.5623 (-0.5373)\n",
            "Epoch: [9][780/781]\tTime  2.503 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.5747 (0.8215)\tD(fake)1 0.2008 (-0.7289)\tD(fake)2 -0.9374 (-0.6901)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6071 (-0.5554)\tD repr loss -0.5623 (-0.5373)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUGjJ-6Pf3xE",
        "outputId": "f6ff4259-76b5-463f-bf03-2910cc668387"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.2399 (1.0920)\tD(fake)1 -0.1342 (-0.1342)\tD(fake)2 -0.9730 (-0.5059)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5865 (-0.5865)\tD repr loss -0.5304 (-0.4970)\n",
            "Epoch: [0][120/781]\tTime  2.538 ( 2.535)\tData  0.000 ( 0.000)\tD(real) 0.1082 (0.7997)\tD(fake)1 -1.4056 (-0.6152)\tD(fake)2 -1.4481 (-0.6670)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4911 (-0.5511)\tD repr loss -0.5299 (-0.5294)\n",
            "Epoch: [0][230/781]\tTime  2.514 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.9394 (0.7981)\tD(fake)1 -0.8481 (-0.6849)\tD(fake)2 -0.4998 (-0.6729)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6271 (-0.5576)\tD repr loss -0.4873 (-0.5343)\n",
            "Epoch: [0][340/781]\tTime  2.538 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 0.1366 (0.8030)\tD(fake)1 -1.0015 (-0.6876)\tD(fake)2 -1.1575 (-0.6761)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6615 (-0.5701)\tD repr loss -0.5279 (-0.5377)\n",
            "Epoch: [0][450/781]\tTime  2.554 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.8703 (0.8016)\tD(fake)1 0.1137 (-0.6419)\tD(fake)2 -0.5612 (-0.6772)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5658 (-0.5668)\tD repr loss -0.5545 (-0.5393)\n",
            "Epoch: [0][560/781]\tTime  2.506 ( 2.509)\tData  0.000 ( 0.000)\tD(real) -0.3018 (0.8026)\tD(fake)1 -0.8023 (-0.6570)\tD(fake)2 -1.5037 (-0.6781)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5569 (-0.5550)\tD repr loss -0.5238 (-0.5379)\n",
            "Epoch: [0][670/781]\tTime  2.525 ( 2.512)\tData  0.000 ( 0.000)\tD(real) -0.2779 (0.8002)\tD(fake)1 -0.9654 (-0.6422)\tD(fake)2 -1.3689 (-0.6739)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5080 (-0.5544)\tD repr loss -0.4943 (-0.5395)\n",
            "Epoch: [0][780/781]\tTime  2.517 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.8530 (0.8017)\tD(fake)1 -2.1656 (-0.7072)\tD(fake)2 -0.7667 (-0.6788)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3758 (-0.5474)\tD repr loss -0.5243 (-0.5392)\n",
            "Epoch: [0][780/781]\tTime  2.488 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.8530 (0.8017)\tD(fake)1 -2.1656 (-0.7072)\tD(fake)2 -0.7667 (-0.6788)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3758 (-0.5474)\tD repr loss -0.5243 (-0.5392)\n",
            "Epoch: [1][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.0725 (0.8059)\tD(fake)1 -0.6192 (-0.6192)\tD(fake)2 -0.3723 (-0.7356)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5683 (-0.5683)\tD repr loss -0.4724 (-0.5337)\n",
            "Epoch: [1][120/781]\tTime  2.530 ( 2.537)\tData  0.000 ( 0.000)\tD(real) 0.5141 (0.8091)\tD(fake)1 -1.3490 (-0.8187)\tD(fake)2 -0.8870 (-0.7053)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6174 (-0.5778)\tD repr loss -0.4953 (-0.5513)\n",
            "Epoch: [1][230/781]\tTime  2.527 ( 2.530)\tData  0.000 ( 0.000)\tD(real) -0.1275 (0.8303)\tD(fake)1 -1.1095 (-0.8230)\tD(fake)2 -1.2489 (-0.7043)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5927 (-0.5864)\tD repr loss -0.5255 (-0.5435)\n",
            "Epoch: [1][340/781]\tTime  2.520 ( 2.528)\tData  0.000 ( 0.000)\tD(real) -0.3303 (0.8123)\tD(fake)1 -0.5829 (-0.7864)\tD(fake)2 -1.3464 (-0.6982)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5162 (-0.5866)\tD repr loss -0.5584 (-0.5456)\n",
            "Epoch: [1][450/781]\tTime  2.562 ( 2.527)\tData  0.000 ( 0.000)\tD(real) 2.1959 (0.8400)\tD(fake)1 -0.4039 (-0.8284)\tD(fake)2 0.5501 (-0.7030)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5421 (-0.5870)\tD repr loss -0.5058 (-0.5429)\n",
            "Epoch: [1][560/781]\tTime  2.536 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 0.9181 (0.8541)\tD(fake)1 0.0876 (-0.7774)\tD(fake)2 -0.4778 (-0.6967)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5566 (-0.5751)\tD repr loss -0.5707 (-0.5396)\n",
            "Epoch: [1][670/781]\tTime  2.482 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 1.0551 (0.8401)\tD(fake)1 -0.3459 (-0.7755)\tD(fake)2 -0.7126 (-0.6990)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5471 (-0.5761)\tD repr loss -0.5358 (-0.5415)\n",
            "Epoch: [1][780/781]\tTime  2.494 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 1.0977 (0.8430)\tD(fake)1 -0.3552 (-0.7553)\tD(fake)2 -0.3569 (-0.7013)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5729 (-0.5718)\tD repr loss -0.5425 (-0.5404)\n",
            "Epoch: [1][780/781]\tTime  2.488 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 1.0977 (0.8430)\tD(fake)1 -0.3552 (-0.7553)\tD(fake)2 -0.3569 (-0.7013)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5729 (-0.5718)\tD repr loss -0.5425 (-0.5404)\n",
            "Epoch: [2][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.2290 (0.6587)\tD(fake)1 -1.0022 (-1.0022)\tD(fake)2 -1.4053 (-0.7723)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5782 (-0.5782)\tD repr loss -0.4988 (-0.5639)\n",
            "Epoch: [2][120/781]\tTime  2.468 ( 2.528)\tData  0.000 ( 0.000)\tD(real) 0.3352 (0.7897)\tD(fake)1 -1.3438 (-0.7335)\tD(fake)2 -1.0804 (-0.6982)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6226 (-0.5801)\tD repr loss -0.5814 (-0.5459)\n",
            "Epoch: [2][230/781]\tTime  2.497 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.0189 (0.7982)\tD(fake)1 0.0543 (-0.7608)\tD(fake)2 -0.5733 (-0.7067)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5647 (-0.5425)\tD repr loss -0.5482 (-0.5430)\n",
            "Epoch: [2][340/781]\tTime  2.494 ( 2.499)\tData  0.000 ( 0.000)\tD(real) 0.2632 (0.8093)\tD(fake)1 -1.3272 (-0.8027)\tD(fake)2 -1.1144 (-0.7123)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5561 (-0.5545)\tD repr loss -0.4479 (-0.5429)\n",
            "Epoch: [2][450/781]\tTime  2.467 ( 2.498)\tData  0.000 ( 0.000)\tD(real) 0.2598 (0.8142)\tD(fake)1 -1.1167 (-0.7645)\tD(fake)2 -1.1207 (-0.7113)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5586 (-0.5488)\tD repr loss -0.5284 (-0.5424)\n",
            "Epoch: [2][560/781]\tTime  2.458 ( 2.491)\tData  0.000 ( 0.000)\tD(real) 0.4122 (0.8161)\tD(fake)1 -0.9582 (-0.7626)\tD(fake)2 -0.9359 (-0.7123)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5552 (-0.5513)\tD repr loss -0.5367 (-0.5422)\n",
            "Epoch: [2][670/781]\tTime  2.504 ( 2.494)\tData  0.000 ( 0.000)\tD(real) 1.6070 (0.8211)\tD(fake)1 -0.5266 (-0.7509)\tD(fake)2 -0.2101 (-0.7121)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5546 (-0.5536)\tD repr loss -0.5308 (-0.5429)\n",
            "Epoch: [2][780/781]\tTime  2.521 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.6588 (0.8186)\tD(fake)1 -1.1994 (-0.7628)\tD(fake)2 -0.7306 (-0.7107)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5819 (-0.5600)\tD repr loss -0.5535 (-0.5450)\n",
            "Epoch: [2][780/781]\tTime  2.501 ( 2.496)\tData  0.000 ( 0.000)\tD(real) 0.6588 (0.8186)\tD(fake)1 -1.1994 (-0.7628)\tD(fake)2 -0.7306 (-0.7107)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5819 (-0.5600)\tD repr loss -0.5535 (-0.5450)\n",
            "Epoch: [3][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.8679 (0.8538)\tD(fake)1 -0.8679 (-0.8679)\tD(fake)2 -0.5249 (-0.7489)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5419 (-0.5419)\tD repr loss -0.4724 (-0.5311)\n",
            "Epoch: [3][120/781]\tTime  2.518 ( 2.517)\tData  0.000 ( 0.000)\tD(real) 1.4624 (0.8389)\tD(fake)1 -0.1340 (-0.8140)\tD(fake)2 -0.2625 (-0.7271)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5806 (-0.5664)\tD repr loss -0.5082 (-0.5496)\n",
            "Epoch: [3][230/781]\tTime  2.515 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.6442 (0.8468)\tD(fake)1 -1.4473 (-0.8628)\tD(fake)2 -0.1593 (-0.7118)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5823 (-0.5290)\tD repr loss -0.4024 (-0.5352)\n",
            "Epoch: [3][340/781]\tTime  2.465 ( 2.510)\tData  0.000 ( 0.000)\tD(real) -0.0791 (0.8356)\tD(fake)1 -1.2228 (-0.8735)\tD(fake)2 -1.1036 (-0.7231)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5740 (-0.5261)\tD repr loss -0.4449 (-0.5346)\n",
            "Epoch: [3][450/781]\tTime  2.543 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 1.2053 (0.8403)\tD(fake)1 -1.2410 (-0.8482)\tD(fake)2 -0.5905 (-0.7217)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6089 (-0.5439)\tD repr loss -0.5208 (-0.5385)\n",
            "Epoch: [3][560/781]\tTime  2.518 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 0.9537 (0.8472)\tD(fake)1 0.1764 (-0.7995)\tD(fake)2 -0.8106 (-0.7243)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6779 (-0.5448)\tD repr loss -0.5247 (-0.5377)\n",
            "Epoch: [3][670/781]\tTime  2.513 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.9154 (0.8430)\tD(fake)1 -0.2444 (-0.7763)\tD(fake)2 0.1323 (-0.7185)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5493 (-0.5499)\tD repr loss -0.4862 (-0.5390)\n",
            "Epoch: [3][780/781]\tTime  2.552 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 2.2203 (0.8415)\tD(fake)1 -0.9778 (-0.7796)\tD(fake)2 0.0733 (-0.7169)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2702 (-0.5471)\tD repr loss -0.5241 (-0.5390)\n",
            "Epoch: [3][780/781]\tTime  2.478 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 2.2203 (0.8415)\tD(fake)1 -0.9778 (-0.7796)\tD(fake)2 0.0733 (-0.7169)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2702 (-0.5471)\tD repr loss -0.5241 (-0.5390)\n",
            "Epoch: [4][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.8081 (0.7539)\tD(fake)1 -1.3391 (-1.3391)\tD(fake)2 -0.3162 (-0.8491)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5887 (-0.5887)\tD repr loss -0.5398 (-0.5436)\n",
            "Epoch: [4][120/781]\tTime  2.512 ( 2.532)\tData  0.000 ( 0.000)\tD(real) 1.0919 (0.8192)\tD(fake)1 0.5860 (-0.6618)\tD(fake)2 -0.5815 (-0.7060)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5304 (-0.5848)\tD repr loss -0.5274 (-0.5455)\n",
            "Epoch: [4][230/781]\tTime  2.537 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 0.2897 (0.8083)\tD(fake)1 0.4403 (-0.6237)\tD(fake)2 -0.9762 (-0.7210)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6060 (-0.5891)\tD repr loss -0.4983 (-0.5525)\n",
            "Epoch: [4][340/781]\tTime  2.506 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 1.6850 (0.8379)\tD(fake)1 -0.1968 (-0.6632)\tD(fake)2 -0.1194 (-0.7093)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4910 (-0.5827)\tD repr loss -0.4688 (-0.5479)\n",
            "Epoch: [4][450/781]\tTime  2.523 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 2.1708 (0.8347)\tD(fake)1 -0.3095 (-0.6863)\tD(fake)2 0.2754 (-0.7052)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6001 (-0.5880)\tD repr loss -0.5478 (-0.5489)\n",
            "Epoch: [4][560/781]\tTime  2.469 ( 2.510)\tData  0.000 ( 0.000)\tD(real) 1.4922 (0.8318)\tD(fake)1 -0.4150 (-0.6974)\tD(fake)2 -0.5346 (-0.7079)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5734 (-0.5843)\tD repr loss -0.4458 (-0.5482)\n",
            "Epoch: [4][670/781]\tTime  2.506 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 2.2994 (0.8342)\tD(fake)1 -0.7586 (-0.7209)\tD(fake)2 0.3973 (-0.7098)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6006 (-0.5800)\tD repr loss -0.5325 (-0.5489)\n",
            "Epoch: [4][780/781]\tTime  2.516 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.3860 (0.8325)\tD(fake)1 -0.2030 (-0.7086)\tD(fake)2 -0.2053 (-0.7115)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6266 (-0.5810)\tD repr loss -0.5238 (-0.5476)\n",
            "Epoch: [4][780/781]\tTime  2.485 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.3860 (0.8325)\tD(fake)1 -0.2030 (-0.7086)\tD(fake)2 -0.2053 (-0.7115)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6266 (-0.5810)\tD repr loss -0.5238 (-0.5476)\n",
            "Epoch: [5][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.2906 (0.7000)\tD(fake)1 -1.1625 (-1.1625)\tD(fake)2 -1.3484 (-0.7868)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4336 (-0.4336)\tD repr loss -0.5282 (-0.5213)\n",
            "Epoch: [5][120/781]\tTime  2.517 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 0.8852 (0.8226)\tD(fake)1 -0.7006 (-0.5970)\tD(fake)2 -0.7310 (-0.6794)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5830 (-0.5237)\tD repr loss -0.5405 (-0.5229)\n",
            "Epoch: [5][230/781]\tTime  2.523 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 1.6334 (0.8413)\tD(fake)1 -0.4574 (-0.6236)\tD(fake)2 -0.1767 (-0.6808)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6437 (-0.5370)\tD repr loss -0.5303 (-0.5299)\n",
            "Epoch: [5][340/781]\tTime  2.487 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 1.5730 (0.8234)\tD(fake)1 -0.4852 (-0.7407)\tD(fake)2 -0.1930 (-0.6997)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5531 (-0.5366)\tD repr loss -0.5157 (-0.5360)\n",
            "Epoch: [5][450/781]\tTime  2.479 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 1.5445 (0.8316)\tD(fake)1 -0.6898 (-0.7259)\tD(fake)2 -1.0549 (-0.7070)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5326 (-0.5353)\tD repr loss -0.2959 (-0.5394)\n",
            "Epoch: [5][560/781]\tTime  2.527 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.8299 (0.8349)\tD(fake)1 -1.1880 (-0.6798)\tD(fake)2 -0.6608 (-0.7040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5402 (-0.5391)\tD repr loss -0.5398 (-0.5381)\n",
            "Epoch: [5][670/781]\tTime  2.529 ( 2.513)\tData  0.000 ( 0.000)\tD(real) -0.4900 (0.8276)\tD(fake)1 -0.3508 (-0.6786)\tD(fake)2 -1.4984 (-0.7078)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5567 (-0.5473)\tD repr loss -0.5013 (-0.5417)\n",
            "Epoch: [5][780/781]\tTime  2.521 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 1.1635 (0.8312)\tD(fake)1 -0.5912 (-0.6941)\tD(fake)2 -0.5761 (-0.7083)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6096 (-0.5516)\tD repr loss -0.5590 (-0.5418)\n",
            "Epoch: [5][780/781]\tTime  2.521 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 1.1635 (0.8312)\tD(fake)1 -0.5912 (-0.6941)\tD(fake)2 -0.5761 (-0.7083)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6096 (-0.5516)\tD repr loss -0.5590 (-0.5418)\n",
            "Epoch: [6][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.4534 (0.7205)\tD(fake)1 -0.8941 (-0.8941)\tD(fake)2 -1.4772 (-0.7280)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5285 (-0.5285)\tD repr loss -0.5774 (-0.5572)\n",
            "Epoch: [6][120/781]\tTime  2.509 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.0670 (0.8621)\tD(fake)1 -0.5969 (-0.6282)\tD(fake)2 -0.4518 (-0.6997)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6497 (-0.5860)\tD repr loss -0.5218 (-0.5420)\n",
            "Epoch: [6][230/781]\tTime  2.536 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 1.5155 (0.8661)\tD(fake)1 -0.4972 (-0.7389)\tD(fake)2 -0.4066 (-0.7132)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6693 (-0.5825)\tD repr loss -0.4718 (-0.5415)\n",
            "Epoch: [6][340/781]\tTime  2.529 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 0.6100 (0.8476)\tD(fake)1 -0.9026 (-0.7370)\tD(fake)2 -0.8224 (-0.7132)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5612 (-0.5897)\tD repr loss -0.5142 (-0.5453)\n",
            "Epoch: [6][450/781]\tTime  2.469 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 1.5235 (0.8544)\tD(fake)1 -0.5303 (-0.7806)\tD(fake)2 -0.0747 (-0.7168)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6143 (-0.5855)\tD repr loss -0.5664 (-0.5476)\n",
            "Epoch: [6][560/781]\tTime  2.518 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.8573 (0.8542)\tD(fake)1 -0.2514 (-0.7455)\tD(fake)2 -1.0430 (-0.7179)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6742 (-0.5907)\tD repr loss -0.4934 (-0.5487)\n",
            "Epoch: [6][670/781]\tTime  2.533 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 0.6034 (0.8422)\tD(fake)1 -1.1628 (-0.7067)\tD(fake)2 -0.9467 (-0.7194)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5780 (-0.5837)\tD repr loss -0.5593 (-0.5479)\n",
            "Epoch: [6][780/781]\tTime  2.472 ( 2.509)\tData  0.000 ( 0.000)\tD(real) 1.2809 (0.8445)\tD(fake)1 -0.3855 (-0.7271)\tD(fake)2 -0.4130 (-0.7234)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4918 (-0.5760)\tD repr loss -0.5296 (-0.5448)\n",
            "Epoch: [6][780/781]\tTime  2.458 ( 2.508)\tData  0.000 ( 0.000)\tD(real) 1.2809 (0.8445)\tD(fake)1 -0.3855 (-0.7271)\tD(fake)2 -0.4130 (-0.7234)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4918 (-0.5760)\tD repr loss -0.5296 (-0.5448)\n",
            "Epoch: [7][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.1064 (0.7528)\tD(fake)1 -1.1653 (-1.1653)\tD(fake)2 -1.2338 (-0.7950)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6308 (-0.6308)\tD repr loss -0.5274 (-0.5520)\n",
            "Epoch: [7][120/781]\tTime  2.481 ( 2.525)\tData  0.000 ( 0.000)\tD(real) 1.6659 (0.8939)\tD(fake)1 -0.3640 (-0.5991)\tD(fake)2 0.0337 (-0.7156)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5891 (-0.5966)\tD repr loss -0.4316 (-0.5412)\n",
            "Epoch: [7][230/781]\tTime  2.470 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.4294 (0.8738)\tD(fake)1 -0.3008 (-0.7214)\tD(fake)2 -0.3119 (-0.7124)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6174 (-0.5787)\tD repr loss -0.4937 (-0.5428)\n",
            "Epoch: [7][340/781]\tTime  2.514 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 2.3611 (0.8825)\tD(fake)1 -0.1206 (-0.6925)\tD(fake)2 0.8323 (-0.7106)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6322 (-0.5842)\tD repr loss -0.4676 (-0.5434)\n",
            "Epoch: [7][450/781]\tTime  2.527 ( 2.514)\tData  0.000 ( 0.000)\tD(real) -0.0189 (0.8770)\tD(fake)1 -0.4056 (-0.7149)\tD(fake)2 -1.3636 (-0.7225)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6198 (-0.5786)\tD repr loss -0.4823 (-0.5435)\n",
            "Epoch: [7][560/781]\tTime  2.522 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.3420 (0.8752)\tD(fake)1 -0.1509 (-0.7276)\tD(fake)2 -0.5529 (-0.7175)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5710 (-0.5787)\tD repr loss -0.5711 (-0.5432)\n",
            "Epoch: [7][670/781]\tTime  2.495 ( 2.517)\tData  0.000 ( 0.000)\tD(real) -0.0043 (0.8680)\tD(fake)1 -1.2644 (-0.7037)\tD(fake)2 -1.2526 (-0.7192)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6195 (-0.5776)\tD repr loss -0.5460 (-0.5431)\n",
            "Epoch: [7][780/781]\tTime  2.496 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.0730 (0.8753)\tD(fake)1 -1.2349 (-0.7091)\tD(fake)2 -1.2504 (-0.7157)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5663 (-0.5722)\tD repr loss -0.5313 (-0.5428)\n",
            "Epoch: [7][780/781]\tTime  2.493 ( 2.516)\tData  0.000 ( 0.000)\tD(real) 0.0730 (0.8753)\tD(fake)1 -1.2349 (-0.7091)\tD(fake)2 -1.2504 (-0.7157)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5663 (-0.5722)\tD repr loss -0.5313 (-0.5428)\n",
            "Epoch: [8][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.8983 (0.9922)\tD(fake)1 -0.6621 (-0.6621)\tD(fake)2 -0.7422 (-0.7289)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5000 (-0.5000)\tD repr loss -0.5035 (-0.5096)\n",
            "Epoch: [8][120/781]\tTime  2.505 ( 2.528)\tData  0.000 ( 0.000)\tD(real) 1.5865 (0.8694)\tD(fake)1 -1.4682 (-0.8688)\tD(fake)2 -0.2343 (-0.6884)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1581 (-0.5318)\tD repr loss -0.5514 (-0.5392)\n",
            "Epoch: [8][230/781]\tTime  2.525 ( 2.524)\tData  0.000 ( 0.000)\tD(real) 0.0406 (0.8546)\tD(fake)1 0.7088 (-0.7395)\tD(fake)2 -1.1993 (-0.6987)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6406 (-0.5630)\tD repr loss -0.5053 (-0.5385)\n",
            "Epoch: [8][340/781]\tTime  2.471 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 1.9995 (0.8517)\tD(fake)1 -0.5342 (-0.7279)\tD(fake)2 0.1628 (-0.7016)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5699 (-0.5717)\tD repr loss -0.5374 (-0.5418)\n",
            "Epoch: [8][450/781]\tTime  2.511 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.0051 (0.8419)\tD(fake)1 -0.1929 (-0.7448)\tD(fake)2 -0.6022 (-0.7090)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6161 (-0.5776)\tD repr loss -0.5544 (-0.5467)\n",
            "Epoch: [8][560/781]\tTime  2.535 ( 2.518)\tData  0.000 ( 0.000)\tD(real) 0.2772 (0.8268)\tD(fake)1 -1.4137 (-0.7636)\tD(fake)2 -1.1003 (-0.7103)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4618 (-0.5727)\tD repr loss -0.5619 (-0.5483)\n",
            "Epoch: [8][670/781]\tTime  2.528 ( 2.520)\tData  0.000 ( 0.000)\tD(real) 1.9962 (0.8309)\tD(fake)1 -0.3593 (-0.7335)\tD(fake)2 0.3430 (-0.7059)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5985 (-0.5730)\tD repr loss -0.5300 (-0.5479)\n",
            "Epoch: [8][780/781]\tTime  2.515 ( 2.517)\tData  0.000 ( 0.000)\tD(real) -0.4090 (0.8311)\tD(fake)1 -0.8007 (-0.7592)\tD(fake)2 -1.5777 (-0.7097)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4013 (-0.5718)\tD repr loss -0.4535 (-0.5473)\n",
            "Epoch: [8][780/781]\tTime  2.484 ( 2.516)\tData  0.000 ( 0.000)\tD(real) -0.4090 (0.8311)\tD(fake)1 -0.8007 (-0.7592)\tD(fake)2 -1.5777 (-0.7097)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4013 (-0.5718)\tD repr loss -0.4535 (-0.5473)\n",
            "Epoch: [9][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.3235 (0.9454)\tD(fake)1 -0.2748 (-0.2748)\tD(fake)2 -0.4255 (-0.6597)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.4709 (-0.4709)\tD repr loss -0.5040 (-0.5034)\n",
            "Epoch: [9][120/781]\tTime  2.505 ( 2.526)\tData  0.000 ( 0.000)\tD(real) 1.9043 (0.8648)\tD(fake)1 -0.0531 (-0.6819)\tD(fake)2 0.0460 (-0.7019)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6428 (-0.5762)\tD repr loss -0.5219 (-0.5456)\n",
            "Epoch: [9][230/781]\tTime  2.492 ( 2.514)\tData  0.000 ( 0.000)\tD(real) 1.2212 (0.8593)\tD(fake)1 -0.3251 (-0.6886)\tD(fake)2 -0.1919 (-0.7078)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5843 (-0.5866)\tD repr loss -0.5055 (-0.5465)\n",
            "Epoch: [9][340/781]\tTime  2.534 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.6476 (0.8478)\tD(fake)1 -1.2705 (-0.7429)\tD(fake)2 -0.9824 (-0.7108)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6271 (-0.5844)\tD repr loss -0.5268 (-0.5482)\n",
            "Epoch: [9][450/781]\tTime  2.519 ( 2.513)\tData  0.000 ( 0.000)\tD(real) 0.1080 (0.8398)\tD(fake)1 -0.9625 (-0.7308)\tD(fake)2 -1.2621 (-0.7178)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6431 (-0.5776)\tD repr loss -0.5333 (-0.5474)\n",
            "Epoch: [9][560/781]\tTime  2.534 ( 2.512)\tData  0.000 ( 0.000)\tD(real) 1.3540 (0.8406)\tD(fake)1 0.9054 (-0.6357)\tD(fake)2 -0.1435 (-0.7128)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5793 (-0.5752)\tD repr loss -0.4998 (-0.5469)\n",
            "Epoch: [9][670/781]\tTime  2.539 ( 2.515)\tData  0.000 ( 0.000)\tD(real) 1.8634 (0.8414)\tD(fake)1 -0.5547 (-0.6421)\tD(fake)2 0.0440 (-0.7119)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6404 (-0.5732)\tD repr loss -0.5379 (-0.5478)\n",
            "Epoch: [9][780/781]\tTime  2.480 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.1801 (0.8400)\tD(fake)1 -0.4920 (-0.6567)\tD(fake)2 -0.5358 (-0.7126)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3892 (-0.5701)\tD repr loss -0.4795 (-0.5469)\n",
            "Epoch: [9][780/781]\tTime  2.513 ( 2.511)\tData  0.000 ( 0.000)\tD(real) 1.1801 (0.8400)\tD(fake)1 -0.4920 (-0.6567)\tD(fake)2 -0.5358 (-0.7126)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3892 (-0.5701)\tD repr loss -0.4795 (-0.5469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhsj8_owgDSl",
        "outputId": "c8b905e2-c057-4656-a904-e82f36dc17bd"
      },
      "source": [
        "args.G_consistency = 0.1\n",
        "args.D_consistency = 0.1\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0][ 10/781]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) -0.5058 (0.8233)\tD(fake)1 -0.7195 (-0.7195)\tD(fake)2 -1.6718 (-0.7904)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5287 (-0.5287)\tD repr loss -0.5199 (-0.5619)\n",
            "Epoch: [0][120/781]\tTime  2.553 ( 2.529)\tData  0.000 ( 0.000)\tD(real) 0.0807 (0.8248)\tD(fake)1 -1.0137 (-0.7171)\tD(fake)2 -1.3882 (-0.7565)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5815 (-0.5134)\tD repr loss -0.5668 (-0.5475)\n",
            "Epoch: [0][230/781]\tTime  2.535 ( 2.523)\tData  0.000 ( 0.000)\tD(real) 0.1271 (0.8707)\tD(fake)1 -1.2562 (-0.7315)\tD(fake)2 -1.1752 (-0.7425)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.6527 (-0.5541)\tD repr loss -0.5731 (-0.5439)\n",
            "Epoch: [0][340/781]\tTime  2.514 ( 2.519)\tData  0.000 ( 0.000)\tD(real) 0.9182 (0.8884)\tD(fake)1 -0.4967 (-0.7112)\tD(fake)2 -0.4424 (-0.7266)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.5014 (-0.5362)\tD repr loss -0.5180 (-0.5363)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxlmBIutPfw"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iepY_Go7tf7Y"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5V-0_k5tpiW"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdIo707ZyUic"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9naW-A2OGLMg"
      },
      "source": [
        "args.G_consistency = 1.\n",
        "args.D_consistency = 1.\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzUaCS1tS8YV"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKWZPniqS5uX"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYyP-fb7S-WE"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jC0_2Vt4Yd6"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpaUfV94ZJI"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Bh97MA4aCW"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMSlrEvie7Pa"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvYdbtKQe_2-"
      },
      "source": [
        "def show_grid(grid):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(grid.permute(1,2,0))\n",
        "\n",
        "def sample_interpolated_repr(real1, real2):\n",
        "    repr1, repr2 = get_repr(real1), get_repr(real2)\n",
        "    repr = slerp(repr1, repr2)\n",
        "    #repr = lerp(repr1, repr2)\n",
        "    return repr\n",
        "\n",
        "def show_sample(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    #plt.hist(F.normalize(simsiam.encoder(x)).detach()[0].cpu().numpy()); return\n",
        "    x1 = x.cuda(args.gpu)[:16]\n",
        "    x2 = x.cuda(args.gpu)[16:32]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_fake1 = sample_G(sample_interpolated_repr(x1, x2))\n",
        "        x_fake2 = sample_G(sample_interpolated_repr(x1, x2))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "data_sampler = iter(train_loader)\n",
        "show_sample(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gfx3T5m2wah"
      },
      "source": [
        "def show_sample2(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    x = x.cuda(args.gpu)[:16]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_fake = sample_G(get_repr(x))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake).cpu(), padding=2, nrow=4))\n",
        "\n",
        "show_sample2(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKfockIQPyzO"
      },
      "source": [
        "def show_sample3(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    x = x.cuda(args.gpu)[:16]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        repr1 = -1+2*torch.rand(16, args.repr_dim).cuda(args.gpu)\n",
        "        repr2 = torch.randn(16, args.repr_dim).cuda(args.gpu)\n",
        "        x_fake1 = sample_G(repr1)\n",
        "        x_fake2 = sample_G(repr2)\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "show_sample3(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtDpMGCMid7O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU296umGlbxU"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqJajcHmlcOD"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itX7h7kylcnQ"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuR7QOUQlc7p"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2wAhFAbldNu"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZDNQca57Hif"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Metrics"
      ],
      "metadata": {
        "id": "fOJDDiKcl_Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Samples"
      ],
      "metadata": {
        "id": "amfnRSk_nF6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLES_DIR = f\"{GANSIAM_DIR}/generated_samples\"\n",
        "NUM_SAMPLES = 10000\n",
        "! mkdir \"{SAMPLES_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9iP0Jgy0ZtY",
        "outputId": "abb1d6c2-c94d-4708-b8a6-f54e171ec346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/gansiam/generated_samples’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset loader to sample repr\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "    transform=transforms.Compose(augmentation))\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=0, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "metadata": {
        "id": "58HfLOhYoq9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model.eval()\n",
        "im_idx = 0\n",
        "for _ in tqdm(range(NUM_SAMPLES // (len(train_loader) * args.batch_size) + 1)):\n",
        "    for x, _ in tqdm(train_loader):\n",
        "        if im_idx > NUM_SAMPLES:\n",
        "            break\n",
        "        x = x.cuda(args.gpu)\n",
        "        with torch.no_grad():\n",
        "            repr = get_repr(x)\n",
        "            noise = sample_noise(args.batch_size).cuda(args.gpu)\n",
        "            z = latent_transform(repr, noise)\n",
        "            x_fake = model.G(z, repr)\n",
        "        for batch_idx in range(args.batch_size):\n",
        "            save_image(x_fake[batch_idx], f\"{SAMPLES_DIR}/{im_idx:04}.png\",\n",
        "                       normalize=True, range=(-1,1))\n",
        "            im_idx += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "ce15db1308cf4137a2651c8dfe89f3c2",
            "8703519d345d4810b176a58f12e00af3",
            "9442ab6eda044d92a55b12aadd92a654",
            "2444b40302af4c889a2ae77e7c01a3b3",
            "5b87e2d7c84e41d390d9b563c688a7b7",
            "28ea9c3081944102a13d7b6d3857eeb1",
            "d822e29f9bde48b69ed5d7190fb60cef",
            "ecef038dece54a0ab78ad42ac9512dea",
            "4b8dbe767bb9460bba2e7b209d16fdf8",
            "6a11c43e1ef24e8a9a6bbbac57f00baa",
            "68328d286f264b8a9af2596a229ddb0a",
            "d80138f64466454e9e4b082a2ca9ae2d",
            "2435793fc4104ff28dd4f7331d190de7",
            "e1670c2b447a4f4aa3a90cf43063099c",
            "57845f65f9ed4616a94a8705c24a5633",
            "c2a0baa293da4d80882a040cc2213d05",
            "94b490b78049466e9841e8d19375bab3",
            "81ec79b2732541c68192101ea5ed93c5",
            "fe4dc33999b2426cb90c315f0132315f",
            "27db98ab6d5540b98eacbc5533566cee",
            "e40ed04938fd43c4806e148878ebd31b",
            "168e2b0a3f9846aaa4da5fa989d4ee43"
          ]
        },
        "id": "hjdpBkcUtJtM",
        "outputId": "82b43974-c135-4711-9acc-3af2df80391d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce15db1308cf4137a2651c8dfe89f3c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d80138f64466454e9e4b082a2ca9ae2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/781 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception Score"
      ],
      "metadata": {
        "id": "w00eHq1ltw41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sbarratt/inception-score-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XUf5i4o6brj",
        "outputId": "5fc88231-e41f-4d29-977e-49eedc2b9763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'inception-score-pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd inception-score-pytorch\n",
        "from inception_score import inception_score\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUBqMUnamS77",
        "outputId": "28987e77-ae00-4971-af9d-d1f6dcb1c33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/inception-score-pytorch\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Images(torch.utils.data.Dataset):\n",
        "    def __init__(self, main_dir, transform=None):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        all_imgs = os.listdir(main_dir)\n",
        "        self.total_imgs = sorted(all_imgs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
        "        image = Image.open(img_loc).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            tensor_image = self.transform(image)\n",
        "        else:\n",
        "            tensor_image = torch.Tensor(image)\n",
        "        return tensor_image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "samples_dataset = Images(SAMPLES_DIR, transform)"
      ],
      "metadata": {
        "id": "8BNlMvEeve07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_score(samples_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BWuNsEPm6O2",
        "outputId": "28af6e8f-3541-4c1d-aad7-7ef8c2545d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/inception-score-pytorch/inception_score.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x).data.cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.390274434158649, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FID"
      ],
      "metadata": {
        "id": "e1jht22Lxtt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caGUOYRfxwvT",
        "outputId": "e1044bb5-4ede-42c2-db2b-7f73b4b409a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch-fid-0.2.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (3.10.0.2)\n",
            "Building wheels for collected packages: pytorch-fid\n",
            "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.1-py3-none-any.whl size=14835 sha256=b9bc2b25138faafe83b7bbaf0976cc2611cf27f577434f011a84cee638138e24\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/ac/03/c5634775c8a64f702343ef5923278f8d3bb8c651debc4a6890\n",
            "Successfully built pytorch-fid\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"{TINYIMAGENET_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXrQF37bFsku",
        "outputId": "6274e097-c073-4db6-be52-2d7a774f24f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiny-imagenet-200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten tiny imagenet\n",
        "! rm -rf flattinyimagenet && mkdir -p flattinyimagenet\n",
        "! for folder in \"tiny-imagenet-200\"/train/*; do for im in \"$folder\"/images/*; do cp \"$(echo $im | tr 'A-Z' 'a-z')\" flattinyimagenet ; done; done"
      ],
      "metadata": {
        "id": "IaMFBXuBCrsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pytorch_fid --device cuda:0 flattinyimagenet \"{SAMPLES_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEruFG3__bTv",
        "outputId": "682169ca-873b-4165-d3c2-1b62bc717b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 1638400000 bytes == 0x5629ab83a000 @  0x7f13b71661e7 0x7f13b4c6646e 0x7f13b4cb6c7b 0x7f13b4cb735f 0x7f13b4d59103 0x5629299fb4b0 0x5629299fb240 0x562929a6f0f3 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x562929a69ced 0x5629299fcbda 0x562929a6a915 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x5629299fcafa 0x562929a6ed00 0x562929a699ee 0x562929a696f3 0x562929a67b60 0x5629299fb349 0x5629299fb240 0x562929a6e973 0x562929a699ee 0x5629299fcbda 0x562929a6a915\n",
            "100% 2000/2000 [04:04<00:00,  8.19it/s]\n",
            "tcmalloc: large alloc 1638400000 bytes == 0x562a0d2ea000 @  0x7f13b71661e7 0x7f13b4c6646e 0x7f13b4cb6c7b 0x7f13b4cb6d97 0x7f13b4cb04a5 0x7f13b4d5b823 0x5629299fb544 0x5629299fb240 0x562929a6f627 0x562929a699ee 0x56292993be2b 0x7f13b4ca3ef7 0x5629299fb437 0x5629299fb240 0x562929a6e973 0x562929a699ee 0x5629299fcbda 0x562929a6b737 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x562929a69ced 0x5629299fcbda 0x562929a6a915 0x562929a699ee 0x5629299fcbda 0x562929a6a915 0x5629299fcafa 0x562929a6ed00 0x562929a699ee 0x562929a696f3\n",
            "100% 203/203 [00:29<00:00,  6.90it/s]\n",
            "FID:  230.0156421720286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5e8mEUXaCZ5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}