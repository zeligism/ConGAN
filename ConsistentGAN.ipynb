{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConsistentGAN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/ConGAN/blob/main/ConsistentGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxx3Jy_8qsPE"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFx20xTNkpQ",
        "outputId": "7e5e306b-773f-4c33-9bef-32954ef48826"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QNzdq01hSb"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlF68ff2K8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_Qrpq7z3iJ"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import log2\n",
        "from pprint import pformat\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDduLe1Qkd9"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRxrufxw1cm"
      },
      "source": [
        "### Report Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmEyNG58w2kJ"
      },
      "source": [
        "def plot_lines(losses_dict, filename=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots the losses of the discriminator and the generator.\n",
        "\n",
        "    Args:\n",
        "        filename: The plot's filename. If None, plot won't be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(title)\n",
        "    for label, losses in losses_dict.items():\n",
        "        plt.plot(losses, label=label)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.legend()\n",
        "    \n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def create_progress_animation(frames, filename):\n",
        "    \"\"\"\n",
        "    Creates a video of the progress of the generator on a fixed latent vector.\n",
        "\n",
        "    Args:\n",
        "        filename: The animation's filename.\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    ims = [[plt.imshow(img.permute(1,2,0), animated=True)]\n",
        "           for img in frames]\n",
        "    ani = animation.ArtistAnimation(fig, ims, blit=True)\n",
        "    \n",
        "    ani.save(filename)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def generate_grid(generator, latent):\n",
        "    \"\"\"\n",
        "    Check generator's output on latent vectors and return it.\n",
        "\n",
        "    Args:\n",
        "        generator: The generator.\n",
        "        latent: Latent vector from which an image grid will be generated.\n",
        "\n",
        "    Returns:\n",
        "        A grid of images generated by `generator` from `latent`.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(latent).detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(fake.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzwGurc1qOx"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhc2oS53G4e"
      },
      "source": [
        "## PyTorch Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU7HFc6t5N8w"
      },
      "source": [
        "### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHPo8w13JmH"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding half the size of features,\n",
        "    e.g. if input is [in_channels, 64, 64], output will be [out_channels, 32, 32].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.conv = nn.utils.parametrizations.spectral_norm(self.conv)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.LeakyReLU(0.2, inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding double the size of features,\n",
        "    e.g. if input is [in_channels, 32, 32], output will be [out_channels, 64, 64].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.convT = nn.utils.parametrizations.spectral_norm(self.convT)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.ReLU(inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convT(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=16,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,\n",
        "                 D_block=ConvBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        using_grad_penalty = gan_type in (\"gan-gp\", \"wgan-gp\")\n",
        "        output_sigmoid = output_sigmoid and gan_type in (\"gan\", \"gan-gp\")\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm and not using_grad_penalty,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Input layer\n",
        "        self.input_layer = D_block(image_channels, features[0], **block_config)\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            D_block(in_features, out_features, **block_config)\n",
        "            for in_features, out_features in zip(features, features[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer (feature_size = 3, 4, or 5 -> 1)\n",
        "        if fully_convolutional:\n",
        "            conv = nn.Conv2d(features[-1], num_latents, latent_kernel, bias=False)\n",
        "            if use_spectralnorm:\n",
        "                conv = nn.utils.parametrizations.spectral_norm(conv)\n",
        "            self.output_layer = nn.Sequential(conv, nn.Flatten())\n",
        "        else:\n",
        "            linear = nn.Linear(features[-1] * latent_kernel**2, num_latents, bias=False)\n",
        "            if use_spectralnorm:\n",
        "                linear = nn.utils.parametrizations.spectral_norm(linear)\n",
        "            self.output_layer = nn.Sequential(nn.Flatten(), linear)\n",
        "        \n",
        "        self.hidden_dim = features[-1] * latent_kernel**2\n",
        "\n",
        "        # Add sigmoid activation if using regular GAN loss\n",
        "        self.output_activation = nn.Sigmoid() if output_sigmoid else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        if self.output_activation:\n",
        "            x = self.output_activation(x)\n",
        "        # Remove H and W dimensions, infer channels dim (remove if 1)\n",
        "        x = x.view(x.size(0), -1).squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 G_block=ConvTBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Reverse order of image sizes and features for generator\n",
        "        image_sizes = image_sizes[::-1]\n",
        "        features = features[::-1]\n",
        "\n",
        "        # Input layer\n",
        "        if fully_convolutional:\n",
        "            self.input_layer = G_block(num_latents, features[0], kernel_size=latent_kernel,\n",
        "                                       stride=1, padding=0, **block_config)\n",
        "        else:\n",
        "            self.input_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(num_latents, features[0] * image_sizes[0]**2, bias=False),\n",
        "                View(features[0], image_sizes[0], image_sizes[0])\n",
        "            )\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            G_block(in_features, out_features, kernel_size=4+(expected_size%2), **block_config)\n",
        "            for in_features, out_features, expected_size in zip(features, features[1:], image_sizes[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.ConvTranspose2d(features[-1], image_channels, kernel_size=4+(image_size%2),\n",
        "                                               stride=2, padding=1, bias=False)\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add H and W dimensions, infer channels dim (add if none)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = self.output_activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    \"\"\"Deep Convolutional Generative Adversarial Network\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 D_num_features=64,\n",
        "                 G_num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,):\n",
        "        \"\"\"\n",
        "        Initializes DCGAN.\n",
        "\n",
        "        Args:\n",
        "            num_latents: Number of latent factors.\n",
        "            num_features: Number of features in the convolutions.\n",
        "            image_channels: Number of channels in the input image.\n",
        "            image_size: Size (i.e. height or width) of image.\n",
        "            gan_type: Type of GAN (e.g. \"gan\" or \"wgan-gp\").\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_latents = num_latents\n",
        "        self.D_num_features = D_num_features\n",
        "        self.G_num_features = G_num_features\n",
        "        self.image_channels = image_channels\n",
        "        self.image_size = image_size\n",
        "        self.feature_multiplier = feature_multiplier\n",
        "        self.gan_type = gan_type\n",
        "        self.fully_convolutional = fully_convolutional\n",
        "        self.activation = activation\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.use_spectralnorm = use_spectralnorm\n",
        "\n",
        "        D_params = {\n",
        "            \"num_latents\": 1,  # XXX\n",
        "            \"num_features\": D_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "            \"output_sigmoid\": output_sigmoid,\n",
        "        }\n",
        "        G_params = {\n",
        "            \"num_latents\": num_latents,\n",
        "            \"num_features\": G_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": True,\n",
        "            \"use_spectralnorm\": False,  # XXX\n",
        "        }\n",
        "\n",
        "        self.D = DCGAN_Discriminator(**D_params)\n",
        "        self.G = DCGAN_Generator(**G_params)\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape, including_batch=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.including_batch = including_batch\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.including_batch:\n",
        "            return x.view(*self.shape)\n",
        "        else:\n",
        "            return x.view(x.size(0), *self.shape)\n",
        "\n",
        "class ChannelNoise(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel noise injection module.\n",
        "    Adds a linearly transformed noise to a convolution layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, std=0.02):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise_size = [x.size()[0], 1, *x.size()[2:]]  # single channel\n",
        "        noise = self.std * torch.randn(noise_size).to(x)\n",
        "\n",
        "        return x + self.scale * noise"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSPvaklIYvwT"
      },
      "source": [
        "### Third-party modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9B8z4ZY4oX"
      },
      "source": [
        "#### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLNQ90KUY_Is"
      },
      "source": [
        "class ConditionalBatchNorm2d(nn.Module):\n",
        "  def __init__(self, num_features, repr_dim):\n",
        "    super().__init__()\n",
        "    self.num_features = num_features\n",
        "    self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
        "    self.embed = nn.Linear(repr_dim, num_features * 2)\n",
        "    self.embed.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
        "    self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    out = self.bn(x)\n",
        "    gamma, beta = self.embed(y).chunk(2, 1)\n",
        "    out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
        "    return out\n",
        "\n",
        "\n",
        "#https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class SNDCGAN_Generator(nn.Module):\n",
        "    def __init__(self, z_dim, image_size=32, num_features=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(z_dim, 8*num_features, 4, stride=1)\n",
        "        self.bn1 = ConditionalBatchNorm2d(8*num_features, repr_dim)\n",
        "        self.conv2 = nn.ConvTranspose2d(8*num_features, 4*num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn2 = ConditionalBatchNorm2d(4*num_features, repr_dim)\n",
        "        self.conv3 = nn.ConvTranspose2d(4*num_features, 2*num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn3 = ConditionalBatchNorm2d(2*num_features, repr_dim)\n",
        "        self.conv4 = nn.ConvTranspose2d(2*num_features, num_features, 4, stride=2, padding=(1,1))\n",
        "        self.bn4 = ConditionalBatchNorm2d(num_features, repr_dim)\n",
        "\n",
        "        if image_size == 64:\n",
        "            self.conv5 = nn.ConvTranspose2d(num_features, num_features//2, 4, stride=2, padding=(1,1))\n",
        "            self.bn5 = ConditionalBatchNorm2d(num_features//2, repr_dim)\n",
        "            self.final_conv = nn.ConvTranspose2d(num_features//2, channels, 3, stride=1, padding=(1,1))\n",
        "        else:\n",
        "            self.conv5 = None\n",
        "            self.bn5 = None\n",
        "            self.final_conv = nn.ConvTranspose2d(num_features, channels, 3, stride=1, padding=(1,1))\n",
        "\n",
        "        self.block_activation = nn.ReLU()\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, z, repr=None):\n",
        "        h = z.view(-1, self.z_dim, 1, 1)\n",
        "        h = self.block_activation(self.bn1(self.conv1(h), repr))\n",
        "        h = self.block_activation(self.bn2(self.conv2(h), repr))\n",
        "        h = self.block_activation(self.bn3(self.conv3(h), repr))\n",
        "        h = self.block_activation(self.bn4(self.conv4(h), repr))\n",
        "        if self.conv5 is not None:\n",
        "            h = self.block_activation(self.bn5(self.conv5(h), repr))\n",
        "        return self.output_activation(self.final_conv(h))\n",
        "\n",
        "class SNDCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self, image_size=32, num_features=64, channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(channels, num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(num_features, num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(num_features, 2*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(2*num_features, 2*num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(2*num_features, 4*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(4*num_features, 4*num_features, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(4*num_features, 8*num_features, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "\n",
        "        if image_size == 64:\n",
        "            self.from64 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(8*num_features, 8*num_features, 3, stride=2, padding=(1,1))),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "                spectral_norm(nn.Conv2d(8*num_features, 16*num_features, 3, stride=1, padding=(1,1))),\n",
        "                nn.LeakyReLU(0.1, inplace=True),\n",
        "            )\n",
        "            self.hidden_dim = 4*4 * 16*num_features\n",
        "        else:\n",
        "            self.from64 = None\n",
        "            self.hidden_dim = 4*4 * 8*num_features\n",
        "\n",
        "        self.fc = spectral_norm(nn.Linear(self.hidden_dim, 1))\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.main(x)\n",
        "        if self.from64 is not None:\n",
        "            h = self.from64(h)\n",
        "        h = h.flatten(start_dim=1)\n",
        "        out = self.fc(h).squeeze(1)\n",
        "        if return_h:\n",
        "            return out, h\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class SNDCGAN(nn.Module):\n",
        "    def __init__(self, num_latents, image_size=32,\n",
        "                 D_num_features=64, G_num_features=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNDCGAN_Discriminator(channels=channels,\n",
        "                                       image_size=image_size,\n",
        "                                       num_features=D_num_features)\n",
        "        self.G = SNDCGAN_Generator(num_latents, channels=channels,\n",
        "                                   image_size=image_size,\n",
        "                                   num_features=G_num_features,\n",
        "                                   repr_dim=repr_dim)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiu_Ri-XY6yy"
      },
      "source": [
        "#### ResNet GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjWBbXzdlSF"
      },
      "source": [
        "# https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model_resnet.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class ResBlockGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, repr_dim=None):\n",
        "        super(ResBlockGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            self.conv1,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            self.conv2\n",
        "            )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "class ResBlockGeneratorConditional(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, repr_dim=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.bn1 = ConditionalBatchNorm2d(in_channels, repr_dim)\n",
        "        self.upsample = nn.Upsample(scale_factor=2)\n",
        "        self.bn2 = ConditionalBatchNorm2d(out_channels, repr_dim)\n",
        "\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x, repr):\n",
        "        h = F.relu(self.bn1(x, repr))\n",
        "        h = self.conv1(self.upsample(h))\n",
        "        h = F.relu(self.bn2(h, repr))\n",
        "        h = self.conv2(h)\n",
        "        return self.bypass(x) + h\n",
        "\n",
        "\n",
        "class ResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        if stride == 1:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2)\n",
        "                )\n",
        "        else:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "                )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "\n",
        "            self.bypass_conv = nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)\n",
        "            nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "            self.bypass = nn.Sequential(\n",
        "                spectral_norm(self.bypass_conv),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            )\n",
        "            # if in_channels == out_channels:\n",
        "            #     self.bypass = nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            # else:\n",
        "            #     self.bypass = nn.Sequential(\n",
        "            #         spectral_norm(nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)),\n",
        "            #         nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            #     )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "# special ResBlock just for the first layer of the discriminator\n",
        "class FirstResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(FirstResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        self.bypass_conv = nn.Conv2d(in_channels, out_channels, 1, 1, padding=0)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "        # we don't want to apply ReLU activation to raw image before convolution transformation.\n",
        "        self.model = nn.Sequential(\n",
        "            spectral_norm(self.conv1),\n",
        "            nn.ReLU(),\n",
        "            spectral_norm(self.conv2),\n",
        "            nn.AvgPool2d(2)\n",
        "            )\n",
        "        self.bypass = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            spectral_norm(self.bypass_conv),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "\n",
        "class SNResNetGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, num_features=128, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * num_features)\n",
        "        self.final = nn.Conv2d(num_features, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            ResBlockGenerator(num_features, num_features, stride=2),\n",
        "            nn.BatchNorm2d(num_features),\n",
        "            nn.ReLU(),\n",
        "            self.final,\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(self.dense(z).view(-1, self.num_features, 4, 4))\n",
        "\n",
        "class SNResNetGeneratorConditional(nn.Module):\n",
        "    def __init__(self, z_dim, num_features=128, image_size=32, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * num_features)\n",
        "        self.final = nn.Conv2d(num_features, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.block1 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        self.block2 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        self.block3 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        if image_size == 64:\n",
        "            self.block4 = ResBlockGeneratorConditional(num_features, num_features, stride=2, repr_dim=repr_dim)\n",
        "        else:\n",
        "            self.block4 = None\n",
        "        self.bn = ConditionalBatchNorm2d(num_features, repr_dim)\n",
        "\n",
        "    def forward(self, z, repr):\n",
        "        h = self.dense(z).view(-1, self.num_features, 4, 4)\n",
        "        h = self.block1(h, repr)\n",
        "        h = self.block2(h, repr)\n",
        "        h = self.block3(h, repr)\n",
        "        if self.block4 is not None:\n",
        "            h = self.block4(h, repr)\n",
        "        h = F.relu(self.bn(h, repr))\n",
        "        out = F.tanh(self.final(h))\n",
        "        return out\n",
        "\n",
        "\n",
        "class SNResNetDiscriminator(nn.Module):\n",
        "    def __init__(self, num_features=128, image_size=32, channels=3):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.hidden_dim = num_features\n",
        "        if image_size == 64:\n",
        "            self.hidden_dim *= 4\n",
        "\n",
        "        self.model = [\n",
        "                FirstResBlockDiscriminator(channels, num_features, stride=2),\n",
        "                ResBlockDiscriminator(num_features, num_features, stride=2),\n",
        "                ResBlockDiscriminator(num_features, num_features),\n",
        "                ResBlockDiscriminator(num_features, num_features),\n",
        "        ]\n",
        "        if image_size == 64:\n",
        "            self.model += [ResBlockDiscriminator(num_features, num_features)]\n",
        "        self.model += [nn.ReLU(), nn.AvgPool2d(8)]\n",
        "        self.model = nn.Sequential(*self.model)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
        "        nn.init.xavier_uniform_(self.fc.weight.data, 1.)\n",
        "        self.fc = spectral_norm(self.fc)\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.model(x)\n",
        "        h = h.view(-1, self.hidden_dim)\n",
        "        if return_h:\n",
        "            return self.fc(h), h\n",
        "        else:\n",
        "            return self.fc(h)\n",
        "\n",
        "\n",
        "class SNResNetGAN(nn.Module):\n",
        "    def __init__(self, num_latents,\n",
        "                 D_num_features=128, G_num_features=128,\n",
        "                 image_size=64, channels=3, repr_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNResNetDiscriminator(num_features=D_num_features,\n",
        "                                       image_size=image_size,\n",
        "                                       channels=channels)\n",
        "        self.G = SNResNetGeneratorConditional(num_latents,\n",
        "                                              num_features=G_num_features,\n",
        "                                              image_size=image_size,\n",
        "                                              channels=channels,\n",
        "                                              repr_dim=repr_dim)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYujBEzC7EOO"
      },
      "source": [
        "#### SimSiam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YcNut27F-v"
      },
      "source": [
        "class SimSiam(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a SimSiam model.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 2048)\n",
        "        pred_dim: hidden dimension of the predictor (default: 512)\n",
        "        \"\"\"\n",
        "        super(SimSiam, self).__init__()\n",
        "\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEuurkcmLLd3"
      },
      "source": [
        "### Latent Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTlMYVgLN5E"
      },
      "source": [
        "class LatentTransform(nn.Module):\n",
        "    def __init__(self, repr_dim, latent_dim, hidden_dim, full_transform=True, noop=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.full_transform = full_transform\n",
        "        self.noop = noop\n",
        "\n",
        "        if self.noop:\n",
        "            self.output_dim = self.latent_dim\n",
        "            return\n",
        "        elif self.full_transform:\n",
        "            self.input_dim = self.repr_dim + self.latent_dim\n",
        "            self.output_dim = self.hidden_dim\n",
        "        else:\n",
        "            self.input_dim = self.repr_dim\n",
        "            self.output_dim = self.hidden_dim + self.latent_dim\n",
        "\n",
        "        self.transform = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "    \n",
        "    def forward(self, repr, noise):\n",
        "        if self.noop:\n",
        "            return noise\n",
        "\n",
        "        # assuming latent is concat as [repr,noise] XXX\n",
        "        if self.full_transform:\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "            latent = self.transform(latent)\n",
        "        else:\n",
        "            repr = self.transform(repr)\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "\n",
        "        return latent\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRivPV9BwFk"
      },
      "source": [
        "# Training v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rpQp2E9rE5"
      },
      "source": [
        "### Imports and globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51zFNn509xLz"
      },
      "source": [
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "GANSIAM_DIR = \"/content/drive/My Drive/gansiam/\"\n",
        "SIMSIAM_PATH = os.path.join(GANSIAM_DIR, \"pretrained_batch256.tar\")\n",
        "TINYIMAGENET_DIR = \"tiny-imagenet-200\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9X_JYE2Vwxd"
      },
      "source": [
        "### Download Tiny Imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "559H2an_V03M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805a0a03-7354-45e4-a031-e5ca7554b132"
      },
      "source": [
        "%%bash\n",
        "if [[ -d  \"tiny-imagenet-200\" ]]; then\n",
        "    echo \"Tiny Imagenet exists.\"\n",
        "else\n",
        "    wget -q \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "    unzip -qq \"tiny-imagenet-200.zip\" && rm \"tiny-imagenet-200.zip\"\n",
        "    echo \"Downloaded Tiny Imagenet.\"\n",
        "fi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiny Imagenet exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbo7T6blPVTc"
      },
      "source": [
        "### Load pre-trained SimSiam model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyzHmINsryyh"
      },
      "source": [
        "#### SimSiam Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8KJUUeWr1dI"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "import random\n",
        "\n",
        "\n",
        "class TwoCropsTransform:\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        q = self.base_transform(x)\n",
        "        k = self.base_transform(x)\n",
        "        return [q, k]\n",
        "\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
        "\n",
        "    def __init__(self, sigma=[.1, 2.]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr8clgi_AzY",
        "outputId": "b88ef99b-07d3-4d98-d9e8-9674cda5abb8"
      },
      "source": [
        "checkpoint = torch.load(SIMSIAM_PATH, map_location=\"cuda:0\")\n",
        "# remove 'module.' from dict keys\n",
        "model_dict = OrderedDict((k[7:], v) for k, v in checkpoint[\"state_dict\"].items())\n",
        "\n",
        "# Load model\n",
        "simsiam = SimSiam(models.__dict__[\"resnet50\"])\n",
        "simsiam.load_state_dict(model_dict)\n",
        "#print(simsiam)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckB_xSVX8kB"
      },
      "source": [
        "# Training v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nouxldrYb0r"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUP5vn8OX--p"
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.load = False\n",
        "        self.print_freq = 10\n",
        "        self.seed = None\n",
        "        self.gpu = 0\n",
        "        self.workers = 2\n",
        "        self.epochs = 100\n",
        "\n",
        "        ### lr is about 2e-4 for batch size of 64\n",
        "        # we scale according to our choice of batch size\n",
        "        self.batch_size = 256\n",
        "        self.D_lr = 2e-4\n",
        "        self.G_lr = 2e-4\n",
        "        self.Q_lr = self.D_lr\n",
        "        self.latent_transform_lr = self.G_lr\n",
        "        self.lr_decay = 0.02\n",
        "        #self.betas = (0.5, 0.999)\n",
        "        self.betas = (0., 0.9)\n",
        "\n",
        "        # SimSiam (_don't change_ if loading pre-trained)\n",
        "        self.dim = 2048\n",
        "        self.pred_dim = 512\n",
        "\n",
        "        # GAN\n",
        "        self.repr_dim = self.dim  # don't change\n",
        "        self.latent_full_transform = False\n",
        "        self.latent_noise_dim = 128\n",
        "        self.latent_hidden_dim = 128  # dim of transform output\n",
        "        self.Q_hidden_dim = 128\n",
        "        self.num_features = 64\n",
        "        self.D_iters = 5\n",
        "\n",
        "        self.gan_type = \"gan\"  # ignore this\n",
        "        self.resnetgan = True  # overrides wgan when True\n",
        "        self.wgan = False  # if False, use spectral norm\n",
        "        self.grad_penalty = 0.  # 0 if wgan is False\n",
        "        self.grad_center = 1.  # not important\n",
        "\n",
        "        self.generate_grid_interval = 50\n",
        "\n",
        "        # make noise proportional to sd(data)\n",
        "        self.im_noise = 1e-2  # image sd is about 1.0\n",
        "        self.repr_noise = 1e-4  # repr sd is about 1e-3\n",
        "\n",
        "        # Start small, increase later\n",
        "        self.G_consistency = 0.01\n",
        "        self.D_consistency = 0.01\n",
        "\n",
        "\n",
        "GENERATED_GRIDS = []\n",
        "IMAGE_SIZE = 64\n",
        "DATASET = \"Tiny ImageNet\"\n",
        "#DATASET = \"CIFAR10\"\n",
        "args = Args()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xihRlU0PYhiJ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW_P-JfeYiOe"
      },
      "source": [
        "# image normalization\n",
        "mean = [0.5]\n",
        "std = [0.5]\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "inv_normalize = transforms.Normalize(\n",
        "   mean= [-m/s for m, s in zip(mean, std)],\n",
        "   std= [1/s for s in std]\n",
        ")\n",
        "\n",
        "augmentation = [\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "# MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "_augmentation = [\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.2, 1.)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "if DATASET == \"MNIST\":\n",
        "    augmentation = [transforms.Grayscale(3)] + augmentation\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=os.path.join(GANSIAM_DIR, \"mnist/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CelebA\":\n",
        "    train_dataset = datasets.CelebA(\n",
        "        root=os.path.join(GANSIAM_DIR, \"celeba\"), download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CIFAR10\":\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=os.path.join(GANSIAM_DIR, \"cifar10/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "        #transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "elif DATASET == \"Tiny ImageNet\":\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "        transform=transforms.Compose(augmentation))\n",
        "else:\n",
        "    raise Exception(f\"Dataset '{DATASET}' not found\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=args.workers, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQ0_BfjmAHf"
      },
      "source": [
        "### Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLiHFvBimb3"
      },
      "source": [
        "def D_criterion_NS(D_real, D_fake):\n",
        "    d_loss = F.softplus(-D_real) + F.softplus(D_fake)\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_NS(D_fake):\n",
        "    return F.softplus(-D_fake).mean()\n",
        "\n",
        "def D_criterion_LS(D_real, D_fake):\n",
        "    d_loss = 0.5 * (D_real - torch.ones_like(D_real))**2 + 0.5 * (D_fake)**2\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_LS(D_fake):\n",
        "    gen_loss = 0.5 * (D_fake - torch.ones_like(D_fake))**2\n",
        "    return gen_loss.mean()\n",
        "\n",
        "def D_criterion_hinge(D_real, D_fake):\n",
        "    return torch.mean(F.relu(1. - D_real)) + torch.mean(F.relu(1. + D_fake))\n",
        "\n",
        "def G_criterion_hinge(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def D_criterion_wasserstein(D_real, D_fake):\n",
        "    return torch.mean(D_fake - D_real)\n",
        "\n",
        "def G_criterion_wasserstein(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def interpolate(real, fake, eps=None):\n",
        "    if eps is None:\n",
        "        eps_size = [1] * len(real.size())\n",
        "        eps_size[0] = real.size(0)\n",
        "        eps = torch.rand(eps_size).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "    \n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_x, x, torch.ones_like(D_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n",
        "\n",
        "def lerp(x1, x2, t=None):\n",
        "    return interpolate(x1, x2, t)\n",
        "\n",
        "def slerp(x1, x2, t=None):\n",
        "    if t is None:\n",
        "        t = torch.rand(x1.size(0)).to(x1)\n",
        "    # assuming normalized x and x2\n",
        "    omega = torch.acos((x1*x2).sum(1))\n",
        "    so = torch.sin(omega)\n",
        "    res = (torch.sin((1.-t)*omega) / so).unsqueeze(1) * x1 \\\n",
        "        + (torch.sin(t*omega) / so).unsqueeze(1) * x2\n",
        "    return res\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Z4Ke6DYkDg"
      },
      "source": [
        "## Model + Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rO_MvGzYldx",
        "outputId": "ed1352ed-77c5-499f-eb16-63c56217de21"
      },
      "source": [
        "if args.seed is not None:\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.set_device(args.gpu)\n",
        "\n",
        "latent_transform = LatentTransform(repr_dim=args.repr_dim,\n",
        "                                   latent_dim=args.latent_noise_dim,\n",
        "                                   hidden_dim=args.latent_hidden_dim,\n",
        "                                   full_transform=args.latent_full_transform,\n",
        "                                   )\n",
        "\n",
        "model = DCGAN(num_latents=latent_transform.output_dim,\n",
        "              image_size=IMAGE_SIZE,\n",
        "              gan_type=args.gan_type,  # doesn't make a difference\n",
        "              D_num_features=args.num_features,\n",
        "              G_num_features=args.num_features,\n",
        "              use_batchnorm=False,  # for D only\n",
        "              output_sigmoid=False,  # for D only\n",
        "              use_spectralnorm=not args.wgan,  # for spectral norm, use the below model\n",
        "              )\n",
        "\n",
        "\n",
        "if not args.wgan:\n",
        "    model = SNDCGAN(num_latents=latent_transform.output_dim,\n",
        "                    image_size=IMAGE_SIZE,\n",
        "                    D_num_features=args.num_features//(IMAGE_SIZE//32),\n",
        "                    G_num_features=args.num_features,\n",
        "                    repr_dim=args.repr_dim)\n",
        "if args.resnetgan:\n",
        "    model = SNResNetGAN(num_latents=latent_transform.output_dim,\n",
        "                        image_size=IMAGE_SIZE,\n",
        "                        D_num_features=args.num_features*2,\n",
        "                        G_num_features=args.num_features*2,\n",
        "                        repr_dim=args.repr_dim)\n",
        "\n",
        "Q_hidden_dim = args.Q_hidden_dim\n",
        "Q = nn.Sequential(nn.Linear(model.D.hidden_dim, Q_hidden_dim, bias=False),\n",
        "                    nn.Linear(Q_hidden_dim, args.repr_dim))\n",
        "\n",
        "model = model.cuda(args.gpu)\n",
        "Q = Q.cuda(args.gpu)\n",
        "latent_transform = latent_transform.cuda(args.gpu)\n",
        "simsiam = simsiam.cuda(args.gpu)\n",
        "\n",
        "print(\"Num of params in D:\", sum(map(torch.numel, model.D.parameters())))\n",
        "print(\"Num of params in G:\", sum(map(torch.numel, model.G.parameters())))\n",
        "print(\"Num of params in Q:\", sum(map(torch.numel, Q.parameters())))\n",
        "print(\"Num of params in L:\", sum(map(torch.numel, latent_transform.parameters())))\n",
        "\n",
        "# Define D and G loss functions\n",
        "if args.wgan:\n",
        "    args.grad_penalty = 10.\n",
        "    D_criterion = D_criterion_wasserstein\n",
        "    G_criterion = G_criterion_wasserstein\n",
        "else:\n",
        "    args.grad_penalty = 0.\n",
        "    D_criterion = D_criterion_hinge\n",
        "    G_criterion = G_criterion_hinge\n",
        "\n",
        "# Optimizers\n",
        "G_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.G.parameters()},\n",
        "     {\"params\": latent_transform.parameters(), \"lr\": args.latent_transform_lr}],\n",
        "     args.G_lr, betas=args.betas)\n",
        "D_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.D.parameters(), \"lr\": args.D_lr},\n",
        "     {\"params\": Q.parameters(), \"lr\": args.Q_lr}],\n",
        "     args.Q_lr, betas=args.betas)\n",
        "\n",
        "D_sched = torch.optim.lr_scheduler.ExponentialLR(D_optimizer, 1. - args.lr_decay)\n",
        "G_sched = torch.optim.lr_scheduler.ExponentialLR(G_optimizer, 1. - args.lr_decay)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if args.load:\n",
        "    print(\"Loading...\")\n",
        "    model.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/model.pth.tar\")[\"state_dict\"])\n",
        "    latent_transform.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")[\"state_dict\"])\n",
        "    Q.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/Q.pth.tar\")[\"state_dict\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of params in D: 1349377\n",
            "Num of params in G: 6431363\n",
            "Num of params in Q: 329728\n",
            "Num of params in L: 262272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTqwby4cX0i",
        "outputId": "18688552-39d4-414b-d9cb-45ced977adc6"
      },
      "source": [
        "print(model)\n",
        "print(Q)\n",
        "print(latent_transform)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SNResNetGAN(\n",
            "  (D): SNResNetDiscriminator(\n",
            "    (model): Sequential(\n",
            "      (0): FirstResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass_conv): ParametrizedConv2d(\n",
            "          3, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ParametrizedConv2d(\n",
            "            3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1): ReLU()\n",
            "          (2): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass): Sequential(\n",
            "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "          (1): ParametrizedConv2d(\n",
            "            3, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass): Sequential(\n",
            "          (0): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        )\n",
            "        (bypass_conv): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (3): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (4): ResBlockDiscriminator(\n",
            "        (conv1): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv2): ParametrizedConv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          (parametrizations): ModuleDict(\n",
            "            (weight): ParametrizationList(\n",
            "              (0): _SpectralNorm()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (model): Sequential(\n",
            "          (0): ReLU()\n",
            "          (1): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (2): ReLU()\n",
            "          (3): ParametrizedConv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "            (parametrizations): ModuleDict(\n",
            "              (weight): ParametrizationList(\n",
            "                (0): _SpectralNorm()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (bypass): Sequential()\n",
            "      )\n",
            "      (5): ReLU()\n",
            "      (6): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "    )\n",
            "    (fc): ParametrizedLinear(\n",
            "      in_features=512, out_features=1, bias=True\n",
            "      (parametrizations): ModuleDict(\n",
            "        (weight): ParametrizationList(\n",
            "          (0): _SpectralNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (G): SNResNetGeneratorConditional(\n",
            "    (dense): Linear(in_features=256, out_features=2048, bias=True)\n",
            "    (final): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (block1): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block2): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block3): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (block4): ResBlockGeneratorConditional(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (bn2): ConditionalBatchNorm2d(\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "      )\n",
            "      (bypass): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    )\n",
            "    (bn): ConditionalBatchNorm2d(\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=512, out_features=128, bias=False)\n",
            "  (1): Linear(in_features=128, out_features=2048, bias=True)\n",
            ")\n",
            "LatentTransform(\n",
            "  (transform): Linear(in_features=2048, out_features=128, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeDicP6QZNQ2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj9x-2fNtnp"
      },
      "source": [
        "def sample_noise(num_samples):\n",
        "    return torch.randn(num_samples, args.latent_noise_dim)\n",
        "\n",
        "def get_repr(img):\n",
        "    with torch.no_grad():\n",
        "        repr = simsiam.encoder(img)\n",
        "        repr = repr + args.repr_noise * torch.randn_like(repr)\n",
        "    return repr\n",
        "\n",
        "def sample_G(repr):\n",
        "    noise = sample_noise(repr.size(0)).cuda(args.gpu)\n",
        "    z = latent_transform(repr, noise)\n",
        "    fake = model.G(z, repr)\n",
        "    fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "    return fake"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEVERm6alJt6"
      },
      "source": [
        "# Sample a global latent for reuse\n",
        "fixed_x, _ = next(iter(train_loader))\n",
        "fixed_x = fixed_x[:32].cuda(args.gpu)\n",
        "fixed_repr = get_repr(fixed_x)\n",
        "fixed_noise = sample_noise(32).cuda(args.gpu)\n",
        "\n",
        "def check_G_progress(G):\n",
        "    with torch.no_grad():\n",
        "        z = latent_transform(fixed_repr, fixed_noise)\n",
        "        fake_progress = G(z, fixed_repr)\n",
        "    im_grid = torch.cat([fixed_x, fake_progress], dim=0)\n",
        "    grid = vutils.make_grid(im_grid.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "    return grid"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7gU4I8OZOer"
      },
      "source": [
        "def train(train_loader, model, simsiam,\n",
        "          D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    D_on_reals = AverageMeter('D(real)', ':.4f')\n",
        "    D_on_fakes1 = AverageMeter('D(fake)1', ':.4f')\n",
        "    D_on_fakes2 = AverageMeter('D(fake)2', ':.4f')\n",
        "    D_grads = AverageMeter('grad(D)', ':.4f')\n",
        "    G_repr_losses = AverageMeter('G repr loss', ':.4f')\n",
        "    D_repr_losses = AverageMeter('D repr loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time,\n",
        "         D_on_reals, D_on_fakes1, D_on_fakes2, D_grads, G_repr_losses, D_repr_losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    \n",
        "    # Create dataset sampler\n",
        "    data_iter = iter(enumerate(train_loader))\n",
        "    batch_idx = [0]  # just an ugly hack\n",
        "    def sample_data():\n",
        "        i, (x, y) = next(data_iter)\n",
        "        batch_idx[0] = i\n",
        "        x = x.cuda(args.gpu, non_blocking=True)\n",
        "        real = x + args.im_noise * torch.randn_like(x)\n",
        "        return real\n",
        "    \n",
        "    def sample_repr():\n",
        "        # (1) Sample a random representation from a prior distribution\n",
        "        #repr = 1e-2*torch.rand(args.batch_size, args.repr_dim).cuda(args.gpu)\n",
        "        #repr = torch.randn(args.batch_size, args.repr_dim).cuda(args.gpu)\n",
        "\n",
        "        # (2) Sample a real represenation (best so far)\n",
        "        repr = get_repr(sample_data())\n",
        "\n",
        "        # (3) Sample an interpolated represenation\n",
        "        \"\"\"\n",
        "        real1, real2 = sample_data(), sample_data()\n",
        "        repr1, repr2 = get_repr(real1), get_repr(real2)\n",
        "        repr = lerp(repr1, repr2)\n",
        "        #repr = slerp(repr1, repr2)\n",
        "        \"\"\"\n",
        "        \n",
        "        return repr\n",
        "\n",
        "    end = time.time()\n",
        "    # Train until data_iter is exhausted\n",
        "    try:\n",
        "        i = -1\n",
        "        while True:\n",
        "            i += 1\n",
        "            # measure data loading time\n",
        "            data_time.update(time.time() - end)\n",
        "\n",
        "            ### Train generator\n",
        "            # Sample data and get representation\n",
        "            repr = sample_repr()\n",
        "            # Sample from generator given repr\n",
        "            fake = sample_G(repr)\n",
        "            # Classify fake data\n",
        "            D_fake, h_fake = model.D(fake, return_h=True)\n",
        "            # Calculate adversarial loss\n",
        "            G_loss = G_criterion(D_fake)\n",
        "            # Calculate consistency loss\n",
        "            if args.G_consistency != 0.:\n",
        "                fake_repr = simsiam.encoder(fake)\n",
        "                G_repr_loss = -F.cosine_similarity(fake_repr, repr).mean()\n",
        "                G_repr_losses.update(G_repr_loss.mean().item(), args.batch_size)\n",
        "                G_loss = G_loss + args.G_consistency * G_repr_loss\n",
        "            if args.D_consistency != 0.:\n",
        "                D_repr_loss = -F.cosine_similarity(Q(h_fake), repr).mean()\n",
        "                D_repr_losses.update(D_repr_loss.mean().item(), args.batch_size)\n",
        "                G_loss = G_loss + args.D_consistency * D_repr_loss\n",
        "            # Calculate gradient and minimize\n",
        "            G_optimizer.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_optimizer.step()\n",
        "            # Update average\n",
        "            D_on_fakes1.update(D_fake.mean().item(), args.batch_size)\n",
        "\n",
        "            ### Train discriminator\n",
        "            for _ in range(args.D_iters):\n",
        "                # Sample data and get representation\n",
        "                real = sample_data()\n",
        "                repr = sample_repr()\n",
        "                # Sample from generator given repr\n",
        "                with torch.no_grad():\n",
        "                    fake = sample_G(repr)\n",
        "                # Classify real and fake data\n",
        "                D_real, h_real = model.D(real, return_h=True)\n",
        "                D_fake, h_fake = model.D(fake, return_h=True)\n",
        "                # Calculate loss\n",
        "                D_loss = D_criterion(D_real, D_fake)\n",
        "                # Gradient penalty\n",
        "                if args.grad_penalty != 0.:\n",
        "                    D_grad_penalty = simple_gradient_penalty(\n",
        "                        model.D, interpolate(real, fake), center=args.grad_center)\n",
        "                    D_loss = D_loss + args.grad_penalty * D_grad_penalty\n",
        "                    D_grads.update(D_grad_penalty.mean().item(), args.batch_size)\n",
        "                # Calculate consistency loss\n",
        "                if args.D_consistency != 0.:\n",
        "                    real_repr = simsiam.encoder(real)\n",
        "                    D_repr_loss_real = -F.cosine_similarity(Q(h_real), real_repr).mean()\n",
        "                    D_repr_loss_fake = -F.cosine_similarity(Q(h_fake), repr).mean()\n",
        "                    D_repr_loss = 0.5 * (D_repr_loss_real + D_repr_loss_fake)\n",
        "                    D_repr_losses.update(D_repr_loss.mean().item(), args.batch_size)\n",
        "                    D_loss = D_loss + args.D_consistency * D_repr_loss\n",
        "                # Calculate gradient and minimize\n",
        "                D_optimizer.zero_grad()\n",
        "                D_loss.backward()\n",
        "                D_optimizer.step()\n",
        "                # Update average\n",
        "                D_on_reals.update(D_real.mean().item(), args.batch_size)\n",
        "                D_on_fakes2.update(D_fake.mean().item(), args.batch_size)\n",
        "\n",
        "            # Check generator's progress by recording its output on a fixed input\n",
        "            if i % args.generate_grid_interval == 0:\n",
        "                grid = check_G_progress(model.G)\n",
        "                GENERATED_GRIDS.append(grid)\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.display(batch_idx[0])\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "    \n",
        "    except StopIteration:\n",
        "        progress.display(batch_idx[0])\n",
        "        return"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24ES94Re55W"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDMPwe-ae6q-"
      },
      "source": [
        "def save():\n",
        "    torch.save({'state_dict': model.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/model.pth.tar\")\n",
        "    torch.save({'state_dict': latent_transform.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")\n",
        "    torch.save({'state_dict': Q.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/Q.pth.tar\")\n",
        "\n",
        "def save_vid():\n",
        "    vidname = f\"grids_per_{args.generate_grid_interval}_iters.mp4\"\n",
        "    vidname = os.path.join(GANSIAM_DIR, \"results\", \"progress\", vidname)\n",
        "    create_progress_animation(GENERATED_GRIDS, vidname)\n",
        "\n",
        "def run(epochs):\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, simsiam,\n",
        "            D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\n",
        "        D_sched.step()\n",
        "        G_sched.step()\n",
        "\n",
        "        # Check G's progress evey epoch by generating an image\n",
        "        grid = check_G_progress(model.G)\n",
        "        imname = f'{GANSIAM_DIR}/results/progress/grid_{epoch:04d}.png'\n",
        "        plt.imsave(imname, grid.permute(1,2,0).numpy())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            save()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qjya-BRT_cJ"
      },
      "source": [
        "epochs_per_cell = 5"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNNZfXWe5Rr",
        "outputId": "81f3ef43-20c7-480b-b320-7009de769305"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 0.4659 (0.0755)\tD(fake)1 -0.1294 (-0.1294)\tD(fake)2 -0.2167 (-0.1895)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0021 (-0.0021)\tD repr loss -0.0082 (0.0027)\n",
            "Epoch: [0][120/390]\tTime  4.574 ( 5.125)\tData  0.000 ( 0.000)\tD(real) 1.9630 (2.5209)\tD(fake)1 -0.9763 (-1.0559)\tD(fake)2 -0.7818 (-1.1346)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0048 (-0.0199)\tD repr loss -0.1382 (-0.0442)\n",
            "Epoch: [0][230/390]\tTime  4.643 ( 4.846)\tData  0.000 ( 0.000)\tD(real) 2.9287 (2.5971)\tD(fake)1 -1.7738 (-1.4309)\tD(fake)2 -1.6183 (-1.3952)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0256 (-0.0347)\tD repr loss -0.0838 (-0.0731)\n",
            "Epoch: [0][340/390]\tTime  4.556 ( 4.756)\tData  0.000 ( 0.000)\tD(real) 4.2904 (2.7754)\tD(fake)1 -0.8548 (-1.3945)\tD(fake)2 -1.9085 (-1.4079)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0652 (-0.0409)\tD repr loss -0.1024 (-0.0913)\n",
            "Epoch: [0][389/390]\tTime  4.534 ( 4.729)\tData  0.000 ( 0.000)\tD(real) 2.8189 (2.9534)\tD(fake)1 -1.2076 (-1.3998)\tD(fake)2 -1.3437 (-1.4096)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0856 (-0.0460)\tD repr loss -0.0994 (-0.0949)\n",
            "Epoch: [1][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 3.7139 (4.3892)\tD(fake)1 -1.3821 (-1.3821)\tD(fake)2 -1.2096 (-1.2868)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1314 (-0.1314)\tD repr loss -0.1947 (-0.1183)\n",
            "Epoch: [1][120/390]\tTime  4.611 ( 4.597)\tData  0.000 ( 0.000)\tD(real) 2.3617 (3.6434)\tD(fake)1 -1.3083 (-1.5594)\tD(fake)2 -1.5092 (-1.6511)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1039 (-0.0559)\tD repr loss -0.1680 (-0.1279)\n",
            "Epoch: [1][230/390]\tTime  4.546 ( 4.575)\tData  0.000 ( 0.000)\tD(real) 1.8025 (3.3015)\tD(fake)1 -1.2737 (-1.4666)\tD(fake)2 -1.5583 (-1.5383)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0743 (-0.0395)\tD repr loss -0.1491 (-0.1253)\n",
            "Epoch: [1][340/390]\tTime  4.517 ( 4.568)\tData  0.000 ( 0.000)\tD(real) 2.2208 (2.9991)\tD(fake)1 -1.2158 (-1.4556)\tD(fake)2 -1.3324 (-1.4836)\tgrad(D) 0.0000 (0.0000)\tG repr loss 0.0708 (-0.0386)\tD repr loss -0.0920 (-0.1277)\n",
            "Epoch: [1][389/390]\tTime  4.598 ( 4.571)\tData  0.000 ( 0.000)\tD(real) 2.8775 (2.9607)\tD(fake)1 -1.1383 (-1.3960)\tD(fake)2 -1.0864 (-1.4540)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0483 (-0.0396)\tD repr loss -0.1727 (-0.1283)\n",
            "Epoch: [2][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.7973 (2.0752)\tD(fake)1 -1.1441 (-1.1441)\tD(fake)2 -1.2223 (-1.2051)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0103 (-0.0103)\tD repr loss -0.1355 (-0.1594)\n",
            "Epoch: [2][120/390]\tTime  4.558 ( 4.598)\tData  0.000 ( 0.000)\tD(real) 1.7034 (2.0977)\tD(fake)1 -2.0998 (-1.3869)\tD(fake)2 -1.8930 (-1.4231)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0843 (-0.0490)\tD repr loss -0.1709 (-0.1269)\n",
            "Epoch: [2][230/390]\tTime  4.525 ( 4.585)\tData  0.000 ( 0.000)\tD(real) 2.4452 (2.0939)\tD(fake)1 -1.4513 (-1.4488)\tD(fake)2 -1.2362 (-1.4555)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1143 (-0.0553)\tD repr loss -0.1616 (-0.1329)\n",
            "Epoch: [2][340/390]\tTime  4.541 ( 4.578)\tData  0.000 ( 0.000)\tD(real) 1.7674 (2.0442)\tD(fake)1 -2.3040 (-1.4102)\tD(fake)2 -1.2865 (-1.3971)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1120 (-0.0571)\tD repr loss -0.1224 (-0.1327)\n",
            "Epoch: [2][389/390]\tTime  4.566 ( 4.576)\tData  0.000 ( 0.000)\tD(real) 1.5989 (2.0065)\tD(fake)1 -2.6150 (-1.4136)\tD(fake)2 -2.6656 (-1.3901)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0725 (-0.0565)\tD repr loss -0.1311 (-0.1329)\n",
            "Epoch: [3][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 1.4680 (1.7105)\tD(fake)1 -2.5387 (-2.5387)\tD(fake)2 -2.3676 (-2.5249)\tgrad(D) 0.0000 (0.0000)\tG repr loss 0.0463 (0.0463)\tD repr loss -0.1901 (-0.1485)\n",
            "Epoch: [3][120/390]\tTime  4.555 ( 4.599)\tData  0.000 ( 0.000)\tD(real) 1.2343 (1.7350)\tD(fake)1 -1.1970 (-1.7291)\tD(fake)2 -1.4355 (-1.6755)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0700 (-0.0451)\tD repr loss -0.1239 (-0.1322)\n",
            "Epoch: [3][230/390]\tTime  4.571 ( 4.585)\tData  0.000 ( 0.000)\tD(real) 2.1433 (1.8648)\tD(fake)1 -1.2699 (-1.6485)\tD(fake)2 -1.2854 (-1.6463)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0736 (-0.0587)\tD repr loss -0.1948 (-0.1359)\n",
            "Epoch: [3][340/390]\tTime  4.592 ( 4.581)\tData  0.000 ( 0.000)\tD(real) 2.0075 (1.9084)\tD(fake)1 -1.8927 (-1.6148)\tD(fake)2 -1.7714 (-1.6178)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0881 (-0.0618)\tD repr loss -0.1192 (-0.1377)\n",
            "Epoch: [3][389/390]\tTime  4.616 ( 4.584)\tData  0.000 ( 0.000)\tD(real) 2.9290 (1.9919)\tD(fake)1 -1.1254 (-1.5714)\tD(fake)2 -1.1208 (-1.5773)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0635 (-0.0609)\tD repr loss -0.1199 (-0.1411)\n",
            "Epoch: [4][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 2.4537 (2.8916)\tD(fake)1 -1.0656 (-1.0656)\tD(fake)2 -1.2110 (-1.1522)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0539 (-0.0539)\tD repr loss -0.1538 (-0.1547)\n",
            "Epoch: [4][120/390]\tTime  4.535 ( 4.599)\tData  0.000 ( 0.000)\tD(real) 3.0285 (3.0356)\tD(fake)1 -1.2161 (-1.5837)\tD(fake)2 -1.2790 (-1.5943)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0797 (-0.0281)\tD repr loss -0.2093 (-0.1519)\n",
            "Epoch: [4][230/390]\tTime  4.579 ( 4.580)\tData  0.000 ( 0.000)\tD(real) 2.0659 (2.8371)\tD(fake)1 -1.3912 (-1.5315)\tD(fake)2 -1.4365 (-1.5302)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0184 (-0.0311)\tD repr loss -0.2114 (-0.1585)\n",
            "Epoch: [4][340/390]\tTime  4.553 ( 4.576)\tData  0.000 ( 0.000)\tD(real) 9.0178 (3.0963)\tD(fake)1 -1.6842 (-1.5459)\tD(fake)2 -1.5968 (-1.5412)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0612 (-0.0318)\tD repr loss -0.1860 (-0.1634)\n",
            "Epoch: [4][389/390]\tTime  4.567 ( 4.575)\tData  0.000 ( 0.000)\tD(real) 9.1881 (3.7632)\tD(fake)1 -1.3400 (-1.5255)\tD(fake)2 -1.3452 (-1.5222)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1010 (-0.0351)\tD repr loss -0.1434 (-0.1651)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-p4wAlbftUb",
        "outputId": "39690d57-f9c1-432f-c04d-1802346fa1a8"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 10.1380 (6.4362)\tD(fake)1 -1.3214 (-1.3214)\tD(fake)2 -1.2358 (-1.2970)\tgrad(D) 0.0000 (0.0000)\tG repr loss 0.0414 (0.0414)\tD repr loss -0.1906 (-0.1931)\n",
            "Epoch: [0][120/390]\tTime  4.558 ( 4.614)\tData  0.000 ( 0.000)\tD(real) 2.5698 (6.9820)\tD(fake)1 -1.0925 (-1.4303)\tD(fake)2 -1.7221 (-1.4183)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0597 (-0.0322)\tD repr loss -0.1464 (-0.2096)\n",
            "Epoch: [0][230/390]\tTime  4.566 ( 4.593)\tData  0.000 ( 0.000)\tD(real) 2.6891 (4.9389)\tD(fake)1 -1.3180 (-1.4300)\tD(fake)2 -1.4229 (-1.4053)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0435 (-0.0306)\tD repr loss -0.2528 (-0.2269)\n",
            "Epoch: [0][340/390]\tTime  4.576 ( 4.581)\tData  0.000 ( 0.000)\tD(real) 3.8382 (5.1286)\tD(fake)1 -1.2642 (-1.4018)\tD(fake)2 -1.1402 (-1.3964)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0795 (-0.0373)\tD repr loss -0.2459 (-0.2338)\n",
            "Epoch: [0][389/390]\tTime  4.589 ( 4.583)\tData  0.000 ( 0.000)\tD(real) 4.5447 (4.9956)\tD(fake)1 -1.6225 (-1.3934)\tD(fake)2 -1.3486 (-1.3873)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1015 (-0.0387)\tD repr loss -0.2737 (-0.2323)\n",
            "Epoch: [1][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 5.7831 (4.2401)\tD(fake)1 -1.1371 (-1.1371)\tD(fake)2 -1.6166 (-1.3975)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0910 (-0.0910)\tD repr loss -0.2719 (-0.1972)\n",
            "Epoch: [1][120/390]\tTime  4.529 ( 4.606)\tData  0.000 ( 0.000)\tD(real) 5.2676 (3.8008)\tD(fake)1 -1.2576 (-1.4480)\tD(fake)2 -1.1712 (-1.4333)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1272 (-0.0972)\tD repr loss -0.2483 (-0.2628)\n",
            "Epoch: [1][230/390]\tTime  4.586 ( 4.591)\tData  0.000 ( 0.000)\tD(real) 5.3742 (4.8938)\tD(fake)1 -1.1978 (-1.3066)\tD(fake)2 -1.2470 (-1.3363)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0922 (-0.0972)\tD repr loss -0.2805 (-0.2792)\n",
            "Epoch: [1][340/390]\tTime  4.620 ( 4.588)\tData  0.000 ( 0.000)\tD(real) 9.2471 (5.1848)\tD(fake)1 -1.2138 (-1.2741)\tD(fake)2 -1.2894 (-1.2976)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1375 (-0.1048)\tD repr loss -0.2113 (-0.2942)\n",
            "Epoch: [1][389/390]\tTime  4.554 ( 4.585)\tData  0.000 ( 0.000)\tD(real) 4.2918 (5.3438)\tD(fake)1 -1.4029 (-1.2944)\tD(fake)2 -1.4174 (-1.3036)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1646 (-0.1081)\tD repr loss -0.3091 (-0.3013)\n",
            "Epoch: [2][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 6.0592 (5.5816)\tD(fake)1 -1.3659 (-1.3659)\tD(fake)2 -1.2060 (-1.3317)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1494 (-0.1494)\tD repr loss -0.2409 (-0.3241)\n",
            "Epoch: [2][120/390]\tTime  4.597 ( 4.605)\tData  0.000 ( 0.000)\tD(real) 9.3547 (7.6666)\tD(fake)1 -1.6218 (-1.4001)\tD(fake)2 -1.3434 (-1.4273)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2434 (-0.1609)\tD repr loss -0.2640 (-0.3583)\n",
            "Epoch: [2][230/390]\tTime  4.565 ( 4.590)\tData  0.000 ( 0.000)\tD(real) 22.4330 (9.5191)\tD(fake)1 -1.1854 (-1.2910)\tD(fake)2 -1.1742 (-1.3120)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1608 (-0.1695)\tD repr loss -0.2968 (-0.3644)\n",
            "Epoch: [2][340/390]\tTime  4.556 ( 4.587)\tData  0.000 ( 0.000)\tD(real) 22.0926 (11.0205)\tD(fake)1 -1.3160 (-1.2803)\tD(fake)2 -1.2086 (-1.3019)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1938 (-0.1728)\tD repr loss -0.3498 (-0.3649)\n",
            "Epoch: [2][389/390]\tTime  4.588 ( 4.584)\tData  0.000 ( 0.000)\tD(real) 22.7556 (11.7675)\tD(fake)1 -1.1929 (-1.2820)\tD(fake)2 -1.0063 (-1.2975)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1851 (-0.1757)\tD repr loss -0.3829 (-0.3670)\n",
            "Epoch: [3][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 22.5052 (17.9459)\tD(fake)1 -1.4646 (-1.4646)\tD(fake)2 -1.2360 (-1.2907)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1507 (-0.1507)\tD repr loss -0.3759 (-0.3882)\n",
            "Epoch: [3][120/390]\tTime  4.601 ( 4.616)\tData  0.000 ( 0.000)\tD(real) 8.7527 (16.5752)\tD(fake)1 -1.2373 (-1.2664)\tD(fake)2 -1.3871 (-1.2504)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1329 (-0.1899)\tD repr loss -0.3017 (-0.3826)\n",
            "Epoch: [3][230/390]\tTime  4.564 ( 4.595)\tData  0.000 ( 0.000)\tD(real) 29.4810 (19.3725)\tD(fake)1 -1.1690 (-1.2741)\tD(fake)2 -1.0843 (-1.2549)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1704 (-0.1893)\tD repr loss -0.3782 (-0.3834)\n",
            "Epoch: [3][340/390]\tTime  4.596 ( 4.590)\tData  0.000 ( 0.000)\tD(real) 27.3734 (19.6555)\tD(fake)1 -1.1255 (-1.2360)\tD(fake)2 -1.0497 (-1.2372)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1641 (-0.1860)\tD repr loss -0.3547 (-0.3823)\n",
            "Epoch: [3][389/390]\tTime  4.561 ( 4.587)\tData  0.000 ( 0.000)\tD(real) 20.2013 (19.3995)\tD(fake)1 -1.2161 (-1.2423)\tD(fake)2 -1.0402 (-1.2332)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2028 (-0.1824)\tD repr loss -0.3127 (-0.3819)\n",
            "Epoch: [4][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 18.5765 (17.7630)\tD(fake)1 -1.3216 (-1.3216)\tD(fake)2 -1.2556 (-1.2997)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0883 (-0.0883)\tD repr loss -0.3981 (-0.3872)\n",
            "Epoch: [4][120/390]\tTime  4.599 ( 4.606)\tData  0.000 ( 0.000)\tD(real) 35.0376 (16.1854)\tD(fake)1 -1.4137 (-1.3205)\tD(fake)2 -1.0685 (-1.3213)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1190 (-0.1108)\tD repr loss -0.3098 (-0.3737)\n",
            "Epoch: [4][230/390]\tTime  4.553 ( 4.585)\tData  0.000 ( 0.000)\tD(real) 9.6976 (15.8801)\tD(fake)1 -1.3492 (-1.3668)\tD(fake)2 -1.2098 (-1.3726)\tgrad(D) 0.0000 (0.0000)\tG repr loss 0.0015 (-0.1012)\tD repr loss -0.3257 (-0.3769)\n",
            "Epoch: [4][340/390]\tTime  4.589 ( 4.579)\tData  0.000 ( 0.000)\tD(real) 13.6899 (15.1175)\tD(fake)1 -1.2646 (-1.3261)\tD(fake)2 -1.1910 (-1.3325)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0967 (-0.1061)\tD repr loss -0.3338 (-0.3790)\n",
            "Epoch: [4][389/390]\tTime  4.585 ( 4.574)\tData  0.000 ( 0.000)\tD(real) 10.8270 (14.7165)\tD(fake)1 -1.1661 (-1.3036)\tD(fake)2 -1.2653 (-1.3171)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1328 (-0.1098)\tD repr loss -0.3393 (-0.3807)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUGjJ-6Pf3xE",
        "outputId": "3ee18760-e74e-4e32-de3b-9747640cf90d"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 14.2454 (13.4419)\tD(fake)1 -1.1724 (-1.1724)\tD(fake)2 -1.1480 (-1.1912)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1726 (-0.1726)\tD repr loss -0.3408 (-0.3638)\n",
            "Epoch: [0][120/390]\tTime  4.545 ( 4.599)\tData  0.000 ( 0.000)\tD(real) 7.4975 (10.6750)\tD(fake)1 -1.3372 (-1.2792)\tD(fake)2 -1.2428 (-1.3887)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1608 (-0.1279)\tD repr loss -0.3586 (-0.3848)\n",
            "Epoch: [0][230/390]\tTime  4.581 ( 4.589)\tData  0.000 ( 0.000)\tD(real) 9.6916 (10.0375)\tD(fake)1 -1.1985 (-1.2688)\tD(fake)2 -1.2744 (-1.3146)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1666 (-0.1253)\tD repr loss -0.4132 (-0.3926)\n",
            "Epoch: [0][340/390]\tTime  4.611 ( 4.585)\tData  0.000 ( 0.000)\tD(real) 13.5348 (10.4361)\tD(fake)1 -1.2862 (-1.2730)\tD(fake)2 -1.3188 (-1.3040)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0785 (-0.1188)\tD repr loss -0.3129 (-0.3918)\n",
            "Epoch: [0][389/390]\tTime  4.549 ( 4.586)\tData  0.000 ( 0.000)\tD(real) 11.0917 (10.7342)\tD(fake)1 -1.1808 (-1.2626)\tD(fake)2 -1.1761 (-1.2925)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0991 (-0.1207)\tD repr loss -0.3638 (-0.3921)\n",
            "Epoch: [1][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 11.5821 (11.3436)\tD(fake)1 -1.1419 (-1.1419)\tD(fake)2 -1.2102 (-1.1582)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1421 (-0.1421)\tD repr loss -0.4047 (-0.4060)\n",
            "Epoch: [1][120/390]\tTime  4.567 ( 4.605)\tData  0.000 ( 0.000)\tD(real) 7.7779 (9.1780)\tD(fake)1 -1.2075 (-1.1661)\tD(fake)2 -1.2640 (-1.1887)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1321 (-0.1169)\tD repr loss -0.4229 (-0.4023)\n",
            "Epoch: [1][230/390]\tTime  4.566 ( 4.583)\tData  0.000 ( 0.000)\tD(real) 7.2605 (8.6042)\tD(fake)1 -1.2231 (-1.1836)\tD(fake)2 -1.2103 (-1.1811)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1230 (-0.1176)\tD repr loss -0.3961 (-0.4023)\n",
            "Epoch: [1][340/390]\tTime  4.559 ( 4.582)\tData  0.000 ( 0.000)\tD(real) 10.1363 (8.7020)\tD(fake)1 -1.1456 (-1.1802)\tD(fake)2 -1.2255 (-1.1808)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1053 (-0.1160)\tD repr loss -0.3523 (-0.4034)\n",
            "Epoch: [1][389/390]\tTime  4.579 ( 4.578)\tData  0.000 ( 0.000)\tD(real) 9.2718 (8.9291)\tD(fake)1 -1.1729 (-1.1768)\tD(fake)2 -1.2176 (-1.1782)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1631 (-0.1171)\tD repr loss -0.3598 (-0.4024)\n",
            "Epoch: [2][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 6.6991 (8.2990)\tD(fake)1 -1.1924 (-1.1924)\tD(fake)2 -1.2073 (-1.1972)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1678 (-0.1678)\tD repr loss -0.3961 (-0.4106)\n",
            "Epoch: [2][120/390]\tTime  4.555 ( 4.604)\tData  0.000 ( 0.000)\tD(real) 9.8453 (9.4354)\tD(fake)1 -1.1207 (-1.1446)\tD(fake)2 -1.0994 (-1.1606)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1398 (-0.1385)\tD repr loss -0.3602 (-0.3988)\n",
            "Epoch: [2][230/390]\tTime  4.548 ( 4.589)\tData  0.000 ( 0.000)\tD(real) 6.9954 (8.7169)\tD(fake)1 -1.1317 (-1.1024)\tD(fake)2 -1.1681 (-1.1794)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2130 (-0.1439)\tD repr loss -0.4189 (-0.4018)\n",
            "Epoch: [2][340/390]\tTime  4.603 ( 4.590)\tData  0.000 ( 0.000)\tD(real) 7.1072 (8.5944)\tD(fake)1 -1.0872 (-1.1243)\tD(fake)2 -1.1559 (-1.1743)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1671 (-0.1534)\tD repr loss -0.4079 (-0.4045)\n",
            "Epoch: [2][389/390]\tTime  4.554 ( 4.589)\tData  0.000 ( 0.000)\tD(real) 7.0427 (8.5660)\tD(fake)1 -1.1426 (-1.1472)\tD(fake)2 -1.1596 (-1.1817)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2263 (-0.1530)\tD repr loss -0.3857 (-0.4050)\n",
            "Epoch: [3][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 8.5337 (8.6809)\tD(fake)1 -1.1035 (-1.1035)\tD(fake)2 -1.2909 (-1.2425)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1778 (-0.1778)\tD repr loss -0.3717 (-0.4106)\n",
            "Epoch: [3][120/390]\tTime  4.544 ( 4.604)\tData  0.000 ( 0.000)\tD(real) 8.8910 (9.9377)\tD(fake)1 -1.4113 (-1.2690)\tD(fake)2 -1.2494 (-1.2659)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1535 (-0.1335)\tD repr loss -0.3668 (-0.4109)\n",
            "Epoch: [3][230/390]\tTime  4.582 ( 4.576)\tData  0.000 ( 0.000)\tD(real) 14.5760 (11.2957)\tD(fake)1 -1.4657 (-1.2629)\tD(fake)2 -1.3257 (-1.2510)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2243 (-0.1614)\tD repr loss -0.3972 (-0.4083)\n",
            "Epoch: [3][340/390]\tTime  4.521 ( 4.568)\tData  0.000 ( 0.000)\tD(real) 13.8375 (12.1073)\tD(fake)1 -1.1695 (-1.2574)\tD(fake)2 -1.2371 (-1.2470)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1806 (-0.1743)\tD repr loss -0.4271 (-0.4114)\n",
            "Epoch: [3][389/390]\tTime  4.559 ( 4.567)\tData  0.000 ( 0.000)\tD(real) 10.4878 (12.1387)\tD(fake)1 -1.2540 (-1.2543)\tD(fake)2 -1.2279 (-1.2488)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2812 (-0.1812)\tD repr loss -0.3993 (-0.4132)\n",
            "Epoch: [4][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 8.2359 (11.2906)\tD(fake)1 -1.2394 (-1.2394)\tD(fake)2 -1.2497 (-1.2309)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1663 (-0.1663)\tD repr loss -0.3692 (-0.4052)\n",
            "Epoch: [4][120/390]\tTime  4.553 ( 4.592)\tData  0.000 ( 0.000)\tD(real) 14.0647 (14.9182)\tD(fake)1 -1.1946 (-1.1942)\tD(fake)2 -1.2097 (-1.2059)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1931 (-0.1928)\tD repr loss -0.3911 (-0.4167)\n",
            "Epoch: [4][230/390]\tTime  4.577 ( 4.588)\tData  0.000 ( 0.000)\tD(real) 11.9124 (14.9738)\tD(fake)1 -1.2740 (-1.2094)\tD(fake)2 -1.2612 (-1.2092)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1188 (-0.1943)\tD repr loss -0.4254 (-0.4195)\n",
            "Epoch: [4][340/390]\tTime  4.554 ( 4.575)\tData  0.000 ( 0.000)\tD(real) 17.6103 (15.3470)\tD(fake)1 -1.1701 (-1.2100)\tD(fake)2 -1.1842 (-1.2162)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2695 (-0.2101)\tD repr loss -0.4080 (-0.4204)\n",
            "Epoch: [4][389/390]\tTime  4.529 ( 4.570)\tData  0.000 ( 0.000)\tD(real) 15.7332 (15.4403)\tD(fake)1 -1.1714 (-1.1937)\tD(fake)2 -1.1722 (-1.2066)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2583 (-0.2179)\tD repr loss -0.3899 (-0.4198)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhsj8_owgDSl",
        "outputId": "d38d0c7e-12e4-4c36-d67b-7d864092dde2"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 12.2745 (12.9429)\tD(fake)1 -1.1619 (-1.1619)\tD(fake)2 -1.1472 (-1.1634)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2922 (-0.2922)\tD repr loss -0.3964 (-0.4151)\n",
            "Epoch: [0][120/390]\tTime  4.582 ( 4.619)\tData  0.000 ( 0.000)\tD(real) 15.8072 (12.1128)\tD(fake)1 -1.1126 (-1.1947)\tD(fake)2 -1.1556 (-1.2044)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2838 (-0.2534)\tD repr loss -0.3905 (-0.4306)\n",
            "Epoch: [0][230/390]\tTime  4.593 ( 4.590)\tData  0.000 ( 0.000)\tD(real) 11.6539 (12.9616)\tD(fake)1 -1.2010 (-1.2607)\tD(fake)2 -1.2275 (-1.2413)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2373 (-0.2461)\tD repr loss -0.4013 (-0.4258)\n",
            "Epoch: [0][340/390]\tTime  4.549 ( 4.579)\tData  0.000 ( 0.000)\tD(real) 23.4725 (13.5782)\tD(fake)1 -1.4825 (-1.2732)\tD(fake)2 -1.4190 (-1.2641)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1048 (-0.2367)\tD repr loss -0.3836 (-0.4236)\n",
            "Epoch: [0][389/390]\tTime  4.537 ( 4.575)\tData  0.000 ( 0.000)\tD(real) 17.0385 (13.7992)\tD(fake)1 -1.3550 (-1.2771)\tD(fake)2 -1.4175 (-1.2674)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2133 (-0.2324)\tD repr loss -0.3966 (-0.4224)\n",
            "Epoch: [1][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 14.5431 (13.7801)\tD(fake)1 -1.1141 (-1.1141)\tD(fake)2 -1.1880 (-1.2262)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2022 (-0.2022)\tD repr loss -0.3847 (-0.4151)\n",
            "Epoch: [1][120/390]\tTime  4.563 ( 4.601)\tData  0.000 ( 0.000)\tD(real) 12.8267 (13.6906)\tD(fake)1 -1.1836 (-1.1532)\tD(fake)2 -1.1850 (-1.1786)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2344 (-0.2306)\tD repr loss -0.3825 (-0.4226)\n",
            "Epoch: [1][230/390]\tTime  4.554 ( 4.586)\tData  0.000 ( 0.000)\tD(real) 17.9190 (13.7829)\tD(fake)1 -1.2954 (-1.2095)\tD(fake)2 -1.3097 (-1.2209)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1781 (-0.2035)\tD repr loss -0.3644 (-0.4206)\n",
            "Epoch: [1][340/390]\tTime  4.553 ( 4.578)\tData  0.000 ( 0.000)\tD(real) 13.9479 (13.3512)\tD(fake)1 -1.1116 (-1.2003)\tD(fake)2 -1.2248 (-1.2188)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2553 (-0.2111)\tD repr loss -0.4005 (-0.4209)\n",
            "Epoch: [1][389/390]\tTime  4.580 ( 4.577)\tData  0.000 ( 0.000)\tD(real) 17.9149 (13.5405)\tD(fake)1 -1.2144 (-1.1985)\tD(fake)2 -1.1885 (-1.2151)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2239 (-0.2105)\tD repr loss -0.3971 (-0.4210)\n",
            "Epoch: [2][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 15.7814 (15.7733)\tD(fake)1 -1.1566 (-1.1566)\tD(fake)2 -1.2876 (-1.2312)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2434 (-0.2434)\tD repr loss -0.3900 (-0.4282)\n",
            "Epoch: [2][120/390]\tTime  4.580 ( 4.594)\tData  0.000 ( 0.000)\tD(real) 14.7819 (13.2908)\tD(fake)1 -1.1515 (-1.1555)\tD(fake)2 -1.0529 (-1.1749)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1519 (-0.2104)\tD repr loss -0.4119 (-0.4243)\n",
            "Epoch: [2][230/390]\tTime  4.543 ( 4.585)\tData  0.000 ( 0.000)\tD(real) 16.0267 (14.1420)\tD(fake)1 -1.1866 (-1.2317)\tD(fake)2 -1.2180 (-1.2358)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2371 (-0.2039)\tD repr loss -0.3923 (-0.4228)\n",
            "Epoch: [2][340/390]\tTime  4.570 ( 4.581)\tData  0.000 ( 0.000)\tD(real) 21.6414 (15.4322)\tD(fake)1 -1.2244 (-1.2392)\tD(fake)2 -1.1698 (-1.2339)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1073 (-0.1991)\tD repr loss -0.3816 (-0.4247)\n",
            "Epoch: [2][389/390]\tTime  4.527 ( 4.580)\tData  0.000 ( 0.000)\tD(real) 19.4220 (15.8821)\tD(fake)1 -1.8235 (-1.2563)\tD(fake)2 -1.8728 (-1.2542)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1452 (-0.1978)\tD repr loss -0.3849 (-0.4220)\n",
            "Epoch: [3][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 30.2186 (18.6208)\tD(fake)1 -1.8193 (-1.8193)\tD(fake)2 -1.3693 (-1.6763)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1458 (-0.1458)\tD repr loss -0.3390 (-0.3650)\n",
            "Epoch: [3][120/390]\tTime  4.603 ( 4.613)\tData  0.000 ( 0.000)\tD(real) 14.4002 (16.9300)\tD(fake)1 -1.3043 (-1.4237)\tD(fake)2 -1.3647 (-1.3855)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0936 (-0.1747)\tD repr loss -0.3407 (-0.4246)\n",
            "Epoch: [3][230/390]\tTime  4.597 ( 4.595)\tData  0.000 ( 0.000)\tD(real) 18.8868 (17.7457)\tD(fake)1 -1.1794 (-1.3321)\tD(fake)2 -1.1514 (-1.3012)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0868 (-0.1569)\tD repr loss -0.4264 (-0.4244)\n",
            "Epoch: [3][340/390]\tTime  4.565 ( 4.589)\tData  0.000 ( 0.000)\tD(real) 13.5195 (16.2922)\tD(fake)1 -1.1691 (-1.2378)\tD(fake)2 -1.1102 (-1.2691)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1781 (-0.1582)\tD repr loss -0.3729 (-0.4244)\n",
            "Epoch: [3][389/390]\tTime  4.588 ( 4.588)\tData  0.000 ( 0.000)\tD(real) 15.7003 (15.9532)\tD(fake)1 -1.2055 (-1.2316)\tD(fake)2 -1.1961 (-1.2613)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1962 (-0.1602)\tD repr loss -0.3569 (-0.4256)\n",
            "Epoch: [4][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 12.2331 (13.8607)\tD(fake)1 -1.2142 (-1.2142)\tD(fake)2 -1.2059 (-1.2274)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1937 (-0.1937)\tD repr loss -0.4117 (-0.4241)\n",
            "Epoch: [4][120/390]\tTime  4.583 ( 4.581)\tData  0.000 ( 0.000)\tD(real) 16.7249 (14.9351)\tD(fake)1 -1.3164 (-1.3139)\tD(fake)2 -1.4134 (-1.3267)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0774 (-0.1545)\tD repr loss -0.4247 (-0.4248)\n",
            "Epoch: [4][230/390]\tTime  4.536 ( 4.562)\tData  0.000 ( 0.000)\tD(real) 19.5256 (15.4506)\tD(fake)1 -1.3732 (-1.3239)\tD(fake)2 -1.3663 (-1.3191)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1978 (-0.1670)\tD repr loss -0.4183 (-0.4247)\n",
            "Epoch: [4][340/390]\tTime  4.537 ( 4.558)\tData  0.000 ( 0.000)\tD(real) 16.6235 (16.1384)\tD(fake)1 -1.1760 (-1.2817)\tD(fake)2 -1.2057 (-1.2783)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2094 (-0.1752)\tD repr loss -0.3931 (-0.4248)\n",
            "Epoch: [4][389/390]\tTime  4.514 ( 4.559)\tData  0.000 ( 0.000)\tD(real) 35.2026 (16.7589)\tD(fake)1 -1.1395 (-1.2671)\tD(fake)2 -1.0930 (-1.2682)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2159 (-0.1802)\tD repr loss -0.3452 (-0.4252)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNxlmBIutPfw",
        "outputId": "b23f80c2-400c-49e0-bea4-37c48ad06060"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 18.4805 (18.4542)\tD(fake)1 -1.1450 (-1.1450)\tD(fake)2 -1.4831 (-1.3275)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1902 (-0.1902)\tD repr loss -0.3878 (-0.4161)\n",
            "Epoch: [0][120/390]\tTime  4.597 ( 4.599)\tData  0.000 ( 0.000)\tD(real) 14.2404 (17.2133)\tD(fake)1 -1.7073 (-1.3366)\tD(fake)2 -1.4957 (-1.3555)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2489 (-0.1992)\tD repr loss -0.3884 (-0.4237)\n",
            "Epoch: [0][230/390]\tTime  4.578 ( 4.603)\tData  0.000 ( 0.000)\tD(real) 20.4414 (17.0761)\tD(fake)1 -1.4280 (-1.2958)\tD(fake)2 -1.3233 (-1.2991)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1793 (-0.2023)\tD repr loss -0.3891 (-0.4220)\n",
            "Epoch: [0][340/390]\tTime  4.567 ( 4.597)\tData  0.000 ( 0.000)\tD(real) 11.6684 (17.1595)\tD(fake)1 -1.1255 (-1.2552)\tD(fake)2 -1.1378 (-1.2510)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2707 (-0.2034)\tD repr loss -0.4089 (-0.4242)\n",
            "Epoch: [0][389/390]\tTime  4.550 ( 4.590)\tData  0.000 ( 0.000)\tD(real) 14.7977 (16.8478)\tD(fake)1 -1.3383 (-1.2507)\tD(fake)2 -1.2453 (-1.2489)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1396 (-0.2039)\tD repr loss -0.3939 (-0.4249)\n",
            "Epoch: [1][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 15.4116 (14.2661)\tD(fake)1 -1.2289 (-1.2289)\tD(fake)2 -1.2145 (-1.2277)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2127 (-0.2127)\tD repr loss -0.3879 (-0.4229)\n",
            "Epoch: [1][120/390]\tTime  4.611 ( 4.596)\tData  0.000 ( 0.000)\tD(real) 5.7391 (14.0721)\tD(fake)1 -1.5314 (-1.2575)\tD(fake)2 -1.5162 (-1.2882)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2850 (-0.2282)\tD repr loss -0.3825 (-0.4240)\n",
            "Epoch: [1][230/390]\tTime  4.567 ( 4.579)\tData  0.000 ( 0.000)\tD(real) 13.3311 (13.8963)\tD(fake)1 -1.2135 (-1.2536)\tD(fake)2 -1.1197 (-1.2584)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2432 (-0.2348)\tD repr loss -0.3985 (-0.4236)\n",
            "Epoch: [1][340/390]\tTime  4.598 ( 4.574)\tData  0.000 ( 0.000)\tD(real) 11.8330 (14.9978)\tD(fake)1 -1.3824 (-1.2403)\tD(fake)2 -1.2440 (-1.2305)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2227 (-0.2199)\tD repr loss -0.3385 (-0.4247)\n",
            "Epoch: [1][389/390]\tTime  4.591 ( 4.573)\tData  0.000 ( 0.000)\tD(real) 15.5168 (15.0162)\tD(fake)1 -1.2934 (-1.2353)\tD(fake)2 -1.3160 (-1.2287)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1944 (-0.2221)\tD repr loss -0.3664 (-0.4261)\n",
            "Epoch: [2][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 13.8994 (15.1083)\tD(fake)1 -1.3482 (-1.3482)\tD(fake)2 -1.2207 (-1.2627)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2230 (-0.2230)\tD repr loss -0.4252 (-0.4521)\n",
            "Epoch: [2][120/390]\tTime  4.551 ( 4.574)\tData  0.000 ( 0.000)\tD(real) 14.0501 (16.4390)\tD(fake)1 -1.2391 (-1.2692)\tD(fake)2 -1.1831 (-1.2197)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1734 (-0.2065)\tD repr loss -0.4279 (-0.4289)\n",
            "Epoch: [2][230/390]\tTime  4.504 ( 4.563)\tData  0.000 ( 0.000)\tD(real) 8.3755 (16.1225)\tD(fake)1 -1.2279 (-1.2275)\tD(fake)2 -1.3786 (-1.1974)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2401 (-0.1984)\tD repr loss -0.4467 (-0.4295)\n",
            "Epoch: [2][340/390]\tTime  4.548 ( 4.561)\tData  0.000 ( 0.000)\tD(real) 18.7384 (16.6172)\tD(fake)1 -1.4190 (-1.2218)\tD(fake)2 -1.3385 (-1.1974)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1525 (-0.1834)\tD repr loss -0.4153 (-0.4265)\n",
            "Epoch: [2][389/390]\tTime  4.565 ( 4.560)\tData  0.000 ( 0.000)\tD(real) 20.3366 (16.8102)\tD(fake)1 -1.3234 (-1.2389)\tD(fake)2 -1.3258 (-1.2152)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1633 (-0.1812)\tD repr loss -0.4399 (-0.4280)\n",
            "Epoch: [3][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 22.5017 (22.2762)\tD(fake)1 -1.3511 (-1.3511)\tD(fake)2 -1.3989 (-1.4306)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1342 (-0.1342)\tD repr loss -0.4270 (-0.4213)\n",
            "Epoch: [3][120/390]\tTime  4.554 ( 4.586)\tData  0.000 ( 0.000)\tD(real) 12.9875 (17.8158)\tD(fake)1 -1.2367 (-1.2598)\tD(fake)2 -1.2393 (-1.2642)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1380 (-0.1446)\tD repr loss -0.4094 (-0.4155)\n",
            "Epoch: [3][230/390]\tTime  4.563 ( 4.565)\tData  0.000 ( 0.000)\tD(real) 19.3669 (18.0022)\tD(fake)1 -1.1495 (-1.2803)\tD(fake)2 -1.1378 (-1.2821)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.0747 (-0.1336)\tD repr loss -0.4428 (-0.4212)\n",
            "Epoch: [3][340/390]\tTime  4.536 ( 4.562)\tData  0.000 ( 0.000)\tD(real) 11.9431 (18.2359)\tD(fake)1 -1.2300 (-1.2506)\tD(fake)2 -1.2739 (-1.2657)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1388 (-0.1356)\tD repr loss -0.4020 (-0.4242)\n",
            "Epoch: [3][389/390]\tTime  4.550 ( 4.561)\tData  0.000 ( 0.000)\tD(real) 14.4251 (17.8802)\tD(fake)1 -1.1097 (-1.2466)\tD(fake)2 -1.1113 (-1.2492)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1965 (-0.1434)\tD repr loss -0.4746 (-0.4263)\n",
            "Epoch: [4][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 14.2345 (14.2646)\tD(fake)1 -1.0945 (-1.0945)\tD(fake)2 -1.1087 (-1.0971)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1919 (-0.1919)\tD repr loss -0.4293 (-0.4349)\n",
            "Epoch: [4][120/390]\tTime  4.548 ( 4.593)\tData  0.000 ( 0.000)\tD(real) 18.4222 (15.3829)\tD(fake)1 -1.0922 (-1.1232)\tD(fake)2 -1.4917 (-1.1389)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1288 (-0.1621)\tD repr loss -0.3474 (-0.4353)\n",
            "Epoch: [4][230/390]\tTime  4.592 ( 4.565)\tData  0.000 ( 0.000)\tD(real) 17.6018 (16.3201)\tD(fake)1 -1.2001 (-1.1830)\tD(fake)2 -1.1861 (-1.1896)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2098 (-0.1616)\tD repr loss -0.3925 (-0.4344)\n",
            "Epoch: [4][340/390]\tTime  4.534 ( 4.561)\tData  0.000 ( 0.000)\tD(real) 15.6905 (16.1984)\tD(fake)1 -1.0809 (-1.1918)\tD(fake)2 -1.3916 (-1.2027)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1599 (-0.1688)\tD repr loss -0.3695 (-0.4319)\n",
            "Epoch: [4][389/390]\tTime  4.593 ( 4.563)\tData  0.000 ( 0.000)\tD(real) 13.3790 (16.2321)\tD(fake)1 -1.2508 (-1.2130)\tD(fake)2 -1.2440 (-1.2183)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.1977 (-0.1757)\tD repr loss -0.3865 (-0.4328)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iepY_Go7tf7Y",
        "outputId": "91efbfd3-2ffe-41f1-b9a3-761a4487cf58"
      },
      "source": [
        "args.G_consistency = 0.05\n",
        "args.D_consistency = 0.05\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 17.9570 (14.2278)\tD(fake)1 -1.2709 (-1.2709)\tD(fake)2 -1.1829 (-1.2269)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2012 (-0.2012)\tD repr loss -0.3399 (-0.4037)\n",
            "Epoch: [0][120/390]\tTime  4.588 ( 4.584)\tData  0.000 ( 0.000)\tD(real) 15.2885 (14.5284)\tD(fake)1 -1.0913 (-1.1684)\tD(fake)2 -1.1294 (-1.1457)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2909 (-0.2288)\tD repr loss -0.4536 (-0.4246)\n",
            "Epoch: [0][230/390]\tTime  4.548 ( 4.574)\tData  0.000 ( 0.000)\tD(real) 20.0972 (15.1417)\tD(fake)1 -1.1295 (-1.1620)\tD(fake)2 -2.0565 (-1.1608)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2435 (-0.2391)\tD repr loss -0.3935 (-0.4245)\n",
            "Epoch: [0][340/390]\tTime  4.580 ( 4.569)\tData  0.000 ( 0.000)\tD(real) 10.9581 (15.1178)\tD(fake)1 -1.3627 (-1.2940)\tD(fake)2 -1.2888 (-1.2766)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3094 (-0.2503)\tD repr loss -0.4270 (-0.4265)\n",
            "Epoch: [0][389/390]\tTime  4.568 ( 4.567)\tData  0.000 ( 0.000)\tD(real) 18.6149 (15.0957)\tD(fake)1 -1.2136 (-1.2826)\tD(fake)2 -1.2514 (-1.2700)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3331 (-0.2552)\tD repr loss -0.3976 (-0.4256)\n",
            "Epoch: [1][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 16.6029 (14.0924)\tD(fake)1 -1.1814 (-1.1814)\tD(fake)2 -1.1267 (-1.1550)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2700 (-0.2700)\tD repr loss -0.4439 (-0.4293)\n",
            "Epoch: [1][120/390]\tTime  4.536 ( 4.586)\tData  0.000 ( 0.000)\tD(real) 18.5129 (14.3796)\tD(fake)1 -1.2272 (-1.2711)\tD(fake)2 -1.1943 (-1.2424)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2937 (-0.2479)\tD repr loss -0.3838 (-0.4234)\n",
            "Epoch: [1][230/390]\tTime  4.564 ( 4.574)\tData  0.000 ( 0.000)\tD(real) 14.4511 (15.1209)\tD(fake)1 -1.2663 (-1.2566)\tD(fake)2 -1.2633 (-1.2396)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2962 (-0.2669)\tD repr loss -0.3746 (-0.4253)\n",
            "Epoch: [1][340/390]\tTime  4.524 ( 4.566)\tData  0.000 ( 0.000)\tD(real) 15.2517 (15.5388)\tD(fake)1 -1.1422 (-1.2367)\tD(fake)2 -1.1537 (-1.2241)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3504 (-0.2734)\tD repr loss -0.3846 (-0.4233)\n",
            "Epoch: [1][389/390]\tTime  4.557 ( 4.563)\tData  0.000 ( 0.000)\tD(real) 14.8143 (15.7401)\tD(fake)1 -1.4697 (-1.2364)\tD(fake)2 -1.4513 (-1.2194)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3142 (-0.2790)\tD repr loss -0.3916 (-0.4224)\n",
            "Epoch: [2][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 18.4076 (16.9659)\tD(fake)1 -1.4121 (-1.4121)\tD(fake)2 -1.1742 (-1.3517)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3411 (-0.3411)\tD repr loss -0.4220 (-0.4226)\n",
            "Epoch: [2][120/390]\tTime  4.563 ( 4.579)\tData  0.000 ( 0.000)\tD(real) 18.3822 (17.4185)\tD(fake)1 -1.2465 (-1.2526)\tD(fake)2 -1.2474 (-1.2261)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3162 (-0.3109)\tD repr loss -0.3761 (-0.4250)\n",
            "Epoch: [2][230/390]\tTime  4.525 ( 4.568)\tData  0.000 ( 0.000)\tD(real) 15.9744 (18.5483)\tD(fake)1 -1.2378 (-1.2332)\tD(fake)2 -1.1969 (-1.2184)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3689 (-0.3020)\tD repr loss -0.4121 (-0.4204)\n",
            "Epoch: [2][340/390]\tTime  4.587 ( 4.568)\tData  0.000 ( 0.000)\tD(real) 20.5525 (19.1856)\tD(fake)1 -1.1665 (-1.2191)\tD(fake)2 -1.2514 (-1.2083)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3516 (-0.2999)\tD repr loss -0.3892 (-0.4194)\n",
            "Epoch: [2][389/390]\tTime  4.570 ( 4.567)\tData  0.000 ( 0.000)\tD(real) 16.3172 (19.3420)\tD(fake)1 -1.1972 (-1.2163)\tD(fake)2 -1.1303 (-1.2071)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3351 (-0.3054)\tD repr loss -0.3795 (-0.4200)\n",
            "Epoch: [3][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 23.6180 (20.1167)\tD(fake)1 -1.2649 (-1.2649)\tD(fake)2 -1.2457 (-1.1786)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3180 (-0.3180)\tD repr loss -0.3818 (-0.3992)\n",
            "Epoch: [3][120/390]\tTime  4.550 ( 4.586)\tData  0.000 ( 0.000)\tD(real) 16.8996 (17.2577)\tD(fake)1 -1.0948 (-1.1637)\tD(fake)2 -1.2320 (-1.1708)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2744 (-0.3236)\tD repr loss -0.4025 (-0.4188)\n",
            "Epoch: [3][230/390]\tTime  4.524 ( 4.570)\tData  0.000 ( 0.000)\tD(real) 16.9130 (16.8826)\tD(fake)1 -1.3062 (-1.1931)\tD(fake)2 -1.2894 (-1.2069)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2514 (-0.3072)\tD repr loss -0.4319 (-0.4218)\n",
            "Epoch: [3][340/390]\tTime  4.559 ( 4.566)\tData  0.000 ( 0.000)\tD(real) 14.2646 (17.0278)\tD(fake)1 -1.2867 (-1.2334)\tD(fake)2 -1.2251 (-1.2377)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3381 (-0.3030)\tD repr loss -0.4236 (-0.4186)\n",
            "Epoch: [3][389/390]\tTime  4.554 ( 4.566)\tData  0.000 ( 0.000)\tD(real) 18.4658 (17.2360)\tD(fake)1 -1.3214 (-1.2446)\tD(fake)2 -1.2390 (-1.2458)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3782 (-0.3037)\tD repr loss -0.3808 (-0.4196)\n",
            "Epoch: [4][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 17.6994 (17.7156)\tD(fake)1 -1.1580 (-1.1580)\tD(fake)2 -1.2292 (-1.1934)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3008 (-0.3008)\tD repr loss -0.3626 (-0.4188)\n",
            "Epoch: [4][120/390]\tTime  4.596 ( 4.594)\tData  0.000 ( 0.000)\tD(real) 19.3101 (17.8066)\tD(fake)1 -1.2428 (-1.2666)\tD(fake)2 -1.2176 (-1.2541)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2516 (-0.3045)\tD repr loss -0.4418 (-0.4327)\n",
            "Epoch: [4][230/390]\tTime  4.593 ( 4.576)\tData  0.000 ( 0.000)\tD(real) 18.3570 (18.0451)\tD(fake)1 -1.3053 (-1.2389)\tD(fake)2 -1.2918 (-1.2326)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2809 (-0.2959)\tD repr loss -0.4104 (-0.4289)\n",
            "Epoch: [4][340/390]\tTime  4.560 ( 4.567)\tData  0.000 ( 0.000)\tD(real) 14.8931 (17.6221)\tD(fake)1 -1.1222 (-1.2152)\tD(fake)2 -1.2308 (-1.2199)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3058 (-0.2977)\tD repr loss -0.4356 (-0.4276)\n",
            "Epoch: [4][389/390]\tTime  4.521 ( 4.564)\tData  0.000 ( 0.000)\tD(real) 13.3088 (17.1797)\tD(fake)1 -1.2897 (-1.2221)\tD(fake)2 -1.2591 (-1.2285)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.3064 (-0.2972)\tD repr loss -0.3977 (-0.4269)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5V-0_k5tpiW",
        "outputId": "909de91b-5b75-4a59-854f-94c5006fb1a6"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][ 10/390]\tTime  0.000 ( 0.000)\tData  0.000 ( 0.000)\tD(real) 15.3613 (15.4025)\tD(fake)1 -1.2471 (-1.2471)\tD(fake)2 -1.2362 (-1.2428)\tgrad(D) 0.0000 (0.0000)\tG repr loss -0.2335 (-0.2335)\tD repr loss -0.3741 (-0.4442)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdIo707ZyUic"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9naW-A2OGLMg"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzUaCS1tS8YV"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKWZPniqS5uX"
      },
      "source": [
        "args.G_consistency = 0.1\n",
        "args.D_consistency = 0.1\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYyP-fb7S-WE"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jC0_2Vt4Yd6"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpaUfV94ZJI"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Bh97MA4aCW"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMSlrEvie7Pa"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvYdbtKQe_2-"
      },
      "source": [
        "def show_grid(grid):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(grid.permute(1,2,0))\n",
        "\n",
        "def sample_interpolated_repr(real1, real2):\n",
        "    repr1, repr2 = get_repr(real1), get_repr(real2)\n",
        "    repr = slerp(repr1, repr2)\n",
        "    #repr = lerp(repr1, repr2)\n",
        "    return repr\n",
        "\n",
        "def show_sample(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    #plt.hist(F.normalize(simsiam.encoder(x)).detach()[0].cpu().numpy()); return\n",
        "    x1 = x.cuda(args.gpu)[:16]\n",
        "    x2 = x.cuda(args.gpu)[16:32]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_fake1 = sample_G(sample_interpolated_repr(x1, x2))\n",
        "        x_fake2 = sample_G(sample_interpolated_repr(x1, x2))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "data_sampler = iter(train_loader)\n",
        "show_sample(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gfx3T5m2wah"
      },
      "source": [
        "def show_sample2(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    x = x.cuda(args.gpu)[:16]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_fake = sample_G(get_repr(x))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake).cpu(), padding=2, nrow=4))\n",
        "\n",
        "show_sample2(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKfockIQPyzO"
      },
      "source": [
        "def show_sample3(data_sampler):\n",
        "    x, _ = next(data_sampler)\n",
        "    x = x.cuda(args.gpu)[:16]\n",
        "    show_grid(vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        repr1 = -1+2*torch.rand(16, args.repr_dim).cuda(args.gpu)\n",
        "        repr2 = torch.randn(16, args.repr_dim).cuda(args.gpu)\n",
        "        x_fake1 = sample_G(repr1)\n",
        "        x_fake2 = sample_G(repr2)\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake1).cpu(), padding=2, nrow=4))\n",
        "    show_grid(vutils.make_grid(inv_normalize(x_fake2).cpu(), padding=2, nrow=4))\n",
        "\n",
        "show_sample3(data_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtDpMGCMid7O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU296umGlbxU"
      },
      "source": [
        "args.G_consistency = 100.\n",
        "args.D_consistency = 100.\n",
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqJajcHmlcOD"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itX7h7kylcnQ"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuR7QOUQlc7p"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2wAhFAbldNu"
      },
      "source": [
        "run(epochs_per_cell)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZDNQca57Hif"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}