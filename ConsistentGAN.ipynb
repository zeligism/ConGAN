{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConsistentGAN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/ConGAN/blob/main/ConsistentGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxx3Jy_8qsPE"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFx20xTNkpQ",
        "outputId": "7ab69b96-b651-4eeb-af76-31402f32dcb6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QNzdq01hSb"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlF68ff2K8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_Qrpq7z3iJ"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import log2\n",
        "from pprint import pformat\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDduLe1Qkd9"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRxrufxw1cm"
      },
      "source": [
        "### Report Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmEyNG58w2kJ"
      },
      "source": [
        "def plot_lines(losses_dict, filename=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots the losses of the discriminator and the generator.\n",
        "\n",
        "    Args:\n",
        "        filename: The plot's filename. If None, plot won't be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(title)\n",
        "    for label, losses in losses_dict.items():\n",
        "        plt.plot(losses, label=label)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.legend()\n",
        "    \n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def create_progress_animation(frames, filename):\n",
        "    \"\"\"\n",
        "    Creates a video of the progress of the generator on a fixed latent vector.\n",
        "\n",
        "    Args:\n",
        "        filename: The animation's filename.\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    ims = [[plt.imshow(img.permute(1,2,0), animated=True)]\n",
        "           for img in frames]\n",
        "    ani = animation.ArtistAnimation(fig, ims, blit=True)\n",
        "    \n",
        "    ani.save(filename)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def generate_grid(generator, latent):\n",
        "    \"\"\"\n",
        "    Check generator's output on latent vectors and return it.\n",
        "\n",
        "    Args:\n",
        "        generator: The generator.\n",
        "        latent: Latent vector from which an image grid will be generated.\n",
        "\n",
        "    Returns:\n",
        "        A grid of images generated by `generator` from `latent`.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(latent).detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(fake.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzwGurc1qOx"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhc2oS53G4e"
      },
      "source": [
        "## PyTorch Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU7HFc6t5N8w"
      },
      "source": [
        "### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHPo8w13JmH"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding half the size of features,\n",
        "    e.g. if input is [in_channels, 64, 64], output will be [out_channels, 32, 32].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.conv = nn.utils.parametrizations.spectral_norm(self.conv)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.LeakyReLU(0.2, inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding double the size of features,\n",
        "    e.g. if input is [in_channels, 32, 32], output will be [out_channels, 64, 64].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.convT = nn.utils.parametrizations.spectral_norm(self.convT)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.ReLU(inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convT(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=16,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,\n",
        "                 D_block=ConvBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        using_grad_penalty = gan_type in (\"gan-gp\", \"wgan-gp\")\n",
        "        output_sigmoid = output_sigmoid and gan_type in (\"gan\", \"gan-gp\")\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm and not using_grad_penalty,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Input layer\n",
        "        self.input_layer = D_block(image_channels, features[0], **block_config)\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            D_block(in_features, out_features, **block_config)\n",
        "            for in_features, out_features in zip(features, features[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer (feature_size = 3, 4, or 5 -> 1)\n",
        "        if fully_convolutional:\n",
        "            self.output_layer = nn.Sequential(\n",
        "                nn.Conv2d(features[-1], num_latents, latent_kernel, bias=False),\n",
        "                nn.Flatten(),\n",
        "            )\n",
        "        else:\n",
        "            self.output_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(features[-1] * latent_kernel**2, num_latents, bias=False)\n",
        "            )\n",
        "        \n",
        "        self.hidden_dim = features[-1] * latent_kernel**2\n",
        "\n",
        "        # Add sigmoid activation if using regular GAN loss\n",
        "        self.output_activation = nn.Sigmoid() if output_sigmoid else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        if self.output_activation:\n",
        "            x = self.output_activation(x)\n",
        "        # Remove H and W dimensions, infer channels dim (remove if 1)\n",
        "        x = x.view(x.size(0), -1).squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 G_block=ConvTBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Reverse order of image sizes and features for generator\n",
        "        image_sizes = image_sizes[::-1]\n",
        "        features = features[::-1]\n",
        "\n",
        "        # Input layer\n",
        "        if fully_convolutional:\n",
        "            self.input_layer = G_block(num_latents, features[0], kernel_size=latent_kernel,\n",
        "                                       stride=1, padding=0, **block_config)\n",
        "        else:\n",
        "            self.input_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(num_latents, features[0] * image_sizes[0]**2, bias=False),\n",
        "                View(features[0], image_sizes[0], image_sizes[0])\n",
        "            )\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            G_block(in_features, out_features, kernel_size=4+(expected_size%2), **block_config)\n",
        "            for in_features, out_features, expected_size in zip(features, features[1:], image_sizes[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.ConvTranspose2d(features[-1], image_channels, kernel_size=4+(image_size%2),\n",
        "                                               stride=2, padding=1, bias=False)\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add H and W dimensions, infer channels dim (add if none)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = self.output_activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN(nn.Module):\n",
        "    \"\"\"Deep Convolutional Generative Adversarial Network\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 D_num_features=64,\n",
        "                 G_num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 output_sigmoid=True,):\n",
        "        \"\"\"\n",
        "        Initializes DCGAN.\n",
        "\n",
        "        Args:\n",
        "            num_latents: Number of latent factors.\n",
        "            num_features: Number of features in the convolutions.\n",
        "            image_channels: Number of channels in the input image.\n",
        "            image_size: Size (i.e. height or width) of image.\n",
        "            gan_type: Type of GAN (e.g. \"gan\" or \"wgan-gp\").\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_latents = num_latents\n",
        "        self.D_num_features = D_num_features\n",
        "        self.G_num_features = G_num_features\n",
        "        self.image_channels = image_channels\n",
        "        self.image_size = image_size\n",
        "        self.feature_multiplier = feature_multiplier\n",
        "        self.gan_type = gan_type\n",
        "        self.fully_convolutional = fully_convolutional\n",
        "        self.activation = activation\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.use_spectralnorm = use_spectralnorm\n",
        "\n",
        "        D_params = {\n",
        "            \"num_latents\": 1,  # XXX\n",
        "            \"num_features\": D_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "            \"output_sigmoid\": output_sigmoid,\n",
        "        }\n",
        "        G_params = {\n",
        "            \"num_latents\": num_latents,\n",
        "            \"num_features\": G_num_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "            \"fully_convolutional\": fully_convolutional,\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": True,\n",
        "            \"use_spectralnorm\": False,  # XXX\n",
        "        }\n",
        "\n",
        "        self.D = DCGAN_Discriminator(**D_params)\n",
        "        self.G = DCGAN_Generator(**G_params)\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape, including_batch=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.including_batch = including_batch\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.including_batch:\n",
        "            return x.view(*self.shape)\n",
        "        else:\n",
        "            return x.view(x.size(0), *self.shape)\n",
        "\n",
        "class ChannelNoise(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel noise injection module.\n",
        "    Adds a linearly transformed noise to a convolution layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, std=0.02):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise_size = [x.size()[0], 1, *x.size()[2:]]  # single channel\n",
        "        noise = self.std * torch.randn(noise_size).to(x)\n",
        "\n",
        "        return x + self.scale * noise"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSPvaklIYvwT"
      },
      "source": [
        "### Third-party modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9B8z4ZY4oX"
      },
      "source": [
        "#### DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLNQ90KUY_Is"
      },
      "source": [
        "#https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model.py\n",
        "\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "\n",
        "class SNDCGAN_Generator(nn.Module):\n",
        "    def __init__(self, z_dim, channels=3):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, 512, 4, stride=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=(1,1)),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=(1,1)),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=(1,1)),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, channels, 3, stride=1, padding=(1,1)),\n",
        "            # use this instead of last line for 64:\n",
        "            # nn.ConvTranspose2d(64, 32, 4, stride=2, padding=(1,1)),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z.view(-1, self.z_dim, 1, 1))\n",
        "\n",
        "class SNDCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self, channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(channels, 64, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(64, 64, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(64, 128, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(128, 128, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(128, 256, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(256, 256, 4, stride=2, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            spectral_norm(nn.Conv2d(256, 512, 3, stride=1, padding=(1,1))),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            # use this instead of last 2 lines for 64:\n",
        "            # spectral_norm(nn.Conv2d(256, 256, 3, stride=1, padding=(1,1))),\n",
        "            # nn.LeakyReLU(0.1, inplace=True),\n",
        "            # spectral_norm(nn.Conv2d(256, 512, 3, stride=1, padding=(1,1))),\n",
        "            # nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.hidden_dim = 4 * 4 * 512\n",
        "        self.fc = spectral_norm(nn.Linear(self.hidden_dim, 1))\n",
        "\n",
        "    def forward(self, x, return_h=False):\n",
        "        h = self.main(x)\n",
        "        out = self.fc(h).squeeze(1)\n",
        "        if return_h:\n",
        "            return out, h\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class SNDCGAN(nn.Module):\n",
        "    def __init__(self, num_latents, channels=3):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNDCGAN_Discriminator(channels=channels)\n",
        "        self.G = SNDCGAN_Generator(num_latents, channels=channels)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiu_Ri-XY6yy"
      },
      "source": [
        "#### ResNet GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjWBbXzdlSF"
      },
      "source": [
        "# https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/model_resnet.py\n",
        "\n",
        "from torch.nn.utils import spectral_norm\n",
        "\n",
        "class ResBlockGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            self.conv1,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            self.conv2\n",
        "            )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "\n",
        "class ResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "\n",
        "        if stride == 1:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2)\n",
        "                )\n",
        "        else:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                spectral_norm(self.conv2),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "                )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "\n",
        "            self.bypass_conv = nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)\n",
        "            nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "            self.bypass = nn.Sequential(\n",
        "                spectral_norm(self.bypass_conv),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            )\n",
        "            # if in_channels == out_channels:\n",
        "            #     self.bypass = nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            # else:\n",
        "            #     self.bypass = nn.Sequential(\n",
        "            #         spectral_norm(nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)),\n",
        "            #         nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            #     )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "# special ResBlock just for the first layer of the discriminator\n",
        "class FirstResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(FirstResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        self.bypass_conv = nn.Conv2d(in_channels, out_channels, 1, 1, padding=0)\n",
        "        nn.init.xavier_uniform_(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.conv2.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "        # we don't want to apply ReLU activation to raw image before convolution transformation.\n",
        "        self.model = nn.Sequential(\n",
        "            spectral_norm(self.conv1),\n",
        "            nn.ReLU(),\n",
        "            spectral_norm(self.conv2),\n",
        "            nn.AvgPool2d(2)\n",
        "            )\n",
        "        self.bypass = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            spectral_norm(self.bypass_conv),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "class SNResNet_Generator(nn.Module):\n",
        "    def __init__(self, z_dim, image_size=64, channels=3):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * image_size)\n",
        "        self.final = nn.Conv2d(image_size, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform_(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform_(self.final.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ResBlockGenerator(image_size, image_size, stride=2),\n",
        "            ResBlockGenerator(image_size, image_size, stride=2),\n",
        "            ResBlockGenerator(image_size, image_size, stride=2),\n",
        "            nn.BatchNorm2d(image_size),\n",
        "            nn.ReLU(),\n",
        "            self.final,\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(self.dense(z).view(-1, self.image_size, 4, 4))\n",
        "\n",
        "class SNResNet_Discriminator(nn.Module):\n",
        "    def __init__(self, image_size=64, channels=3):\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "                FirstResBlockDiscriminator(channels, image_size, stride=2),\n",
        "                ResBlockDiscriminator(image_size, image_size, stride=2),\n",
        "                ResBlockDiscriminator(image_size, image_size),\n",
        "                ResBlockDiscriminator(image_size, image_size),\n",
        "                nn.ReLU(),\n",
        "                nn.AvgPool2d(8),\n",
        "            )\n",
        "        self.fc = nn.Linear(image_size, 1)\n",
        "        nn.init.xavier_uniform_(self.fc.weight.data, 1.)\n",
        "        self.fc = spectral_norm(self.fc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.model(x).view(-1, self.image_size))\n",
        "\n",
        "\n",
        "class SNResNetGAN(nn.Module):\n",
        "    def __init__(self, num_latents, image_size=64, channels=3):\n",
        "        super().__init__()\n",
        "        self.num_latents = num_latents\n",
        "        self.channels = channels\n",
        "        self.D = SNResNet_Discriminator(image_size=image_size, channels=channels)\n",
        "        self.G = SNResNet_Generator(num_latents, image_size=image_size, channels=channels)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZA5i3oaK3kK",
        "outputId": "e97d3152-eb98-472c-942a-1b05db9c3534"
      },
      "source": [
        "! clone https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.git\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: clone: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYujBEzC7EOO"
      },
      "source": [
        "#### SimSiam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YcNut27F-v"
      },
      "source": [
        "class SimSiam(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a SimSiam model.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=2048, pred_dim=512):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 2048)\n",
        "        pred_dim: hidden dimension of the predictor (default: 512)\n",
        "        \"\"\"\n",
        "        super(SimSiam, self).__init__()\n",
        "\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEuurkcmLLd3"
      },
      "source": [
        "### Latent Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTlMYVgLN5E"
      },
      "source": [
        "class LatentTransform(nn.Module):\n",
        "    def __init__(self, repr_dim, latent_dim, hidden_dim, full_transform=True, noop=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.full_transform = full_transform\n",
        "        self.noop = noop\n",
        "\n",
        "        if self.noop:\n",
        "            self.output_dim = self.latent_dim\n",
        "            return\n",
        "        elif self.full_transform:\n",
        "            self.input_dim = self.repr_dim + self.latent_dim\n",
        "            self.output_dim = self.hidden_dim\n",
        "        else:\n",
        "            self.input_dim = self.repr_dim\n",
        "            self.output_dim = self.hidden_dim + self.latent_dim\n",
        "\n",
        "        self.transform = nn.Linear(self.input_dim, self.hidden_dim, bias=False)\n",
        "    \n",
        "    def forward(self, repr, noise):\n",
        "        if self.noop:\n",
        "            return noise\n",
        "\n",
        "        # assuming latent is concat as [repr,noise] XXX\n",
        "        if self.full_transform:\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "            latent = self.transform(latent)\n",
        "        else:\n",
        "            repr = self.transform(repr)\n",
        "            latent = torch.cat([repr, noise], dim=1)\n",
        "\n",
        "        return latent\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRivPV9BwFk"
      },
      "source": [
        "# Training v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rpQp2E9rE5"
      },
      "source": [
        "### Imports and globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51zFNn509xLz"
      },
      "source": [
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "GANSIAM_DIR = \"/content/drive/My Drive/gansiam/\"\n",
        "SIMSIAM_PATH = os.path.join(GANSIAM_DIR, \"pretrained_batch256.tar\")\n",
        "TINYIMAGENET_DIR = \"tiny-imagenet-200\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9X_JYE2Vwxd"
      },
      "source": [
        "### Download Tiny Imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "559H2an_V03M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5029940-cfed-4662-d4a1-394c40bff723"
      },
      "source": [
        "%%bash\n",
        "if [[ -d  \"tiny-imagenet-200\" ]]; then\n",
        "    echo \"Tiny Imagenet exists.\"\n",
        "else\n",
        "    wget -q \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "    unzip -qq \"tiny-imagenet-200.zip\" && rm \"tiny-imagenet-200.zip\"\n",
        "    echo \"Downloaded Tiny Imagenet.\"\n",
        "fi"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Tiny Imagenet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbo7T6blPVTc"
      },
      "source": [
        "### Load pre-trained SimSiam model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyzHmINsryyh"
      },
      "source": [
        "#### SimSiam Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8KJUUeWr1dI"
      },
      "source": [
        "from PIL import ImageFilter\n",
        "import random\n",
        "\n",
        "\n",
        "class TwoCropsTransform:\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        q = self.base_transform(x)\n",
        "        k = self.base_transform(x)\n",
        "        return [q, k]\n",
        "\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
        "\n",
        "    def __init__(self, sigma=[.1, 2.]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr8clgi_AzY",
        "outputId": "343d211a-d710-4e11-894a-e4d4d4aea6ba"
      },
      "source": [
        "checkpoint = torch.load(SIMSIAM_PATH, map_location=\"cuda:0\")\n",
        "# remove 'module.' from dict keys\n",
        "model_dict = OrderedDict((k[7:], v) for k, v in checkpoint[\"state_dict\"].items())\n",
        "\n",
        "# Load model\n",
        "simsiam = SimSiam(models.__dict__[\"resnet50\"])\n",
        "simsiam.load_state_dict(model_dict)\n",
        "#print(simsiam)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckB_xSVX8kB"
      },
      "source": [
        "# Training v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nouxldrYb0r"
      },
      "source": [
        "## Args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUP5vn8OX--p"
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        #self.data = TINYIMAGENET_DIR  # used for training Tiny ImageNet\n",
        "        self.load = False\n",
        "        self.print_freq = 10\n",
        "        self.seed = None\n",
        "        self.gpu = 0\n",
        "        self.workers = 2\n",
        "        self.epochs = 100\n",
        "\n",
        "        ### lr is about 2e-4 for batch size of 64\n",
        "        # we scale according to our choice of batch size\n",
        "        self.batch_size = 256\n",
        "        self.D_lr = 2e-4 * (64 / self.batch_size)\n",
        "        self.G_lr = 2e-4 * (64 / self.batch_size)\n",
        "        self.Q_lr = self.D_lr\n",
        "        self.latent_transform_lr = self.G_lr\n",
        "        self.lr_decay = 0.01\n",
        "        self.betas = (0.5, 0.9)\n",
        "\n",
        "        # SimSiam (don't change if loading pre-trained)\n",
        "        self.dim = 2048\n",
        "        self.pred_dim = 512\n",
        "\n",
        "        # GAN\n",
        "        self.repr_dim = self.dim  # don't change\n",
        "        self.latent_dim = 128\n",
        "        self.num_features = 64\n",
        "        self.D_iters = 1\n",
        "\n",
        "        self.gan_type = \"gan\"  # ignore this\n",
        "        self.wgan = False  # if False, use spectral norm\n",
        "        self.grad_penalty = 0.  # 0 if wgan is False\n",
        "        self.grad_center = 1.  # not important\n",
        "\n",
        "        self.generate_grid_interval = 200\n",
        "\n",
        "        # make noise proportional to sd(data)\n",
        "        self.im_noise = 1e-3  # image sd is about 1.0\n",
        "        self.repr_noise = 1e-6  # repr sd is about 0.001\n",
        "        \n",
        "        \n",
        "        self.G_consistency = 0.1\n",
        "        self.D_consistency = 0.1\n",
        "\n",
        "\n",
        "GENERATED_GRIDS = []\n",
        "IMAGE_SIZE = 32\n",
        "DATASET = \"CIFAR10\"\n",
        "args = Args()"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xihRlU0PYhiJ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW_P-JfeYiOe",
        "outputId": "22d95863-acee-4c01-b5ca-31ea096d3098"
      },
      "source": [
        "# image normalization\n",
        "#mean = [0.485, 0.456, 0.406]\n",
        "#std = [0.229, 0.224, 0.225]\n",
        "mean = [0.5]\n",
        "std = [0.5]\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "inv_normalize = transforms.Normalize(\n",
        "   mean= [-m/s for m, s in zip(mean, std)],\n",
        "   std= [1/s for s in std]\n",
        ")\n",
        "\n",
        "augmentation = [\n",
        "    #transforms.RandomResizedCrop(IMAGE_SIZE),\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "# MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "_augmentation = [\n",
        "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.2, 1.)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]\n",
        "\n",
        "if DATASET == \"MNIST\":\n",
        "    augmentation = [transforms.Grayscale(3)] + augmentation\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=os.path.join(GANSIAM_DIR, \"mnist/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CelebA\":\n",
        "    train_dataset = datasets.CelebA(\n",
        "        root=os.path.join(GANSIAM_DIR, \"celeba\"), download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "elif DATASET == \"CIFAR10\":\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=os.path.join(GANSIAM_DIR, \"cifar10/train\"), train=True, download=True,\n",
        "        transform=transforms.Compose(augmentation))\n",
        "        #transform=TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "elif DATASET == \"Tiny Imagenet\":\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        root=os.path.join(TINYIMAGENET_DIR, 'train'),\n",
        "        transform=transforms.Compose(augmentation))\n",
        "else:\n",
        "    raise Exception(f\"Dataset '{DATASET}' not found\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=args.workers, pin_memory=True, sampler=None, drop_last=True)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQ0_BfjmAHf"
      },
      "source": [
        "### Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLiHFvBimb3"
      },
      "source": [
        "def D_criterion_NS(D_real, D_fake):\n",
        "    d_loss = F.softplus(-D_real) + F.softplus(D_fake)\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_NS(D_fake):\n",
        "    return F.softplus(-D_fake).mean()\n",
        "\n",
        "def D_criterion_LS(D_real, D_fake):\n",
        "    d_loss = 0.5 * (D_real - torch.ones_like(D_real))**2 + 0.5 * (D_fake)**2\n",
        "    return d_loss.mean()\n",
        "\n",
        "def G_criterion_LS(D_fake):\n",
        "    gen_loss = 0.5 * (D_fake - torch.ones_like(D_fake))**2\n",
        "    return gen_loss.mean()\n",
        "\n",
        "def D_criterion_hinge(D_real, D_fake):\n",
        "    return torch.mean(F.relu(1. - D_real)) + torch.mean(F.relu(1. + D_fake))\n",
        "\n",
        "def G_criterion_hinge(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def D_criterion_wasserstein(D_real, D_fake):\n",
        "    return torch.mean(D_fake - D_real)\n",
        "\n",
        "def G_criterion_wasserstein(D_fake):\n",
        "    return -torch.mean(D_fake)\n",
        "\n",
        "def interpolate(real, fake):\n",
        "    eps_size = [1] * len(real.size())\n",
        "    eps_size[0] = real.size(0)\n",
        "    eps = torch.rand(eps_size).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "\n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_x, x, torch.ones_like(D_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Z4Ke6DYkDg"
      },
      "source": [
        "## Model + Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rO_MvGzYldx",
        "outputId": "4e69b104-aa22-44a1-9d0c-b807056a4fd8"
      },
      "source": [
        "if args.seed is not None:\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.set_device(args.gpu)\n",
        "\n",
        "latent_transform = LatentTransform(repr_dim=args.repr_dim,\n",
        "                                   latent_dim=args.latent_dim,\n",
        "                                   hidden_dim=args.latent_dim,\n",
        "                                   full_transform=False,\n",
        "                                   #noop=True,  # for testing\n",
        "                                   )\n",
        "\n",
        "\n",
        "model = DCGAN(num_latents=latent_transform.output_dim,\n",
        "              image_size=IMAGE_SIZE,\n",
        "              gan_type=args.gan_type,  # doesn't make a difference\n",
        "              use_batchnorm=False,  # for D only\n",
        "              output_sigmoid=False,  # for D only\n",
        "              use_spectralnorm=not args.wgan,\n",
        "              )\n",
        "\n",
        "model = SNDCGAN(num_latents=latent_transform.output_dim)\n",
        "\n",
        "Q_hidden_dim = args.pred_dim//4\n",
        "Q = nn.Sequential(nn.Linear(model.D.hidden_dim, Q_hidden_dim, bias=False),\n",
        "                  nn.BatchNorm1d(Q_hidden_dim),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Linear(Q_hidden_dim, args.repr_dim))\n",
        "\n",
        "if args.D_consistency == 0.:\n",
        "    Q = nn.Module()\n",
        "\n",
        "model = model.cuda(args.gpu)\n",
        "Q = Q.cuda(args.gpu)\n",
        "latent_transform = latent_transform.cuda(args.gpu)\n",
        "simsiam = simsiam.cuda(args.gpu)\n",
        "\n",
        "print(\"Num of params in D:\", sum(map(torch.numel, model.D.parameters())))\n",
        "print(\"Num of params in G:\", sum(map(torch.numel, model.G.parameters())))\n",
        "print(\"Num of params in Q:\", sum(map(torch.numel, Q.parameters())))\n",
        "print(\"Num of params in LT:\", sum(map(torch.numel, latent_transform.parameters())))\n",
        "\n",
        "# Define D and G loss functions\n",
        "if args.wgan:\n",
        "    args.grad_penalty = 10.\n",
        "    D_criterion = D_criterion_wasserstein\n",
        "    G_criterion = G_criterion_wasserstein\n",
        "else:\n",
        "    args.grad_penalty = 0.\n",
        "    D_criterion = D_criterion_LS\n",
        "    G_criterion = G_criterion_LS\n",
        "\n",
        "# Optimizers\n",
        "D_optimizer = torch.optim.Adam(model.D.parameters(), args.D_lr, betas=args.betas)\n",
        "\n",
        "G_optimizer = torch.optim.Adam(\n",
        "    [{\"params\": model.G.parameters()},\n",
        "     {\"params\": latent_transform.parameters(), \"lr\": args.latent_transform_lr},\n",
        "     {\"params\": Q.parameters(), \"lr\": args.Q_lr}],\n",
        "     args.G_lr, betas=args.betas)\n",
        "\n",
        "D_sched = torch.optim.lr_scheduler.ExponentialLR(D_optimizer, 1. - args.lr_decay)\n",
        "G_sched = torch.optim.lr_scheduler.ExponentialLR(G_optimizer, 1. - args.lr_decay)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if args.load:\n",
        "    model.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/model.pth.tar\"))\n",
        "    latent_transform.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\"))\n",
        "    D_sched.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/D_sched.pth.tar\"))\n",
        "    G_sched.load_state_dict(torch.load(f\"{GANSIAM_DIR}/results/G_sched.pth.tar\"))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of params in D: 2935873\n",
            "Num of params in G: 4854275\n",
            "Num of params in Q: 1313024\n",
            "Num of params in LT: 262144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTqwby4cX0i",
        "outputId": "e13c99cc-9849-45b4-d3ae-28b83feed57f"
      },
      "source": [
        "print(model)\n",
        "print(Q)\n",
        "print(latent_transform)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SNDCGAN(\n",
            "  (D): SNDCGAN_Discriminator(\n",
            "    (main): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (3): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (9): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (10): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            "      (14): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (fc): Linear(in_features=8192, out_features=1, bias=True)\n",
            "  )\n",
            "  (G): SNDCGAN_Generator(\n",
            "    (model): Sequential(\n",
            "      (0): ConvTranspose2d(256, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "      (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU()\n",
            "      (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ReLU()\n",
            "      (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (11): ReLU()\n",
            "      (12): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=8192, out_features=128, bias=False)\n",
            "  (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Linear(in_features=128, out_features=2048, bias=True)\n",
            ")\n",
            "LatentTransform(\n",
            "  (transform): Linear(in_features=2048, out_features=128, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeDicP6QZNQ2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA8BoUEjNrlR"
      },
      "source": [
        "def sample_latent(num_samples):\n",
        "    return torch.randn(num_samples, args.latent_dim)\n",
        "\n",
        "def check_G_progress(G):\n",
        "    with torch.no_grad():\n",
        "        z = latent_transform(fixed_repr, fixed_noise)\n",
        "        fake_progress = G(z)\n",
        "    im_grid = torch.cat([fixed_x, fake_progress], dim=0)\n",
        "    grid = vutils.make_grid(im_grid.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "    return grid"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckj9x-2fNtnp"
      },
      "source": [
        "# Sample a global latent for reuse\n",
        "fixed_x, _ = next(iter(train_loader))\n",
        "fixed_x = fixed_x[:32].cuda(args.gpu)\n",
        "with torch.no_grad():\n",
        "    fixed_repr = simsiam.encoder(fixed_x)\n",
        "    fixed_repr = F.normalize(fixed_repr)\n",
        "fixed_noise = sample_latent(32).cuda(args.gpu)\n",
        "fixed_latent = torch.cat([fixed_repr, fixed_noise], dim=1)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7gU4I8OZOer"
      },
      "source": [
        "def train(train_loader, model, simsiam,\n",
        "          D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    D_on_reals = AverageMeter('D(real)', ':.4f')\n",
        "    D_on_fakes1 = AverageMeter('D(fake)1', ':.4f')\n",
        "    D_on_fakes2 = AverageMeter('D(fake)2', ':.4f')\n",
        "    D_grads = AverageMeter('grad(D)', ':.4f')\n",
        "    repr_losses = AverageMeter('repr loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time,\n",
        "         D_on_reals, D_on_fakes1, D_on_fakes2, D_grads, repr_losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    D_grad_penalty = torch.zeros(1).cuda(args.gpu)\n",
        "    repr_loss = torch.zeros(1).cuda(args.gpu)\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        x = x.cuda(args.gpu, non_blocking=True)\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # compute output and loss\n",
        "        with torch.no_grad():\n",
        "            repr = simsiam.encoder(x)\n",
        "            repr = F.normalize(repr + args.repr_noise * torch.randn_like(repr))\n",
        "\n",
        "        ### train GAN\n",
        "        # Add noise to real sample\n",
        "        real = x + args.im_noise * torch.randn_like(x)\n",
        "\n",
        "        # Sample from generator\n",
        "        noise = sample_latent(batch_size).cuda(args.gpu)\n",
        "        z = latent_transform(repr, noise)\n",
        "        with torch.no_grad():\n",
        "            fake = model.G(z)\n",
        "        # Add noise to fake sample as well\n",
        "        fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "\n",
        "        # Classify real and fake data\n",
        "        D_real = model.D(real)\n",
        "        D_fake = model.D(fake)\n",
        "\n",
        "        # Calculate loss\n",
        "        D_loss = D_criterion(D_real, D_fake)\n",
        "        # Gradient penalty\n",
        "        if args.grad_penalty != 0.:\n",
        "            D_grad_penalty = simple_gradient_penalty(\n",
        "                model.D, interpolate(real, fake), center=args.grad_center)\n",
        "            D_loss += args.grad_penalty * D_grad_penalty\n",
        "\n",
        "        # Calculate gradient and minimize\n",
        "        D_optimizer.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Save data\n",
        "        D_on_reals.update(D_real.mean().item(), batch_size)\n",
        "        D_on_fakes1.update(D_fake.mean().item(), batch_size)\n",
        "        D_grads.update(D_grad_penalty.mean().item(), batch_size)\n",
        "\n",
        "        if (i+1) % args.D_iters == 0:\n",
        "            # Sample from generator\n",
        "            noise = sample_latent(batch_size).cuda(args.gpu)\n",
        "            z = latent_transform(repr, noise)\n",
        "            fake = model.G(z)\n",
        "            fake = fake + args.im_noise * torch.randn_like(fake)\n",
        "            # Classify fake images\n",
        "            D_fake, h_fake = model.D(fake, return_h=True)\n",
        "            # Calculate adversarial loss\n",
        "            G_loss = G_criterion(D_fake)\n",
        "            # Caluclate consistency loss\n",
        "            consistency_loss = torch.zeros(1).cuda(args.gpu)\n",
        "            if args.G_consistency != 0.:\n",
        "                G_repr = simsiam.encoder(fake)\n",
        "                G_repr_loss = -F.cosine_similarity(G_repr, repr).mean()\n",
        "                consistency_loss += args.G_consistency * G_repr_loss\n",
        "            if args.D_consistency != 0.:\n",
        "                D_repr = Q(h_fake)\n",
        "                D_repr_loss = -F.cosine_similarity(D_repr, repr).mean()\n",
        "                consistency_loss += args.D_consistency * D_repr_loss\n",
        "            # Calculate gradient and minimize\n",
        "            G_optimizer.zero_grad()\n",
        "            (G_loss + consistency_loss).backward()\n",
        "            G_optimizer.step()\n",
        "\n",
        "            # Save data\n",
        "            D_on_fakes2.update(D_fake.mean().item(), batch_size)\n",
        "            repr_losses.update(consistency_loss.mean().item(), batch_size)\n",
        "\n",
        "        # Check generator's progress by recording its output on a fixed input\n",
        "        if i % args.generate_grid_interval == 0:\n",
        "            grid = check_G_progress(model.G)\n",
        "            GENERATED_GRIDS.append(grid)\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.display(i)\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24ES94Re55W"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDMPwe-ae6q-"
      },
      "source": [
        "def save():\n",
        "    torch.save({'state_dict': model.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/model.pth.tar\")\n",
        "    torch.save({'state_dict': latent_transform.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/latent_transform.pth.tar\")\n",
        "    torch.save({'state_dict': D_sched.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/D_sched.pth.tar\")\n",
        "    torch.save({'state_dict': G_sched.state_dict()},\n",
        "                f\"{GANSIAM_DIR}/results/G_sched.pth.tar\")\n",
        "\n",
        "def save_vid():\n",
        "    vidname = f\"grids_per_{args.generate_grid_interval}_iters.mp4\"\n",
        "    vidname = os.path.join(GANSIAM_DIR, \"results\", \"progress\", vidname)\n",
        "    create_progress_animation(GENERATED_GRIDS, vidname)\n",
        "\n",
        "def run(epochs):\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, simsiam,\n",
        "            D_criterion, G_criterion, D_optimizer, G_optimizer, epoch, args)\n",
        "\n",
        "        D_sched.step()\n",
        "        G_sched.step()\n",
        "\n",
        "        # Check G's progress evey epoch by generating an image\n",
        "        grid = check_G_progress(model.G)\n",
        "        imname = f'{GANSIAM_DIR}/results/progress/grid_{epoch:04d}.png'\n",
        "        plt.imsave(imname, grid.permute(1,2,0).numpy())\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            save()\n"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNNZfXWe5Rr",
        "outputId": "67c0a771-f769-4029-c7c1-65f6b4d45703"
      },
      "source": [
        "run(10)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  2.989 ( 2.989)\tData  0.193 ( 0.193)\tD(real) 0.0068 (0.0068)\tD(fake)1 0.0080 (0.0080)\tD(fake)2 0.0534 (0.0534)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0081 (-0.0081)\n",
            "Epoch: [0][ 10/195]\tTime  0.358 ( 0.590)\tData  0.000 ( 0.018)\tD(real) 0.6539 (0.2950)\tD(fake)1 0.3965 (0.2456)\tD(fake)2 0.3649 (0.2891)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0009 (-0.0023)\n",
            "Epoch: [0][ 20/195]\tTime  0.346 ( 0.473)\tData  0.000 ( 0.009)\tD(real) 0.9362 (0.5609)\tD(fake)1 0.1287 (0.2212)\tD(fake)2 0.0278 (0.2148)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0317 (-0.0046)\n",
            "Epoch: [0][ 30/195]\tTime  0.343 ( 0.433)\tData  0.000 ( 0.007)\tD(real) 1.1096 (0.6770)\tD(fake)1 0.1834 (0.1760)\tD(fake)2 -0.0651 (0.1450)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0068 (-0.0049)\n",
            "Epoch: [0][ 40/195]\tTime  0.345 ( 0.412)\tData  0.000 ( 0.005)\tD(real) 0.9961 (0.7460)\tD(fake)1 0.0304 (0.1355)\tD(fake)2 -0.0154 (0.1062)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0036 (-0.0043)\n",
            "Epoch: [0][ 50/195]\tTime  0.344 ( 0.399)\tData  0.000 ( 0.004)\tD(real) 0.9106 (0.7922)\tD(fake)1 -0.0159 (0.1083)\tD(fake)2 0.0536 (0.0806)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0036 (-0.0046)\n",
            "Epoch: [0][ 60/195]\tTime  0.356 ( 0.391)\tData  0.000 ( 0.003)\tD(real) 0.9838 (0.8247)\tD(fake)1 -0.0033 (0.0920)\tD(fake)2 0.0010 (0.0658)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0052 (-0.0058)\n",
            "Epoch: [0][ 70/195]\tTime  0.347 ( 0.385)\tData  0.000 ( 0.003)\tD(real) 1.0589 (0.8461)\tD(fake)1 0.0449 (0.0795)\tD(fake)2 -0.0180 (0.0539)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0104 (-0.0070)\n",
            "Epoch: [0][ 80/195]\tTime  0.343 ( 0.380)\tData  0.000 ( 0.003)\tD(real) 0.9966 (0.8640)\tD(fake)1 0.0086 (0.0702)\tD(fake)2 -0.0107 (0.0465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0308 (-0.0092)\n",
            "Epoch: [0][ 90/195]\tTime  0.346 ( 0.376)\tData  0.000 ( 0.002)\tD(real) 0.9952 (0.8778)\tD(fake)1 -0.0005 (0.0623)\tD(fake)2 -0.0154 (0.0402)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0503 (-0.0121)\n",
            "Epoch: [0][100/195]\tTime  0.343 ( 0.373)\tData  0.000 ( 0.002)\tD(real) 0.9414 (0.8892)\tD(fake)1 -0.0154 (0.0561)\tD(fake)2 0.0018 (0.0360)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0615 (-0.0155)\n",
            "Epoch: [0][110/195]\tTime  0.344 ( 0.371)\tData  0.000 ( 0.002)\tD(real) 1.0336 (0.8990)\tD(fake)1 0.0086 (0.0511)\tD(fake)2 -0.0041 (0.0326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0786 (-0.0202)\n",
            "Epoch: [0][120/195]\tTime  0.344 ( 0.369)\tData  0.000 ( 0.002)\tD(real) 0.7385 (0.9057)\tD(fake)1 -0.0885 (0.0468)\tD(fake)2 -0.0484 (0.0289)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0751 (-0.0251)\n",
            "Epoch: [0][130/195]\tTime  0.342 ( 0.367)\tData  0.000 ( 0.002)\tD(real) 0.9809 (0.9130)\tD(fake)1 0.0030 (0.0434)\tD(fake)2 0.0029 (0.0270)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0928 (-0.0304)\n",
            "Epoch: [0][140/195]\tTime  0.346 ( 0.365)\tData  0.000 ( 0.002)\tD(real) 0.9932 (0.9188)\tD(fake)1 0.0191 (0.0404)\tD(fake)2 0.0127 (0.0245)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0958 (-0.0354)\n",
            "Epoch: [0][150/195]\tTime  0.346 ( 0.364)\tData  0.000 ( 0.002)\tD(real) 0.9959 (0.9239)\tD(fake)1 0.0068 (0.0379)\tD(fake)2 -0.0060 (0.0225)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0963 (-0.0401)\n",
            "Epoch: [0][160/195]\tTime  0.345 ( 0.363)\tData  0.000 ( 0.002)\tD(real) 1.0440 (0.9282)\tD(fake)1 -0.0301 (0.0354)\tD(fake)2 -0.0142 (0.0206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1117 (-0.0443)\n",
            "Epoch: [0][170/195]\tTime  0.352 ( 0.362)\tData  0.000 ( 0.001)\tD(real) 0.9273 (0.9320)\tD(fake)1 -0.0032 (0.0335)\tD(fake)2 0.0235 (0.0197)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1126 (-0.0483)\n",
            "Epoch: [0][180/195]\tTime  0.344 ( 0.361)\tData  0.001 ( 0.001)\tD(real) 1.0246 (0.9356)\tD(fake)1 0.0017 (0.0318)\tD(fake)2 -0.0033 (0.0183)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1168 (-0.0521)\n",
            "Epoch: [0][190/195]\tTime  0.346 ( 0.360)\tData  0.000 ( 0.001)\tD(real) 0.7796 (0.9379)\tD(fake)1 -0.0709 (0.0301)\tD(fake)2 -0.0321 (0.0168)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1005 (-0.0554)\n",
            "Epoch: [1][  0/195]\tTime  0.585 ( 0.585)\tData  0.206 ( 0.206)\tD(real) 1.0235 (1.0235)\tD(fake)1 0.0148 (0.0148)\tD(fake)2 0.0063 (0.0063)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1141 (-0.1141)\n",
            "Epoch: [1][ 10/195]\tTime  0.351 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.9804 (0.9984)\tD(fake)1 -0.0030 (0.0042)\tD(fake)2 0.0013 (0.0004)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1280 (-0.1250)\n",
            "Epoch: [1][ 20/195]\tTime  0.343 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.9661 (0.9962)\tD(fake)1 -0.0032 (0.0020)\tD(fake)2 -0.0026 (-0.0012)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1334 (-0.1246)\n",
            "Epoch: [1][ 30/195]\tTime  0.343 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.9813 (0.9970)\tD(fake)1 -0.0061 (0.0013)\tD(fake)2 0.0108 (-0.0010)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1287 (-0.1259)\n",
            "Epoch: [1][ 40/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.9818 (0.9962)\tD(fake)1 0.0058 (0.0012)\tD(fake)2 0.0061 (-0.0011)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1350 (-0.1272)\n",
            "Epoch: [1][ 50/195]\tTime  0.342 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.9665 (0.9963)\tD(fake)1 -0.0063 (0.0011)\tD(fake)2 0.0046 (-0.0012)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1288 (-0.1287)\n",
            "Epoch: [1][ 60/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 1.0576 (0.9969)\tD(fake)1 0.0061 (0.0011)\tD(fake)2 0.0079 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1430 (-0.1299)\n",
            "Epoch: [1][ 70/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 1.0781 (0.9974)\tD(fake)1 -0.0019 (0.0010)\tD(fake)2 0.0005 (-0.0016)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1180 (-0.1298)\n",
            "Epoch: [1][ 80/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.9999 (0.9964)\tD(fake)1 -0.0016 (0.0012)\tD(fake)2 0.0009 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1079 (-0.1307)\n",
            "Epoch: [1][ 90/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 1.0427 (0.9958)\tD(fake)1 -0.0077 (0.0009)\tD(fake)2 0.0135 (-0.0016)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1389 (-0.1310)\n",
            "Epoch: [1][100/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9901 (0.9962)\tD(fake)1 -0.0055 (0.0011)\tD(fake)2 -0.0033 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1489 (-0.1320)\n",
            "Epoch: [1][110/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 1.0679 (0.9965)\tD(fake)1 0.0165 (0.0011)\tD(fake)2 0.0123 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1463 (-0.1328)\n",
            "Epoch: [1][120/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 1.0078 (0.9963)\tD(fake)1 -0.0029 (0.0011)\tD(fake)2 0.0002 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1287 (-0.1339)\n",
            "Epoch: [1][130/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 1.0820 (0.9964)\tD(fake)1 0.0265 (0.0012)\tD(fake)2 -0.0249 (-0.0016)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1544 (-0.1352)\n",
            "Epoch: [1][140/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 1.0041 (0.9963)\tD(fake)1 0.0023 (0.0012)\tD(fake)2 -0.0054 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1516 (-0.1358)\n",
            "Epoch: [1][150/195]\tTime  0.349 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.9307 (0.9960)\tD(fake)1 -0.0227 (0.0011)\tD(fake)2 -0.0054 (-0.0016)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1482 (-0.1368)\n",
            "Epoch: [1][160/195]\tTime  0.344 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.9439 (0.9962)\tD(fake)1 -0.0220 (0.0010)\tD(fake)2 0.0031 (-0.0016)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1561 (-0.1378)\n",
            "Epoch: [1][170/195]\tTime  0.342 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.9845 (0.9964)\tD(fake)1 -0.0091 (0.0010)\tD(fake)2 0.0020 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1385)\n",
            "Epoch: [1][180/195]\tTime  0.344 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 1.0265 (0.9964)\tD(fake)1 0.0051 (0.0011)\tD(fake)2 -0.0101 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1444 (-0.1392)\n",
            "Epoch: [1][190/195]\tTime  0.343 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.9662 (0.9964)\tD(fake)1 0.0001 (0.0010)\tD(fake)2 -0.0002 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1422 (-0.1395)\n",
            "Epoch: [2][  0/195]\tTime  0.601 ( 0.601)\tData  0.206 ( 0.206)\tD(real) 0.9821 (0.9821)\tD(fake)1 -0.0017 (-0.0017)\tD(fake)2 0.0086 (0.0086)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1583)\n",
            "Epoch: [2][ 10/195]\tTime  0.345 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.9899 (0.9955)\tD(fake)1 0.0025 (0.0015)\tD(fake)2 0.0012 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1498)\n",
            "Epoch: [2][ 20/195]\tTime  0.344 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 1.0289 (0.9970)\tD(fake)1 0.0161 (0.0011)\tD(fake)2 0.0116 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1531)\n",
            "Epoch: [2][ 30/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.9566 (0.9963)\tD(fake)1 0.0012 (0.0010)\tD(fake)2 0.0005 (-0.0013)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1326 (-0.1512)\n",
            "Epoch: [2][ 40/195]\tTime  0.342 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.9966 (0.9973)\tD(fake)1 -0.0030 (0.0008)\tD(fake)2 0.0001 (-0.0013)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1512)\n",
            "Epoch: [2][ 50/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.9769 (0.9962)\tD(fake)1 -0.0023 (0.0012)\tD(fake)2 -0.0009 (-0.0020)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1528)\n",
            "Epoch: [2][ 60/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 1.0234 (0.9971)\tD(fake)1 0.0002 (0.0011)\tD(fake)2 0.0004 (-0.0017)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1574 (-0.1529)\n",
            "Epoch: [2][ 70/195]\tTime  0.341 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9905 (0.9970)\tD(fake)1 0.0001 (0.0009)\tD(fake)2 0.0000 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1526 (-0.1538)\n",
            "Epoch: [2][ 80/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.9970 (0.9968)\tD(fake)1 0.0007 (0.0008)\tD(fake)2 0.0007 (-0.0014)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1547)\n",
            "Epoch: [2][ 90/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.9981 (0.9974)\tD(fake)1 -0.0003 (0.0007)\tD(fake)2 -0.0002 (-0.0013)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1558)\n",
            "Epoch: [2][100/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9761 (0.9972)\tD(fake)1 -0.0019 (0.0009)\tD(fake)2 -0.0070 (-0.0015)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1551)\n",
            "Epoch: [2][110/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9956 (0.9974)\tD(fake)1 0.0022 (0.0008)\tD(fake)2 -0.0004 (-0.0014)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1561)\n",
            "Epoch: [2][120/195]\tTime  0.350 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9944 (0.9967)\tD(fake)1 -0.0038 (0.0013)\tD(fake)2 -0.0024 (-0.0020)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1567)\n",
            "Epoch: [2][130/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9818 (0.9969)\tD(fake)1 0.0007 (0.0012)\tD(fake)2 -0.0004 (-0.0018)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1571)\n",
            "Epoch: [2][140/195]\tTime  0.338 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 1.0086 (0.9971)\tD(fake)1 0.0005 (0.0011)\tD(fake)2 -0.0002 (-0.0017)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1420 (-0.1575)\n",
            "Epoch: [2][150/195]\tTime  0.355 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9690 (0.9965)\tD(fake)1 -0.0224 (0.0011)\tD(fake)2 0.0018 (-0.0021)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1579)\n",
            "Epoch: [2][160/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.9956 (0.9969)\tD(fake)1 0.0016 (0.0012)\tD(fake)2 -0.0003 (-0.0018)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1584)\n",
            "Epoch: [2][170/195]\tTime  0.341 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 1.0427 (0.9972)\tD(fake)1 0.0002 (0.0012)\tD(fake)2 -0.0005 (-0.0017)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1711 (-0.1585)\n",
            "Epoch: [2][180/195]\tTime  0.347 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.8373 (0.9955)\tD(fake)1 -0.0153 (0.0022)\tD(fake)2 -0.0186 (-0.0021)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1405 (-0.1585)\n",
            "Epoch: [2][190/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 1.0006 (0.9949)\tD(fake)1 -0.0274 (0.0028)\tD(fake)2 -0.0087 (-0.0018)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1763 (-0.1590)\n",
            "Epoch: [3][  0/195]\tTime  0.595 ( 0.595)\tData  0.202 ( 0.202)\tD(real) 0.9952 (0.9952)\tD(fake)1 0.0042 (0.0042)\tD(fake)2 -0.0009 (-0.0009)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1728 (-0.1728)\n",
            "Epoch: [3][ 10/195]\tTime  0.343 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.9916 (0.9925)\tD(fake)1 0.0038 (0.0033)\tD(fake)2 0.0117 (-0.0097)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1606)\n",
            "Epoch: [3][ 20/195]\tTime  0.350 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 1.0030 (0.9953)\tD(fake)1 -0.0003 (0.0035)\tD(fake)2 -0.0008 (-0.0051)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1620)\n",
            "Epoch: [3][ 30/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.9937 (0.9961)\tD(fake)1 0.0003 (0.0024)\tD(fake)2 -0.0002 (-0.0035)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1638)\n",
            "Epoch: [3][ 40/195]\tTime  0.341 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 1.0332 (0.9970)\tD(fake)1 0.0008 (0.0018)\tD(fake)2 -0.0006 (-0.0027)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1723 (-0.1653)\n",
            "Epoch: [3][ 50/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.9453 (0.9967)\tD(fake)1 0.0006 (0.0015)\tD(fake)2 0.0004 (-0.0022)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1659)\n",
            "Epoch: [3][ 60/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 1.0574 (0.9980)\tD(fake)1 0.0019 (0.0013)\tD(fake)2 -0.0040 (-0.0019)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1794 (-0.1668)\n",
            "Epoch: [3][ 70/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8969 (0.9937)\tD(fake)1 -0.0129 (0.0025)\tD(fake)2 0.0204 (-0.0029)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1737 (-0.1673)\n",
            "Epoch: [3][ 80/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9995 (0.9948)\tD(fake)1 0.0024 (0.0031)\tD(fake)2 0.0002 (-0.0020)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1668)\n",
            "Epoch: [3][ 90/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9982 (0.9915)\tD(fake)1 0.0020 (0.0055)\tD(fake)2 0.0279 (-0.0029)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1441 (-0.1667)\n",
            "Epoch: [3][100/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9961 (0.9912)\tD(fake)1 0.0013 (0.0062)\tD(fake)2 0.0009 (-0.0017)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1767 (-0.1669)\n",
            "Epoch: [3][110/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9910 (0.9912)\tD(fake)1 0.0413 (0.0071)\tD(fake)2 -0.0391 (-0.0021)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1667)\n",
            "Epoch: [3][120/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 1.0120 (0.9904)\tD(fake)1 0.0079 (0.0073)\tD(fake)2 0.0403 (-0.0014)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1774 (-0.1666)\n",
            "Epoch: [3][130/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9735 (0.9892)\tD(fake)1 0.0087 (0.0082)\tD(fake)2 -0.0055 (-0.0011)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1757 (-0.1661)\n",
            "Epoch: [3][140/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9461 (0.9868)\tD(fake)1 0.0511 (0.0098)\tD(fake)2 0.0340 (-0.0008)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1661)\n",
            "Epoch: [3][150/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9873 (0.9871)\tD(fake)1 0.0212 (0.0101)\tD(fake)2 0.0250 (-0.0005)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1663)\n",
            "Epoch: [3][160/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 1.0507 (0.9872)\tD(fake)1 0.0165 (0.0100)\tD(fake)2 0.0191 (-0.0004)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1665)\n",
            "Epoch: [3][170/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9963 (0.9864)\tD(fake)1 0.0158 (0.0104)\tD(fake)2 0.0018 (0.0001)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1743 (-0.1665)\n",
            "Epoch: [3][180/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.9963 (0.9861)\tD(fake)1 0.0062 (0.0105)\tD(fake)2 -0.0021 (0.0004)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1736 (-0.1661)\n",
            "Epoch: [3][190/195]\tTime  0.352 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 1.0022 (0.9864)\tD(fake)1 0.0202 (0.0103)\tD(fake)2 0.0156 (0.0004)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1579 (-0.1662)\n",
            "Epoch: [4][  0/195]\tTime  0.587 ( 0.587)\tData  0.195 ( 0.195)\tD(real) 0.9338 (0.9338)\tD(fake)1 0.0141 (0.0141)\tD(fake)2 0.0074 (0.0074)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1765 (-0.1765)\n",
            "Epoch: [4][ 10/195]\tTime  0.348 ( 0.370)\tData  0.000 ( 0.018)\tD(real) 0.9090 (0.9612)\tD(fake)1 0.0718 (0.0341)\tD(fake)2 0.0415 (-0.0053)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1591 (-0.1681)\n",
            "Epoch: [4][ 20/195]\tTime  0.343 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.7058 (0.8465)\tD(fake)1 0.2070 (0.1668)\tD(fake)2 0.1893 (0.1256)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1634)\n",
            "Epoch: [4][ 30/195]\tTime  0.345 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.8920 (0.8404)\tD(fake)1 0.2914 (0.1812)\tD(fake)2 0.1461 (0.1447)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1640)\n",
            "Epoch: [4][ 40/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.7423 (0.8245)\tD(fake)1 0.2388 (0.1936)\tD(fake)2 0.2788 (0.1612)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1403 (-0.1623)\n",
            "Epoch: [4][ 50/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8337 (0.8242)\tD(fake)1 0.1525 (0.1957)\tD(fake)2 0.1486 (0.1644)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1617)\n",
            "Epoch: [4][ 60/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8075 (0.8307)\tD(fake)1 0.1198 (0.1907)\tD(fake)2 0.2233 (0.1619)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1604)\n",
            "Epoch: [4][ 70/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6705 (0.8303)\tD(fake)1 0.1233 (0.1868)\tD(fake)2 0.1859 (0.1572)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1594)\n",
            "Epoch: [4][ 80/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8928 (0.8324)\tD(fake)1 0.2459 (0.1867)\tD(fake)2 0.1129 (0.1563)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1041 (-0.1590)\n",
            "Epoch: [4][ 90/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9254 (0.8328)\tD(fake)1 0.1313 (0.1839)\tD(fake)2 0.1013 (0.1543)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1592)\n",
            "Epoch: [4][100/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6907 (0.8336)\tD(fake)1 0.2405 (0.1821)\tD(fake)2 0.2141 (0.1512)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1594)\n",
            "Epoch: [4][110/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6583 (0.8346)\tD(fake)1 0.0835 (0.1809)\tD(fake)2 0.1355 (0.1476)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1599)\n",
            "Epoch: [4][120/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8636 (0.8338)\tD(fake)1 0.1572 (0.1808)\tD(fake)2 0.1139 (0.1464)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1595)\n",
            "Epoch: [4][130/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7191 (0.8333)\tD(fake)1 0.1901 (0.1806)\tD(fake)2 0.1749 (0.1445)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1599)\n",
            "Epoch: [4][140/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8751 (0.8289)\tD(fake)1 0.3813 (0.1859)\tD(fake)2 0.0417 (0.1454)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1598)\n",
            "Epoch: [4][150/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7305 (0.8218)\tD(fake)1 0.1576 (0.1873)\tD(fake)2 0.1179 (0.1449)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1597)\n",
            "Epoch: [4][160/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7968 (0.8212)\tD(fake)1 0.1840 (0.1874)\tD(fake)2 0.1624 (0.1437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1592)\n",
            "Epoch: [4][170/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7237 (0.8196)\tD(fake)1 0.3278 (0.1897)\tD(fake)2 0.2432 (0.1448)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1584 (-0.1589)\n",
            "Epoch: [4][180/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.9795 (0.8133)\tD(fake)1 0.4038 (0.1972)\tD(fake)2 -0.0860 (0.1502)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1708 (-0.1588)\n",
            "Epoch: [4][190/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8511 (0.8110)\tD(fake)1 0.2466 (0.1989)\tD(fake)2 0.1753 (0.1533)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1592)\n",
            "Epoch: [5][  0/195]\tTime  0.581 ( 0.581)\tData  0.199 ( 0.199)\tD(real) 0.7867 (0.7867)\tD(fake)1 0.2726 (0.2726)\tD(fake)2 0.2265 (0.2265)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1698)\n",
            "Epoch: [5][ 10/195]\tTime  0.344 ( 0.368)\tData  0.000 ( 0.019)\tD(real) 0.5937 (0.7214)\tD(fake)1 0.0918 (0.2943)\tD(fake)2 0.2043 (0.2047)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1580)\n",
            "Epoch: [5][ 20/195]\tTime  0.341 ( 0.358)\tData  0.000 ( 0.010)\tD(real) 0.6444 (0.7235)\tD(fake)1 0.0768 (0.2665)\tD(fake)2 0.1833 (0.1661)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1512 (-0.1539)\n",
            "Epoch: [5][ 30/195]\tTime  0.351 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.6558 (0.7416)\tD(fake)1 0.3770 (0.2493)\tD(fake)2 0.2800 (0.1497)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1526)\n",
            "Epoch: [5][ 40/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6735 (0.7228)\tD(fake)1 0.1214 (0.2639)\tD(fake)2 0.3280 (0.1718)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1554 (-0.1537)\n",
            "Epoch: [5][ 50/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7491 (0.7326)\tD(fake)1 0.2253 (0.2618)\tD(fake)2 0.1411 (0.1701)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1547)\n",
            "Epoch: [5][ 60/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.7979 (0.7377)\tD(fake)1 0.2722 (0.2583)\tD(fake)2 0.1427 (0.1626)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1409 (-0.1550)\n",
            "Epoch: [5][ 70/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5531 (0.7412)\tD(fake)1 0.0228 (0.2495)\tD(fake)2 0.0931 (0.1516)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1553)\n",
            "Epoch: [5][ 80/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6663 (0.7479)\tD(fake)1 0.1613 (0.2432)\tD(fake)2 0.2736 (0.1492)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1551)\n",
            "Epoch: [5][ 90/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7805 (0.7441)\tD(fake)1 0.3580 (0.2516)\tD(fake)2 0.1737 (0.1542)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1555)\n",
            "Epoch: [5][100/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5740 (0.7405)\tD(fake)1 0.0936 (0.2548)\tD(fake)2 0.2922 (0.1609)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1369 (-0.1557)\n",
            "Epoch: [5][110/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6468 (0.7397)\tD(fake)1 0.3291 (0.2591)\tD(fake)2 0.2992 (0.1650)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1551)\n",
            "Epoch: [5][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6510 (0.7371)\tD(fake)1 0.2542 (0.2624)\tD(fake)2 0.1894 (0.1673)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1554)\n",
            "Epoch: [5][130/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6403 (0.7357)\tD(fake)1 0.3035 (0.2645)\tD(fake)2 0.2434 (0.1694)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1561)\n",
            "Epoch: [5][140/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8810 (0.7353)\tD(fake)1 0.2442 (0.2650)\tD(fake)2 -0.0170 (0.1680)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1564)\n",
            "Epoch: [5][150/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6228 (0.7339)\tD(fake)1 0.3365 (0.2657)\tD(fake)2 0.2181 (0.1684)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1554)\n",
            "Epoch: [5][160/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8860 (0.7337)\tD(fake)1 0.3061 (0.2674)\tD(fake)2 0.0787 (0.1704)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1188 (-0.1551)\n",
            "Epoch: [5][170/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7012 (0.7361)\tD(fake)1 0.2766 (0.2660)\tD(fake)2 0.2240 (0.1708)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1556)\n",
            "Epoch: [5][180/195]\tTime  0.341 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8203 (0.7354)\tD(fake)1 0.2695 (0.2646)\tD(fake)2 0.1819 (0.1697)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1557)\n",
            "Epoch: [5][190/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.9199 (0.7381)\tD(fake)1 0.3624 (0.2637)\tD(fake)2 0.0095 (0.1661)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1561)\n",
            "Epoch: [6][  0/195]\tTime  0.571 ( 0.571)\tData  0.198 ( 0.198)\tD(real) 0.7980 (0.7980)\tD(fake)1 0.2582 (0.2582)\tD(fake)2 0.1600 (0.1600)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1735)\n",
            "Epoch: [6][ 10/195]\tTime  0.350 ( 0.368)\tData  0.000 ( 0.018)\tD(real) 0.4524 (0.7228)\tD(fake)1 -0.0089 (0.2730)\tD(fake)2 0.2173 (0.1650)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1549)\n",
            "Epoch: [6][ 20/195]\tTime  0.342 ( 0.357)\tData  0.000 ( 0.010)\tD(real) 0.6804 (0.7288)\tD(fake)1 0.3011 (0.2826)\tD(fake)2 0.1886 (0.1851)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1575)\n",
            "Epoch: [6][ 30/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.007)\tD(real) 0.8309 (0.7340)\tD(fake)1 0.3192 (0.2786)\tD(fake)2 0.1817 (0.1779)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1570)\n",
            "Epoch: [6][ 40/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.9921 (0.7435)\tD(fake)1 0.4690 (0.2662)\tD(fake)2 0.1412 (0.1682)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1582)\n",
            "Epoch: [6][ 50/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8349 (0.7502)\tD(fake)1 0.2953 (0.2626)\tD(fake)2 0.1234 (0.1642)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1287 (-0.1569)\n",
            "Epoch: [6][ 60/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.9492 (0.7522)\tD(fake)1 0.4473 (0.2604)\tD(fake)2 0.1089 (0.1611)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1320 (-0.1581)\n",
            "Epoch: [6][ 70/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.5782 (0.7433)\tD(fake)1 0.1120 (0.2649)\tD(fake)2 0.3283 (0.1689)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1586)\n",
            "Epoch: [6][ 80/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.7428 (0.7427)\tD(fake)1 0.3837 (0.2701)\tD(fake)2 0.2037 (0.1744)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1699 (-0.1578)\n",
            "Epoch: [6][ 90/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.7475 (0.7406)\tD(fake)1 0.2902 (0.2716)\tD(fake)2 0.2983 (0.1747)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1583)\n",
            "Epoch: [6][100/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7304 (0.7420)\tD(fake)1 0.2472 (0.2710)\tD(fake)2 0.1354 (0.1703)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1590)\n",
            "Epoch: [6][110/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6263 (0.7446)\tD(fake)1 0.1657 (0.2664)\tD(fake)2 0.1260 (0.1673)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1334 (-0.1592)\n",
            "Epoch: [6][120/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6723 (0.7414)\tD(fake)1 0.3691 (0.2712)\tD(fake)2 0.1981 (0.1727)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1596)\n",
            "Epoch: [6][130/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6851 (0.7412)\tD(fake)1 0.2066 (0.2693)\tD(fake)2 0.0828 (0.1708)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1601)\n",
            "Epoch: [6][140/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7154 (0.7411)\tD(fake)1 0.2664 (0.2689)\tD(fake)2 0.1511 (0.1693)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1743 (-0.1597)\n",
            "Epoch: [6][150/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6086 (0.7438)\tD(fake)1 0.1741 (0.2663)\tD(fake)2 0.1007 (0.1657)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1554 (-0.1599)\n",
            "Epoch: [6][160/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8559 (0.7413)\tD(fake)1 0.3781 (0.2680)\tD(fake)2 0.0081 (0.1664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1601)\n",
            "Epoch: [6][170/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7754 (0.7415)\tD(fake)1 0.2504 (0.2669)\tD(fake)2 0.1746 (0.1679)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1748 (-0.1604)\n",
            "Epoch: [6][180/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8330 (0.7427)\tD(fake)1 0.3303 (0.2673)\tD(fake)2 0.2027 (0.1690)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1532 (-0.1604)\n",
            "Epoch: [6][190/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7677 (0.7449)\tD(fake)1 0.2530 (0.2658)\tD(fake)2 0.1696 (0.1675)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1466 (-0.1606)\n",
            "Epoch: [7][  0/195]\tTime  0.585 ( 0.585)\tData  0.203 ( 0.203)\tD(real) 0.8045 (0.8045)\tD(fake)1 0.2520 (0.2520)\tD(fake)2 0.0762 (0.0762)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1587)\n",
            "Epoch: [7][ 10/195]\tTime  0.349 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.9063 (0.7693)\tD(fake)1 0.2722 (0.2327)\tD(fake)2 0.1103 (0.1763)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1605)\n",
            "Epoch: [7][ 20/195]\tTime  0.350 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.6296 (0.7640)\tD(fake)1 0.2043 (0.2408)\tD(fake)2 0.3423 (0.1868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1748 (-0.1628)\n",
            "Epoch: [7][ 30/195]\tTime  0.355 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7826 (0.7539)\tD(fake)1 0.2968 (0.2607)\tD(fake)2 0.1364 (0.1931)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1733 (-0.1598)\n",
            "Epoch: [7][ 40/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.5860 (0.7369)\tD(fake)1 0.3336 (0.2758)\tD(fake)2 0.3265 (0.2011)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1591)\n",
            "Epoch: [7][ 50/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7488 (0.7233)\tD(fake)1 0.3155 (0.2848)\tD(fake)2 0.2096 (0.2076)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1765 (-0.1614)\n",
            "Epoch: [7][ 60/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8342 (0.7322)\tD(fake)1 0.2610 (0.2803)\tD(fake)2 0.0590 (0.1976)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1763 (-0.1625)\n",
            "Epoch: [7][ 70/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8536 (0.7342)\tD(fake)1 0.3683 (0.2811)\tD(fake)2 0.0747 (0.1967)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1623)\n",
            "Epoch: [7][ 80/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8069 (0.7338)\tD(fake)1 0.3952 (0.2809)\tD(fake)2 0.1144 (0.1952)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1424 (-0.1621)\n",
            "Epoch: [7][ 90/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6725 (0.7304)\tD(fake)1 0.2102 (0.2818)\tD(fake)2 0.3034 (0.1965)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1459 (-0.1623)\n",
            "Epoch: [7][100/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9516 (0.7295)\tD(fake)1 0.4274 (0.2861)\tD(fake)2 -0.0937 (0.1967)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1619)\n",
            "Epoch: [7][110/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6112 (0.7272)\tD(fake)1 0.1363 (0.2821)\tD(fake)2 0.2116 (0.1974)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1627)\n",
            "Epoch: [7][120/195]\tTime  0.360 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6590 (0.7278)\tD(fake)1 0.1760 (0.2807)\tD(fake)2 0.2194 (0.1953)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1352 (-0.1621)\n",
            "Epoch: [7][130/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7290 (0.7288)\tD(fake)1 0.3487 (0.2809)\tD(fake)2 0.2439 (0.1948)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1621)\n",
            "Epoch: [7][140/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6133 (0.7263)\tD(fake)1 0.2972 (0.2821)\tD(fake)2 0.2361 (0.1982)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1760 (-0.1626)\n",
            "Epoch: [7][150/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.5247 (0.7252)\tD(fake)1 0.1425 (0.2836)\tD(fake)2 0.2947 (0.2011)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1626)\n",
            "Epoch: [7][160/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8378 (0.7264)\tD(fake)1 0.3157 (0.2838)\tD(fake)2 0.1613 (0.2005)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1624)\n",
            "Epoch: [7][170/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7879 (0.7279)\tD(fake)1 0.2763 (0.2820)\tD(fake)2 0.1376 (0.1981)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1621)\n",
            "Epoch: [7][180/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6700 (0.7254)\tD(fake)1 0.3927 (0.2823)\tD(fake)2 0.3131 (0.1988)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1743 (-0.1624)\n",
            "Epoch: [7][190/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6283 (0.7247)\tD(fake)1 0.1615 (0.2827)\tD(fake)2 0.2628 (0.1993)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1160 (-0.1624)\n",
            "Epoch: [8][  0/195]\tTime  0.593 ( 0.593)\tData  0.201 ( 0.201)\tD(real) 0.5136 (0.5136)\tD(fake)1 0.0998 (0.0998)\tD(fake)2 0.3040 (0.3040)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1688)\n",
            "Epoch: [8][ 10/195]\tTime  0.354 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.7145 (0.6970)\tD(fake)1 0.3443 (0.3045)\tD(fake)2 0.2609 (0.2301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1636)\n",
            "Epoch: [8][ 20/195]\tTime  0.340 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7585 (0.7142)\tD(fake)1 0.3481 (0.3008)\tD(fake)2 0.1600 (0.2128)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1044 (-0.1619)\n",
            "Epoch: [8][ 30/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.8750 (0.7125)\tD(fake)1 0.4555 (0.3033)\tD(fake)2 -0.0227 (0.2073)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1757 (-0.1626)\n",
            "Epoch: [8][ 40/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6964 (0.7019)\tD(fake)1 0.3274 (0.3022)\tD(fake)2 0.2127 (0.2143)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1739 (-0.1640)\n",
            "Epoch: [8][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7944 (0.6996)\tD(fake)1 0.4601 (0.3077)\tD(fake)2 0.1525 (0.2146)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1628)\n",
            "Epoch: [8][ 60/195]\tTime  0.342 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7732 (0.7016)\tD(fake)1 0.2612 (0.3033)\tD(fake)2 0.2473 (0.2168)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1745 (-0.1629)\n",
            "Epoch: [8][ 70/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6327 (0.7078)\tD(fake)1 0.2039 (0.2984)\tD(fake)2 0.3082 (0.2138)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1626)\n",
            "Epoch: [8][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.9882 (0.7160)\tD(fake)1 0.3517 (0.2955)\tD(fake)2 -0.0535 (0.2094)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1744 (-0.1637)\n",
            "Epoch: [8][ 90/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9950 (0.7196)\tD(fake)1 0.5370 (0.2888)\tD(fake)2 0.1732 (0.2072)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1432 (-0.1630)\n",
            "Epoch: [8][100/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7027 (0.7164)\tD(fake)1 0.2909 (0.2915)\tD(fake)2 0.1900 (0.2083)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1629)\n",
            "Epoch: [8][110/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8440 (0.7171)\tD(fake)1 0.3737 (0.2930)\tD(fake)2 0.0664 (0.2059)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1764 (-0.1635)\n",
            "Epoch: [8][120/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7080 (0.7166)\tD(fake)1 0.2259 (0.2914)\tD(fake)2 0.2464 (0.2057)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1638)\n",
            "Epoch: [8][130/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7897 (0.7149)\tD(fake)1 0.3960 (0.2925)\tD(fake)2 0.1320 (0.2057)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1638)\n",
            "Epoch: [8][140/195]\tTime  0.355 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.4030 (0.7152)\tD(fake)1 0.0162 (0.2886)\tD(fake)2 0.3065 (0.2031)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1804 (-0.1635)\n",
            "Epoch: [8][150/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8978 (0.7166)\tD(fake)1 0.4474 (0.2908)\tD(fake)2 -0.0190 (0.2027)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1633)\n",
            "Epoch: [8][160/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5260 (0.7161)\tD(fake)1 0.0893 (0.2885)\tD(fake)2 0.2691 (0.2007)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1711 (-0.1634)\n",
            "Epoch: [8][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6114 (0.7177)\tD(fake)1 0.1436 (0.2874)\tD(fake)2 0.2121 (0.1982)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1633)\n",
            "Epoch: [8][180/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6177 (0.7199)\tD(fake)1 0.1767 (0.2861)\tD(fake)2 0.2757 (0.1958)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1632)\n",
            "Epoch: [8][190/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6614 (0.7191)\tD(fake)1 0.3237 (0.2875)\tD(fake)2 0.3489 (0.1963)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1606 (-0.1631)\n",
            "Epoch: [9][  0/195]\tTime  0.594 ( 0.594)\tData  0.200 ( 0.200)\tD(real) 0.7053 (0.7053)\tD(fake)1 0.1701 (0.1701)\tD(fake)2 0.2433 (0.2433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1640)\n",
            "Epoch: [9][ 10/195]\tTime  0.343 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.3809 (0.7135)\tD(fake)1 0.1009 (0.2621)\tD(fake)2 0.2930 (0.1876)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1271 (-0.1644)\n",
            "Epoch: [9][ 20/195]\tTime  0.350 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.5456 (0.7017)\tD(fake)1 0.1463 (0.2846)\tD(fake)2 0.2827 (0.2069)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1657)\n",
            "Epoch: [9][ 30/195]\tTime  0.341 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.7906 (0.7157)\tD(fake)1 0.2745 (0.2832)\tD(fake)2 0.1721 (0.2001)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1246 (-0.1623)\n",
            "Epoch: [9][ 40/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.7579 (0.7194)\tD(fake)1 0.3113 (0.2813)\tD(fake)2 0.1761 (0.1979)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1036 (-0.1610)\n",
            "Epoch: [9][ 50/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.9179 (0.7266)\tD(fake)1 0.4080 (0.2785)\tD(fake)2 -0.0546 (0.1897)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1615)\n",
            "Epoch: [9][ 60/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.8571 (0.7252)\tD(fake)1 0.3935 (0.2775)\tD(fake)2 0.0203 (0.1885)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1614)\n",
            "Epoch: [9][ 70/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.8275 (0.7270)\tD(fake)1 0.3487 (0.2762)\tD(fake)2 0.1221 (0.1869)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1724 (-0.1623)\n",
            "Epoch: [9][ 80/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6962 (0.7262)\tD(fake)1 0.1701 (0.2757)\tD(fake)2 0.2125 (0.1872)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1441 (-0.1614)\n",
            "Epoch: [9][ 90/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.7591 (0.7311)\tD(fake)1 0.3063 (0.2716)\tD(fake)2 0.1839 (0.1828)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1619)\n",
            "Epoch: [9][100/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7924 (0.7279)\tD(fake)1 0.3281 (0.2750)\tD(fake)2 0.2447 (0.1846)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1716 (-0.1616)\n",
            "Epoch: [9][110/195]\tTime  0.340 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6469 (0.7286)\tD(fake)1 0.2972 (0.2744)\tD(fake)2 0.3758 (0.1835)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1783 (-0.1610)\n",
            "Epoch: [9][120/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7086 (0.7253)\tD(fake)1 0.2208 (0.2788)\tD(fake)2 0.1897 (0.1857)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1604)\n",
            "Epoch: [9][130/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9173 (0.7302)\tD(fake)1 0.2860 (0.2752)\tD(fake)2 0.0211 (0.1804)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1732 (-0.1611)\n",
            "Epoch: [9][140/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7056 (0.7317)\tD(fake)1 0.2809 (0.2736)\tD(fake)2 0.2442 (0.1788)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1180 (-0.1614)\n",
            "Epoch: [9][150/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7290 (0.7308)\tD(fake)1 0.2264 (0.2748)\tD(fake)2 0.1648 (0.1805)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1718 (-0.1608)\n",
            "Epoch: [9][160/195]\tTime  0.352 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6020 (0.7291)\tD(fake)1 0.1966 (0.2759)\tD(fake)2 0.3113 (0.1823)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1460 (-0.1610)\n",
            "Epoch: [9][170/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8598 (0.7315)\tD(fake)1 0.3902 (0.2750)\tD(fake)2 0.0296 (0.1799)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1610)\n",
            "Epoch: [9][180/195]\tTime  0.343 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.6647 (0.7307)\tD(fake)1 0.2267 (0.2741)\tD(fake)2 0.2229 (0.1804)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1611)\n",
            "Epoch: [9][190/195]\tTime  0.348 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.7860 (0.7308)\tD(fake)1 0.3388 (0.2740)\tD(fake)2 0.1764 (0.1798)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1739 (-0.1613)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-p4wAlbftUb",
        "outputId": "7df05887-8e53-4665-ea02-71379f616a7a"
      },
      "source": [
        "run(10)\n",
        "save_vid()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.616 ( 0.616)\tData  0.212 ( 0.212)\tD(real) 0.9941 (0.9941)\tD(fake)1 0.4838 (0.4838)\tD(fake)2 0.0127 (0.0127)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1680)\n",
            "Epoch: [0][ 10/195]\tTime  0.348 ( 0.371)\tData  0.000 ( 0.020)\tD(real) 0.7027 (0.7249)\tD(fake)1 0.1873 (0.2962)\tD(fake)2 0.2552 (0.2012)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1483 (-0.1569)\n",
            "Epoch: [0][ 20/195]\tTime  0.344 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.6913 (0.7415)\tD(fake)1 0.2218 (0.2757)\tD(fake)2 0.2573 (0.1877)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1191 (-0.1569)\n",
            "Epoch: [0][ 30/195]\tTime  0.343 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.6105 (0.7335)\tD(fake)1 0.2006 (0.2741)\tD(fake)2 0.2408 (0.1866)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1572)\n",
            "Epoch: [0][ 40/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.8913 (0.7423)\tD(fake)1 0.3015 (0.2751)\tD(fake)2 0.0275 (0.1816)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1590)\n",
            "Epoch: [0][ 50/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8945 (0.7504)\tD(fake)1 0.3883 (0.2685)\tD(fake)2 0.0186 (0.1749)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1592)\n",
            "Epoch: [0][ 60/195]\tTime  0.340 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.7426 (0.7435)\tD(fake)1 0.2016 (0.2681)\tD(fake)2 0.1696 (0.1739)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1594)\n",
            "Epoch: [0][ 70/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7524 (0.7452)\tD(fake)1 0.3024 (0.2655)\tD(fake)2 0.1534 (0.1714)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1590 (-0.1589)\n",
            "Epoch: [0][ 80/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 1.0222 (0.7458)\tD(fake)1 0.4761 (0.2674)\tD(fake)2 -0.0183 (0.1694)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1758 (-0.1591)\n",
            "Epoch: [0][ 90/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6038 (0.7453)\tD(fake)1 0.1251 (0.2640)\tD(fake)2 0.3088 (0.1699)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1591)\n",
            "Epoch: [0][100/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7156 (0.7432)\tD(fake)1 0.2256 (0.2652)\tD(fake)2 0.2199 (0.1691)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1593)\n",
            "Epoch: [0][110/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8574 (0.7468)\tD(fake)1 0.2274 (0.2624)\tD(fake)2 0.0769 (0.1656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1600)\n",
            "Epoch: [0][120/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6626 (0.7432)\tD(fake)1 0.2612 (0.2633)\tD(fake)2 0.2721 (0.1692)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1604)\n",
            "Epoch: [0][130/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6810 (0.7406)\tD(fake)1 0.2992 (0.2672)\tD(fake)2 0.2293 (0.1734)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1602)\n",
            "Epoch: [0][140/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7760 (0.7385)\tD(fake)1 0.4552 (0.2686)\tD(fake)2 0.2558 (0.1752)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1604)\n",
            "Epoch: [0][150/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8168 (0.7398)\tD(fake)1 0.2543 (0.2679)\tD(fake)2 0.0995 (0.1738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1549 (-0.1609)\n",
            "Epoch: [0][160/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8574 (0.7410)\tD(fake)1 0.3492 (0.2673)\tD(fake)2 -0.0113 (0.1719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1514 (-0.1611)\n",
            "Epoch: [0][170/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7491 (0.7415)\tD(fake)1 0.2278 (0.2645)\tD(fake)2 0.2671 (0.1719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1607)\n",
            "Epoch: [0][180/195]\tTime  0.341 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6940 (0.7414)\tD(fake)1 0.2564 (0.2652)\tD(fake)2 0.2325 (0.1717)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1610)\n",
            "Epoch: [0][190/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6877 (0.7398)\tD(fake)1 0.3004 (0.2668)\tD(fake)2 0.2176 (0.1733)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1608)\n",
            "Epoch: [1][  0/195]\tTime  0.584 ( 0.584)\tData  0.196 ( 0.196)\tD(real) 0.6444 (0.6444)\tD(fake)1 0.1287 (0.1287)\tD(fake)2 0.2812 (0.2812)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1655)\n",
            "Epoch: [1][ 10/195]\tTime  0.343 ( 0.365)\tData  0.000 ( 0.018)\tD(real) 0.7881 (0.7658)\tD(fake)1 0.2324 (0.2219)\tD(fake)2 0.1412 (0.1545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1747 (-0.1566)\n",
            "Epoch: [1][ 20/195]\tTime  0.381 ( 0.356)\tData  0.000 ( 0.010)\tD(real) 0.6818 (0.7554)\tD(fake)1 0.2373 (0.2321)\tD(fake)2 0.2590 (0.1522)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1311 (-0.1594)\n",
            "Epoch: [1][ 30/195]\tTime  0.341 ( 0.352)\tData  0.000 ( 0.007)\tD(real) 0.5226 (0.7570)\tD(fake)1 0.0133 (0.2333)\tD(fake)2 0.1749 (0.1521)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1582)\n",
            "Epoch: [1][ 40/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.005)\tD(real) 0.8374 (0.7661)\tD(fake)1 0.2435 (0.2337)\tD(fake)2 0.0711 (0.1458)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1739 (-0.1610)\n",
            "Epoch: [1][ 50/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.7363 (0.7647)\tD(fake)1 0.2905 (0.2376)\tD(fake)2 0.1561 (0.1476)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1601)\n",
            "Epoch: [1][ 60/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.9158 (0.7611)\tD(fake)1 0.4390 (0.2423)\tD(fake)2 0.0685 (0.1482)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1719 (-0.1605)\n",
            "Epoch: [1][ 70/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.7526 (0.7571)\tD(fake)1 0.2151 (0.2440)\tD(fake)2 0.1412 (0.1527)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1403 (-0.1609)\n",
            "Epoch: [1][ 80/195]\tTime  0.344 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.7845 (0.7561)\tD(fake)1 0.2691 (0.2444)\tD(fake)2 0.1143 (0.1527)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1514 (-0.1606)\n",
            "Epoch: [1][ 90/195]\tTime  0.340 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.8267 (0.7574)\tD(fake)1 0.3383 (0.2453)\tD(fake)2 -0.0164 (0.1496)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1750 (-0.1605)\n",
            "Epoch: [1][100/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6948 (0.7579)\tD(fake)1 0.2742 (0.2443)\tD(fake)2 0.1642 (0.1472)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1776 (-0.1607)\n",
            "Epoch: [1][110/195]\tTime  0.340 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7078 (0.7544)\tD(fake)1 0.2695 (0.2474)\tD(fake)2 0.1859 (0.1491)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1758 (-0.1610)\n",
            "Epoch: [1][120/195]\tTime  0.341 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6332 (0.7508)\tD(fake)1 0.2356 (0.2488)\tD(fake)2 0.2350 (0.1513)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1617)\n",
            "Epoch: [1][130/195]\tTime  0.349 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6801 (0.7485)\tD(fake)1 0.2675 (0.2494)\tD(fake)2 0.3944 (0.1548)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1786 (-0.1614)\n",
            "Epoch: [1][140/195]\tTime  0.341 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7355 (0.7492)\tD(fake)1 0.2343 (0.2513)\tD(fake)2 0.1751 (0.1557)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1612)\n",
            "Epoch: [1][150/195]\tTime  0.348 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7326 (0.7482)\tD(fake)1 0.2376 (0.2543)\tD(fake)2 0.1522 (0.1565)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1610)\n",
            "Epoch: [1][160/195]\tTime  0.340 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.3640 (0.7493)\tD(fake)1 -0.0282 (0.2523)\tD(fake)2 0.1231 (0.1532)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1614)\n",
            "Epoch: [1][170/195]\tTime  0.346 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.6158 (0.7481)\tD(fake)1 0.2148 (0.2537)\tD(fake)2 0.2189 (0.1545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1616)\n",
            "Epoch: [1][180/195]\tTime  0.343 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.8516 (0.7469)\tD(fake)1 0.3415 (0.2559)\tD(fake)2 -0.0939 (0.1550)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1292 (-0.1614)\n",
            "Epoch: [1][190/195]\tTime  0.341 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.6893 (0.7439)\tD(fake)1 0.2925 (0.2573)\tD(fake)2 0.1969 (0.1587)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1615)\n",
            "Epoch: [2][  0/195]\tTime  0.589 ( 0.589)\tData  0.193 ( 0.193)\tD(real) 0.8627 (0.8627)\tD(fake)1 0.3706 (0.3706)\tD(fake)2 0.0577 (0.0577)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1724 (-0.1724)\n",
            "Epoch: [2][ 10/195]\tTime  0.342 ( 0.367)\tData  0.000 ( 0.018)\tD(real) 0.7022 (0.7435)\tD(fake)1 0.2292 (0.2707)\tD(fake)2 0.1790 (0.1623)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1696)\n",
            "Epoch: [2][ 20/195]\tTime  0.346 ( 0.355)\tData  0.000 ( 0.009)\tD(real) 0.6655 (0.7165)\tD(fake)1 0.2783 (0.2875)\tD(fake)2 0.2102 (0.1799)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1671)\n",
            "Epoch: [2][ 30/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.007)\tD(real) 1.0146 (0.7335)\tD(fake)1 0.4729 (0.2841)\tD(fake)2 -0.1290 (0.1657)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1741 (-0.1643)\n",
            "Epoch: [2][ 40/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.005)\tD(real) 0.7027 (0.7174)\tD(fake)1 0.2467 (0.2820)\tD(fake)2 0.1968 (0.1770)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1647)\n",
            "Epoch: [2][ 50/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.7877 (0.7296)\tD(fake)1 0.2758 (0.2741)\tD(fake)2 0.1150 (0.1711)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1733 (-0.1633)\n",
            "Epoch: [2][ 60/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.8442 (0.7393)\tD(fake)1 0.2640 (0.2682)\tD(fake)2 0.0438 (0.1656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1627)\n",
            "Epoch: [2][ 70/195]\tTime  0.343 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.6556 (0.7499)\tD(fake)1 0.0945 (0.2574)\tD(fake)2 0.2708 (0.1578)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1757 (-0.1619)\n",
            "Epoch: [2][ 80/195]\tTime  0.343 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.6418 (0.7465)\tD(fake)1 0.2808 (0.2631)\tD(fake)2 0.2002 (0.1564)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1614)\n",
            "Epoch: [2][ 90/195]\tTime  0.343 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6751 (0.7402)\tD(fake)1 0.2005 (0.2668)\tD(fake)2 0.1687 (0.1595)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1614)\n",
            "Epoch: [2][100/195]\tTime  0.342 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8819 (0.7400)\tD(fake)1 0.3991 (0.2681)\tD(fake)2 -0.0882 (0.1589)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1436 (-0.1608)\n",
            "Epoch: [2][110/195]\tTime  0.345 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6932 (0.7404)\tD(fake)1 0.1799 (0.2652)\tD(fake)2 0.1787 (0.1598)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1395 (-0.1611)\n",
            "Epoch: [2][120/195]\tTime  0.344 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6634 (0.7394)\tD(fake)1 0.2262 (0.2652)\tD(fake)2 0.1909 (0.1600)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1487 (-0.1605)\n",
            "Epoch: [2][130/195]\tTime  0.344 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8598 (0.7378)\tD(fake)1 0.4154 (0.2661)\tD(fake)2 0.2679 (0.1618)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1608)\n",
            "Epoch: [2][140/195]\tTime  0.341 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6402 (0.7390)\tD(fake)1 0.1175 (0.2652)\tD(fake)2 0.2653 (0.1631)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1612)\n",
            "Epoch: [2][150/195]\tTime  0.346 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8533 (0.7400)\tD(fake)1 0.3501 (0.2659)\tD(fake)2 0.0791 (0.1613)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1725 (-0.1613)\n",
            "Epoch: [2][160/195]\tTime  0.344 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7085 (0.7388)\tD(fake)1 0.3626 (0.2670)\tD(fake)2 0.1396 (0.1614)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1614)\n",
            "Epoch: [2][170/195]\tTime  0.341 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7419 (0.7375)\tD(fake)1 0.2820 (0.2674)\tD(fake)2 0.2459 (0.1623)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1612)\n",
            "Epoch: [2][180/195]\tTime  0.344 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7316 (0.7387)\tD(fake)1 0.3828 (0.2676)\tD(fake)2 0.0679 (0.1613)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1612)\n",
            "Epoch: [2][190/195]\tTime  0.339 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.8011 (0.7390)\tD(fake)1 0.2806 (0.2666)\tD(fake)2 0.0918 (0.1592)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1608)\n",
            "Epoch: [3][  0/195]\tTime  0.589 ( 0.589)\tData  0.204 ( 0.204)\tD(real) 0.6358 (0.6358)\tD(fake)1 0.0831 (0.0831)\tD(fake)2 0.1844 (0.1844)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1664)\n",
            "Epoch: [3][ 10/195]\tTime  0.344 ( 0.366)\tData  0.000 ( 0.019)\tD(real) 1.0008 (0.8437)\tD(fake)1 0.3608 (0.1791)\tD(fake)2 -0.0255 (0.0872)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1654)\n",
            "Epoch: [3][ 20/195]\tTime  0.344 ( 0.357)\tData  0.000 ( 0.010)\tD(real) 0.8538 (0.7895)\tD(fake)1 0.4569 (0.2307)\tD(fake)2 0.0261 (0.1085)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1620)\n",
            "Epoch: [3][ 30/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.007)\tD(real) 0.5345 (0.7605)\tD(fake)1 0.0459 (0.2336)\tD(fake)2 0.4416 (0.1256)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1738 (-0.1633)\n",
            "Epoch: [3][ 40/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.005)\tD(real) 0.7168 (0.7480)\tD(fake)1 0.2617 (0.2526)\tD(fake)2 0.1628 (0.1403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1649)\n",
            "Epoch: [3][ 50/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.7332 (0.7445)\tD(fake)1 0.2247 (0.2548)\tD(fake)2 0.1352 (0.1459)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1755 (-0.1639)\n",
            "Epoch: [3][ 60/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.004)\tD(real) 0.8602 (0.7454)\tD(fake)1 0.3702 (0.2565)\tD(fake)2 0.0541 (0.1439)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1761 (-0.1652)\n",
            "Epoch: [3][ 70/195]\tTime  0.341 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.6120 (0.7482)\tD(fake)1 0.1566 (0.2499)\tD(fake)2 0.2592 (0.1405)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1646)\n",
            "Epoch: [3][ 80/195]\tTime  0.348 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.6627 (0.7411)\tD(fake)1 0.2518 (0.2559)\tD(fake)2 0.2857 (0.1465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1635)\n",
            "Epoch: [3][ 90/195]\tTime  0.340 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.7699 (0.7429)\tD(fake)1 0.2508 (0.2536)\tD(fake)2 0.2409 (0.1421)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1634)\n",
            "Epoch: [3][100/195]\tTime  0.343 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7942 (0.7476)\tD(fake)1 0.3195 (0.2523)\tD(fake)2 0.1450 (0.1386)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1182 (-0.1629)\n",
            "Epoch: [3][110/195]\tTime  0.340 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6779 (0.7492)\tD(fake)1 0.2252 (0.2504)\tD(fake)2 0.2649 (0.1375)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1506 (-0.1620)\n",
            "Epoch: [3][120/195]\tTime  0.339 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 1.0066 (0.7526)\tD(fake)1 0.4825 (0.2483)\tD(fake)2 0.0906 (0.1341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1625)\n",
            "Epoch: [3][130/195]\tTime  0.345 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7907 (0.7512)\tD(fake)1 0.2893 (0.2486)\tD(fake)2 0.0745 (0.1351)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1445 (-0.1623)\n",
            "Epoch: [3][140/195]\tTime  0.343 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.4889 (0.7511)\tD(fake)1 0.0422 (0.2470)\tD(fake)2 0.2866 (0.1353)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1620)\n",
            "Epoch: [3][150/195]\tTime  0.344 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.6543 (0.7501)\tD(fake)1 0.1992 (0.2492)\tD(fake)2 0.2177 (0.1381)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1281 (-0.1617)\n",
            "Epoch: [3][160/195]\tTime  0.342 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.7247 (0.7465)\tD(fake)1 0.3314 (0.2518)\tD(fake)2 0.3471 (0.1428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1085 (-0.1613)\n",
            "Epoch: [3][170/195]\tTime  0.343 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7635 (0.7454)\tD(fake)1 0.3460 (0.2548)\tD(fake)2 0.1375 (0.1447)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1608)\n",
            "Epoch: [3][180/195]\tTime  0.344 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7467 (0.7457)\tD(fake)1 0.2041 (0.2551)\tD(fake)2 0.1173 (0.1448)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1605)\n",
            "Epoch: [3][190/195]\tTime  0.341 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7916 (0.7496)\tD(fake)1 0.1727 (0.2521)\tD(fake)2 0.1209 (0.1427)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1605)\n",
            "Epoch: [4][  0/195]\tTime  0.585 ( 0.585)\tData  0.200 ( 0.200)\tD(real) 0.4705 (0.4705)\tD(fake)1 0.1109 (0.1109)\tD(fake)2 0.2986 (0.2986)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1613)\n",
            "Epoch: [4][ 10/195]\tTime  0.341 ( 0.366)\tData  0.000 ( 0.019)\tD(real) 0.7247 (0.6924)\tD(fake)1 0.2870 (0.2846)\tD(fake)2 0.2215 (0.2164)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1279 (-0.1639)\n",
            "Epoch: [4][ 20/195]\tTime  0.340 ( 0.355)\tData  0.000 ( 0.010)\tD(real) 0.9142 (0.7327)\tD(fake)1 0.4345 (0.2629)\tD(fake)2 0.0192 (0.1799)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1615)\n",
            "Epoch: [4][ 30/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.007)\tD(real) 0.4854 (0.7307)\tD(fake)1 -0.0086 (0.2507)\tD(fake)2 0.4653 (0.1796)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1638)\n",
            "Epoch: [4][ 40/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.005)\tD(real) 0.7122 (0.7200)\tD(fake)1 0.3018 (0.2713)\tD(fake)2 0.2497 (0.1934)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1414 (-0.1624)\n",
            "Epoch: [4][ 50/195]\tTime  0.336 ( 0.348)\tData  0.000 ( 0.004)\tD(real) 0.7067 (0.7212)\tD(fake)1 0.2884 (0.2733)\tD(fake)2 0.2156 (0.1929)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1354 (-0.1612)\n",
            "Epoch: [4][ 60/195]\tTime  0.342 ( 0.347)\tData  0.000 ( 0.004)\tD(real) 0.7462 (0.7243)\tD(fake)1 0.2659 (0.2717)\tD(fake)2 0.1027 (0.1868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1608)\n",
            "Epoch: [4][ 70/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.7780 (0.7255)\tD(fake)1 0.4325 (0.2711)\tD(fake)2 0.2123 (0.1848)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1418 (-0.1613)\n",
            "Epoch: [4][ 80/195]\tTime  0.344 ( 0.346)\tData  0.000 ( 0.003)\tD(real) 0.5078 (0.7216)\tD(fake)1 0.0725 (0.2719)\tD(fake)2 0.3211 (0.1868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1616)\n",
            "Epoch: [4][ 90/195]\tTime  0.342 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8859 (0.7252)\tD(fake)1 0.3939 (0.2739)\tD(fake)2 0.0295 (0.1834)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1623)\n",
            "Epoch: [4][100/195]\tTime  0.350 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6164 (0.7286)\tD(fake)1 0.0786 (0.2677)\tD(fake)2 0.4802 (0.1810)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1615)\n",
            "Epoch: [4][110/195]\tTime  0.342 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8024 (0.7287)\tD(fake)1 0.2885 (0.2712)\tD(fake)2 0.1059 (0.1776)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1614)\n",
            "Epoch: [4][120/195]\tTime  0.347 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 1.2210 (0.7350)\tD(fake)1 0.7697 (0.2696)\tD(fake)2 0.0603 (0.1741)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1169 (-0.1597)\n",
            "Epoch: [4][130/195]\tTime  0.348 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.8170 (0.7319)\tD(fake)1 0.2788 (0.2681)\tD(fake)2 0.0046 (0.1721)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1760 (-0.1599)\n",
            "Epoch: [4][140/195]\tTime  0.344 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.6651 (0.7305)\tD(fake)1 0.2628 (0.2687)\tD(fake)2 0.2352 (0.1737)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1598)\n",
            "Epoch: [4][150/195]\tTime  0.348 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.8087 (0.7301)\tD(fake)1 0.3630 (0.2692)\tD(fake)2 0.1592 (0.1733)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1596)\n",
            "Epoch: [4][160/195]\tTime  0.345 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.7126 (0.7301)\tD(fake)1 0.2257 (0.2689)\tD(fake)2 0.1251 (0.1734)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1592)\n",
            "Epoch: [4][170/195]\tTime  0.341 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.8719 (0.7314)\tD(fake)1 0.2907 (0.2692)\tD(fake)2 0.0037 (0.1728)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1592)\n",
            "Epoch: [4][180/195]\tTime  0.340 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.8962 (0.7321)\tD(fake)1 0.4787 (0.2697)\tD(fake)2 -0.1596 (0.1702)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1716 (-0.1597)\n",
            "Epoch: [4][190/195]\tTime  0.341 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.6818 (0.7291)\tD(fake)1 0.2554 (0.2698)\tD(fake)2 0.2475 (0.1730)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1782 (-0.1600)\n",
            "Epoch: [5][  0/195]\tTime  0.597 ( 0.597)\tData  0.203 ( 0.203)\tD(real) 0.7580 (0.7580)\tD(fake)1 0.3153 (0.3153)\tD(fake)2 0.1514 (0.1514)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1640)\n",
            "Epoch: [5][ 10/195]\tTime  0.338 ( 0.368)\tData  0.000 ( 0.019)\tD(real) 0.7034 (0.7234)\tD(fake)1 0.2920 (0.2915)\tD(fake)2 0.1586 (0.1991)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1607)\n",
            "Epoch: [5][ 20/195]\tTime  0.344 ( 0.358)\tData  0.000 ( 0.010)\tD(real) 0.5749 (0.7308)\tD(fake)1 0.0906 (0.2748)\tD(fake)2 0.2456 (0.1778)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1448 (-0.1574)\n",
            "Epoch: [5][ 30/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.007)\tD(real) 0.6271 (0.7369)\tD(fake)1 0.2693 (0.2677)\tD(fake)2 0.3447 (0.1639)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1596)\n",
            "Epoch: [5][ 40/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.005)\tD(real) 0.8196 (0.7289)\tD(fake)1 0.4150 (0.2772)\tD(fake)2 0.1008 (0.1691)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1620)\n",
            "Epoch: [5][ 50/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.7493 (0.7292)\tD(fake)1 0.2742 (0.2778)\tD(fake)2 0.1468 (0.1712)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1623)\n",
            "Epoch: [5][ 60/195]\tTime  0.353 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.6649 (0.7275)\tD(fake)1 0.2525 (0.2766)\tD(fake)2 0.2496 (0.1686)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1756 (-0.1637)\n",
            "Epoch: [5][ 70/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.5355 (0.7286)\tD(fake)1 0.0538 (0.2738)\tD(fake)2 0.4180 (0.1675)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1331 (-0.1630)\n",
            "Epoch: [5][ 80/195]\tTime  0.340 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.6284 (0.7306)\tD(fake)1 0.1628 (0.2736)\tD(fake)2 0.3805 (0.1663)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1311 (-0.1625)\n",
            "Epoch: [5][ 90/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.7969 (0.7285)\tD(fake)1 0.2903 (0.2758)\tD(fake)2 0.0527 (0.1664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1725 (-0.1621)\n",
            "Epoch: [5][100/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.7262 (0.7281)\tD(fake)1 0.2851 (0.2750)\tD(fake)2 0.1808 (0.1697)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1753 (-0.1616)\n",
            "Epoch: [5][110/195]\tTime  0.348 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6087 (0.7237)\tD(fake)1 0.2598 (0.2780)\tD(fake)2 0.1941 (0.1741)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1614)\n",
            "Epoch: [5][120/195]\tTime  0.345 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7238 (0.7206)\tD(fake)1 0.3433 (0.2822)\tD(fake)2 0.1470 (0.1770)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1615)\n",
            "Epoch: [5][130/195]\tTime  0.348 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8010 (0.7197)\tD(fake)1 0.3206 (0.2836)\tD(fake)2 0.0568 (0.1774)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1612)\n",
            "Epoch: [5][140/195]\tTime  0.345 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6555 (0.7195)\tD(fake)1 0.2591 (0.2833)\tD(fake)2 0.1869 (0.1780)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1607)\n",
            "Epoch: [5][150/195]\tTime  0.341 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6950 (0.7175)\tD(fake)1 0.2659 (0.2839)\tD(fake)2 0.2457 (0.1789)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1544 (-0.1608)\n",
            "Epoch: [5][160/195]\tTime  0.343 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6079 (0.7177)\tD(fake)1 0.2001 (0.2832)\tD(fake)2 0.2403 (0.1783)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1606)\n",
            "Epoch: [5][170/195]\tTime  0.346 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.8075 (0.7195)\tD(fake)1 0.3773 (0.2813)\tD(fake)2 0.2177 (0.1768)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1608)\n",
            "Epoch: [5][180/195]\tTime  0.344 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.7880 (0.7211)\tD(fake)1 0.2748 (0.2804)\tD(fake)2 0.0477 (0.1738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1605)\n",
            "Epoch: [5][190/195]\tTime  0.350 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.7544 (0.7211)\tD(fake)1 0.2761 (0.2806)\tD(fake)2 0.1781 (0.1738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1741 (-0.1611)\n",
            "Epoch: [6][  0/195]\tTime  0.594 ( 0.594)\tData  0.199 ( 0.199)\tD(real) 0.6944 (0.6944)\tD(fake)1 0.1510 (0.1510)\tD(fake)2 0.1814 (0.1814)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1374 (-0.1374)\n",
            "Epoch: [6][ 10/195]\tTime  0.348 ( 0.369)\tData  0.000 ( 0.018)\tD(real) 0.8016 (0.7614)\tD(fake)1 0.3230 (0.2350)\tD(fake)2 0.1489 (0.1398)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1669)\n",
            "Epoch: [6][ 20/195]\tTime  0.341 ( 0.358)\tData  0.000 ( 0.010)\tD(real) 0.6811 (0.7283)\tD(fake)1 0.2693 (0.2750)\tD(fake)2 0.1651 (0.1701)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1677)\n",
            "Epoch: [6][ 30/195]\tTime  0.341 ( 0.353)\tData  0.000 ( 0.007)\tD(real) 0.6524 (0.7238)\tD(fake)1 0.2704 (0.2827)\tD(fake)2 0.2325 (0.1809)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1406 (-0.1643)\n",
            "Epoch: [6][ 40/195]\tTime  0.341 ( 0.351)\tData  0.000 ( 0.005)\tD(real) 0.7257 (0.7197)\tD(fake)1 0.2857 (0.2788)\tD(fake)2 0.2473 (0.1805)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1655)\n",
            "Epoch: [6][ 50/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.6162 (0.7219)\tD(fake)1 0.1938 (0.2760)\tD(fake)2 0.2540 (0.1780)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0982 (-0.1638)\n",
            "Epoch: [6][ 60/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.004)\tD(real) 0.8390 (0.7242)\tD(fake)1 0.3657 (0.2774)\tD(fake)2 0.0484 (0.1755)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1650)\n",
            "Epoch: [6][ 70/195]\tTime  0.341 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.5993 (0.7252)\tD(fake)1 0.1365 (0.2729)\tD(fake)2 0.2377 (0.1730)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1653)\n",
            "Epoch: [6][ 80/195]\tTime  0.340 ( 0.347)\tData  0.000 ( 0.003)\tD(real) 0.8285 (0.7256)\tD(fake)1 0.4717 (0.2746)\tD(fake)2 0.2035 (0.1738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1644)\n",
            "Epoch: [6][ 90/195]\tTime  0.337 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7038 (0.7264)\tD(fake)1 0.2229 (0.2747)\tD(fake)2 0.2174 (0.1758)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1631)\n",
            "Epoch: [6][100/195]\tTime  0.341 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8351 (0.7253)\tD(fake)1 0.4199 (0.2767)\tD(fake)2 0.1232 (0.1760)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1461 (-0.1629)\n",
            "Epoch: [6][110/195]\tTime  0.340 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7649 (0.7265)\tD(fake)1 0.2997 (0.2762)\tD(fake)2 0.1110 (0.1744)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1445 (-0.1631)\n",
            "Epoch: [6][120/195]\tTime  0.345 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7347 (0.7279)\tD(fake)1 0.2733 (0.2754)\tD(fake)2 0.1142 (0.1727)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1634)\n",
            "Epoch: [6][130/195]\tTime  0.347 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6127 (0.7293)\tD(fake)1 0.2089 (0.2726)\tD(fake)2 0.2655 (0.1715)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1621)\n",
            "Epoch: [6][140/195]\tTime  0.342 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.9443 (0.7306)\tD(fake)1 0.4644 (0.2731)\tD(fake)2 0.0392 (0.1704)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1725 (-0.1619)\n",
            "Epoch: [6][150/195]\tTime  0.343 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.8625 (0.7325)\tD(fake)1 0.2847 (0.2704)\tD(fake)2 0.0052 (0.1671)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1533 (-0.1621)\n",
            "Epoch: [6][160/195]\tTime  0.340 ( 0.345)\tData  0.000 ( 0.002)\tD(real) 0.4135 (0.7328)\tD(fake)1 -0.0568 (0.2667)\tD(fake)2 0.4728 (0.1646)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1624)\n",
            "Epoch: [6][170/195]\tTime  0.348 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.8221 (0.7330)\tD(fake)1 0.3163 (0.2694)\tD(fake)2 0.0986 (0.1655)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1626)\n",
            "Epoch: [6][180/195]\tTime  0.342 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.8050 (0.7332)\tD(fake)1 0.3239 (0.2694)\tD(fake)2 0.1466 (0.1649)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1620)\n",
            "Epoch: [6][190/195]\tTime  0.340 ( 0.345)\tData  0.000 ( 0.001)\tD(real) 0.7983 (0.7336)\tD(fake)1 0.4040 (0.2694)\tD(fake)2 0.1346 (0.1654)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1243 (-0.1618)\n",
            "Epoch: [7][  0/195]\tTime  0.602 ( 0.602)\tData  0.206 ( 0.206)\tD(real) 0.6626 (0.6626)\tD(fake)1 0.3287 (0.3287)\tD(fake)2 0.2258 (0.2258)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1611)\n",
            "Epoch: [7][ 10/195]\tTime  0.345 ( 0.369)\tData  0.000 ( 0.019)\tD(real) 0.8652 (0.7403)\tD(fake)1 0.3135 (0.2674)\tD(fake)2 0.1326 (0.1542)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1542 (-0.1575)\n",
            "Epoch: [7][ 20/195]\tTime  0.347 ( 0.358)\tData  0.000 ( 0.010)\tD(real) 0.4689 (0.7500)\tD(fake)1 -0.0795 (0.2381)\tD(fake)2 0.2457 (0.1198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1614)\n",
            "Epoch: [7][ 30/195]\tTime  0.343 ( 0.354)\tData  0.000 ( 0.007)\tD(real) 0.7543 (0.7456)\tD(fake)1 0.3937 (0.2568)\tD(fake)2 0.1494 (0.1363)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1329 (-0.1617)\n",
            "Epoch: [7][ 40/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.5827 (0.7341)\tD(fake)1 0.3137 (0.2647)\tD(fake)2 0.2738 (0.1462)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1631)\n",
            "Epoch: [7][ 50/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.7291 (0.7281)\tD(fake)1 0.2720 (0.2707)\tD(fake)2 0.1458 (0.1535)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1272 (-0.1633)\n",
            "Epoch: [7][ 60/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.7074 (0.7298)\tD(fake)1 0.2101 (0.2683)\tD(fake)2 0.1528 (0.1577)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1725 (-0.1629)\n",
            "Epoch: [7][ 70/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.5232 (0.7320)\tD(fake)1 0.0116 (0.2631)\tD(fake)2 0.4178 (0.1561)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1616)\n",
            "Epoch: [7][ 80/195]\tTime  0.340 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.7780 (0.7286)\tD(fake)1 0.2743 (0.2704)\tD(fake)2 0.1155 (0.1582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1190 (-0.1602)\n",
            "Epoch: [7][ 90/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.7964 (0.7305)\tD(fake)1 0.3046 (0.2687)\tD(fake)2 0.1060 (0.1582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1596)\n",
            "Epoch: [7][100/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.8207 (0.7338)\tD(fake)1 0.3680 (0.2670)\tD(fake)2 0.1275 (0.1537)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1451 (-0.1597)\n",
            "Epoch: [7][110/195]\tTime  0.344 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.7899 (0.7348)\tD(fake)1 0.2825 (0.2663)\tD(fake)2 0.0812 (0.1527)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1602)\n",
            "Epoch: [7][120/195]\tTime  0.342 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6904 (0.7353)\tD(fake)1 0.2057 (0.2656)\tD(fake)2 0.1706 (0.1536)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1733 (-0.1603)\n",
            "Epoch: [7][130/195]\tTime  0.346 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.7414 (0.7365)\tD(fake)1 0.2150 (0.2655)\tD(fake)2 0.1643 (0.1516)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1127 (-0.1601)\n",
            "Epoch: [7][140/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.7131 (0.7366)\tD(fake)1 0.2734 (0.2662)\tD(fake)2 0.1662 (0.1502)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1452 (-0.1603)\n",
            "Epoch: [7][150/195]\tTime  0.343 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.6514 (0.7373)\tD(fake)1 0.2761 (0.2672)\tD(fake)2 0.1242 (0.1506)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1770 (-0.1605)\n",
            "Epoch: [7][160/195]\tTime  0.351 ( 0.346)\tData  0.000 ( 0.002)\tD(real) 0.8096 (0.7336)\tD(fake)1 0.4349 (0.2704)\tD(fake)2 0.1381 (0.1539)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1251 (-0.1603)\n",
            "Epoch: [7][170/195]\tTime  0.346 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.6933 (0.7313)\tD(fake)1 0.3066 (0.2713)\tD(fake)2 0.1592 (0.1566)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1606)\n",
            "Epoch: [7][180/195]\tTime  0.343 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.6804 (0.7308)\tD(fake)1 0.1495 (0.2708)\tD(fake)2 0.2320 (0.1583)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1601)\n",
            "Epoch: [7][190/195]\tTime  0.349 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.7499 (0.7307)\tD(fake)1 0.2347 (0.2725)\tD(fake)2 0.1071 (0.1593)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1603)\n",
            "Epoch: [8][  0/195]\tTime  0.587 ( 0.587)\tData  0.188 ( 0.188)\tD(real) 0.9054 (0.9054)\tD(fake)1 0.4026 (0.4026)\tD(fake)2 -0.2400 (-0.2400)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1531 (-0.1531)\n",
            "Epoch: [8][ 10/195]\tTime  0.343 ( 0.367)\tData  0.000 ( 0.017)\tD(real) 0.7196 (0.6603)\tD(fake)1 0.3419 (0.3338)\tD(fake)2 0.1702 (0.1877)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1763 (-0.1613)\n",
            "Epoch: [8][ 20/195]\tTime  0.346 ( 0.358)\tData  0.000 ( 0.009)\tD(real) 0.6961 (0.6722)\tD(fake)1 0.2313 (0.3207)\tD(fake)2 0.2561 (0.1889)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1471 (-0.1597)\n",
            "Epoch: [8][ 30/195]\tTime  0.341 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.6774 (0.6870)\tD(fake)1 0.1356 (0.3035)\tD(fake)2 0.2646 (0.1863)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1711 (-0.1606)\n",
            "Epoch: [8][ 40/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.7788 (0.7076)\tD(fake)1 0.2223 (0.2954)\tD(fake)2 0.1163 (0.1793)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1368 (-0.1590)\n",
            "Epoch: [8][ 50/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8980 (0.7128)\tD(fake)1 0.3522 (0.2931)\tD(fake)2 -0.1383 (0.1649)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1605)\n",
            "Epoch: [8][ 60/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6720 (0.7061)\tD(fake)1 0.3345 (0.2950)\tD(fake)2 0.1015 (0.1678)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1511 (-0.1599)\n",
            "Epoch: [8][ 70/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.7941 (0.7034)\tD(fake)1 0.3888 (0.2966)\tD(fake)2 0.1154 (0.1748)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1598)\n",
            "Epoch: [8][ 80/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6173 (0.7026)\tD(fake)1 0.1849 (0.2964)\tD(fake)2 0.2324 (0.1798)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1592)\n",
            "Epoch: [8][ 90/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9424 (0.7090)\tD(fake)1 0.5544 (0.2960)\tD(fake)2 -0.1019 (0.1754)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1447 (-0.1596)\n",
            "Epoch: [8][100/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6561 (0.7018)\tD(fake)1 0.2319 (0.2977)\tD(fake)2 0.1867 (0.1819)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1708 (-0.1597)\n",
            "Epoch: [8][110/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7793 (0.7038)\tD(fake)1 0.4617 (0.2963)\tD(fake)2 0.2605 (0.1817)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1542 (-0.1594)\n",
            "Epoch: [8][120/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7319 (0.7091)\tD(fake)1 0.1878 (0.2922)\tD(fake)2 0.1761 (0.1785)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1592)\n",
            "Epoch: [8][130/195]\tTime  0.340 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6803 (0.7065)\tD(fake)1 0.2115 (0.2923)\tD(fake)2 0.2186 (0.1782)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1597)\n",
            "Epoch: [8][140/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.4258 (0.7078)\tD(fake)1 -0.0930 (0.2893)\tD(fake)2 0.2378 (0.1749)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1601)\n",
            "Epoch: [8][150/195]\tTime  0.341 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6479 (0.7082)\tD(fake)1 0.2522 (0.2913)\tD(fake)2 0.2850 (0.1771)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1341 (-0.1599)\n",
            "Epoch: [8][160/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.8367 (0.7096)\tD(fake)1 0.3277 (0.2901)\tD(fake)2 0.0711 (0.1758)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1604)\n",
            "Epoch: [8][170/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.8973 (0.7127)\tD(fake)1 0.4273 (0.2881)\tD(fake)2 0.0128 (0.1741)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1608)\n",
            "Epoch: [8][180/195]\tTime  0.343 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.7701 (0.7151)\tD(fake)1 0.2961 (0.2860)\tD(fake)2 0.0625 (0.1709)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1608)\n",
            "Epoch: [8][190/195]\tTime  0.341 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.8656 (0.7147)\tD(fake)1 0.4735 (0.2868)\tD(fake)2 0.0647 (0.1710)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1611)\n",
            "Epoch: [9][  0/195]\tTime  0.590 ( 0.590)\tData  0.196 ( 0.196)\tD(real) 0.6867 (0.6867)\tD(fake)1 0.2218 (0.2218)\tD(fake)2 0.1793 (0.1793)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1729 (-0.1729)\n",
            "Epoch: [9][ 10/195]\tTime  0.345 ( 0.369)\tData  0.000 ( 0.018)\tD(real) 0.7337 (0.7881)\tD(fake)1 0.1386 (0.2235)\tD(fake)2 0.0608 (0.0727)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1669)\n",
            "Epoch: [9][ 20/195]\tTime  0.343 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.7703 (0.7507)\tD(fake)1 0.3032 (0.2562)\tD(fake)2 0.1633 (0.1182)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1229 (-0.1598)\n",
            "Epoch: [9][ 30/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.007)\tD(real) 0.8406 (0.7539)\tD(fake)1 0.3481 (0.2532)\tD(fake)2 -0.0150 (0.1278)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1603)\n",
            "Epoch: [9][ 40/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.005)\tD(real) 0.7298 (0.7291)\tD(fake)1 0.2939 (0.2674)\tD(fake)2 0.1769 (0.1429)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1626)\n",
            "Epoch: [9][ 50/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.7231 (0.7258)\tD(fake)1 0.2196 (0.2671)\tD(fake)2 0.2299 (0.1491)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1557 (-0.1614)\n",
            "Epoch: [9][ 60/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.004)\tD(real) 0.6868 (0.7293)\tD(fake)1 0.3092 (0.2687)\tD(fake)2 0.2582 (0.1499)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1034 (-0.1608)\n",
            "Epoch: [9][ 70/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6877 (0.7249)\tD(fake)1 0.2577 (0.2772)\tD(fake)2 0.1853 (0.1562)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1616)\n",
            "Epoch: [9][ 80/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.003)\tD(real) 0.7221 (0.7238)\tD(fake)1 0.3721 (0.2787)\tD(fake)2 0.2714 (0.1599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1619)\n",
            "Epoch: [9][ 90/195]\tTime  0.341 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6517 (0.7216)\tD(fake)1 0.2772 (0.2795)\tD(fake)2 0.1965 (0.1613)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1622)\n",
            "Epoch: [9][100/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6162 (0.7209)\tD(fake)1 0.1193 (0.2806)\tD(fake)2 0.1581 (0.1639)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1623)\n",
            "Epoch: [9][110/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7412 (0.7207)\tD(fake)1 0.2358 (0.2813)\tD(fake)2 0.0954 (0.1640)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1498 (-0.1624)\n",
            "Epoch: [9][120/195]\tTime  0.342 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6581 (0.7235)\tD(fake)1 0.2509 (0.2779)\tD(fake)2 0.2170 (0.1601)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1421 (-0.1626)\n",
            "Epoch: [9][130/195]\tTime  0.342 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.7450 (0.7240)\tD(fake)1 0.1645 (0.2758)\tD(fake)2 0.1323 (0.1573)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1625)\n",
            "Epoch: [9][140/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.5886 (0.7254)\tD(fake)1 0.2871 (0.2756)\tD(fake)2 0.1655 (0.1561)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1625)\n",
            "Epoch: [9][150/195]\tTime  0.349 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6318 (0.7242)\tD(fake)1 0.2465 (0.2766)\tD(fake)2 0.2436 (0.1588)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1628)\n",
            "Epoch: [9][160/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6914 (0.7235)\tD(fake)1 0.2638 (0.2774)\tD(fake)2 0.1801 (0.1606)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1627)\n",
            "Epoch: [9][170/195]\tTime  0.347 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.8337 (0.7245)\tD(fake)1 0.4631 (0.2772)\tD(fake)2 0.2410 (0.1622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1175 (-0.1618)\n",
            "Epoch: [9][180/195]\tTime  0.340 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.7450 (0.7247)\tD(fake)1 0.4111 (0.2783)\tD(fake)2 0.1327 (0.1615)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1205 (-0.1618)\n",
            "Epoch: [9][190/195]\tTime  0.345 ( 0.346)\tData  0.000 ( 0.001)\tD(real) 0.7218 (0.7224)\tD(fake)1 0.3232 (0.2801)\tD(fake)2 0.2340 (0.1624)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1617)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUGjJ-6Pf3xE",
        "outputId": "8292b616-769a-4ad4-f023-c2d5c8025026"
      },
      "source": [
        "run(10)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.595 ( 0.595)\tData  0.214 ( 0.214)\tD(real) 0.7013 (0.7013)\tD(fake)1 0.1567 (0.1567)\tD(fake)2 0.2419 (0.2419)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1647)\n",
            "Epoch: [0][ 10/195]\tTime  0.347 ( 0.370)\tData  0.000 ( 0.020)\tD(real) 0.6105 (0.7298)\tD(fake)1 0.1781 (0.2557)\tD(fake)2 0.3188 (0.1745)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1380 (-0.1590)\n",
            "Epoch: [0][ 20/195]\tTime  0.342 ( 0.358)\tData  0.000 ( 0.010)\tD(real) 0.7475 (0.7064)\tD(fake)1 0.3147 (0.2930)\tD(fake)2 0.1843 (0.1885)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1587)\n",
            "Epoch: [0][ 30/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.007)\tD(real) 0.7767 (0.7350)\tD(fake)1 0.3261 (0.2737)\tD(fake)2 0.0541 (0.1622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1595)\n",
            "Epoch: [0][ 40/195]\tTime  0.341 ( 0.352)\tData  0.000 ( 0.006)\tD(real) 0.7311 (0.7352)\tD(fake)1 0.2401 (0.2704)\tD(fake)2 0.1282 (0.1515)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1514 (-0.1609)\n",
            "Epoch: [0][ 50/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.005)\tD(real) 0.9744 (0.7459)\tD(fake)1 0.4603 (0.2660)\tD(fake)2 -0.1646 (0.1435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1456 (-0.1607)\n",
            "Epoch: [0][ 60/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.7683 (0.7290)\tD(fake)1 0.3965 (0.2711)\tD(fake)2 0.0804 (0.1559)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1789 (-0.1614)\n",
            "Epoch: [0][ 70/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6944 (0.7252)\tD(fake)1 0.3439 (0.2753)\tD(fake)2 0.2249 (0.1648)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1445 (-0.1614)\n",
            "Epoch: [0][ 80/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.8113 (0.7268)\tD(fake)1 0.3370 (0.2750)\tD(fake)2 0.0397 (0.1633)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1620)\n",
            "Epoch: [0][ 90/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6928 (0.7236)\tD(fake)1 0.1201 (0.2730)\tD(fake)2 0.4224 (0.1659)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1625)\n",
            "Epoch: [0][100/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6400 (0.7179)\tD(fake)1 0.3385 (0.2796)\tD(fake)2 0.2546 (0.1706)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1465 (-0.1618)\n",
            "Epoch: [0][110/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6759 (0.7190)\tD(fake)1 0.2886 (0.2823)\tD(fake)2 0.1760 (0.1737)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1609)\n",
            "Epoch: [0][120/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6732 (0.7164)\tD(fake)1 0.2914 (0.2833)\tD(fake)2 0.2750 (0.1759)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1748 (-0.1609)\n",
            "Epoch: [0][130/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.4616 (0.7141)\tD(fake)1 0.0864 (0.2841)\tD(fake)2 0.2534 (0.1773)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.1604)\n",
            "Epoch: [0][140/195]\tTime  0.349 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6627 (0.7170)\tD(fake)1 0.1512 (0.2820)\tD(fake)2 0.3473 (0.1761)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1610)\n",
            "Epoch: [0][150/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6983 (0.7166)\tD(fake)1 0.2384 (0.2824)\tD(fake)2 0.1268 (0.1740)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1610)\n",
            "Epoch: [0][160/195]\tTime  0.343 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6423 (0.7161)\tD(fake)1 0.2668 (0.2825)\tD(fake)2 0.2211 (0.1740)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1611)\n",
            "Epoch: [0][170/195]\tTime  0.341 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.5988 (0.7169)\tD(fake)1 0.0336 (0.2817)\tD(fake)2 0.3365 (0.1746)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1611)\n",
            "Epoch: [0][180/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.6995 (0.7174)\tD(fake)1 0.3938 (0.2821)\tD(fake)2 0.2216 (0.1748)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1606)\n",
            "Epoch: [0][190/195]\tTime  0.350 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.7581 (0.7159)\tD(fake)1 0.3286 (0.2829)\tD(fake)2 0.2259 (0.1761)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1414 (-0.1607)\n",
            "Epoch: [1][  0/195]\tTime  0.595 ( 0.595)\tData  0.204 ( 0.204)\tD(real) 0.7660 (0.7660)\tD(fake)1 0.2806 (0.2806)\tD(fake)2 0.1448 (0.1448)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1491 (-0.1491)\n",
            "Epoch: [1][ 10/195]\tTime  0.347 ( 0.368)\tData  0.000 ( 0.019)\tD(real) 0.6912 (0.7119)\tD(fake)1 0.2701 (0.3060)\tD(fake)2 0.1551 (0.1875)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1592)\n",
            "Epoch: [1][ 20/195]\tTime  0.348 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.6905 (0.7212)\tD(fake)1 0.3753 (0.2993)\tD(fake)2 0.1389 (0.1823)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1121 (-0.1559)\n",
            "Epoch: [1][ 30/195]\tTime  0.345 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.7767 (0.7211)\tD(fake)1 0.2627 (0.2925)\tD(fake)2 0.0603 (0.1753)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1754 (-0.1582)\n",
            "Epoch: [1][ 40/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.6321 (0.7219)\tD(fake)1 0.1359 (0.2835)\tD(fake)2 0.2070 (0.1644)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1592)\n",
            "Epoch: [1][ 50/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.6361 (0.7167)\tD(fake)1 0.1003 (0.2851)\tD(fake)2 0.2092 (0.1629)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1564 (-0.1591)\n",
            "Epoch: [1][ 60/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.7617 (0.7260)\tD(fake)1 0.1998 (0.2801)\tD(fake)2 0.1380 (0.1586)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1604)\n",
            "Epoch: [1][ 70/195]\tTime  0.341 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6252 (0.7306)\tD(fake)1 0.0541 (0.2729)\tD(fake)2 0.2235 (0.1509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1362 (-0.1603)\n",
            "Epoch: [1][ 80/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6966 (0.7327)\tD(fake)1 0.2290 (0.2679)\tD(fake)2 0.3274 (0.1495)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1716 (-0.1595)\n",
            "Epoch: [1][ 90/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6682 (0.7341)\tD(fake)1 0.1872 (0.2677)\tD(fake)2 0.3057 (0.1504)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1781 (-0.1610)\n",
            "Epoch: [1][100/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7275 (0.7324)\tD(fake)1 0.2829 (0.2710)\tD(fake)2 0.1784 (0.1546)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1746 (-0.1616)\n",
            "Epoch: [1][110/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8165 (0.7365)\tD(fake)1 0.2536 (0.2693)\tD(fake)2 0.1819 (0.1536)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1752 (-0.1621)\n",
            "Epoch: [1][120/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8802 (0.7375)\tD(fake)1 0.4806 (0.2696)\tD(fake)2 -0.0756 (0.1519)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1620)\n",
            "Epoch: [1][130/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6596 (0.7321)\tD(fake)1 0.2454 (0.2712)\tD(fake)2 0.2194 (0.1569)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1471 (-0.1618)\n",
            "Epoch: [1][140/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8446 (0.7318)\tD(fake)1 0.3408 (0.2726)\tD(fake)2 0.0671 (0.1574)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1618)\n",
            "Epoch: [1][150/195]\tTime  0.342 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.6619 (0.7328)\tD(fake)1 0.1409 (0.2706)\tD(fake)2 0.2199 (0.1565)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1406 (-0.1617)\n",
            "Epoch: [1][160/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.002)\tD(real) 0.5714 (0.7353)\tD(fake)1 0.2166 (0.2687)\tD(fake)2 0.0633 (0.1524)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1171 (-0.1617)\n",
            "Epoch: [1][170/195]\tTime  0.344 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.6881 (0.7330)\tD(fake)1 0.2581 (0.2697)\tD(fake)2 0.2230 (0.1549)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1612)\n",
            "Epoch: [1][180/195]\tTime  0.346 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.6665 (0.7312)\tD(fake)1 0.3014 (0.2714)\tD(fake)2 0.2341 (0.1573)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1614)\n",
            "Epoch: [1][190/195]\tTime  0.345 ( 0.347)\tData  0.000 ( 0.001)\tD(real) 0.7684 (0.7301)\tD(fake)1 0.4265 (0.2726)\tD(fake)2 0.1547 (0.1594)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1484 (-0.1618)\n",
            "Epoch: [2][  0/195]\tTime  0.593 ( 0.593)\tData  0.201 ( 0.201)\tD(real) 0.7525 (0.7525)\tD(fake)1 0.3649 (0.3649)\tD(fake)2 0.1265 (0.1265)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1715 (-0.1715)\n",
            "Epoch: [2][ 10/195]\tTime  0.346 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.7212 (0.7326)\tD(fake)1 0.2614 (0.2914)\tD(fake)2 0.1346 (0.1647)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1637)\n",
            "Epoch: [2][ 20/195]\tTime  0.344 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.8083 (0.7403)\tD(fake)1 0.3222 (0.2718)\tD(fake)2 0.1295 (0.1505)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1625)\n",
            "Epoch: [2][ 30/195]\tTime  0.345 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.7554 (0.7385)\tD(fake)1 0.2733 (0.2663)\tD(fake)2 0.2119 (0.1556)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1745 (-0.1635)\n",
            "Epoch: [2][ 40/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6303 (0.7342)\tD(fake)1 0.1765 (0.2674)\tD(fake)2 0.3236 (0.1656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1635)\n",
            "Epoch: [2][ 50/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6234 (0.7344)\tD(fake)1 0.1070 (0.2683)\tD(fake)2 0.2978 (0.1642)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1138 (-0.1627)\n",
            "Epoch: [2][ 60/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.6087 (0.7387)\tD(fake)1 0.1854 (0.2629)\tD(fake)2 0.3245 (0.1604)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1708 (-0.1631)\n",
            "Epoch: [2][ 70/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7017 (0.7416)\tD(fake)1 0.2179 (0.2617)\tD(fake)2 0.2265 (0.1609)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1616)\n",
            "Epoch: [2][ 80/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6708 (0.7353)\tD(fake)1 0.2483 (0.2651)\tD(fake)2 0.1933 (0.1637)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1617)\n",
            "Epoch: [2][ 90/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.7557 (0.7394)\tD(fake)1 0.2198 (0.2628)\tD(fake)2 0.0798 (0.1599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1611)\n",
            "Epoch: [2][100/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7696 (0.7378)\tD(fake)1 0.2905 (0.2654)\tD(fake)2 0.1248 (0.1589)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1607)\n",
            "Epoch: [2][110/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7053 (0.7409)\tD(fake)1 0.3664 (0.2652)\tD(fake)2 0.1807 (0.1578)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1610)\n",
            "Epoch: [2][120/195]\tTime  0.353 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6076 (0.7327)\tD(fake)1 0.2469 (0.2706)\tD(fake)2 0.3323 (0.1630)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1606)\n",
            "Epoch: [2][130/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6532 (0.7315)\tD(fake)1 0.1429 (0.2715)\tD(fake)2 0.2362 (0.1644)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1608)\n",
            "Epoch: [2][140/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7747 (0.7305)\tD(fake)1 0.3799 (0.2721)\tD(fake)2 0.1112 (0.1644)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1483 (-0.1610)\n",
            "Epoch: [2][150/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7400 (0.7289)\tD(fake)1 0.2747 (0.2730)\tD(fake)2 0.2024 (0.1658)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1610)\n",
            "Epoch: [2][160/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5788 (0.7282)\tD(fake)1 0.3754 (0.2750)\tD(fake)2 0.2685 (0.1657)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0880 (-0.1607)\n",
            "Epoch: [2][170/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6158 (0.7239)\tD(fake)1 0.1962 (0.2777)\tD(fake)2 0.2940 (0.1696)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1607)\n",
            "Epoch: [2][180/195]\tTime  0.352 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7397 (0.7239)\tD(fake)1 0.3237 (0.2789)\tD(fake)2 0.1055 (0.1695)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1755 (-0.1613)\n",
            "Epoch: [2][190/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6646 (0.7212)\tD(fake)1 0.3174 (0.2800)\tD(fake)2 0.2338 (0.1709)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1527 (-0.1615)\n",
            "Epoch: [3][  0/195]\tTime  0.604 ( 0.604)\tData  0.209 ( 0.209)\tD(real) 0.6734 (0.6734)\tD(fake)1 0.3470 (0.3470)\tD(fake)2 0.1811 (0.1811)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1349 (-0.1349)\n",
            "Epoch: [3][ 10/195]\tTime  0.354 ( 0.375)\tData  0.000 ( 0.019)\tD(real) 0.7474 (0.7476)\tD(fake)1 0.2370 (0.2592)\tD(fake)2 0.0889 (0.1381)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1502)\n",
            "Epoch: [3][ 20/195]\tTime  0.350 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.7173 (0.7287)\tD(fake)1 0.3038 (0.2685)\tD(fake)2 0.2379 (0.1578)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1543)\n",
            "Epoch: [3][ 30/195]\tTime  0.349 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6741 (0.7341)\tD(fake)1 0.2552 (0.2671)\tD(fake)2 0.1360 (0.1582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1559)\n",
            "Epoch: [3][ 40/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7429 (0.7379)\tD(fake)1 0.2463 (0.2659)\tD(fake)2 0.1737 (0.1595)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1581)\n",
            "Epoch: [3][ 50/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.8227 (0.7353)\tD(fake)1 0.2965 (0.2687)\tD(fake)2 0.1030 (0.1600)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1588)\n",
            "Epoch: [3][ 60/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6240 (0.7326)\tD(fake)1 0.1886 (0.2672)\tD(fake)2 0.2208 (0.1626)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1743 (-0.1592)\n",
            "Epoch: [3][ 70/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8262 (0.7324)\tD(fake)1 0.4052 (0.2685)\tD(fake)2 0.1249 (0.1656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1710 (-0.1595)\n",
            "Epoch: [3][ 80/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7773 (0.7298)\tD(fake)1 0.2838 (0.2712)\tD(fake)2 0.1471 (0.1695)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1464 (-0.1602)\n",
            "Epoch: [3][ 90/195]\tTime  0.342 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8429 (0.7289)\tD(fake)1 0.5118 (0.2746)\tD(fake)2 0.1445 (0.1710)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1423 (-0.1597)\n",
            "Epoch: [3][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6001 (0.7285)\tD(fake)1 0.1651 (0.2738)\tD(fake)2 0.2710 (0.1719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1227 (-0.1592)\n",
            "Epoch: [3][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8613 (0.7314)\tD(fake)1 0.3174 (0.2738)\tD(fake)2 -0.0691 (0.1674)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1699 (-0.1597)\n",
            "Epoch: [3][120/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6739 (0.7257)\tD(fake)1 0.3391 (0.2770)\tD(fake)2 0.2190 (0.1743)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1718 (-0.1603)\n",
            "Epoch: [3][130/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7158 (0.7237)\tD(fake)1 0.2746 (0.2777)\tD(fake)2 0.2364 (0.1775)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1540 (-0.1606)\n",
            "Epoch: [3][140/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6813 (0.7241)\tD(fake)1 0.1889 (0.2765)\tD(fake)2 0.3240 (0.1786)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1240 (-0.1608)\n",
            "Epoch: [3][150/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7547 (0.7251)\tD(fake)1 0.3256 (0.2778)\tD(fake)2 0.1347 (0.1772)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1488 (-0.1611)\n",
            "Epoch: [3][160/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6641 (0.7214)\tD(fake)1 0.3195 (0.2810)\tD(fake)2 0.2315 (0.1793)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1463 (-0.1614)\n",
            "Epoch: [3][170/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6795 (0.7237)\tD(fake)1 0.0744 (0.2779)\tD(fake)2 0.2982 (0.1760)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1612)\n",
            "Epoch: [3][180/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6866 (0.7226)\tD(fake)1 0.2788 (0.2802)\tD(fake)2 0.2091 (0.1760)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1744 (-0.1614)\n",
            "Epoch: [3][190/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7365 (0.7213)\tD(fake)1 0.4723 (0.2824)\tD(fake)2 0.2908 (0.1772)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1612)\n",
            "Epoch: [4][  0/195]\tTime  0.587 ( 0.587)\tData  0.207 ( 0.207)\tD(real) 0.7995 (0.7995)\tD(fake)1 0.2594 (0.2594)\tD(fake)2 0.1411 (0.1411)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1622)\n",
            "Epoch: [4][ 10/195]\tTime  0.346 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.7470 (0.7211)\tD(fake)1 0.3581 (0.3029)\tD(fake)2 -0.0069 (0.1412)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1763 (-0.1687)\n",
            "Epoch: [4][ 20/195]\tTime  0.343 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.9190 (0.7173)\tD(fake)1 0.3000 (0.2938)\tD(fake)2 0.0155 (0.1599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1634)\n",
            "Epoch: [4][ 30/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.5382 (0.7067)\tD(fake)1 0.2459 (0.2907)\tD(fake)2 0.3310 (0.1675)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1599)\n",
            "Epoch: [4][ 40/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.7646 (0.7085)\tD(fake)1 0.1988 (0.2910)\tD(fake)2 0.1470 (0.1635)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1619)\n",
            "Epoch: [4][ 50/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7604 (0.7166)\tD(fake)1 0.2454 (0.2839)\tD(fake)2 0.1560 (0.1589)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1559 (-0.1618)\n",
            "Epoch: [4][ 60/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.7262 (0.7235)\tD(fake)1 0.3590 (0.2788)\tD(fake)2 0.0947 (0.1499)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1621)\n",
            "Epoch: [4][ 70/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7421 (0.7183)\tD(fake)1 0.3087 (0.2818)\tD(fake)2 0.1514 (0.1559)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1739 (-0.1615)\n",
            "Epoch: [4][ 80/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8230 (0.7251)\tD(fake)1 0.2723 (0.2775)\tD(fake)2 0.1084 (0.1551)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1611)\n",
            "Epoch: [4][ 90/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.5812 (0.7227)\tD(fake)1 0.3103 (0.2793)\tD(fake)2 0.1723 (0.1561)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1613)\n",
            "Epoch: [4][100/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6953 (0.7195)\tD(fake)1 0.2546 (0.2817)\tD(fake)2 0.1940 (0.1628)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1614)\n",
            "Epoch: [4][110/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6000 (0.7176)\tD(fake)1 0.1140 (0.2815)\tD(fake)2 0.4689 (0.1651)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1618)\n",
            "Epoch: [4][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8148 (0.7200)\tD(fake)1 0.2436 (0.2810)\tD(fake)2 0.0815 (0.1636)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1616)\n",
            "Epoch: [4][130/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7321 (0.7189)\tD(fake)1 0.3769 (0.2824)\tD(fake)2 0.1990 (0.1651)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1620)\n",
            "Epoch: [4][140/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.4699 (0.7226)\tD(fake)1 0.0596 (0.2784)\tD(fake)2 0.2482 (0.1612)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1139 (-0.1619)\n",
            "Epoch: [4][150/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6996 (0.7221)\tD(fake)1 0.2854 (0.2799)\tD(fake)2 0.1771 (0.1619)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1623)\n",
            "Epoch: [4][160/195]\tTime  0.352 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7232 (0.7203)\tD(fake)1 0.3177 (0.2828)\tD(fake)2 0.2039 (0.1656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1618)\n",
            "Epoch: [4][170/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7438 (0.7210)\tD(fake)1 0.4333 (0.2813)\tD(fake)2 0.3720 (0.1660)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1622)\n",
            "Epoch: [4][180/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7252 (0.7179)\tD(fake)1 0.3621 (0.2845)\tD(fake)2 0.0939 (0.1684)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1514 (-0.1617)\n",
            "Epoch: [4][190/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7588 (0.7193)\tD(fake)1 0.2382 (0.2820)\tD(fake)2 0.0899 (0.1666)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1619)\n",
            "Epoch: [5][  0/195]\tTime  0.602 ( 0.602)\tData  0.206 ( 0.206)\tD(real) 0.7498 (0.7498)\tD(fake)1 0.2786 (0.2786)\tD(fake)2 0.1184 (0.1184)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1677)\n",
            "Epoch: [5][ 10/195]\tTime  0.351 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.6768 (0.7506)\tD(fake)1 0.2394 (0.2561)\tD(fake)2 0.2045 (0.1357)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1554)\n",
            "Epoch: [5][ 20/195]\tTime  0.343 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.8209 (0.7607)\tD(fake)1 0.3776 (0.2488)\tD(fake)2 0.1104 (0.1192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1574)\n",
            "Epoch: [5][ 30/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6073 (0.7445)\tD(fake)1 0.0720 (0.2522)\tD(fake)2 0.2059 (0.1301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1743 (-0.1613)\n",
            "Epoch: [5][ 40/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6446 (0.7439)\tD(fake)1 0.2505 (0.2555)\tD(fake)2 0.2354 (0.1368)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1040 (-0.1607)\n",
            "Epoch: [5][ 50/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8596 (0.7454)\tD(fake)1 0.3623 (0.2543)\tD(fake)2 0.2048 (0.1420)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1747 (-0.1623)\n",
            "Epoch: [5][ 60/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7168 (0.7448)\tD(fake)1 0.1566 (0.2582)\tD(fake)2 0.1600 (0.1448)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1494 (-0.1624)\n",
            "Epoch: [5][ 70/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6076 (0.7395)\tD(fake)1 0.1853 (0.2625)\tD(fake)2 0.1817 (0.1466)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1503 (-0.1625)\n",
            "Epoch: [5][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7747 (0.7398)\tD(fake)1 0.2571 (0.2626)\tD(fake)2 0.1450 (0.1479)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1217 (-0.1623)\n",
            "Epoch: [5][ 90/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6722 (0.7381)\tD(fake)1 0.3343 (0.2667)\tD(fake)2 0.2356 (0.1538)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1499 (-0.1628)\n",
            "Epoch: [5][100/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8012 (0.7373)\tD(fake)1 0.3891 (0.2714)\tD(fake)2 0.0862 (0.1578)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1484 (-0.1628)\n",
            "Epoch: [5][110/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6000 (0.7370)\tD(fake)1 0.2054 (0.2700)\tD(fake)2 0.2641 (0.1572)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1303 (-0.1619)\n",
            "Epoch: [5][120/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7247 (0.7346)\tD(fake)1 0.3114 (0.2722)\tD(fake)2 0.1698 (0.1573)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1747 (-0.1621)\n",
            "Epoch: [5][130/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7776 (0.7390)\tD(fake)1 0.1932 (0.2681)\tD(fake)2 0.1073 (0.1532)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1618)\n",
            "Epoch: [5][140/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6103 (0.7392)\tD(fake)1 0.2660 (0.2670)\tD(fake)2 0.1828 (0.1526)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1616)\n",
            "Epoch: [5][150/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7750 (0.7347)\tD(fake)1 0.2612 (0.2709)\tD(fake)2 0.1511 (0.1562)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0929 (-0.1617)\n",
            "Epoch: [5][160/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6641 (0.7376)\tD(fake)1 0.2205 (0.2677)\tD(fake)2 0.1925 (0.1534)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1517 (-0.1620)\n",
            "Epoch: [5][170/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6971 (0.7344)\tD(fake)1 0.2715 (0.2697)\tD(fake)2 0.1249 (0.1549)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1615)\n",
            "Epoch: [5][180/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6409 (0.7348)\tD(fake)1 0.1904 (0.2692)\tD(fake)2 0.1271 (0.1549)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1531 (-0.1613)\n",
            "Epoch: [5][190/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6775 (0.7337)\tD(fake)1 0.3313 (0.2708)\tD(fake)2 0.2186 (0.1564)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1615)\n",
            "Epoch: [6][  0/195]\tTime  0.600 ( 0.600)\tData  0.203 ( 0.203)\tD(real) 0.7808 (0.7808)\tD(fake)1 0.2370 (0.2370)\tD(fake)2 0.1079 (0.1079)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1655)\n",
            "Epoch: [6][ 10/195]\tTime  0.344 ( 0.369)\tData  0.000 ( 0.019)\tD(real) 0.9614 (0.7357)\tD(fake)1 0.6039 (0.2756)\tD(fake)2 0.0767 (0.1365)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1451 (-0.1556)\n",
            "Epoch: [6][ 20/195]\tTime  0.342 ( 0.358)\tData  0.000 ( 0.010)\tD(real) 0.8657 (0.7181)\tD(fake)1 0.4570 (0.2826)\tD(fake)2 0.0975 (0.1630)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1565)\n",
            "Epoch: [6][ 30/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.007)\tD(real) 0.8065 (0.7286)\tD(fake)1 0.2971 (0.2712)\tD(fake)2 0.0576 (0.1652)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1594)\n",
            "Epoch: [6][ 40/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.6371 (0.7180)\tD(fake)1 0.3161 (0.2778)\tD(fake)2 0.2176 (0.1750)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1590)\n",
            "Epoch: [6][ 50/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.5686 (0.7133)\tD(fake)1 0.2120 (0.2834)\tD(fake)2 0.2732 (0.1787)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1586)\n",
            "Epoch: [6][ 60/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8090 (0.7122)\tD(fake)1 0.4014 (0.2882)\tD(fake)2 -0.1205 (0.1719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1586)\n",
            "Epoch: [6][ 70/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6965 (0.7127)\tD(fake)1 0.2419 (0.2830)\tD(fake)2 0.2050 (0.1728)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1592)\n",
            "Epoch: [6][ 80/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9244 (0.7186)\tD(fake)1 0.3498 (0.2816)\tD(fake)2 -0.1986 (0.1673)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1595)\n",
            "Epoch: [6][ 90/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6769 (0.7163)\tD(fake)1 0.3294 (0.2823)\tD(fake)2 0.2014 (0.1719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1602)\n",
            "Epoch: [6][100/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7555 (0.7170)\tD(fake)1 0.3640 (0.2828)\tD(fake)2 0.0524 (0.1691)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1595)\n",
            "Epoch: [6][110/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8004 (0.7178)\tD(fake)1 0.3707 (0.2821)\tD(fake)2 0.0773 (0.1684)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1587)\n",
            "Epoch: [6][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8261 (0.7162)\tD(fake)1 0.4305 (0.2860)\tD(fake)2 0.0430 (0.1715)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1581)\n",
            "Epoch: [6][130/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8468 (0.7149)\tD(fake)1 0.4276 (0.2864)\tD(fake)2 0.1083 (0.1722)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1580)\n",
            "Epoch: [6][140/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8123 (0.7142)\tD(fake)1 0.4659 (0.2858)\tD(fake)2 0.2351 (0.1738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1582)\n",
            "Epoch: [6][150/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8368 (0.7144)\tD(fake)1 0.2719 (0.2856)\tD(fake)2 0.0806 (0.1736)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1583)\n",
            "Epoch: [6][160/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6651 (0.7122)\tD(fake)1 0.3155 (0.2876)\tD(fake)2 0.2145 (0.1752)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1589)\n",
            "Epoch: [6][170/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7301 (0.7124)\tD(fake)1 0.3577 (0.2884)\tD(fake)2 0.1825 (0.1752)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1586)\n",
            "Epoch: [6][180/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6126 (0.7110)\tD(fake)1 0.2453 (0.2887)\tD(fake)2 0.1972 (0.1763)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.1587)\n",
            "Epoch: [6][190/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8034 (0.7094)\tD(fake)1 0.2252 (0.2891)\tD(fake)2 0.0649 (0.1737)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1588)\n",
            "Epoch: [7][  0/195]\tTime  0.609 ( 0.609)\tData  0.206 ( 0.206)\tD(real) 0.6999 (0.6999)\tD(fake)1 0.1554 (0.1554)\tD(fake)2 0.1709 (0.1709)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1732 (-0.1732)\n",
            "Epoch: [7][ 10/195]\tTime  0.345 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.4259 (0.6910)\tD(fake)1 0.0960 (0.2926)\tD(fake)2 0.5073 (0.1904)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0986 (-0.1508)\n",
            "Epoch: [7][ 20/195]\tTime  0.350 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6644 (0.6712)\tD(fake)1 0.3121 (0.3305)\tD(fake)2 0.2147 (0.2066)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1569)\n",
            "Epoch: [7][ 30/195]\tTime  0.356 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.8441 (0.7123)\tD(fake)1 0.1583 (0.2923)\tD(fake)2 0.0816 (0.1759)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1589)\n",
            "Epoch: [7][ 40/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6650 (0.7256)\tD(fake)1 0.2762 (0.2809)\tD(fake)2 0.1743 (0.1646)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1411 (-0.1583)\n",
            "Epoch: [7][ 50/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7269 (0.7262)\tD(fake)1 0.0971 (0.2795)\tD(fake)2 0.1745 (0.1652)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1588)\n",
            "Epoch: [7][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7166 (0.7339)\tD(fake)1 0.2095 (0.2708)\tD(fake)2 0.1969 (0.1599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1583)\n",
            "Epoch: [7][ 70/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6161 (0.7368)\tD(fake)1 0.2012 (0.2658)\tD(fake)2 0.1642 (0.1552)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1577)\n",
            "Epoch: [7][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.9306 (0.7412)\tD(fake)1 0.3539 (0.2620)\tD(fake)2 0.0536 (0.1449)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1459 (-0.1573)\n",
            "Epoch: [7][ 90/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8917 (0.7460)\tD(fake)1 0.3758 (0.2584)\tD(fake)2 -0.0150 (0.1407)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1582)\n",
            "Epoch: [7][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6355 (0.7402)\tD(fake)1 0.2021 (0.2614)\tD(fake)2 0.2036 (0.1426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1581)\n",
            "Epoch: [7][110/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8080 (0.7432)\tD(fake)1 0.2271 (0.2610)\tD(fake)2 0.1381 (0.1439)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1581)\n",
            "Epoch: [7][120/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6728 (0.7469)\tD(fake)1 0.1877 (0.2587)\tD(fake)2 0.2037 (0.1433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1586)\n",
            "Epoch: [7][130/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7893 (0.7441)\tD(fake)1 0.3631 (0.2611)\tD(fake)2 0.1115 (0.1433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1593)\n",
            "Epoch: [7][140/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9438 (0.7444)\tD(fake)1 0.4630 (0.2617)\tD(fake)2 -0.0924 (0.1448)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1592)\n",
            "Epoch: [7][150/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6681 (0.7429)\tD(fake)1 0.2017 (0.2599)\tD(fake)2 0.2656 (0.1474)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1593)\n",
            "Epoch: [7][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6937 (0.7411)\tD(fake)1 0.1856 (0.2612)\tD(fake)2 0.2781 (0.1506)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1594)\n",
            "Epoch: [7][170/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8043 (0.7418)\tD(fake)1 0.2773 (0.2626)\tD(fake)2 0.1527 (0.1525)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1715 (-0.1598)\n",
            "Epoch: [7][180/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.4595 (0.7404)\tD(fake)1 -0.0478 (0.2618)\tD(fake)2 0.3608 (0.1519)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1602)\n",
            "Epoch: [7][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6665 (0.7385)\tD(fake)1 0.2388 (0.2643)\tD(fake)2 0.2914 (0.1542)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1604)\n",
            "Epoch: [8][  0/195]\tTime  0.601 ( 0.601)\tData  0.209 ( 0.209)\tD(real) 0.6814 (0.6814)\tD(fake)1 0.1569 (0.1569)\tD(fake)2 0.2145 (0.2145)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1689)\n",
            "Epoch: [8][ 10/195]\tTime  0.352 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.5603 (0.7698)\tD(fake)1 0.0910 (0.2221)\tD(fake)2 0.2480 (0.1194)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1480 (-0.1619)\n",
            "Epoch: [8][ 20/195]\tTime  0.349 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6836 (0.7495)\tD(fake)1 0.2324 (0.2538)\tD(fake)2 0.2085 (0.1511)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1601 (-0.1603)\n",
            "Epoch: [8][ 30/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7379 (0.7414)\tD(fake)1 0.2429 (0.2591)\tD(fake)2 0.1176 (0.1551)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1726 (-0.1634)\n",
            "Epoch: [8][ 40/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8376 (0.7530)\tD(fake)1 0.1842 (0.2534)\tD(fake)2 0.0666 (0.1513)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1610)\n",
            "Epoch: [8][ 50/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6158 (0.7443)\tD(fake)1 0.2393 (0.2571)\tD(fake)2 0.2351 (0.1507)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1719 (-0.1623)\n",
            "Epoch: [8][ 60/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7976 (0.7358)\tD(fake)1 0.3640 (0.2676)\tD(fake)2 0.0631 (0.1565)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1739 (-0.1614)\n",
            "Epoch: [8][ 70/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8698 (0.7396)\tD(fake)1 0.3745 (0.2661)\tD(fake)2 -0.0863 (0.1547)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1628)\n",
            "Epoch: [8][ 80/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8084 (0.7391)\tD(fake)1 0.2527 (0.2637)\tD(fake)2 0.0556 (0.1551)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1634)\n",
            "Epoch: [8][ 90/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6864 (0.7376)\tD(fake)1 0.1998 (0.2638)\tD(fake)2 0.1772 (0.1567)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1638)\n",
            "Epoch: [8][100/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7367 (0.7404)\tD(fake)1 0.1729 (0.2616)\tD(fake)2 0.1948 (0.1555)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1543 (-0.1635)\n",
            "Epoch: [8][110/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7789 (0.7409)\tD(fake)1 0.3273 (0.2622)\tD(fake)2 0.1208 (0.1542)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1638)\n",
            "Epoch: [8][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8591 (0.7407)\tD(fake)1 0.3308 (0.2613)\tD(fake)2 0.0943 (0.1556)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1490 (-0.1633)\n",
            "Epoch: [8][130/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7057 (0.7431)\tD(fake)1 0.1190 (0.2578)\tD(fake)2 0.1287 (0.1530)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1631)\n",
            "Epoch: [8][140/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6552 (0.7435)\tD(fake)1 0.1329 (0.2575)\tD(fake)2 0.2136 (0.1525)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1633)\n",
            "Epoch: [8][150/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8744 (0.7477)\tD(fake)1 0.1016 (0.2539)\tD(fake)2 0.0951 (0.1493)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1438 (-0.1629)\n",
            "Epoch: [8][160/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7915 (0.7534)\tD(fake)1 0.2205 (0.2483)\tD(fake)2 0.0574 (0.1439)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1627)\n",
            "Epoch: [8][170/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7558 (0.7525)\tD(fake)1 0.2627 (0.2479)\tD(fake)2 0.2004 (0.1442)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1593 (-0.1613)\n",
            "Epoch: [8][180/195]\tTime  0.353 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7432 (0.7534)\tD(fake)1 0.2238 (0.2472)\tD(fake)2 0.1639 (0.1452)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1568 (-0.1607)\n",
            "Epoch: [8][190/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8143 (0.7529)\tD(fake)1 0.3113 (0.2467)\tD(fake)2 0.3330 (0.1444)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1606)\n",
            "Epoch: [9][  0/195]\tTime  0.603 ( 0.603)\tData  0.206 ( 0.206)\tD(real) 0.7526 (0.7526)\tD(fake)1 0.2829 (0.2829)\tD(fake)2 0.1653 (0.1653)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1568 (-0.1568)\n",
            "Epoch: [9][ 10/195]\tTime  0.348 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.6035 (0.7404)\tD(fake)1 0.1731 (0.2560)\tD(fake)2 0.2296 (0.1643)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1644)\n",
            "Epoch: [9][ 20/195]\tTime  0.343 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7069 (0.7219)\tD(fake)1 0.2661 (0.2793)\tD(fake)2 0.2266 (0.1753)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1425 (-0.1575)\n",
            "Epoch: [9][ 30/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6855 (0.7342)\tD(fake)1 0.1633 (0.2651)\tD(fake)2 0.2402 (0.1630)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1611)\n",
            "Epoch: [9][ 40/195]\tTime  0.352 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7840 (0.7355)\tD(fake)1 0.2646 (0.2668)\tD(fake)2 0.0811 (0.1582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1598)\n",
            "Epoch: [9][ 50/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7235 (0.7381)\tD(fake)1 0.2611 (0.2638)\tD(fake)2 0.1504 (0.1602)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1589)\n",
            "Epoch: [9][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7022 (0.7327)\tD(fake)1 0.3712 (0.2693)\tD(fake)2 0.2122 (0.1664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1596)\n",
            "Epoch: [9][ 70/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8811 (0.7352)\tD(fake)1 0.3612 (0.2715)\tD(fake)2 -0.0393 (0.1680)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1600)\n",
            "Epoch: [9][ 80/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5923 (0.7287)\tD(fake)1 0.2194 (0.2734)\tD(fake)2 0.3012 (0.1726)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1340 (-0.1583)\n",
            "Epoch: [9][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7765 (0.7308)\tD(fake)1 0.2835 (0.2715)\tD(fake)2 0.2185 (0.1701)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1198 (-0.1582)\n",
            "Epoch: [9][100/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6678 (0.7283)\tD(fake)1 0.2401 (0.2723)\tD(fake)2 0.2539 (0.1728)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1589)\n",
            "Epoch: [9][110/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7364 (0.7274)\tD(fake)1 0.2842 (0.2736)\tD(fake)2 0.1909 (0.1761)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1585)\n",
            "Epoch: [9][120/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6248 (0.7273)\tD(fake)1 0.2515 (0.2732)\tD(fake)2 0.1846 (0.1759)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1475 (-0.1591)\n",
            "Epoch: [9][130/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7314 (0.7266)\tD(fake)1 0.3130 (0.2736)\tD(fake)2 0.1903 (0.1781)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1593)\n",
            "Epoch: [9][140/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7987 (0.7268)\tD(fake)1 0.3126 (0.2740)\tD(fake)2 0.0844 (0.1789)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1595)\n",
            "Epoch: [9][150/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6644 (0.7272)\tD(fake)1 0.2049 (0.2728)\tD(fake)2 0.2675 (0.1792)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1597)\n",
            "Epoch: [9][160/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6839 (0.7281)\tD(fake)1 0.2039 (0.2726)\tD(fake)2 0.1387 (0.1787)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1585 (-0.1594)\n",
            "Epoch: [9][170/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7133 (0.7302)\tD(fake)1 0.1899 (0.2704)\tD(fake)2 0.2372 (0.1768)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1594)\n",
            "Epoch: [9][180/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6734 (0.7299)\tD(fake)1 0.3508 (0.2715)\tD(fake)2 0.1586 (0.1749)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1124 (-0.1594)\n",
            "Epoch: [9][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8400 (0.7286)\tD(fake)1 0.3661 (0.2736)\tD(fake)2 0.0899 (0.1763)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1595)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhsj8_owgDSl",
        "outputId": "88c36394-c83d-44e9-9378-70c293c58f2a"
      },
      "source": [
        "run(10)\n",
        "save_vid()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.603 ( 0.603)\tData  0.206 ( 0.206)\tD(real) 0.7734 (0.7734)\tD(fake)1 0.1789 (0.1789)\tD(fake)2 0.1898 (0.1898)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1669)\n",
            "Epoch: [0][ 10/195]\tTime  0.347 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.6276 (0.7418)\tD(fake)1 0.2411 (0.2555)\tD(fake)2 0.2250 (0.1611)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1642)\n",
            "Epoch: [0][ 20/195]\tTime  0.347 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6943 (0.7261)\tD(fake)1 0.1879 (0.2684)\tD(fake)2 0.1658 (0.1699)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1757 (-0.1587)\n",
            "Epoch: [0][ 30/195]\tTime  0.348 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.9111 (0.7426)\tD(fake)1 0.3667 (0.2574)\tD(fake)2 0.0035 (0.1529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1719 (-0.1548)\n",
            "Epoch: [0][ 40/195]\tTime  0.343 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.5723 (0.7373)\tD(fake)1 0.1080 (0.2563)\tD(fake)2 0.2129 (0.1588)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1601 (-0.1557)\n",
            "Epoch: [0][ 50/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7917 (0.7425)\tD(fake)1 0.2281 (0.2526)\tD(fake)2 0.2485 (0.1587)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1556 (-0.1574)\n",
            "Epoch: [0][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.9178 (0.7501)\tD(fake)1 0.4721 (0.2516)\tD(fake)2 0.0152 (0.1530)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1586)\n",
            "Epoch: [0][ 70/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 1.0034 (0.7513)\tD(fake)1 0.4621 (0.2506)\tD(fake)2 -0.0316 (0.1503)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1592)\n",
            "Epoch: [0][ 80/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7763 (0.7514)\tD(fake)1 0.2837 (0.2480)\tD(fake)2 0.0827 (0.1497)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1591)\n",
            "Epoch: [0][ 90/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6483 (0.7495)\tD(fake)1 0.1711 (0.2492)\tD(fake)2 0.2574 (0.1535)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1269 (-0.1584)\n",
            "Epoch: [0][100/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8068 (0.7522)\tD(fake)1 0.3078 (0.2483)\tD(fake)2 0.1566 (0.1518)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1495 (-0.1584)\n",
            "Epoch: [0][110/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8017 (0.7527)\tD(fake)1 0.3951 (0.2478)\tD(fake)2 0.1867 (0.1514)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1590)\n",
            "Epoch: [0][120/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7875 (0.7498)\tD(fake)1 0.3042 (0.2514)\tD(fake)2 0.1445 (0.1548)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1725 (-0.1596)\n",
            "Epoch: [0][130/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7316 (0.7483)\tD(fake)1 0.3326 (0.2536)\tD(fake)2 0.1911 (0.1560)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1536 (-0.1600)\n",
            "Epoch: [0][140/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6382 (0.7451)\tD(fake)1 0.2101 (0.2555)\tD(fake)2 0.1754 (0.1589)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1599)\n",
            "Epoch: [0][150/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5153 (0.7430)\tD(fake)1 -0.0169 (0.2559)\tD(fake)2 0.3584 (0.1602)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1604)\n",
            "Epoch: [0][160/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8557 (0.7443)\tD(fake)1 0.3286 (0.2570)\tD(fake)2 -0.0420 (0.1589)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1603)\n",
            "Epoch: [0][170/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7409 (0.7429)\tD(fake)1 0.1727 (0.2572)\tD(fake)2 0.2241 (0.1609)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1607)\n",
            "Epoch: [0][180/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8454 (0.7429)\tD(fake)1 0.5058 (0.2591)\tD(fake)2 0.1552 (0.1619)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1604)\n",
            "Epoch: [0][190/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.9801 (0.7406)\tD(fake)1 0.6017 (0.2623)\tD(fake)2 0.1172 (0.1640)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1605)\n",
            "Epoch: [1][  0/195]\tTime  0.600 ( 0.600)\tData  0.204 ( 0.204)\tD(real) 0.7099 (0.7099)\tD(fake)1 0.2386 (0.2386)\tD(fake)2 0.2116 (0.2116)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1688)\n",
            "Epoch: [1][ 10/195]\tTime  0.348 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.9285 (0.7850)\tD(fake)1 0.4136 (0.2356)\tD(fake)2 0.0316 (0.1116)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1666)\n",
            "Epoch: [1][ 20/195]\tTime  0.347 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.8873 (0.7651)\tD(fake)1 0.4410 (0.2464)\tD(fake)2 -0.0413 (0.1264)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1770 (-0.1620)\n",
            "Epoch: [1][ 30/195]\tTime  0.344 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7724 (0.7627)\tD(fake)1 0.1575 (0.2368)\tD(fake)2 0.1587 (0.1385)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1718 (-0.1620)\n",
            "Epoch: [1][ 40/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7394 (0.7602)\tD(fake)1 0.2769 (0.2411)\tD(fake)2 0.1228 (0.1426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1633)\n",
            "Epoch: [1][ 50/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7072 (0.7574)\tD(fake)1 0.2400 (0.2433)\tD(fake)2 0.1659 (0.1417)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1411 (-0.1623)\n",
            "Epoch: [1][ 60/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6635 (0.7561)\tD(fake)1 0.2329 (0.2445)\tD(fake)2 0.2890 (0.1421)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1621)\n",
            "Epoch: [1][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6629 (0.7471)\tD(fake)1 0.2019 (0.2532)\tD(fake)2 0.2426 (0.1481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1617)\n",
            "Epoch: [1][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7593 (0.7442)\tD(fake)1 0.3486 (0.2572)\tD(fake)2 0.1277 (0.1516)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1622)\n",
            "Epoch: [1][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7163 (0.7420)\tD(fake)1 0.2374 (0.2587)\tD(fake)2 0.1081 (0.1528)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1630)\n",
            "Epoch: [1][100/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6218 (0.7398)\tD(fake)1 0.1857 (0.2591)\tD(fake)2 0.3147 (0.1541)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1637)\n",
            "Epoch: [1][110/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7561 (0.7402)\tD(fake)1 0.2707 (0.2598)\tD(fake)2 0.1775 (0.1547)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1785 (-0.1639)\n",
            "Epoch: [1][120/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6913 (0.7410)\tD(fake)1 0.2474 (0.2593)\tD(fake)2 0.1860 (0.1545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0967 (-0.1626)\n",
            "Epoch: [1][130/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7618 (0.7404)\tD(fake)1 0.2773 (0.2595)\tD(fake)2 0.1202 (0.1515)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1554 (-0.1621)\n",
            "Epoch: [1][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8417 (0.7436)\tD(fake)1 0.2593 (0.2580)\tD(fake)2 0.0516 (0.1488)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1465 (-0.1616)\n",
            "Epoch: [1][150/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6427 (0.7414)\tD(fake)1 0.2854 (0.2589)\tD(fake)2 0.1866 (0.1491)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1613)\n",
            "Epoch: [1][160/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8656 (0.7406)\tD(fake)1 0.4540 (0.2602)\tD(fake)2 -0.0311 (0.1487)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1508 (-0.1609)\n",
            "Epoch: [1][170/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6898 (0.7393)\tD(fake)1 0.2187 (0.2603)\tD(fake)2 0.2062 (0.1500)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1728 (-0.1613)\n",
            "Epoch: [1][180/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7272 (0.7385)\tD(fake)1 0.3647 (0.2614)\tD(fake)2 0.2361 (0.1506)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1606)\n",
            "Epoch: [1][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6609 (0.7369)\tD(fake)1 0.1322 (0.2624)\tD(fake)2 0.3101 (0.1531)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1607)\n",
            "Epoch: [2][  0/195]\tTime  0.621 ( 0.621)\tData  0.214 ( 0.214)\tD(real) 0.6636 (0.6636)\tD(fake)1 0.2085 (0.2085)\tD(fake)2 0.1939 (0.1939)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1517 (-0.1517)\n",
            "Epoch: [2][ 10/195]\tTime  0.348 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.6198 (0.7516)\tD(fake)1 0.1613 (0.2479)\tD(fake)2 0.0791 (0.1169)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1438 (-0.1579)\n",
            "Epoch: [2][ 20/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.011)\tD(real) 0.6817 (0.7499)\tD(fake)1 0.1058 (0.2435)\tD(fake)2 0.2775 (0.1388)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1416 (-0.1611)\n",
            "Epoch: [2][ 30/195]\tTime  0.351 ( 0.358)\tData  0.001 ( 0.007)\tD(real) 0.7970 (0.7593)\tD(fake)1 0.2780 (0.2472)\tD(fake)2 0.0526 (0.1297)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1625)\n",
            "Epoch: [2][ 40/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7757 (0.7483)\tD(fake)1 0.2964 (0.2588)\tD(fake)2 0.1802 (0.1509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1638)\n",
            "Epoch: [2][ 50/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.9169 (0.7599)\tD(fake)1 0.4168 (0.2507)\tD(fake)2 0.0564 (0.1449)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1629)\n",
            "Epoch: [2][ 60/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8848 (0.7540)\tD(fake)1 0.3368 (0.2546)\tD(fake)2 -0.0351 (0.1453)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1622)\n",
            "Epoch: [2][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.9108 (0.7623)\tD(fake)1 0.4169 (0.2473)\tD(fake)2 0.0230 (0.1377)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1611)\n",
            "Epoch: [2][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6509 (0.7544)\tD(fake)1 0.2549 (0.2497)\tD(fake)2 0.2394 (0.1428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1606)\n",
            "Epoch: [2][ 90/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8306 (0.7540)\tD(fake)1 0.2564 (0.2504)\tD(fake)2 0.1154 (0.1446)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1520 (-0.1602)\n",
            "Epoch: [2][100/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6424 (0.7515)\tD(fake)1 0.2247 (0.2515)\tD(fake)2 0.2203 (0.1468)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1610)\n",
            "Epoch: [2][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7249 (0.7504)\tD(fake)1 0.1904 (0.2523)\tD(fake)2 0.2338 (0.1485)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1051 (-0.1598)\n",
            "Epoch: [2][120/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6847 (0.7503)\tD(fake)1 0.2710 (0.2524)\tD(fake)2 0.1253 (0.1462)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1604)\n",
            "Epoch: [2][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7630 (0.7489)\tD(fake)1 0.3811 (0.2540)\tD(fake)2 0.2102 (0.1480)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1610)\n",
            "Epoch: [2][140/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8755 (0.7522)\tD(fake)1 0.2497 (0.2534)\tD(fake)2 0.0477 (0.1478)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1760 (-0.1613)\n",
            "Epoch: [2][150/195]\tTime  0.359 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8391 (0.7523)\tD(fake)1 0.4798 (0.2529)\tD(fake)2 0.1826 (0.1472)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1431 (-0.1615)\n",
            "Epoch: [2][160/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8104 (0.7501)\tD(fake)1 0.3004 (0.2545)\tD(fake)2 0.0151 (0.1478)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1619)\n",
            "Epoch: [2][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7693 (0.7485)\tD(fake)1 0.1729 (0.2549)\tD(fake)2 0.1314 (0.1485)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1519 (-0.1610)\n",
            "Epoch: [2][180/195]\tTime  0.358 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7927 (0.7494)\tD(fake)1 0.3305 (0.2548)\tD(fake)2 0.1459 (0.1483)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1611)\n",
            "Epoch: [2][190/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6289 (0.7504)\tD(fake)1 0.1848 (0.2538)\tD(fake)2 0.1587 (0.1480)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1741 (-0.1609)\n",
            "Epoch: [3][  0/195]\tTime  0.603 ( 0.603)\tData  0.207 ( 0.207)\tD(real) 0.6787 (0.6787)\tD(fake)1 0.3705 (0.3705)\tD(fake)2 0.2290 (0.2290)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1759 (-0.1759)\n",
            "Epoch: [3][ 10/195]\tTime  0.351 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.5717 (0.7197)\tD(fake)1 0.0075 (0.2742)\tD(fake)2 0.2930 (0.1891)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1683)\n",
            "Epoch: [3][ 20/195]\tTime  0.349 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.7994 (0.7180)\tD(fake)1 0.4984 (0.2994)\tD(fake)2 -0.0831 (0.1747)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1692)\n",
            "Epoch: [3][ 30/195]\tTime  0.350 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6648 (0.6922)\tD(fake)1 0.2240 (0.3037)\tD(fake)2 0.2290 (0.2034)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1752 (-0.1666)\n",
            "Epoch: [3][ 40/195]\tTime  0.343 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.5668 (0.7008)\tD(fake)1 0.1035 (0.2932)\tD(fake)2 0.3600 (0.1982)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1654)\n",
            "Epoch: [3][ 50/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7158 (0.7179)\tD(fake)1 0.1502 (0.2827)\tD(fake)2 0.1735 (0.1868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1650)\n",
            "Epoch: [3][ 60/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.5354 (0.7263)\tD(fake)1 0.1155 (0.2726)\tD(fake)2 0.3104 (0.1802)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1568 (-0.1650)\n",
            "Epoch: [3][ 70/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8568 (0.7302)\tD(fake)1 0.3531 (0.2745)\tD(fake)2 0.0346 (0.1797)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1752 (-0.1642)\n",
            "Epoch: [3][ 80/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7926 (0.7274)\tD(fake)1 0.4040 (0.2765)\tD(fake)2 0.1207 (0.1797)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1644)\n",
            "Epoch: [3][ 90/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8629 (0.7312)\tD(fake)1 0.2799 (0.2724)\tD(fake)2 -0.0896 (0.1730)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1778 (-0.1649)\n",
            "Epoch: [3][100/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7127 (0.7319)\tD(fake)1 0.2061 (0.2709)\tD(fake)2 0.1695 (0.1722)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1648)\n",
            "Epoch: [3][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7010 (0.7333)\tD(fake)1 0.2705 (0.2710)\tD(fake)2 0.1359 (0.1711)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1643)\n",
            "Epoch: [3][120/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9535 (0.7363)\tD(fake)1 0.3556 (0.2671)\tD(fake)2 0.1294 (0.1681)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1518 (-0.1632)\n",
            "Epoch: [3][130/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6923 (0.7387)\tD(fake)1 0.1516 (0.2628)\tD(fake)2 0.2275 (0.1646)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1628)\n",
            "Epoch: [3][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6437 (0.7376)\tD(fake)1 0.2005 (0.2653)\tD(fake)2 0.3194 (0.1667)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1614)\n",
            "Epoch: [3][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6531 (0.7366)\tD(fake)1 0.3081 (0.2670)\tD(fake)2 0.1734 (0.1666)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1614)\n",
            "Epoch: [3][160/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8011 (0.7342)\tD(fake)1 0.2687 (0.2683)\tD(fake)2 0.1398 (0.1685)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1614)\n",
            "Epoch: [3][170/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7327 (0.7366)\tD(fake)1 0.1781 (0.2654)\tD(fake)2 0.1487 (0.1665)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1615)\n",
            "Epoch: [3][180/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7449 (0.7377)\tD(fake)1 0.3059 (0.2640)\tD(fake)2 0.2025 (0.1661)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1614)\n",
            "Epoch: [3][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7740 (0.7371)\tD(fake)1 0.3573 (0.2650)\tD(fake)2 0.1011 (0.1668)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1615)\n",
            "Epoch: [4][  0/195]\tTime  0.583 ( 0.583)\tData  0.205 ( 0.205)\tD(real) 0.7260 (0.7260)\tD(fake)1 0.3329 (0.3329)\tD(fake)2 0.0872 (0.0872)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1646)\n",
            "Epoch: [4][ 10/195]\tTime  0.346 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.7120 (0.7602)\tD(fake)1 0.1751 (0.2374)\tD(fake)2 0.2188 (0.1392)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1228 (-0.1603)\n",
            "Epoch: [4][ 20/195]\tTime  0.350 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7833 (0.7531)\tD(fake)1 0.2729 (0.2520)\tD(fake)2 0.1437 (0.1425)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1537 (-0.1568)\n",
            "Epoch: [4][ 30/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7664 (0.7532)\tD(fake)1 0.3016 (0.2524)\tD(fake)2 0.1437 (0.1467)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1582)\n",
            "Epoch: [4][ 40/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8139 (0.7499)\tD(fake)1 0.3843 (0.2587)\tD(fake)2 0.0398 (0.1509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1794 (-0.1591)\n",
            "Epoch: [4][ 50/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.4880 (0.7378)\tD(fake)1 0.0834 (0.2609)\tD(fake)2 0.3927 (0.1599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1366 (-0.1595)\n",
            "Epoch: [4][ 60/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.7195 (0.7311)\tD(fake)1 0.3687 (0.2737)\tD(fake)2 0.1279 (0.1692)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1724 (-0.1585)\n",
            "Epoch: [4][ 70/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9524 (0.7284)\tD(fake)1 0.4128 (0.2755)\tD(fake)2 -0.0309 (0.1710)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1594)\n",
            "Epoch: [4][ 80/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6464 (0.7301)\tD(fake)1 0.1155 (0.2697)\tD(fake)2 0.2713 (0.1711)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1757 (-0.1592)\n",
            "Epoch: [4][ 90/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.8083 (0.7284)\tD(fake)1 0.3106 (0.2729)\tD(fake)2 0.1107 (0.1721)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1588)\n",
            "Epoch: [4][100/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7061 (0.7262)\tD(fake)1 0.3154 (0.2744)\tD(fake)2 0.1363 (0.1736)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1588)\n",
            "Epoch: [4][110/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6788 (0.7243)\tD(fake)1 0.2735 (0.2759)\tD(fake)2 0.1653 (0.1758)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1507 (-0.1582)\n",
            "Epoch: [4][120/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9968 (0.7258)\tD(fake)1 0.4078 (0.2775)\tD(fake)2 0.0198 (0.1771)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1589)\n",
            "Epoch: [4][130/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7799 (0.7251)\tD(fake)1 0.4492 (0.2776)\tD(fake)2 0.0217 (0.1772)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1566 (-0.1596)\n",
            "Epoch: [4][140/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7802 (0.7236)\tD(fake)1 0.2897 (0.2776)\tD(fake)2 0.0090 (0.1764)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1596)\n",
            "Epoch: [4][150/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7817 (0.7261)\tD(fake)1 0.2868 (0.2754)\tD(fake)2 0.0625 (0.1727)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1460 (-0.1594)\n",
            "Epoch: [4][160/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8126 (0.7270)\tD(fake)1 0.1374 (0.2737)\tD(fake)2 0.1136 (0.1711)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1583)\n",
            "Epoch: [4][170/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6516 (0.7296)\tD(fake)1 0.2757 (0.2714)\tD(fake)2 0.1706 (0.1692)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1579)\n",
            "Epoch: [4][180/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7561 (0.7314)\tD(fake)1 0.1739 (0.2703)\tD(fake)2 0.1929 (0.1685)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1583)\n",
            "Epoch: [4][190/195]\tTime  0.350 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6942 (0.7322)\tD(fake)1 0.2244 (0.2699)\tD(fake)2 0.1515 (0.1671)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1584)\n",
            "Epoch: [5][  0/195]\tTime  0.577 ( 0.577)\tData  0.197 ( 0.197)\tD(real) 0.8201 (0.8201)\tD(fake)1 0.2839 (0.2839)\tD(fake)2 0.0784 (0.0784)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1685)\n",
            "Epoch: [5][ 10/195]\tTime  0.347 ( 0.370)\tData  0.000 ( 0.018)\tD(real) 0.6431 (0.7335)\tD(fake)1 0.2201 (0.2764)\tD(fake)2 0.2930 (0.1655)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1622)\n",
            "Epoch: [5][ 20/195]\tTime  0.349 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.8521 (0.7281)\tD(fake)1 0.4014 (0.2825)\tD(fake)2 -0.0009 (0.1620)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1555 (-0.1587)\n",
            "Epoch: [5][ 30/195]\tTime  0.350 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.5291 (0.7261)\tD(fake)1 0.0043 (0.2627)\tD(fake)2 0.3046 (0.1608)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1617)\n",
            "Epoch: [5][ 40/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8402 (0.7398)\tD(fake)1 0.3282 (0.2578)\tD(fake)2 0.0682 (0.1548)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1617)\n",
            "Epoch: [5][ 50/195]\tTime  0.355 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8973 (0.7480)\tD(fake)1 0.3345 (0.2539)\tD(fake)2 -0.0281 (0.1495)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1621)\n",
            "Epoch: [5][ 60/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8109 (0.7424)\tD(fake)1 0.3036 (0.2564)\tD(fake)2 0.1376 (0.1555)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1627)\n",
            "Epoch: [5][ 70/195]\tTime  0.342 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7012 (0.7413)\tD(fake)1 0.2148 (0.2553)\tD(fake)2 0.2530 (0.1572)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1624)\n",
            "Epoch: [5][ 80/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6882 (0.7423)\tD(fake)1 0.1382 (0.2565)\tD(fake)2 0.2530 (0.1600)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1737 (-0.1614)\n",
            "Epoch: [5][ 90/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5039 (0.7454)\tD(fake)1 0.0241 (0.2537)\tD(fake)2 0.2462 (0.1579)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1294 (-0.1607)\n",
            "Epoch: [5][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6466 (0.7396)\tD(fake)1 0.2739 (0.2607)\tD(fake)2 0.2289 (0.1641)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1032 (-0.1603)\n",
            "Epoch: [5][110/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7536 (0.7370)\tD(fake)1 0.2632 (0.2638)\tD(fake)2 0.1617 (0.1672)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1602)\n",
            "Epoch: [5][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7074 (0.7364)\tD(fake)1 0.3467 (0.2654)\tD(fake)2 0.1925 (0.1692)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1593 (-0.1602)\n",
            "Epoch: [5][130/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5670 (0.7343)\tD(fake)1 0.0580 (0.2640)\tD(fake)2 0.4338 (0.1709)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1723 (-0.1599)\n",
            "Epoch: [5][140/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8271 (0.7349)\tD(fake)1 0.3718 (0.2666)\tD(fake)2 0.1137 (0.1719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1736 (-0.1599)\n",
            "Epoch: [5][150/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5124 (0.7319)\tD(fake)1 0.1304 (0.2682)\tD(fake)2 0.2910 (0.1748)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1708 (-0.1601)\n",
            "Epoch: [5][160/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7476 (0.7295)\tD(fake)1 0.3212 (0.2712)\tD(fake)2 0.1112 (0.1761)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1450 (-0.1600)\n",
            "Epoch: [5][170/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7173 (0.7272)\tD(fake)1 0.3637 (0.2733)\tD(fake)2 0.1908 (0.1777)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1602)\n",
            "Epoch: [5][180/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.9743 (0.7298)\tD(fake)1 0.3229 (0.2723)\tD(fake)2 -0.1487 (0.1750)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1603)\n",
            "Epoch: [5][190/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7028 (0.7309)\tD(fake)1 0.1722 (0.2699)\tD(fake)2 0.2394 (0.1745)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1605)\n",
            "Epoch: [6][  0/195]\tTime  0.612 ( 0.612)\tData  0.212 ( 0.212)\tD(real) 0.7427 (0.7427)\tD(fake)1 0.3646 (0.3646)\tD(fake)2 0.3046 (0.3046)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1420 (-0.1420)\n",
            "Epoch: [6][ 10/195]\tTime  0.344 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.5033 (0.7098)\tD(fake)1 -0.0072 (0.2714)\tD(fake)2 0.3700 (0.1867)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1548)\n",
            "Epoch: [6][ 20/195]\tTime  0.348 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.5736 (0.7223)\tD(fake)1 0.1644 (0.2731)\tD(fake)2 0.2890 (0.1782)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1581)\n",
            "Epoch: [6][ 30/195]\tTime  0.351 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7063 (0.7312)\tD(fake)1 0.0595 (0.2666)\tD(fake)2 0.2672 (0.1731)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1607)\n",
            "Epoch: [6][ 40/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6349 (0.7458)\tD(fake)1 0.0560 (0.2528)\tD(fake)2 0.2746 (0.1642)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1605 (-0.1606)\n",
            "Epoch: [6][ 50/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.5891 (0.7481)\tD(fake)1 0.1973 (0.2539)\tD(fake)2 0.2421 (0.1650)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1488 (-0.1601)\n",
            "Epoch: [6][ 60/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.8104 (0.7430)\tD(fake)1 0.2977 (0.2608)\tD(fake)2 0.1609 (0.1716)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1607)\n",
            "Epoch: [6][ 70/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5807 (0.7412)\tD(fake)1 0.1811 (0.2598)\tD(fake)2 0.3071 (0.1721)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1612)\n",
            "Epoch: [6][ 80/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7046 (0.7398)\tD(fake)1 0.2659 (0.2644)\tD(fake)2 0.2382 (0.1770)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1548 (-0.1615)\n",
            "Epoch: [6][ 90/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7593 (0.7373)\tD(fake)1 0.2738 (0.2664)\tD(fake)2 0.1468 (0.1782)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1611)\n",
            "Epoch: [6][100/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7813 (0.7366)\tD(fake)1 0.2932 (0.2666)\tD(fake)2 0.1947 (0.1803)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1613)\n",
            "Epoch: [6][110/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7921 (0.7361)\tD(fake)1 0.3859 (0.2679)\tD(fake)2 0.0012 (0.1787)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1616)\n",
            "Epoch: [6][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7422 (0.7332)\tD(fake)1 0.3014 (0.2705)\tD(fake)2 0.1458 (0.1808)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1614)\n",
            "Epoch: [6][130/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7933 (0.7325)\tD(fake)1 0.3269 (0.2708)\tD(fake)2 0.0678 (0.1787)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1618)\n",
            "Epoch: [6][140/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6241 (0.7306)\tD(fake)1 0.1549 (0.2711)\tD(fake)2 0.2544 (0.1774)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1615)\n",
            "Epoch: [6][150/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8518 (0.7320)\tD(fake)1 0.3027 (0.2713)\tD(fake)2 0.0961 (0.1767)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1615)\n",
            "Epoch: [6][160/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8144 (0.7364)\tD(fake)1 0.3128 (0.2676)\tD(fake)2 -0.1090 (0.1716)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1614)\n",
            "Epoch: [6][170/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6722 (0.7314)\tD(fake)1 0.3156 (0.2709)\tD(fake)2 0.2262 (0.1773)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1613)\n",
            "Epoch: [6][180/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8372 (0.7304)\tD(fake)1 0.3568 (0.2719)\tD(fake)2 -0.0052 (0.1783)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1611)\n",
            "Epoch: [6][190/195]\tTime  0.359 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7650 (0.7296)\tD(fake)1 0.2035 (0.2714)\tD(fake)2 0.1429 (0.1785)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1718 (-0.1610)\n",
            "Epoch: [7][  0/195]\tTime  0.598 ( 0.598)\tData  0.215 ( 0.215)\tD(real) 0.7386 (0.7386)\tD(fake)1 0.3379 (0.3379)\tD(fake)2 0.1235 (0.1235)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1670)\n",
            "Epoch: [7][ 10/195]\tTime  0.345 ( 0.371)\tData  0.000 ( 0.020)\tD(real) 0.7495 (0.6882)\tD(fake)1 0.2369 (0.3076)\tD(fake)2 0.1261 (0.1963)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1601)\n",
            "Epoch: [7][ 20/195]\tTime  0.342 ( 0.359)\tData  0.000 ( 0.011)\tD(real) 0.7571 (0.7406)\tD(fake)1 0.1862 (0.2573)\tD(fake)2 0.1635 (0.1666)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1763 (-0.1650)\n",
            "Epoch: [7][ 30/195]\tTime  0.343 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7101 (0.7542)\tD(fake)1 0.2379 (0.2473)\tD(fake)2 0.1781 (0.1598)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1618)\n",
            "Epoch: [7][ 40/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.5617 (0.7321)\tD(fake)1 0.2440 (0.2650)\tD(fake)2 0.2793 (0.1763)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1753 (-0.1605)\n",
            "Epoch: [7][ 50/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6305 (0.7196)\tD(fake)1 0.2367 (0.2751)\tD(fake)2 0.2748 (0.1901)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1793 (-0.1620)\n",
            "Epoch: [7][ 60/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6315 (0.7144)\tD(fake)1 0.3081 (0.2806)\tD(fake)2 0.3035 (0.1966)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1399 (-0.1615)\n",
            "Epoch: [7][ 70/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7441 (0.7142)\tD(fake)1 0.2031 (0.2818)\tD(fake)2 0.2230 (0.1958)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1716 (-0.1613)\n",
            "Epoch: [7][ 80/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7265 (0.7139)\tD(fake)1 0.2852 (0.2840)\tD(fake)2 0.2163 (0.1956)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1608)\n",
            "Epoch: [7][ 90/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7004 (0.7188)\tD(fake)1 0.2689 (0.2812)\tD(fake)2 0.1796 (0.1932)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1601)\n",
            "Epoch: [7][100/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7155 (0.7178)\tD(fake)1 0.2590 (0.2850)\tD(fake)2 0.2280 (0.1964)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1607)\n",
            "Epoch: [7][110/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7694 (0.7204)\tD(fake)1 0.3325 (0.2844)\tD(fake)2 0.1460 (0.1955)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1602)\n",
            "Epoch: [7][120/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6096 (0.7155)\tD(fake)1 0.3173 (0.2863)\tD(fake)2 0.3225 (0.1977)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1605)\n",
            "Epoch: [7][130/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7253 (0.7118)\tD(fake)1 0.3317 (0.2899)\tD(fake)2 0.1659 (0.2005)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1602)\n",
            "Epoch: [7][140/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6754 (0.7130)\tD(fake)1 0.1986 (0.2883)\tD(fake)2 0.1722 (0.2005)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1737 (-0.1605)\n",
            "Epoch: [7][150/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9957 (0.7159)\tD(fake)1 0.5103 (0.2866)\tD(fake)2 0.0053 (0.1981)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1414 (-0.1602)\n",
            "Epoch: [7][160/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7844 (0.7152)\tD(fake)1 0.3016 (0.2856)\tD(fake)2 0.1831 (0.1981)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1484 (-0.1601)\n",
            "Epoch: [7][170/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 1.0005 (0.7196)\tD(fake)1 0.5273 (0.2828)\tD(fake)2 0.1424 (0.1950)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1495 (-0.1599)\n",
            "Epoch: [7][180/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6747 (0.7154)\tD(fake)1 0.3243 (0.2853)\tD(fake)2 0.2335 (0.1976)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1709 (-0.1603)\n",
            "Epoch: [7][190/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6351 (0.7147)\tD(fake)1 0.2319 (0.2841)\tD(fake)2 0.4445 (0.1972)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1604)\n",
            "Epoch: [8][  0/195]\tTime  0.598 ( 0.598)\tData  0.216 ( 0.216)\tD(real) 0.7650 (0.7650)\tD(fake)1 0.3757 (0.3757)\tD(fake)2 0.2137 (0.2137)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1608 (-0.1608)\n",
            "Epoch: [8][ 10/195]\tTime  0.343 ( 0.369)\tData  0.000 ( 0.020)\tD(real) 0.7275 (0.7323)\tD(fake)1 0.1717 (0.2727)\tD(fake)2 0.1909 (0.1875)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1626)\n",
            "Epoch: [8][ 20/195]\tTime  0.347 ( 0.359)\tData  0.000 ( 0.011)\tD(real) 0.6812 (0.7409)\tD(fake)1 0.3385 (0.2644)\tD(fake)2 0.2446 (0.1750)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1197 (-0.1592)\n",
            "Epoch: [8][ 30/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.7632 (0.7203)\tD(fake)1 0.2818 (0.2810)\tD(fake)2 0.1485 (0.1912)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1331 (-0.1585)\n",
            "Epoch: [8][ 40/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.006)\tD(real) 0.6527 (0.7184)\tD(fake)1 0.2713 (0.2808)\tD(fake)2 0.2939 (0.1972)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1747 (-0.1593)\n",
            "Epoch: [8][ 50/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.6840 (0.7164)\tD(fake)1 0.2719 (0.2832)\tD(fake)2 0.2404 (0.2010)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1611)\n",
            "Epoch: [8][ 60/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.6745 (0.7139)\tD(fake)1 0.2283 (0.2875)\tD(fake)2 0.2971 (0.2068)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1538 (-0.1605)\n",
            "Epoch: [8][ 70/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6413 (0.7146)\tD(fake)1 0.2021 (0.2877)\tD(fake)2 0.2365 (0.2052)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1591)\n",
            "Epoch: [8][ 80/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8337 (0.7168)\tD(fake)1 0.3393 (0.2859)\tD(fake)2 0.1752 (0.2029)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1108 (-0.1583)\n",
            "Epoch: [8][ 90/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.4431 (0.7209)\tD(fake)1 -0.0774 (0.2769)\tD(fake)2 0.3610 (0.1977)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1583)\n",
            "Epoch: [8][100/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5873 (0.7215)\tD(fake)1 0.0629 (0.2771)\tD(fake)2 0.3516 (0.1984)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1582)\n",
            "Epoch: [8][110/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7036 (0.7227)\tD(fake)1 0.1926 (0.2764)\tD(fake)2 0.2942 (0.1980)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1576)\n",
            "Epoch: [8][120/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8132 (0.7245)\tD(fake)1 0.2687 (0.2760)\tD(fake)2 0.0823 (0.1950)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1722 (-0.1583)\n",
            "Epoch: [8][130/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7955 (0.7281)\tD(fake)1 0.2951 (0.2731)\tD(fake)2 0.0957 (0.1920)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1583)\n",
            "Epoch: [8][140/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7373 (0.7271)\tD(fake)1 0.2595 (0.2740)\tD(fake)2 0.2231 (0.1940)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1583)\n",
            "Epoch: [8][150/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8007 (0.7291)\tD(fake)1 0.3239 (0.2727)\tD(fake)2 0.1261 (0.1922)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1588)\n",
            "Epoch: [8][160/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6149 (0.7276)\tD(fake)1 0.2313 (0.2728)\tD(fake)2 0.2329 (0.1922)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1588)\n",
            "Epoch: [8][170/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8222 (0.7260)\tD(fake)1 0.3138 (0.2758)\tD(fake)2 0.0911 (0.1926)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1755 (-0.1591)\n",
            "Epoch: [8][180/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7773 (0.7270)\tD(fake)1 0.2585 (0.2749)\tD(fake)2 0.1400 (0.1919)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1591)\n",
            "Epoch: [8][190/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7190 (0.7269)\tD(fake)1 0.3161 (0.2752)\tD(fake)2 0.2233 (0.1927)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1593)\n",
            "Epoch: [9][  0/195]\tTime  0.584 ( 0.584)\tData  0.206 ( 0.206)\tD(real) 0.6558 (0.6558)\tD(fake)1 0.1721 (0.1721)\tD(fake)2 0.3158 (0.3158)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1592)\n",
            "Epoch: [9][ 10/195]\tTime  0.347 ( 0.368)\tData  0.000 ( 0.019)\tD(real) 0.7192 (0.7648)\tD(fake)1 0.2130 (0.2387)\tD(fake)2 0.2501 (0.1642)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1572)\n",
            "Epoch: [9][ 20/195]\tTime  0.354 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.7859 (0.7677)\tD(fake)1 0.2637 (0.2441)\tD(fake)2 0.1706 (0.1644)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1729 (-0.1579)\n",
            "Epoch: [9][ 30/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.6810 (0.7604)\tD(fake)1 0.1950 (0.2452)\tD(fake)2 0.2131 (0.1632)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1605)\n",
            "Epoch: [9][ 40/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.7574 (0.7507)\tD(fake)1 0.4284 (0.2549)\tD(fake)2 0.2339 (0.1673)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1598)\n",
            "Epoch: [9][ 50/195]\tTime  0.341 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6920 (0.7352)\tD(fake)1 0.2881 (0.2665)\tD(fake)2 0.2116 (0.1795)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1590)\n",
            "Epoch: [9][ 60/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.7178 (0.7347)\tD(fake)1 0.2519 (0.2668)\tD(fake)2 0.1368 (0.1790)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1590)\n",
            "Epoch: [9][ 70/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7267 (0.7371)\tD(fake)1 0.1623 (0.2643)\tD(fake)2 0.1610 (0.1795)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1581)\n",
            "Epoch: [9][ 80/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6170 (0.7365)\tD(fake)1 0.2076 (0.2617)\tD(fake)2 0.2929 (0.1783)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1595)\n",
            "Epoch: [9][ 90/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6479 (0.7343)\tD(fake)1 0.1344 (0.2622)\tD(fake)2 0.2913 (0.1795)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1361 (-0.1599)\n",
            "Epoch: [9][100/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8568 (0.7387)\tD(fake)1 0.3667 (0.2612)\tD(fake)2 0.0965 (0.1759)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1557 (-0.1596)\n",
            "Epoch: [9][110/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5990 (0.7369)\tD(fake)1 0.1116 (0.2608)\tD(fake)2 0.2189 (0.1757)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1516 (-0.1599)\n",
            "Epoch: [9][120/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5570 (0.7370)\tD(fake)1 0.0388 (0.2598)\tD(fake)2 0.3392 (0.1765)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1601)\n",
            "Epoch: [9][130/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5891 (0.7371)\tD(fake)1 0.1012 (0.2606)\tD(fake)2 0.2965 (0.1773)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1599)\n",
            "Epoch: [9][140/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.5029 (0.7394)\tD(fake)1 0.0104 (0.2580)\tD(fake)2 0.3273 (0.1769)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1603)\n",
            "Epoch: [9][150/195]\tTime  0.342 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6679 (0.7379)\tD(fake)1 0.2238 (0.2610)\tD(fake)2 0.2490 (0.1799)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1600)\n",
            "Epoch: [9][160/195]\tTime  0.351 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.5936 (0.7375)\tD(fake)1 0.1924 (0.2613)\tD(fake)2 0.2168 (0.1804)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1599)\n",
            "Epoch: [9][170/195]\tTime  0.340 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6904 (0.7350)\tD(fake)1 0.1884 (0.2640)\tD(fake)2 0.2770 (0.1836)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1476 (-0.1599)\n",
            "Epoch: [9][180/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7206 (0.7361)\tD(fake)1 0.2123 (0.2629)\tD(fake)2 0.2427 (0.1819)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1137 (-0.1598)\n",
            "Epoch: [9][190/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6874 (0.7360)\tD(fake)1 0.2470 (0.2632)\tD(fake)2 0.2021 (0.1819)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1598)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNxlmBIutPfw",
        "outputId": "c76e51be-cce2-448d-9f06-dfd814b6eec3"
      },
      "source": [
        "run(10)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.616 ( 0.616)\tData  0.204 ( 0.204)\tD(real) 0.6433 (0.6433)\tD(fake)1 0.1554 (0.1554)\tD(fake)2 0.3490 (0.3490)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1642)\n",
            "Epoch: [0][ 10/195]\tTime  0.348 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.6431 (0.7360)\tD(fake)1 0.2468 (0.2655)\tD(fake)2 0.2498 (0.2073)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1570)\n",
            "Epoch: [0][ 20/195]\tTime  0.351 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.8545 (0.7224)\tD(fake)1 0.4107 (0.2840)\tD(fake)2 0.0407 (0.1991)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1601)\n",
            "Epoch: [0][ 30/195]\tTime  0.352 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.8197 (0.7212)\tD(fake)1 0.3025 (0.2739)\tD(fake)2 0.2231 (0.1931)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1491 (-0.1597)\n",
            "Epoch: [0][ 40/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7938 (0.7221)\tD(fake)1 0.4075 (0.2759)\tD(fake)2 0.1300 (0.1941)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1593)\n",
            "Epoch: [0][ 50/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7678 (0.7220)\tD(fake)1 0.2711 (0.2747)\tD(fake)2 0.1409 (0.1944)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1598)\n",
            "Epoch: [0][ 60/195]\tTime  0.342 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.9573 (0.7318)\tD(fake)1 0.3431 (0.2665)\tD(fake)2 0.1334 (0.1868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1603)\n",
            "Epoch: [0][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6151 (0.7302)\tD(fake)1 0.3266 (0.2688)\tD(fake)2 0.3044 (0.1874)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1139 (-0.1590)\n",
            "Epoch: [0][ 80/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6919 (0.7265)\tD(fake)1 0.2033 (0.2727)\tD(fake)2 0.2389 (0.1903)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1588)\n",
            "Epoch: [0][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7027 (0.7261)\tD(fake)1 0.3012 (0.2741)\tD(fake)2 0.1969 (0.1915)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1314 (-0.1577)\n",
            "Epoch: [0][100/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7623 (0.7253)\tD(fake)1 0.2544 (0.2743)\tD(fake)2 0.0921 (0.1915)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1719 (-0.1580)\n",
            "Epoch: [0][110/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8836 (0.7327)\tD(fake)1 0.2350 (0.2677)\tD(fake)2 -0.0800 (0.1835)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1584)\n",
            "Epoch: [0][120/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7390 (0.7328)\tD(fake)1 0.2720 (0.2676)\tD(fake)2 0.1931 (0.1860)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1723 (-0.1589)\n",
            "Epoch: [0][130/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5887 (0.7305)\tD(fake)1 0.2312 (0.2699)\tD(fake)2 0.3443 (0.1897)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1591)\n",
            "Epoch: [0][140/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8061 (0.7298)\tD(fake)1 0.4819 (0.2719)\tD(fake)2 0.2128 (0.1905)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1344 (-0.1595)\n",
            "Epoch: [0][150/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8912 (0.7278)\tD(fake)1 0.4569 (0.2741)\tD(fake)2 0.0859 (0.1912)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1598)\n",
            "Epoch: [0][160/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7737 (0.7265)\tD(fake)1 0.3277 (0.2756)\tD(fake)2 0.1617 (0.1934)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1600)\n",
            "Epoch: [0][170/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6336 (0.7267)\tD(fake)1 0.2291 (0.2754)\tD(fake)2 0.3137 (0.1944)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1592)\n",
            "Epoch: [0][180/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6073 (0.7241)\tD(fake)1 0.2685 (0.2773)\tD(fake)2 0.2631 (0.1952)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1594)\n",
            "Epoch: [0][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6125 (0.7208)\tD(fake)1 0.1980 (0.2793)\tD(fake)2 0.3510 (0.1970)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1591)\n",
            "Epoch: [1][  0/195]\tTime  0.600 ( 0.600)\tData  0.215 ( 0.215)\tD(real) 0.6675 (0.6675)\tD(fake)1 0.1162 (0.1162)\tD(fake)2 0.2022 (0.2022)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1729 (-0.1729)\n",
            "Epoch: [1][ 10/195]\tTime  0.346 ( 0.371)\tData  0.000 ( 0.020)\tD(real) 0.8287 (0.7409)\tD(fake)1 0.3429 (0.2602)\tD(fake)2 0.0554 (0.1566)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1561)\n",
            "Epoch: [1][ 20/195]\tTime  0.348 ( 0.361)\tData  0.000 ( 0.011)\tD(real) 0.9895 (0.7566)\tD(fake)1 0.5123 (0.2580)\tD(fake)2 0.0209 (0.1582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1574)\n",
            "Epoch: [1][ 30/195]\tTime  0.344 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7611 (0.7441)\tD(fake)1 0.1984 (0.2597)\tD(fake)2 0.1888 (0.1762)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1569)\n",
            "Epoch: [1][ 40/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.8291 (0.7553)\tD(fake)1 0.2794 (0.2513)\tD(fake)2 0.0905 (0.1716)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1737 (-0.1592)\n",
            "Epoch: [1][ 50/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6348 (0.7474)\tD(fake)1 0.2181 (0.2554)\tD(fake)2 0.2690 (0.1768)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1526 (-0.1577)\n",
            "Epoch: [1][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8647 (0.7459)\tD(fake)1 0.3988 (0.2597)\tD(fake)2 -0.0187 (0.1774)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1587)\n",
            "Epoch: [1][ 70/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7490 (0.7391)\tD(fake)1 0.3120 (0.2616)\tD(fake)2 0.1981 (0.1835)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1595)\n",
            "Epoch: [1][ 80/195]\tTime  0.340 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7542 (0.7381)\tD(fake)1 0.3270 (0.2624)\tD(fake)2 0.1108 (0.1826)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1592)\n",
            "Epoch: [1][ 90/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7818 (0.7359)\tD(fake)1 0.3772 (0.2634)\tD(fake)2 0.2427 (0.1832)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1302 (-0.1594)\n",
            "Epoch: [1][100/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7525 (0.7354)\tD(fake)1 0.2318 (0.2636)\tD(fake)2 0.2144 (0.1839)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1591)\n",
            "Epoch: [1][110/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8140 (0.7386)\tD(fake)1 0.2648 (0.2619)\tD(fake)2 0.0776 (0.1818)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1598)\n",
            "Epoch: [1][120/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6880 (0.7368)\tD(fake)1 0.2335 (0.2626)\tD(fake)2 0.2241 (0.1835)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1604)\n",
            "Epoch: [1][130/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8291 (0.7368)\tD(fake)1 0.3713 (0.2640)\tD(fake)2 0.0973 (0.1843)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1606)\n",
            "Epoch: [1][140/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7083 (0.7374)\tD(fake)1 0.1365 (0.2634)\tD(fake)2 0.2418 (0.1858)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1602)\n",
            "Epoch: [1][150/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5434 (0.7383)\tD(fake)1 0.1740 (0.2610)\tD(fake)2 0.4219 (0.1843)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1493 (-0.1601)\n",
            "Epoch: [1][160/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7045 (0.7351)\tD(fake)1 0.3169 (0.2648)\tD(fake)2 0.2324 (0.1869)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1593)\n",
            "Epoch: [1][170/195]\tTime  0.341 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8148 (0.7341)\tD(fake)1 0.3273 (0.2666)\tD(fake)2 0.1277 (0.1878)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1415 (-0.1596)\n",
            "Epoch: [1][180/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7764 (0.7348)\tD(fake)1 0.2611 (0.2656)\tD(fake)2 0.1173 (0.1867)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1592)\n",
            "Epoch: [1][190/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8128 (0.7351)\tD(fake)1 0.3557 (0.2652)\tD(fake)2 0.2186 (0.1868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1140 (-0.1592)\n",
            "Epoch: [2][  0/195]\tTime  0.590 ( 0.590)\tData  0.202 ( 0.202)\tD(real) 0.7702 (0.7702)\tD(fake)1 0.2351 (0.2351)\tD(fake)2 0.1738 (0.1738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1656)\n",
            "Epoch: [2][ 10/195]\tTime  0.350 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.6735 (0.7750)\tD(fake)1 0.1631 (0.2242)\tD(fake)2 0.1491 (0.1535)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1340 (-0.1548)\n",
            "Epoch: [2][ 20/195]\tTime  0.343 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.7475 (0.7498)\tD(fake)1 0.3332 (0.2544)\tD(fake)2 0.1645 (0.1819)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1605)\n",
            "Epoch: [2][ 30/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7587 (0.7326)\tD(fake)1 0.2730 (0.2685)\tD(fake)2 0.1721 (0.1987)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1596)\n",
            "Epoch: [2][ 40/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6839 (0.7283)\tD(fake)1 0.2772 (0.2685)\tD(fake)2 0.2828 (0.1975)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1590)\n",
            "Epoch: [2][ 50/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6713 (0.7275)\tD(fake)1 0.2702 (0.2737)\tD(fake)2 0.2467 (0.2002)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1592)\n",
            "Epoch: [2][ 60/195]\tTime  0.342 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.5499 (0.7302)\tD(fake)1 0.0703 (0.2723)\tD(fake)2 0.2042 (0.1988)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1548 (-0.1579)\n",
            "Epoch: [2][ 70/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7229 (0.7279)\tD(fake)1 0.2795 (0.2754)\tD(fake)2 0.2094 (0.2000)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1580)\n",
            "Epoch: [2][ 80/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7103 (0.7226)\tD(fake)1 0.3101 (0.2797)\tD(fake)2 0.1913 (0.2024)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1587)\n",
            "Epoch: [2][ 90/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.7429 (0.7267)\tD(fake)1 0.2452 (0.2759)\tD(fake)2 0.1442 (0.1984)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1589)\n",
            "Epoch: [2][100/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8902 (0.7251)\tD(fake)1 0.5230 (0.2778)\tD(fake)2 0.0852 (0.1995)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1596)\n",
            "Epoch: [2][110/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6804 (0.7206)\tD(fake)1 0.3108 (0.2789)\tD(fake)2 0.2022 (0.2021)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1236 (-0.1598)\n",
            "Epoch: [2][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7550 (0.7212)\tD(fake)1 0.2687 (0.2776)\tD(fake)2 0.2068 (0.2010)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1528 (-0.1597)\n",
            "Epoch: [2][130/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8849 (0.7269)\tD(fake)1 0.2471 (0.2738)\tD(fake)2 0.0413 (0.1966)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1452 (-0.1581)\n",
            "Epoch: [2][140/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6767 (0.7274)\tD(fake)1 0.3261 (0.2728)\tD(fake)2 0.2331 (0.1963)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1578)\n",
            "Epoch: [2][150/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.5763 (0.7241)\tD(fake)1 0.2483 (0.2748)\tD(fake)2 0.3268 (0.1987)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1582)\n",
            "Epoch: [2][160/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.9844 (0.7250)\tD(fake)1 0.5741 (0.2767)\tD(fake)2 -0.0390 (0.1981)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1585)\n",
            "Epoch: [2][170/195]\tTime  0.341 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6757 (0.7217)\tD(fake)1 0.2729 (0.2779)\tD(fake)2 0.2516 (0.2011)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1482 (-0.1581)\n",
            "Epoch: [2][180/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.9719 (0.7228)\tD(fake)1 0.5404 (0.2794)\tD(fake)2 0.0186 (0.2009)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1525 (-0.1575)\n",
            "Epoch: [2][190/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7640 (0.7224)\tD(fake)1 0.1905 (0.2775)\tD(fake)2 0.1995 (0.2006)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1504 (-0.1573)\n",
            "Epoch: [3][  0/195]\tTime  0.601 ( 0.601)\tData  0.205 ( 0.205)\tD(real) 0.8278 (0.8278)\tD(fake)1 0.2793 (0.2793)\tD(fake)2 0.1188 (0.1188)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1587)\n",
            "Epoch: [3][ 10/195]\tTime  0.349 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.7298 (0.7426)\tD(fake)1 0.2612 (0.2581)\tD(fake)2 0.1647 (0.1717)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1525 (-0.1511)\n",
            "Epoch: [3][ 20/195]\tTime  0.349 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7039 (0.7226)\tD(fake)1 0.3884 (0.2801)\tD(fake)2 0.2359 (0.1974)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1504)\n",
            "Epoch: [3][ 30/195]\tTime  0.348 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7617 (0.7135)\tD(fake)1 0.2901 (0.2912)\tD(fake)2 0.1702 (0.2102)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1297 (-0.1536)\n",
            "Epoch: [3][ 40/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7620 (0.7157)\tD(fake)1 0.3160 (0.2901)\tD(fake)2 0.1352 (0.2119)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1549)\n",
            "Epoch: [3][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7239 (0.7160)\tD(fake)1 0.2161 (0.2853)\tD(fake)2 0.0909 (0.2009)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1562)\n",
            "Epoch: [3][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7057 (0.7162)\tD(fake)1 0.2910 (0.2855)\tD(fake)2 0.1949 (0.2021)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1565)\n",
            "Epoch: [3][ 70/195]\tTime  0.355 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7722 (0.7145)\tD(fake)1 0.3303 (0.2866)\tD(fake)2 0.1477 (0.2012)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1569)\n",
            "Epoch: [3][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5982 (0.7158)\tD(fake)1 0.2151 (0.2829)\tD(fake)2 0.3234 (0.2006)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1035 (-0.1547)\n",
            "Epoch: [3][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7250 (0.7141)\tD(fake)1 0.4066 (0.2876)\tD(fake)2 0.1696 (0.2043)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1448 (-0.1549)\n",
            "Epoch: [3][100/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5991 (0.7078)\tD(fake)1 0.3104 (0.2913)\tD(fake)2 0.3084 (0.2116)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1554)\n",
            "Epoch: [3][110/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6205 (0.7044)\tD(fake)1 0.3301 (0.2944)\tD(fake)2 0.3103 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1429 (-0.1555)\n",
            "Epoch: [3][120/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7273 (0.7032)\tD(fake)1 0.3119 (0.2970)\tD(fake)2 0.2459 (0.2185)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1558)\n",
            "Epoch: [3][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 1.0280 (0.7062)\tD(fake)1 0.6320 (0.2966)\tD(fake)2 0.1121 (0.2177)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1563)\n",
            "Epoch: [3][140/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6954 (0.7012)\tD(fake)1 0.3675 (0.2987)\tD(fake)2 0.2280 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1566)\n",
            "Epoch: [3][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6291 (0.6983)\tD(fake)1 0.1763 (0.3000)\tD(fake)2 0.3826 (0.2231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1561)\n",
            "Epoch: [3][160/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8501 (0.7011)\tD(fake)1 0.3332 (0.2996)\tD(fake)2 0.1024 (0.2203)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1562)\n",
            "Epoch: [3][170/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8238 (0.7040)\tD(fake)1 0.3146 (0.2971)\tD(fake)2 -0.0566 (0.2162)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1500 (-0.1560)\n",
            "Epoch: [3][180/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6433 (0.7015)\tD(fake)1 0.2692 (0.2984)\tD(fake)2 0.2720 (0.2180)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1559)\n",
            "Epoch: [3][190/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6901 (0.7006)\tD(fake)1 0.3555 (0.2993)\tD(fake)2 0.2091 (0.2194)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1564)\n",
            "Epoch: [4][  0/195]\tTime  0.618 ( 0.618)\tData  0.213 ( 0.213)\tD(real) 0.5912 (0.5912)\tD(fake)1 0.2855 (0.2855)\tD(fake)2 0.3519 (0.3519)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1627)\n",
            "Epoch: [4][ 10/195]\tTime  0.343 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.6473 (0.6728)\tD(fake)1 0.2068 (0.3114)\tD(fake)2 0.2889 (0.2543)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1393 (-0.1585)\n",
            "Epoch: [4][ 20/195]\tTime  0.348 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7256 (0.6961)\tD(fake)1 0.3298 (0.3049)\tD(fake)2 0.1623 (0.2303)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1420 (-0.1598)\n",
            "Epoch: [4][ 30/195]\tTime  0.343 ( 0.355)\tData  0.000 ( 0.007)\tD(real) 0.7024 (0.6866)\tD(fake)1 0.3388 (0.3138)\tD(fake)2 0.2826 (0.2436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1588)\n",
            "Epoch: [4][ 40/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6541 (0.6889)\tD(fake)1 0.3054 (0.3122)\tD(fake)2 0.2382 (0.2399)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1444 (-0.1568)\n",
            "Epoch: [4][ 50/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7336 (0.6908)\tD(fake)1 0.3648 (0.3080)\tD(fake)2 0.1788 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1563)\n",
            "Epoch: [4][ 60/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.004)\tD(real) 0.6966 (0.6951)\tD(fake)1 0.2189 (0.3046)\tD(fake)2 0.2150 (0.2309)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1562)\n",
            "Epoch: [4][ 70/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7775 (0.7028)\tD(fake)1 0.2827 (0.2973)\tD(fake)2 0.2442 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1564)\n",
            "Epoch: [4][ 80/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7679 (0.7104)\tD(fake)1 0.2823 (0.2919)\tD(fake)2 0.1204 (0.2195)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1566)\n",
            "Epoch: [4][ 90/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.003)\tD(real) 0.6390 (0.7045)\tD(fake)1 0.3371 (0.2962)\tD(fake)2 0.2558 (0.2254)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1564)\n",
            "Epoch: [4][100/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6022 (0.7016)\tD(fake)1 0.1868 (0.2977)\tD(fake)2 0.3895 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1568)\n",
            "Epoch: [4][110/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5917 (0.6986)\tD(fake)1 0.3062 (0.3010)\tD(fake)2 0.3173 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1573)\n",
            "Epoch: [4][120/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6930 (0.6991)\tD(fake)1 0.3211 (0.3014)\tD(fake)2 0.1734 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1568)\n",
            "Epoch: [4][130/195]\tTime  0.345 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7275 (0.6980)\tD(fake)1 0.2719 (0.3016)\tD(fake)2 0.1652 (0.2284)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1568)\n",
            "Epoch: [4][140/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6837 (0.7011)\tD(fake)1 0.2221 (0.2982)\tD(fake)2 0.2449 (0.2256)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1343 (-0.1568)\n",
            "Epoch: [4][150/195]\tTime  0.349 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.8584 (0.7037)\tD(fake)1 0.3349 (0.2971)\tD(fake)2 0.1098 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1576)\n",
            "Epoch: [4][160/195]\tTime  0.346 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.4286 (0.7059)\tD(fake)1 0.0336 (0.2942)\tD(fake)2 0.1708 (0.2213)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1391 (-0.1579)\n",
            "Epoch: [4][170/195]\tTime  0.348 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6631 (0.7030)\tD(fake)1 0.2862 (0.2962)\tD(fake)2 0.2391 (0.2242)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1579)\n",
            "Epoch: [4][180/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6685 (0.7038)\tD(fake)1 0.1814 (0.2960)\tD(fake)2 0.3546 (0.2233)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1582)\n",
            "Epoch: [4][190/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6708 (0.7033)\tD(fake)1 0.3084 (0.2967)\tD(fake)2 0.2075 (0.2221)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1582)\n",
            "Epoch: [5][  0/195]\tTime  0.605 ( 0.605)\tData  0.205 ( 0.205)\tD(real) 0.5959 (0.5959)\tD(fake)1 0.2690 (0.2690)\tD(fake)2 0.3227 (0.3227)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1525 (-0.1525)\n",
            "Epoch: [5][ 10/195]\tTime  0.352 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.4869 (0.6581)\tD(fake)1 0.0863 (0.3078)\tD(fake)2 0.4478 (0.2473)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1450)\n",
            "Epoch: [5][ 20/195]\tTime  0.348 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7944 (0.6837)\tD(fake)1 0.2932 (0.3087)\tD(fake)2 0.1428 (0.2268)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1559 (-0.1526)\n",
            "Epoch: [5][ 30/195]\tTime  0.353 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6153 (0.6873)\tD(fake)1 0.2693 (0.3091)\tD(fake)2 0.2283 (0.2262)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1639 (-0.1545)\n",
            "Epoch: [5][ 40/195]\tTime  0.342 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7253 (0.6889)\tD(fake)1 0.2408 (0.3073)\tD(fake)2 0.1853 (0.2241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1058 (-0.1550)\n",
            "Epoch: [5][ 50/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6101 (0.6977)\tD(fake)1 0.2549 (0.2979)\tD(fake)2 0.2787 (0.2185)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1558)\n",
            "Epoch: [5][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7010 (0.6962)\tD(fake)1 0.3420 (0.2996)\tD(fake)2 0.2165 (0.2203)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1563)\n",
            "Epoch: [5][ 70/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8485 (0.6989)\tD(fake)1 0.4146 (0.3015)\tD(fake)2 0.2026 (0.2216)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1600 (-0.1557)\n",
            "Epoch: [5][ 80/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8725 (0.6989)\tD(fake)1 0.4546 (0.3029)\tD(fake)2 -0.0348 (0.2207)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1373 (-0.1551)\n",
            "Epoch: [5][ 90/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7435 (0.6959)\tD(fake)1 0.3479 (0.3021)\tD(fake)2 0.1923 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1553)\n",
            "Epoch: [5][100/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5752 (0.6944)\tD(fake)1 0.2051 (0.3032)\tD(fake)2 0.3464 (0.2263)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1558)\n",
            "Epoch: [5][110/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8547 (0.6968)\tD(fake)1 0.4402 (0.3064)\tD(fake)2 0.0107 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1564)\n",
            "Epoch: [5][120/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6332 (0.6928)\tD(fake)1 0.2559 (0.3071)\tD(fake)2 0.2784 (0.2314)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1561 (-0.1568)\n",
            "Epoch: [5][130/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7594 (0.6946)\tD(fake)1 0.3338 (0.3053)\tD(fake)2 0.2699 (0.2309)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1562)\n",
            "Epoch: [5][140/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9226 (0.6986)\tD(fake)1 0.3684 (0.3029)\tD(fake)2 0.1035 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1566)\n",
            "Epoch: [5][150/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6162 (0.6984)\tD(fake)1 0.3153 (0.3018)\tD(fake)2 0.3195 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1566)\n",
            "Epoch: [5][160/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5903 (0.6966)\tD(fake)1 0.2574 (0.3032)\tD(fake)2 0.3535 (0.2306)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1568)\n",
            "Epoch: [5][170/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.9164 (0.6984)\tD(fake)1 0.4468 (0.3023)\tD(fake)2 0.1541 (0.2296)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1574)\n",
            "Epoch: [5][180/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8755 (0.6994)\tD(fake)1 0.4237 (0.3018)\tD(fake)2 0.0757 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1572)\n",
            "Epoch: [5][190/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8080 (0.7010)\tD(fake)1 0.3938 (0.2997)\tD(fake)2 0.1361 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1577)\n",
            "Epoch: [6][  0/195]\tTime  0.591 ( 0.591)\tData  0.199 ( 0.199)\tD(real) 0.7735 (0.7735)\tD(fake)1 0.2761 (0.2761)\tD(fake)2 0.1249 (0.1249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1672)\n",
            "Epoch: [6][ 10/195]\tTime  0.346 ( 0.370)\tData  0.000 ( 0.018)\tD(real) 0.6452 (0.7340)\tD(fake)1 0.2051 (0.2734)\tD(fake)2 0.2283 (0.1879)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1633)\n",
            "Epoch: [6][ 20/195]\tTime  0.347 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 1.0497 (0.7530)\tD(fake)1 0.5354 (0.2728)\tD(fake)2 0.0441 (0.1825)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1188 (-0.1563)\n",
            "Epoch: [6][ 30/195]\tTime  0.348 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7573 (0.7321)\tD(fake)1 0.2843 (0.2791)\tD(fake)2 0.1612 (0.1967)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1581)\n",
            "Epoch: [6][ 40/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7015 (0.7380)\tD(fake)1 0.1786 (0.2721)\tD(fake)2 0.2658 (0.1970)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1595)\n",
            "Epoch: [6][ 50/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7256 (0.7405)\tD(fake)1 0.3176 (0.2707)\tD(fake)2 0.1950 (0.1950)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1495 (-0.1588)\n",
            "Epoch: [6][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7596 (0.7317)\tD(fake)1 0.3577 (0.2754)\tD(fake)2 0.2057 (0.1957)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1598)\n",
            "Epoch: [6][ 70/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6693 (0.7275)\tD(fake)1 0.2342 (0.2777)\tD(fake)2 0.2953 (0.1980)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1216 (-0.1590)\n",
            "Epoch: [6][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5450 (0.7250)\tD(fake)1 0.2153 (0.2788)\tD(fake)2 0.3124 (0.2009)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1402 (-0.1588)\n",
            "Epoch: [6][ 90/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5282 (0.7199)\tD(fake)1 0.1752 (0.2819)\tD(fake)2 0.3914 (0.2061)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1430 (-0.1581)\n",
            "Epoch: [6][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6133 (0.7192)\tD(fake)1 0.1041 (0.2824)\tD(fake)2 0.2251 (0.2068)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1578)\n",
            "Epoch: [6][110/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7646 (0.7237)\tD(fake)1 0.2143 (0.2790)\tD(fake)2 0.1936 (0.2048)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1396 (-0.1579)\n",
            "Epoch: [6][120/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5792 (0.7288)\tD(fake)1 0.0985 (0.2723)\tD(fake)2 0.4032 (0.2006)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1531 (-0.1582)\n",
            "Epoch: [6][130/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7412 (0.7302)\tD(fake)1 0.2418 (0.2727)\tD(fake)2 0.1838 (0.1993)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1577)\n",
            "Epoch: [6][140/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6805 (0.7300)\tD(fake)1 0.3062 (0.2729)\tD(fake)2 0.2241 (0.1983)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1529 (-0.1577)\n",
            "Epoch: [6][150/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7157 (0.7291)\tD(fake)1 0.2523 (0.2725)\tD(fake)2 0.3276 (0.1972)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1578)\n",
            "Epoch: [6][160/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6278 (0.7297)\tD(fake)1 0.2130 (0.2727)\tD(fake)2 0.2928 (0.1977)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1485 (-0.1577)\n",
            "Epoch: [6][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.5892 (0.7268)\tD(fake)1 0.2626 (0.2758)\tD(fake)2 0.3380 (0.2009)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1550 (-0.1567)\n",
            "Epoch: [6][180/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 1.0091 (0.7288)\tD(fake)1 0.3419 (0.2763)\tD(fake)2 -0.1210 (0.1985)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1568)\n",
            "Epoch: [6][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8271 (0.7326)\tD(fake)1 0.1866 (0.2714)\tD(fake)2 0.1268 (0.1960)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1567)\n",
            "Epoch: [7][  0/195]\tTime  0.603 ( 0.603)\tData  0.222 ( 0.222)\tD(real) 0.6715 (0.6715)\tD(fake)1 0.1120 (0.1120)\tD(fake)2 0.0964 (0.0964)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1328 (-0.1328)\n",
            "Epoch: [7][ 10/195]\tTime  0.343 ( 0.371)\tData  0.000 ( 0.021)\tD(real) 0.7933 (0.7262)\tD(fake)1 0.3283 (0.2598)\tD(fake)2 0.0812 (0.1863)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1561 (-0.1570)\n",
            "Epoch: [7][ 20/195]\tTime  0.346 ( 0.359)\tData  0.000 ( 0.011)\tD(real) 0.6715 (0.7032)\tD(fake)1 0.3504 (0.2765)\tD(fake)2 0.2349 (0.2108)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1589)\n",
            "Epoch: [7][ 30/195]\tTime  0.352 ( 0.355)\tData  0.000 ( 0.008)\tD(real) 0.7205 (0.6978)\tD(fake)1 0.3452 (0.2823)\tD(fake)2 0.3197 (0.2181)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1585)\n",
            "Epoch: [7][ 40/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.6274 (0.7018)\tD(fake)1 0.1379 (0.2841)\tD(fake)2 0.3558 (0.2221)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1598)\n",
            "Epoch: [7][ 50/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.7605 (0.7030)\tD(fake)1 0.3840 (0.2902)\tD(fake)2 0.1832 (0.2224)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1478 (-0.1580)\n",
            "Epoch: [7][ 60/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.6635 (0.7028)\tD(fake)1 0.1829 (0.2879)\tD(fake)2 0.3370 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1580)\n",
            "Epoch: [7][ 70/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7408 (0.7091)\tD(fake)1 0.2538 (0.2838)\tD(fake)2 0.2345 (0.2201)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1569)\n",
            "Epoch: [7][ 80/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.8774 (0.7180)\tD(fake)1 0.2237 (0.2771)\tD(fake)2 0.0628 (0.2129)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1572)\n",
            "Epoch: [7][ 90/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6584 (0.7223)\tD(fake)1 0.3056 (0.2733)\tD(fake)2 0.2462 (0.2095)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1572)\n",
            "Epoch: [7][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7598 (0.7224)\tD(fake)1 0.2750 (0.2747)\tD(fake)2 0.2260 (0.2115)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1574)\n",
            "Epoch: [7][110/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7153 (0.7207)\tD(fake)1 0.3366 (0.2765)\tD(fake)2 0.2007 (0.2119)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1563 (-0.1566)\n",
            "Epoch: [7][120/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8822 (0.7220)\tD(fake)1 0.4469 (0.2765)\tD(fake)2 0.1586 (0.2109)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1570)\n",
            "Epoch: [7][130/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8270 (0.7237)\tD(fake)1 0.3014 (0.2747)\tD(fake)2 0.0756 (0.2091)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1573)\n",
            "Epoch: [7][140/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6676 (0.7229)\tD(fake)1 0.2404 (0.2745)\tD(fake)2 0.2793 (0.2105)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1424 (-0.1575)\n",
            "Epoch: [7][150/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6469 (0.7216)\tD(fake)1 0.2774 (0.2766)\tD(fake)2 0.2927 (0.2123)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1577)\n",
            "Epoch: [7][160/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8092 (0.7241)\tD(fake)1 0.3060 (0.2752)\tD(fake)2 0.2358 (0.2101)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1576)\n",
            "Epoch: [7][170/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.7659 (0.7235)\tD(fake)1 0.4169 (0.2766)\tD(fake)2 0.1898 (0.2106)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1579)\n",
            "Epoch: [7][180/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.002)\tD(real) 0.6124 (0.7211)\tD(fake)1 0.2669 (0.2779)\tD(fake)2 0.3372 (0.2125)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1577)\n",
            "Epoch: [7][190/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.7592 (0.7188)\tD(fake)1 0.3894 (0.2808)\tD(fake)2 0.1898 (0.2145)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1558 (-0.1575)\n",
            "Epoch: [8][  0/195]\tTime  0.617 ( 0.617)\tData  0.213 ( 0.213)\tD(real) 0.7511 (0.7511)\tD(fake)1 0.3529 (0.3529)\tD(fake)2 0.1594 (0.1594)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1267 (-0.1267)\n",
            "Epoch: [8][ 10/195]\tTime  0.345 ( 0.371)\tData  0.000 ( 0.020)\tD(real) 0.6717 (0.6923)\tD(fake)1 0.2359 (0.3105)\tD(fake)2 0.2407 (0.2327)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1539)\n",
            "Epoch: [8][ 20/195]\tTime  0.351 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6306 (0.7017)\tD(fake)1 0.2963 (0.2930)\tD(fake)2 0.3403 (0.2209)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1581)\n",
            "Epoch: [8][ 30/195]\tTime  0.350 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.5660 (0.6965)\tD(fake)1 0.1749 (0.2971)\tD(fake)2 0.3890 (0.2345)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1360 (-0.1564)\n",
            "Epoch: [8][ 40/195]\tTime  0.358 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7481 (0.6970)\tD(fake)1 0.3161 (0.3019)\tD(fake)2 0.2266 (0.2370)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1562)\n",
            "Epoch: [8][ 50/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8840 (0.7019)\tD(fake)1 0.4431 (0.2999)\tD(fake)2 0.0940 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1558)\n",
            "Epoch: [8][ 60/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.4820 (0.7000)\tD(fake)1 0.0569 (0.2944)\tD(fake)2 0.3508 (0.2340)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1568)\n",
            "Epoch: [8][ 70/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7888 (0.7075)\tD(fake)1 0.2724 (0.2928)\tD(fake)2 0.1280 (0.2302)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1573)\n",
            "Epoch: [8][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6492 (0.7092)\tD(fake)1 0.3175 (0.2904)\tD(fake)2 0.1615 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1555 (-0.1576)\n",
            "Epoch: [8][ 90/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7715 (0.7101)\tD(fake)1 0.3071 (0.2885)\tD(fake)2 0.1417 (0.2206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1576)\n",
            "Epoch: [8][100/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8290 (0.7125)\tD(fake)1 0.3044 (0.2869)\tD(fake)2 0.0460 (0.2175)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1569)\n",
            "Epoch: [8][110/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7685 (0.7183)\tD(fake)1 0.1703 (0.2810)\tD(fake)2 0.1821 (0.2136)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1567)\n",
            "Epoch: [8][120/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8587 (0.7250)\tD(fake)1 0.2186 (0.2750)\tD(fake)2 0.1093 (0.2082)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1571)\n",
            "Epoch: [8][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5548 (0.7283)\tD(fake)1 0.2032 (0.2701)\tD(fake)2 0.3329 (0.2043)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1570)\n",
            "Epoch: [8][140/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7463 (0.7254)\tD(fake)1 0.3483 (0.2745)\tD(fake)2 0.1805 (0.2087)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1570)\n",
            "Epoch: [8][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7556 (0.7236)\tD(fake)1 0.3787 (0.2763)\tD(fake)2 0.2117 (0.2109)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1757 (-0.1575)\n",
            "Epoch: [8][160/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7531 (0.7212)\tD(fake)1 0.4044 (0.2787)\tD(fake)2 0.1175 (0.2126)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1578)\n",
            "Epoch: [8][170/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7264 (0.7186)\tD(fake)1 0.3690 (0.2808)\tD(fake)2 0.1615 (0.2149)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1574)\n",
            "Epoch: [8][180/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7945 (0.7168)\tD(fake)1 0.3895 (0.2829)\tD(fake)2 0.0642 (0.2169)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1492 (-0.1572)\n",
            "Epoch: [8][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6809 (0.7150)\tD(fake)1 0.3110 (0.2842)\tD(fake)2 0.2405 (0.2186)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1572)\n",
            "Epoch: [9][  0/195]\tTime  0.588 ( 0.588)\tData  0.204 ( 0.204)\tD(real) 0.8219 (0.8219)\tD(fake)1 0.4605 (0.4605)\tD(fake)2 0.2839 (0.2839)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1264 (-0.1264)\n",
            "Epoch: [9][ 10/195]\tTime  0.346 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.7567 (0.7110)\tD(fake)1 0.2434 (0.3044)\tD(fake)2 0.2025 (0.2230)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1555 (-0.1579)\n",
            "Epoch: [9][ 20/195]\tTime  0.347 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.6578 (0.7078)\tD(fake)1 0.2890 (0.3018)\tD(fake)2 0.2884 (0.2225)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1550)\n",
            "Epoch: [9][ 30/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.8391 (0.7160)\tD(fake)1 0.3435 (0.2969)\tD(fake)2 0.1642 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1148 (-0.1531)\n",
            "Epoch: [9][ 40/195]\tTime  0.343 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7403 (0.7179)\tD(fake)1 0.2859 (0.2893)\tD(fake)2 0.2386 (0.2167)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1530)\n",
            "Epoch: [9][ 50/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7926 (0.7249)\tD(fake)1 0.3580 (0.2851)\tD(fake)2 0.1346 (0.2114)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1564 (-0.1543)\n",
            "Epoch: [9][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6918 (0.7232)\tD(fake)1 0.2308 (0.2834)\tD(fake)2 0.2691 (0.2136)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1543)\n",
            "Epoch: [9][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6592 (0.7210)\tD(fake)1 0.3160 (0.2848)\tD(fake)2 0.2543 (0.2164)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1415 (-0.1541)\n",
            "Epoch: [9][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.9264 (0.7207)\tD(fake)1 0.5023 (0.2860)\tD(fake)2 0.0746 (0.2160)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1549)\n",
            "Epoch: [9][ 90/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7262 (0.7213)\tD(fake)1 0.2156 (0.2806)\tD(fake)2 0.1893 (0.2113)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1554)\n",
            "Epoch: [9][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6190 (0.7266)\tD(fake)1 0.1065 (0.2739)\tD(fake)2 0.4319 (0.2064)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1559)\n",
            "Epoch: [9][110/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7313 (0.7254)\tD(fake)1 0.3075 (0.2787)\tD(fake)2 0.2270 (0.2108)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1556)\n",
            "Epoch: [9][120/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 1.0302 (0.7283)\tD(fake)1 0.6084 (0.2795)\tD(fake)2 -0.1703 (0.2089)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1554)\n",
            "Epoch: [9][130/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6339 (0.7219)\tD(fake)1 0.3007 (0.2810)\tD(fake)2 0.3022 (0.2153)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1557)\n",
            "Epoch: [9][140/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 1.0119 (0.7242)\tD(fake)1 0.4248 (0.2816)\tD(fake)2 -0.0029 (0.2145)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1470 (-0.1552)\n",
            "Epoch: [9][150/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7627 (0.7213)\tD(fake)1 0.4402 (0.2821)\tD(fake)2 0.1532 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1408 (-0.1551)\n",
            "Epoch: [9][160/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8265 (0.7203)\tD(fake)1 0.4186 (0.2829)\tD(fake)2 0.1297 (0.2167)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1552)\n",
            "Epoch: [9][170/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7219 (0.7183)\tD(fake)1 0.3248 (0.2845)\tD(fake)2 0.2301 (0.2196)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1412 (-0.1550)\n",
            "Epoch: [9][180/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6930 (0.7177)\tD(fake)1 0.3350 (0.2854)\tD(fake)2 0.2932 (0.2204)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1509 (-0.1549)\n",
            "Epoch: [9][190/195]\tTime  0.343 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.8387 (0.7173)\tD(fake)1 0.3793 (0.2863)\tD(fake)2 0.1984 (0.2216)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1550)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iepY_Go7tf7Y",
        "outputId": "7f1fefa2-05e3-42f3-b4c8-dfa3fdb982ab"
      },
      "source": [
        "run(10)\n",
        "save_vid()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.610 ( 0.610)\tData  0.212 ( 0.212)\tD(real) 0.8702 (0.8702)\tD(fake)1 0.3793 (0.3793)\tD(fake)2 0.0475 (0.0475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1548 (-0.1548)\n",
            "Epoch: [0][ 10/195]\tTime  0.347 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.5910 (0.7268)\tD(fake)1 0.0252 (0.2543)\tD(fake)2 0.3492 (0.1926)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1553 (-0.1541)\n",
            "Epoch: [0][ 20/195]\tTime  0.345 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6608 (0.7319)\tD(fake)1 0.2380 (0.2673)\tD(fake)2 0.2762 (0.1980)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1576)\n",
            "Epoch: [0][ 30/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7220 (0.7311)\tD(fake)1 0.2631 (0.2692)\tD(fake)2 0.2391 (0.2008)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1550 (-0.1577)\n",
            "Epoch: [0][ 40/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6980 (0.7303)\tD(fake)1 0.3085 (0.2730)\tD(fake)2 0.2466 (0.2047)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1415 (-0.1561)\n",
            "Epoch: [0][ 50/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.5845 (0.7168)\tD(fake)1 0.3625 (0.2891)\tD(fake)2 0.3282 (0.2213)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1452 (-0.1555)\n",
            "Epoch: [0][ 60/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8590 (0.7195)\tD(fake)1 0.4111 (0.2899)\tD(fake)2 0.0322 (0.2204)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1451 (-0.1544)\n",
            "Epoch: [0][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6608 (0.7109)\tD(fake)1 0.3282 (0.2933)\tD(fake)2 0.2568 (0.2268)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1550 (-0.1556)\n",
            "Epoch: [0][ 80/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5809 (0.7035)\tD(fake)1 0.2223 (0.2980)\tD(fake)2 0.3267 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1563)\n",
            "Epoch: [0][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7297 (0.7044)\tD(fake)1 0.2539 (0.2978)\tD(fake)2 0.2038 (0.2335)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1510 (-0.1560)\n",
            "Epoch: [0][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7021 (0.7069)\tD(fake)1 0.2956 (0.2961)\tD(fake)2 0.2070 (0.2321)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1563)\n",
            "Epoch: [0][110/195]\tTime  0.341 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7116 (0.7098)\tD(fake)1 0.2348 (0.2932)\tD(fake)2 0.2297 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1568)\n",
            "Epoch: [0][120/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6832 (0.7078)\tD(fake)1 0.2940 (0.2945)\tD(fake)2 0.1861 (0.2290)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1562)\n",
            "Epoch: [0][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8195 (0.7090)\tD(fake)1 0.3232 (0.2923)\tD(fake)2 0.2024 (0.2280)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1559 (-0.1564)\n",
            "Epoch: [0][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8170 (0.7116)\tD(fake)1 0.3684 (0.2907)\tD(fake)2 0.0693 (0.2258)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1488 (-0.1561)\n",
            "Epoch: [0][150/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7953 (0.7114)\tD(fake)1 0.2788 (0.2908)\tD(fake)2 0.1108 (0.2262)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1557 (-0.1557)\n",
            "Epoch: [0][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7799 (0.7166)\tD(fake)1 0.2553 (0.2860)\tD(fake)2 0.1058 (0.2219)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1295 (-0.1558)\n",
            "Epoch: [0][170/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8217 (0.7187)\tD(fake)1 0.3324 (0.2842)\tD(fake)2 0.1468 (0.2206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1561)\n",
            "Epoch: [0][180/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.5915 (0.7170)\tD(fake)1 0.2843 (0.2845)\tD(fake)2 0.2730 (0.2210)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1344 (-0.1559)\n",
            "Epoch: [0][190/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7235 (0.7163)\tD(fake)1 0.3107 (0.2847)\tD(fake)2 0.2310 (0.2212)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1557)\n",
            "Epoch: [1][  0/195]\tTime  0.610 ( 0.610)\tData  0.207 ( 0.207)\tD(real) 0.7677 (0.7677)\tD(fake)1 0.3481 (0.3481)\tD(fake)2 0.1601 (0.1601)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1569)\n",
            "Epoch: [1][ 10/195]\tTime  0.343 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.8032 (0.7162)\tD(fake)1 0.3442 (0.2988)\tD(fake)2 0.1545 (0.2377)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1132 (-0.1494)\n",
            "Epoch: [1][ 20/195]\tTime  0.355 ( 0.364)\tData  0.000 ( 0.010)\tD(real) 0.6395 (0.7249)\tD(fake)1 0.2719 (0.2751)\tD(fake)2 0.4088 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1223 (-0.1487)\n",
            "Epoch: [1][ 30/195]\tTime  0.344 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.7335 (0.7089)\tD(fake)1 0.4060 (0.3008)\tD(fake)2 0.2570 (0.2474)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1753 (-0.1506)\n",
            "Epoch: [1][ 40/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7301 (0.6977)\tD(fake)1 0.4198 (0.3093)\tD(fake)2 0.2188 (0.2547)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1543 (-0.1532)\n",
            "Epoch: [1][ 50/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6137 (0.6926)\tD(fake)1 0.1959 (0.3071)\tD(fake)2 0.3728 (0.2582)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1523)\n",
            "Epoch: [1][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8254 (0.6954)\tD(fake)1 0.3978 (0.3061)\tD(fake)2 0.2057 (0.2546)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1531)\n",
            "Epoch: [1][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5638 (0.7001)\tD(fake)1 0.1641 (0.3008)\tD(fake)2 0.2142 (0.2498)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1546)\n",
            "Epoch: [1][ 80/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7962 (0.7038)\tD(fake)1 0.3588 (0.3006)\tD(fake)2 0.1805 (0.2491)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1579 (-0.1549)\n",
            "Epoch: [1][ 90/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5657 (0.7041)\tD(fake)1 0.1452 (0.2970)\tD(fake)2 0.3248 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1547)\n",
            "Epoch: [1][100/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7045 (0.7047)\tD(fake)1 0.3465 (0.2965)\tD(fake)2 0.2859 (0.2431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1551)\n",
            "Epoch: [1][110/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7425 (0.7046)\tD(fake)1 0.2792 (0.2966)\tD(fake)2 0.1508 (0.2416)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1537 (-0.1548)\n",
            "Epoch: [1][120/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8031 (0.7083)\tD(fake)1 0.3158 (0.2928)\tD(fake)2 0.2115 (0.2392)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0784 (-0.1544)\n",
            "Epoch: [1][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6241 (0.7105)\tD(fake)1 0.1647 (0.2897)\tD(fake)2 0.3081 (0.2363)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1545)\n",
            "Epoch: [1][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6326 (0.7140)\tD(fake)1 0.1996 (0.2872)\tD(fake)2 0.2778 (0.2333)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1304 (-0.1545)\n",
            "Epoch: [1][150/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5647 (0.7144)\tD(fake)1 0.1112 (0.2864)\tD(fake)2 0.3961 (0.2327)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1559 (-0.1540)\n",
            "Epoch: [1][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7656 (0.7144)\tD(fake)1 0.2724 (0.2871)\tD(fake)2 0.1397 (0.2317)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1539)\n",
            "Epoch: [1][170/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6262 (0.7163)\tD(fake)1 0.2308 (0.2848)\tD(fake)2 0.2615 (0.2298)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1399 (-0.1539)\n",
            "Epoch: [1][180/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8624 (0.7167)\tD(fake)1 0.3635 (0.2855)\tD(fake)2 -0.0010 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1539)\n",
            "Epoch: [1][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7194 (0.7163)\tD(fake)1 0.3113 (0.2853)\tD(fake)2 0.2438 (0.2307)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1254 (-0.1533)\n",
            "Epoch: [2][  0/195]\tTime  0.601 ( 0.601)\tData  0.209 ( 0.209)\tD(real) 0.4433 (0.4433)\tD(fake)1 0.0363 (0.0363)\tD(fake)2 0.4780 (0.4780)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1618)\n",
            "Epoch: [2][ 10/195]\tTime  0.346 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.8061 (0.6828)\tD(fake)1 0.3753 (0.3177)\tD(fake)2 0.1114 (0.2672)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1590)\n",
            "Epoch: [2][ 20/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7096 (0.6863)\tD(fake)1 0.2456 (0.3033)\tD(fake)2 0.2390 (0.2543)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1352 (-0.1527)\n",
            "Epoch: [2][ 30/195]\tTime  0.344 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7145 (0.7050)\tD(fake)1 0.2674 (0.2882)\tD(fake)2 0.2469 (0.2365)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1546)\n",
            "Epoch: [2][ 40/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.5883 (0.7142)\tD(fake)1 0.0442 (0.2772)\tD(fake)2 0.2880 (0.2265)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1549 (-0.1536)\n",
            "Epoch: [2][ 50/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.9329 (0.7253)\tD(fake)1 0.4529 (0.2758)\tD(fake)2 0.0012 (0.2171)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1574 (-0.1541)\n",
            "Epoch: [2][ 60/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.6811 (0.7200)\tD(fake)1 0.2635 (0.2761)\tD(fake)2 0.2808 (0.2208)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0844 (-0.1525)\n",
            "Epoch: [2][ 70/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7488 (0.7174)\tD(fake)1 0.3826 (0.2798)\tD(fake)2 0.2666 (0.2227)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1382 (-0.1531)\n",
            "Epoch: [2][ 80/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9629 (0.7187)\tD(fake)1 0.4517 (0.2820)\tD(fake)2 -0.0164 (0.2220)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1536)\n",
            "Epoch: [2][ 90/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6432 (0.7179)\tD(fake)1 0.2112 (0.2798)\tD(fake)2 0.3043 (0.2231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1716 (-0.1544)\n",
            "Epoch: [2][100/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.4900 (0.7195)\tD(fake)1 0.1942 (0.2792)\tD(fake)2 0.1787 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1553)\n",
            "Epoch: [2][110/195]\tTime  0.352 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7244 (0.7146)\tD(fake)1 0.2131 (0.2829)\tD(fake)2 0.1817 (0.2201)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1553)\n",
            "Epoch: [2][120/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7349 (0.7154)\tD(fake)1 0.3075 (0.2827)\tD(fake)2 0.2379 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1118 (-0.1557)\n",
            "Epoch: [2][130/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7278 (0.7127)\tD(fake)1 0.3510 (0.2863)\tD(fake)2 0.2405 (0.2224)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1523 (-0.1555)\n",
            "Epoch: [2][140/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8404 (0.7152)\tD(fake)1 0.2870 (0.2838)\tD(fake)2 0.1624 (0.2208)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1424 (-0.1551)\n",
            "Epoch: [2][150/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6415 (0.7178)\tD(fake)1 0.1663 (0.2819)\tD(fake)2 0.1590 (0.2183)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1552)\n",
            "Epoch: [2][160/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6488 (0.7205)\tD(fake)1 0.2162 (0.2797)\tD(fake)2 0.2375 (0.2165)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1552)\n",
            "Epoch: [2][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5244 (0.7162)\tD(fake)1 0.2122 (0.2821)\tD(fake)2 0.2980 (0.2183)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1719 (-0.1557)\n",
            "Epoch: [2][180/195]\tTime  0.344 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6131 (0.7143)\tD(fake)1 0.2199 (0.2833)\tD(fake)2 0.2865 (0.2191)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1554 (-0.1558)\n",
            "Epoch: [2][190/195]\tTime  0.347 ( 0.348)\tData  0.000 ( 0.001)\tD(real) 0.6938 (0.7149)\tD(fake)1 0.3210 (0.2836)\tD(fake)2 0.1838 (0.2192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1561)\n",
            "Epoch: [3][  0/195]\tTime  0.591 ( 0.591)\tData  0.201 ( 0.201)\tD(real) 0.6936 (0.6936)\tD(fake)1 0.3463 (0.3463)\tD(fake)2 0.2462 (0.2462)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1665)\n",
            "Epoch: [3][ 10/195]\tTime  0.347 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.9493 (0.7990)\tD(fake)1 0.2530 (0.2254)\tD(fake)2 0.0114 (0.1535)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1563)\n",
            "Epoch: [3][ 20/195]\tTime  0.351 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7752 (0.8101)\tD(fake)1 0.2410 (0.2014)\tD(fake)2 0.1288 (0.1465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1577)\n",
            "Epoch: [3][ 30/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6711 (0.7819)\tD(fake)1 0.1914 (0.2197)\tD(fake)2 0.4315 (0.1664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1604)\n",
            "Epoch: [3][ 40/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6874 (0.7579)\tD(fake)1 0.3058 (0.2404)\tD(fake)2 0.2513 (0.1806)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1609)\n",
            "Epoch: [3][ 50/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6488 (0.7461)\tD(fake)1 0.1470 (0.2481)\tD(fake)2 0.2693 (0.1847)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1615)\n",
            "Epoch: [3][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8434 (0.7526)\tD(fake)1 0.2357 (0.2450)\tD(fake)2 0.1094 (0.1816)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1489 (-0.1600)\n",
            "Epoch: [3][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7984 (0.7536)\tD(fake)1 0.2470 (0.2464)\tD(fake)2 0.1596 (0.1838)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1374 (-0.1585)\n",
            "Epoch: [3][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.9834 (0.7545)\tD(fake)1 0.6170 (0.2490)\tD(fake)2 0.1301 (0.1856)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1311 (-0.1580)\n",
            "Epoch: [3][ 90/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6529 (0.7412)\tD(fake)1 0.2743 (0.2558)\tD(fake)2 0.2385 (0.1928)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1552 (-0.1574)\n",
            "Epoch: [3][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6137 (0.7353)\tD(fake)1 0.2364 (0.2629)\tD(fake)2 0.3754 (0.2004)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1314 (-0.1575)\n",
            "Epoch: [3][110/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7435 (0.7294)\tD(fake)1 0.3790 (0.2696)\tD(fake)2 0.0838 (0.2047)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1578)\n",
            "Epoch: [3][120/195]\tTime  0.355 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6133 (0.7235)\tD(fake)1 0.2719 (0.2732)\tD(fake)2 0.3060 (0.2096)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1582)\n",
            "Epoch: [3][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7499 (0.7212)\tD(fake)1 0.2718 (0.2760)\tD(fake)2 0.1100 (0.2113)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1578)\n",
            "Epoch: [3][140/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7971 (0.7236)\tD(fake)1 0.2257 (0.2734)\tD(fake)2 0.1385 (0.2099)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1579)\n",
            "Epoch: [3][150/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6908 (0.7216)\tD(fake)1 0.4199 (0.2765)\tD(fake)2 0.2962 (0.2128)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1576)\n",
            "Epoch: [3][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9478 (0.7225)\tD(fake)1 0.3637 (0.2782)\tD(fake)2 0.0241 (0.2133)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1581)\n",
            "Epoch: [3][170/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.4874 (0.7217)\tD(fake)1 0.0958 (0.2767)\tD(fake)2 0.3282 (0.2128)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1215 (-0.1574)\n",
            "Epoch: [3][180/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8793 (0.7223)\tD(fake)1 0.4484 (0.2779)\tD(fake)2 0.0360 (0.2126)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1577)\n",
            "Epoch: [3][190/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7147 (0.7211)\tD(fake)1 0.2046 (0.2779)\tD(fake)2 0.2470 (0.2142)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1498 (-0.1574)\n",
            "Epoch: [4][  0/195]\tTime  0.613 ( 0.613)\tData  0.214 ( 0.214)\tD(real) 0.9121 (0.9121)\tD(fake)1 0.5028 (0.5028)\tD(fake)2 0.2101 (0.2101)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1688)\n",
            "Epoch: [4][ 10/195]\tTime  0.346 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.6584 (0.7181)\tD(fake)1 0.2826 (0.3247)\tD(fake)2 0.2918 (0.2530)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1583)\n",
            "Epoch: [4][ 20/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.011)\tD(real) 0.6289 (0.6975)\tD(fake)1 0.2584 (0.3165)\tD(fake)2 0.2956 (0.2503)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1549)\n",
            "Epoch: [4][ 30/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.5635 (0.6993)\tD(fake)1 0.1058 (0.3009)\tD(fake)2 0.4418 (0.2388)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1564)\n",
            "Epoch: [4][ 40/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.7225 (0.7049)\tD(fake)1 0.2587 (0.2990)\tD(fake)2 0.2089 (0.2334)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1559)\n",
            "Epoch: [4][ 50/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.8134 (0.7123)\tD(fake)1 0.3900 (0.2941)\tD(fake)2 0.1714 (0.2285)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1567)\n",
            "Epoch: [4][ 60/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6722 (0.7085)\tD(fake)1 0.2194 (0.2953)\tD(fake)2 0.3205 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1583)\n",
            "Epoch: [4][ 70/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8207 (0.7140)\tD(fake)1 0.3391 (0.2916)\tD(fake)2 0.2044 (0.2295)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1591)\n",
            "Epoch: [4][ 80/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.9233 (0.7215)\tD(fake)1 0.3373 (0.2837)\tD(fake)2 0.1293 (0.2210)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1589)\n",
            "Epoch: [4][ 90/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6949 (0.7218)\tD(fake)1 0.2794 (0.2815)\tD(fake)2 0.1930 (0.2194)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1594)\n",
            "Epoch: [4][100/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8190 (0.7181)\tD(fake)1 0.5084 (0.2860)\tD(fake)2 0.0867 (0.2219)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1604)\n",
            "Epoch: [4][110/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8429 (0.7159)\tD(fake)1 0.3581 (0.2872)\tD(fake)2 0.0810 (0.2230)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1348 (-0.1602)\n",
            "Epoch: [4][120/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7184 (0.7127)\tD(fake)1 0.4181 (0.2894)\tD(fake)2 0.2205 (0.2252)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1600)\n",
            "Epoch: [4][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6054 (0.7114)\tD(fake)1 0.0602 (0.2887)\tD(fake)2 0.4403 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1605 (-0.1600)\n",
            "Epoch: [4][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7434 (0.7127)\tD(fake)1 0.3406 (0.2892)\tD(fake)2 0.2042 (0.2268)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1603)\n",
            "Epoch: [4][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5960 (0.7120)\tD(fake)1 0.2348 (0.2896)\tD(fake)2 0.2835 (0.2278)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1594)\n",
            "Epoch: [4][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9186 (0.7135)\tD(fake)1 0.4778 (0.2903)\tD(fake)2 0.1422 (0.2270)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1596)\n",
            "Epoch: [4][170/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6965 (0.7126)\tD(fake)1 0.3463 (0.2896)\tD(fake)2 0.1845 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1595)\n",
            "Epoch: [4][180/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6389 (0.7097)\tD(fake)1 0.2408 (0.2915)\tD(fake)2 0.2977 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1595)\n",
            "Epoch: [4][190/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7676 (0.7100)\tD(fake)1 0.3129 (0.2913)\tD(fake)2 0.1723 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1596)\n",
            "Epoch: [5][  0/195]\tTime  0.608 ( 0.608)\tData  0.213 ( 0.213)\tD(real) 0.6852 (0.6852)\tD(fake)1 0.2764 (0.2764)\tD(fake)2 0.1575 (0.1575)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1657)\n",
            "Epoch: [5][ 10/195]\tTime  0.346 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.8115 (0.7062)\tD(fake)1 0.3726 (0.2952)\tD(fake)2 0.1263 (0.2282)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.1606)\n",
            "Epoch: [5][ 20/195]\tTime  0.344 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7597 (0.7211)\tD(fake)1 0.1674 (0.2817)\tD(fake)2 0.1926 (0.2166)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1580)\n",
            "Epoch: [5][ 30/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7653 (0.7433)\tD(fake)1 0.3360 (0.2621)\tD(fake)2 0.2347 (0.1999)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1582)\n",
            "Epoch: [5][ 40/195]\tTime  0.354 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6408 (0.7316)\tD(fake)1 0.1585 (0.2650)\tD(fake)2 0.4023 (0.2043)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1586)\n",
            "Epoch: [5][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7364 (0.7298)\tD(fake)1 0.2950 (0.2707)\tD(fake)2 0.2424 (0.2076)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1589)\n",
            "Epoch: [5][ 60/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7565 (0.7273)\tD(fake)1 0.3651 (0.2741)\tD(fake)2 0.2069 (0.2122)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1591)\n",
            "Epoch: [5][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6857 (0.7256)\tD(fake)1 0.3374 (0.2736)\tD(fake)2 0.3693 (0.2142)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1588)\n",
            "Epoch: [5][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6375 (0.7213)\tD(fake)1 0.1940 (0.2773)\tD(fake)2 0.4048 (0.2191)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1588)\n",
            "Epoch: [5][ 90/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6980 (0.7190)\tD(fake)1 0.2694 (0.2801)\tD(fake)2 0.2441 (0.2202)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1591)\n",
            "Epoch: [5][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5955 (0.7158)\tD(fake)1 0.2802 (0.2834)\tD(fake)2 0.3345 (0.2227)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1328 (-0.1584)\n",
            "Epoch: [5][110/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7230 (0.7183)\tD(fake)1 0.2320 (0.2813)\tD(fake)2 0.2745 (0.2200)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1573)\n",
            "Epoch: [5][120/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6113 (0.7172)\tD(fake)1 0.3123 (0.2818)\tD(fake)2 0.3376 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1488 (-0.1569)\n",
            "Epoch: [5][130/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6764 (0.7151)\tD(fake)1 0.1717 (0.2835)\tD(fake)2 0.2758 (0.2213)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1568)\n",
            "Epoch: [5][140/195]\tTime  0.356 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7710 (0.7173)\tD(fake)1 0.3765 (0.2831)\tD(fake)2 0.1450 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1131 (-0.1559)\n",
            "Epoch: [5][150/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7566 (0.7168)\tD(fake)1 0.2487 (0.2831)\tD(fake)2 0.1770 (0.2207)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1552 (-0.1553)\n",
            "Epoch: [5][160/195]\tTime  0.354 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7315 (0.7198)\tD(fake)1 0.2637 (0.2810)\tD(fake)2 0.2500 (0.2187)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1544 (-0.1548)\n",
            "Epoch: [5][170/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8848 (0.7242)\tD(fake)1 0.2928 (0.2779)\tD(fake)2 0.1165 (0.2154)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1486 (-0.1543)\n",
            "Epoch: [5][180/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6600 (0.7246)\tD(fake)1 0.2854 (0.2758)\tD(fake)2 0.3951 (0.2149)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1296 (-0.1537)\n",
            "Epoch: [5][190/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6793 (0.7220)\tD(fake)1 0.2628 (0.2782)\tD(fake)2 0.2319 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1319 (-0.1536)\n",
            "Epoch: [6][  0/195]\tTime  0.588 ( 0.588)\tData  0.205 ( 0.205)\tD(real) 0.8051 (0.8051)\tD(fake)1 0.4705 (0.4705)\tD(fake)2 0.1587 (0.1587)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1646)\n",
            "Epoch: [6][ 10/195]\tTime  0.346 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.9212 (0.7177)\tD(fake)1 0.3312 (0.3063)\tD(fake)2 -0.0658 (0.1983)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1491)\n",
            "Epoch: [6][ 20/195]\tTime  0.348 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.5433 (0.7123)\tD(fake)1 0.2330 (0.2852)\tD(fake)2 0.3445 (0.2056)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1097 (-0.1478)\n",
            "Epoch: [6][ 30/195]\tTime  0.346 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.5446 (0.7034)\tD(fake)1 0.1663 (0.2951)\tD(fake)2 0.3013 (0.2177)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1516 (-0.1511)\n",
            "Epoch: [6][ 40/195]\tTime  0.353 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7688 (0.7020)\tD(fake)1 0.4086 (0.3042)\tD(fake)2 0.1279 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1439 (-0.1484)\n",
            "Epoch: [6][ 50/195]\tTime  0.352 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7466 (0.7052)\tD(fake)1 0.2594 (0.3044)\tD(fake)2 0.1580 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1509)\n",
            "Epoch: [6][ 60/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6908 (0.7107)\tD(fake)1 0.2746 (0.2973)\tD(fake)2 0.2282 (0.2236)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1518)\n",
            "Epoch: [6][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5691 (0.7095)\tD(fake)1 0.2320 (0.2962)\tD(fake)2 0.1842 (0.2232)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1421 (-0.1516)\n",
            "Epoch: [6][ 80/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6778 (0.7016)\tD(fake)1 0.2723 (0.3002)\tD(fake)2 0.2291 (0.2265)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1519)\n",
            "Epoch: [6][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7757 (0.7069)\tD(fake)1 0.2653 (0.2958)\tD(fake)2 0.1861 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1517)\n",
            "Epoch: [6][100/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7605 (0.7112)\tD(fake)1 0.2789 (0.2913)\tD(fake)2 0.2209 (0.2195)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1516)\n",
            "Epoch: [6][110/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7457 (0.7150)\tD(fake)1 0.2805 (0.2880)\tD(fake)2 0.2492 (0.2181)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1366 (-0.1519)\n",
            "Epoch: [6][120/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7466 (0.7148)\tD(fake)1 0.2866 (0.2878)\tD(fake)2 0.1689 (0.2172)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1527)\n",
            "Epoch: [6][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6378 (0.7137)\tD(fake)1 0.3188 (0.2887)\tD(fake)2 0.3301 (0.2190)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1529)\n",
            "Epoch: [6][140/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7580 (0.7122)\tD(fake)1 0.3205 (0.2897)\tD(fake)2 0.1473 (0.2199)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1427 (-0.1531)\n",
            "Epoch: [6][150/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6063 (0.7113)\tD(fake)1 0.2583 (0.2895)\tD(fake)2 0.3805 (0.2216)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1529)\n",
            "Epoch: [6][160/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7202 (0.7105)\tD(fake)1 0.2365 (0.2904)\tD(fake)2 0.2851 (0.2232)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1749 (-0.1532)\n",
            "Epoch: [6][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6643 (0.7104)\tD(fake)1 0.2628 (0.2903)\tD(fake)2 0.2777 (0.2243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1535)\n",
            "Epoch: [6][180/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6402 (0.7111)\tD(fake)1 0.1985 (0.2889)\tD(fake)2 0.4099 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1536)\n",
            "Epoch: [6][190/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7578 (0.7104)\tD(fake)1 0.3963 (0.2909)\tD(fake)2 0.2201 (0.2268)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1536)\n",
            "Epoch: [7][  0/195]\tTime  0.602 ( 0.602)\tData  0.203 ( 0.203)\tD(real) 0.7421 (0.7421)\tD(fake)1 0.3558 (0.3558)\tD(fake)2 0.1967 (0.1967)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1666)\n",
            "Epoch: [7][ 10/195]\tTime  0.349 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.7655 (0.6988)\tD(fake)1 0.2945 (0.2979)\tD(fake)2 0.1479 (0.2377)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1495 (-0.1593)\n",
            "Epoch: [7][ 20/195]\tTime  0.345 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.5758 (0.7064)\tD(fake)1 0.2184 (0.2881)\tD(fake)2 0.3475 (0.2387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1619)\n",
            "Epoch: [7][ 30/195]\tTime  0.353 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.8857 (0.7144)\tD(fake)1 0.3558 (0.2917)\tD(fake)2 0.1224 (0.2349)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1414 (-0.1607)\n",
            "Epoch: [7][ 40/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7066 (0.7080)\tD(fake)1 0.2668 (0.2963)\tD(fake)2 0.2462 (0.2391)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1557 (-0.1602)\n",
            "Epoch: [7][ 50/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6076 (0.7196)\tD(fake)1 0.1594 (0.2842)\tD(fake)2 0.2681 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1463 (-0.1600)\n",
            "Epoch: [7][ 60/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7186 (0.7164)\tD(fake)1 0.3020 (0.2855)\tD(fake)2 0.3141 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1590)\n",
            "Epoch: [7][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8443 (0.7177)\tD(fake)1 0.4117 (0.2876)\tD(fake)2 0.0814 (0.2273)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1587)\n",
            "Epoch: [7][ 80/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6865 (0.7165)\tD(fake)1 0.1411 (0.2858)\tD(fake)2 0.2500 (0.2277)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1591)\n",
            "Epoch: [7][ 90/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7317 (0.7215)\tD(fake)1 0.3151 (0.2818)\tD(fake)2 0.2111 (0.2228)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1594)\n",
            "Epoch: [7][100/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7993 (0.7246)\tD(fake)1 0.2957 (0.2798)\tD(fake)2 0.1763 (0.2208)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1555 (-0.1589)\n",
            "Epoch: [7][110/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6093 (0.7241)\tD(fake)1 0.2761 (0.2790)\tD(fake)2 0.2446 (0.2197)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1589)\n",
            "Epoch: [7][120/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6329 (0.7214)\tD(fake)1 0.1750 (0.2801)\tD(fake)2 0.2986 (0.2208)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1588)\n",
            "Epoch: [7][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6365 (0.7220)\tD(fake)1 0.1902 (0.2792)\tD(fake)2 0.3549 (0.2196)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1152 (-0.1575)\n",
            "Epoch: [7][140/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6646 (0.7206)\tD(fake)1 0.2557 (0.2810)\tD(fake)2 0.3316 (0.2205)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1572)\n",
            "Epoch: [7][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7794 (0.7209)\tD(fake)1 0.3563 (0.2828)\tD(fake)2 0.1807 (0.2205)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1571)\n",
            "Epoch: [7][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7586 (0.7243)\tD(fake)1 0.2373 (0.2797)\tD(fake)2 0.2173 (0.2184)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1569)\n",
            "Epoch: [7][170/195]\tTime  0.348 ( 0.350)\tData  0.001 ( 0.002)\tD(real) 0.6019 (0.7225)\tD(fake)1 0.3083 (0.2807)\tD(fake)2 0.2956 (0.2194)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1572)\n",
            "Epoch: [7][180/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7773 (0.7205)\tD(fake)1 0.3635 (0.2820)\tD(fake)2 0.1486 (0.2202)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1570)\n",
            "Epoch: [7][190/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7977 (0.7195)\tD(fake)1 0.3932 (0.2833)\tD(fake)2 0.1445 (0.2216)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1574)\n",
            "Epoch: [8][  0/195]\tTime  0.605 ( 0.605)\tData  0.204 ( 0.204)\tD(real) 0.6944 (0.6944)\tD(fake)1 0.1759 (0.1759)\tD(fake)2 0.2778 (0.2778)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1661)\n",
            "Epoch: [8][ 10/195]\tTime  0.352 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.6435 (0.7450)\tD(fake)1 0.2312 (0.2537)\tD(fake)2 0.3603 (0.1894)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1657)\n",
            "Epoch: [8][ 20/195]\tTime  0.347 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.6759 (0.7187)\tD(fake)1 0.2763 (0.2819)\tD(fake)2 0.2546 (0.2165)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1634)\n",
            "Epoch: [8][ 30/195]\tTime  0.344 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6529 (0.7152)\tD(fake)1 0.2881 (0.2846)\tD(fake)2 0.3360 (0.2240)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1641)\n",
            "Epoch: [8][ 40/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7911 (0.7070)\tD(fake)1 0.4113 (0.2945)\tD(fake)2 0.1627 (0.2298)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1620)\n",
            "Epoch: [8][ 50/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7165 (0.7023)\tD(fake)1 0.3675 (0.2986)\tD(fake)2 0.1803 (0.2349)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1148 (-0.1602)\n",
            "Epoch: [8][ 60/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6978 (0.7017)\tD(fake)1 0.2471 (0.2976)\tD(fake)2 0.2410 (0.2369)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1596)\n",
            "Epoch: [8][ 70/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7391 (0.7042)\tD(fake)1 0.3265 (0.2971)\tD(fake)2 0.1492 (0.2350)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1085 (-0.1586)\n",
            "Epoch: [8][ 80/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6915 (0.7056)\tD(fake)1 0.2136 (0.2927)\tD(fake)2 0.2510 (0.2332)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1533 (-0.1582)\n",
            "Epoch: [8][ 90/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6328 (0.7078)\tD(fake)1 0.1992 (0.2901)\tD(fake)2 0.2992 (0.2315)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1078 (-0.1570)\n",
            "Epoch: [8][100/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6996 (0.7077)\tD(fake)1 0.3126 (0.2926)\tD(fake)2 0.2005 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1527 (-0.1558)\n",
            "Epoch: [8][110/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7213 (0.7156)\tD(fake)1 0.0505 (0.2844)\tD(fake)2 0.1294 (0.2227)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1550)\n",
            "Epoch: [8][120/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7660 (0.7259)\tD(fake)1 0.0876 (0.2741)\tD(fake)2 0.2729 (0.2153)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1336 (-0.1544)\n",
            "Epoch: [8][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6080 (0.7260)\tD(fake)1 0.2356 (0.2741)\tD(fake)2 0.2793 (0.2141)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1390 (-0.1540)\n",
            "Epoch: [8][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8589 (0.7232)\tD(fake)1 0.5455 (0.2783)\tD(fake)2 0.1257 (0.2155)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1530)\n",
            "Epoch: [8][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7259 (0.7203)\tD(fake)1 0.3345 (0.2804)\tD(fake)2 0.2271 (0.2185)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1484 (-0.1525)\n",
            "Epoch: [8][160/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7027 (0.7183)\tD(fake)1 0.3198 (0.2823)\tD(fake)2 0.1869 (0.2206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1525)\n",
            "Epoch: [8][170/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6425 (0.7171)\tD(fake)1 0.2400 (0.2827)\tD(fake)2 0.3382 (0.2220)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1529)\n",
            "Epoch: [8][180/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7089 (0.7174)\tD(fake)1 0.2420 (0.2826)\tD(fake)2 0.2275 (0.2218)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1529)\n",
            "Epoch: [8][190/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7028 (0.7163)\tD(fake)1 0.3082 (0.2834)\tD(fake)2 0.3339 (0.2234)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1529)\n",
            "Epoch: [9][  0/195]\tTime  0.611 ( 0.611)\tData  0.207 ( 0.207)\tD(real) 0.6863 (0.6863)\tD(fake)1 0.3073 (0.3073)\tD(fake)2 0.2420 (0.2420)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1574 (-0.1574)\n",
            "Epoch: [9][ 10/195]\tTime  0.346 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.5537 (0.7359)\tD(fake)1 0.0240 (0.2617)\tD(fake)2 0.2105 (0.2043)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1552)\n",
            "Epoch: [9][ 20/195]\tTime  0.348 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7007 (0.7544)\tD(fake)1 0.2121 (0.2471)\tD(fake)2 0.2358 (0.1981)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1100 (-0.1544)\n",
            "Epoch: [9][ 30/195]\tTime  0.344 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7095 (0.7239)\tD(fake)1 0.3716 (0.2754)\tD(fake)2 0.2418 (0.2182)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1568)\n",
            "Epoch: [9][ 40/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7441 (0.7174)\tD(fake)1 0.3098 (0.2829)\tD(fake)2 0.1458 (0.2231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1564)\n",
            "Epoch: [9][ 50/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7490 (0.7122)\tD(fake)1 0.3352 (0.2876)\tD(fake)2 0.2211 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1577)\n",
            "Epoch: [9][ 60/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6276 (0.7119)\tD(fake)1 0.2321 (0.2866)\tD(fake)2 0.3153 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1573)\n",
            "Epoch: [9][ 70/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7864 (0.7125)\tD(fake)1 0.3667 (0.2902)\tD(fake)2 0.0873 (0.2289)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1488 (-0.1568)\n",
            "Epoch: [9][ 80/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6832 (0.7099)\tD(fake)1 0.2892 (0.2912)\tD(fake)2 0.2519 (0.2321)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1468 (-0.1575)\n",
            "Epoch: [9][ 90/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7258 (0.7080)\tD(fake)1 0.3672 (0.2937)\tD(fake)2 0.2259 (0.2342)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1438 (-0.1566)\n",
            "Epoch: [9][100/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5728 (0.7060)\tD(fake)1 0.2115 (0.2936)\tD(fake)2 0.2526 (0.2343)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1572)\n",
            "Epoch: [9][110/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7056 (0.7055)\tD(fake)1 0.2381 (0.2943)\tD(fake)2 0.2713 (0.2357)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1575)\n",
            "Epoch: [9][120/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5670 (0.7102)\tD(fake)1 0.0246 (0.2884)\tD(fake)2 0.3387 (0.2309)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1639 (-0.1579)\n",
            "Epoch: [9][130/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7317 (0.7124)\tD(fake)1 0.3618 (0.2892)\tD(fake)2 0.1561 (0.2298)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1522 (-0.1577)\n",
            "Epoch: [9][140/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7408 (0.7102)\tD(fake)1 0.3470 (0.2915)\tD(fake)2 0.2339 (0.2333)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1510 (-0.1572)\n",
            "Epoch: [9][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8265 (0.7124)\tD(fake)1 0.3666 (0.2895)\tD(fake)2 0.1352 (0.2313)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1100 (-0.1566)\n",
            "Epoch: [9][160/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6429 (0.7124)\tD(fake)1 0.1955 (0.2874)\tD(fake)2 0.2892 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1565)\n",
            "Epoch: [9][170/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7401 (0.7126)\tD(fake)1 0.3278 (0.2875)\tD(fake)2 0.2430 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1565)\n",
            "Epoch: [9][180/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6700 (0.7128)\tD(fake)1 0.2333 (0.2877)\tD(fake)2 0.2035 (0.2302)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1564)\n",
            "Epoch: [9][190/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8768 (0.7134)\tD(fake)1 0.3815 (0.2877)\tD(fake)2 0.0522 (0.2302)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1566)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5V-0_k5tpiW",
        "outputId": "a1820cb4-41f9-4c38-bd3f-e2879422d9ce"
      },
      "source": [
        "run(10)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.630 ( 0.630)\tData  0.216 ( 0.216)\tD(real) 0.7781 (0.7781)\tD(fake)1 0.3327 (0.3327)\tD(fake)2 0.1505 (0.1505)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1583)\n",
            "Epoch: [0][ 10/195]\tTime  0.346 ( 0.375)\tData  0.000 ( 0.020)\tD(real) 0.6886 (0.7004)\tD(fake)1 0.3014 (0.3072)\tD(fake)2 0.2823 (0.2461)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1515 (-0.1520)\n",
            "Epoch: [0][ 20/195]\tTime  0.344 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.6137 (0.7018)\tD(fake)1 0.1781 (0.3000)\tD(fake)2 0.3104 (0.2351)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1551)\n",
            "Epoch: [0][ 30/195]\tTime  0.349 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6923 (0.7000)\tD(fake)1 0.2269 (0.2966)\tD(fake)2 0.2869 (0.2297)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1562)\n",
            "Epoch: [0][ 40/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.6674 (0.7018)\tD(fake)1 0.2502 (0.2961)\tD(fake)2 0.2660 (0.2285)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1575)\n",
            "Epoch: [0][ 50/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6751 (0.7068)\tD(fake)1 0.2598 (0.2910)\tD(fake)2 0.2547 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1581)\n",
            "Epoch: [0][ 60/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6677 (0.7090)\tD(fake)1 0.2997 (0.2898)\tD(fake)2 0.2973 (0.2273)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1584 (-0.1577)\n",
            "Epoch: [0][ 70/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6451 (0.7091)\tD(fake)1 0.1824 (0.2888)\tD(fake)2 0.4124 (0.2267)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1579)\n",
            "Epoch: [0][ 80/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7586 (0.7123)\tD(fake)1 0.2603 (0.2893)\tD(fake)2 0.1953 (0.2240)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1578)\n",
            "Epoch: [0][ 90/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7195 (0.7153)\tD(fake)1 0.3871 (0.2893)\tD(fake)2 0.2043 (0.2231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1583)\n",
            "Epoch: [0][100/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5138 (0.7057)\tD(fake)1 0.2681 (0.2936)\tD(fake)2 0.3476 (0.2276)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1585 (-0.1583)\n",
            "Epoch: [0][110/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7331 (0.7032)\tD(fake)1 0.3541 (0.2955)\tD(fake)2 0.1703 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1579)\n",
            "Epoch: [0][120/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6927 (0.7027)\tD(fake)1 0.3290 (0.2961)\tD(fake)2 0.2539 (0.2309)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1583)\n",
            "Epoch: [0][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7995 (0.7042)\tD(fake)1 0.3759 (0.2953)\tD(fake)2 0.1823 (0.2314)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1586)\n",
            "Epoch: [0][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6492 (0.7048)\tD(fake)1 0.1598 (0.2933)\tD(fake)2 0.2767 (0.2310)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1585 (-0.1587)\n",
            "Epoch: [0][150/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8727 (0.7088)\tD(fake)1 0.3535 (0.2910)\tD(fake)2 0.1320 (0.2280)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1011 (-0.1579)\n",
            "Epoch: [0][160/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5623 (0.7098)\tD(fake)1 0.0803 (0.2892)\tD(fake)2 0.3058 (0.2276)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1576)\n",
            "Epoch: [0][170/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5943 (0.7119)\tD(fake)1 0.1685 (0.2880)\tD(fake)2 0.2645 (0.2267)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1577)\n",
            "Epoch: [0][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6717 (0.7134)\tD(fake)1 0.1798 (0.2870)\tD(fake)2 0.2935 (0.2264)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1575)\n",
            "Epoch: [0][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6086 (0.7148)\tD(fake)1 0.1454 (0.2850)\tD(fake)2 0.3412 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1528 (-0.1576)\n",
            "Epoch: [1][  0/195]\tTime  0.610 ( 0.610)\tData  0.205 ( 0.205)\tD(real) 0.6458 (0.6458)\tD(fake)1 0.2386 (0.2386)\tD(fake)2 0.2823 (0.2823)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1335 (-0.1335)\n",
            "Epoch: [1][ 10/195]\tTime  0.346 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.7426 (0.7167)\tD(fake)1 0.3193 (0.2763)\tD(fake)2 0.1398 (0.2081)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1540)\n",
            "Epoch: [1][ 20/195]\tTime  0.350 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.8124 (0.7186)\tD(fake)1 0.4118 (0.2810)\tD(fake)2 0.1245 (0.2143)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1591 (-0.1522)\n",
            "Epoch: [1][ 30/195]\tTime  0.344 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.8482 (0.7151)\tD(fake)1 0.3961 (0.2865)\tD(fake)2 0.0199 (0.2197)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1579 (-0.1519)\n",
            "Epoch: [1][ 40/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7199 (0.7164)\tD(fake)1 0.3232 (0.2814)\tD(fake)2 0.2653 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1518)\n",
            "Epoch: [1][ 50/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7654 (0.7170)\tD(fake)1 0.2421 (0.2823)\tD(fake)2 0.1888 (0.2197)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1553 (-0.1528)\n",
            "Epoch: [1][ 60/195]\tTime  0.354 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6939 (0.7251)\tD(fake)1 0.2105 (0.2748)\tD(fake)2 0.2021 (0.2119)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1358 (-0.1538)\n",
            "Epoch: [1][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6543 (0.7244)\tD(fake)1 0.2097 (0.2768)\tD(fake)2 0.2441 (0.2149)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1594 (-0.1534)\n",
            "Epoch: [1][ 80/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8290 (0.7239)\tD(fake)1 0.5250 (0.2793)\tD(fake)2 0.1730 (0.2165)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1503 (-0.1540)\n",
            "Epoch: [1][ 90/195]\tTime  0.355 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6781 (0.7174)\tD(fake)1 0.2242 (0.2822)\tD(fake)2 0.2287 (0.2192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1546)\n",
            "Epoch: [1][100/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7100 (0.7160)\tD(fake)1 0.3317 (0.2833)\tD(fake)2 0.2114 (0.2187)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1535 (-0.1546)\n",
            "Epoch: [1][110/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6981 (0.7172)\tD(fake)1 0.2043 (0.2810)\tD(fake)2 0.2606 (0.2181)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1553)\n",
            "Epoch: [1][120/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8105 (0.7177)\tD(fake)1 0.4073 (0.2810)\tD(fake)2 0.2937 (0.2191)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1555)\n",
            "Epoch: [1][130/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5912 (0.7179)\tD(fake)1 0.1323 (0.2804)\tD(fake)2 0.3957 (0.2199)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1480 (-0.1553)\n",
            "Epoch: [1][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7495 (0.7165)\tD(fake)1 0.3021 (0.2819)\tD(fake)2 0.1706 (0.2201)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1556)\n",
            "Epoch: [1][150/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7203 (0.7178)\tD(fake)1 0.2539 (0.2805)\tD(fake)2 0.2252 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1518 (-0.1556)\n",
            "Epoch: [1][160/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7456 (0.7200)\tD(fake)1 0.2016 (0.2779)\tD(fake)2 0.2326 (0.2183)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1528 (-0.1549)\n",
            "Epoch: [1][170/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7405 (0.7226)\tD(fake)1 0.3071 (0.2767)\tD(fake)2 0.1998 (0.2163)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1546)\n",
            "Epoch: [1][180/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7283 (0.7240)\tD(fake)1 0.2023 (0.2758)\tD(fake)2 0.2051 (0.2157)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1545)\n",
            "Epoch: [1][190/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.8895 (0.7260)\tD(fake)1 0.5151 (0.2752)\tD(fake)2 0.0411 (0.2146)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1500 (-0.1542)\n",
            "Epoch: [2][  0/195]\tTime  0.597 ( 0.597)\tData  0.220 ( 0.220)\tD(real) 0.7739 (0.7739)\tD(fake)1 0.3694 (0.3694)\tD(fake)2 0.2326 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1147 (-0.1147)\n",
            "Epoch: [2][ 10/195]\tTime  0.344 ( 0.371)\tData  0.000 ( 0.020)\tD(real) 0.7830 (0.7194)\tD(fake)1 0.3685 (0.2865)\tD(fake)2 0.2793 (0.2360)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1250 (-0.1556)\n",
            "Epoch: [2][ 20/195]\tTime  0.343 ( 0.360)\tData  0.000 ( 0.011)\tD(real) 0.6737 (0.7164)\tD(fake)1 0.2620 (0.2818)\tD(fake)2 0.3219 (0.2303)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1398 (-0.1587)\n",
            "Epoch: [2][ 30/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6421 (0.7125)\tD(fake)1 0.3121 (0.2882)\tD(fake)2 0.2920 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1604)\n",
            "Epoch: [2][ 40/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.006)\tD(real) 0.8885 (0.7212)\tD(fake)1 0.4077 (0.2889)\tD(fake)2 0.0486 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1600)\n",
            "Epoch: [2][ 50/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.005)\tD(real) 0.6178 (0.7173)\tD(fake)1 0.2683 (0.2874)\tD(fake)2 0.2956 (0.2324)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1507 (-0.1576)\n",
            "Epoch: [2][ 60/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.004)\tD(real) 0.6340 (0.7200)\tD(fake)1 0.1518 (0.2825)\tD(fake)2 0.3240 (0.2279)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1575)\n",
            "Epoch: [2][ 70/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6426 (0.7187)\tD(fake)1 0.2487 (0.2851)\tD(fake)2 0.2650 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1575)\n",
            "Epoch: [2][ 80/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9487 (0.7180)\tD(fake)1 0.5462 (0.2889)\tD(fake)2 0.0042 (0.2268)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1552 (-0.1580)\n",
            "Epoch: [2][ 90/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7817 (0.7133)\tD(fake)1 0.3884 (0.2906)\tD(fake)2 0.1235 (0.2306)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1570)\n",
            "Epoch: [2][100/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7798 (0.7140)\tD(fake)1 0.2949 (0.2886)\tD(fake)2 0.1111 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1552 (-0.1560)\n",
            "Epoch: [2][110/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7116 (0.7135)\tD(fake)1 0.2988 (0.2884)\tD(fake)2 0.2620 (0.2322)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1364 (-0.1561)\n",
            "Epoch: [2][120/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7189 (0.7121)\tD(fake)1 0.2562 (0.2896)\tD(fake)2 0.2135 (0.2328)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1563)\n",
            "Epoch: [2][130/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7151 (0.7141)\tD(fake)1 0.3123 (0.2887)\tD(fake)2 0.1777 (0.2317)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1560)\n",
            "Epoch: [2][140/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8855 (0.7148)\tD(fake)1 0.4634 (0.2897)\tD(fake)2 0.0049 (0.2312)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1562)\n",
            "Epoch: [2][150/195]\tTime  0.355 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6359 (0.7096)\tD(fake)1 0.3171 (0.2920)\tD(fake)2 0.2871 (0.2347)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1504 (-0.1562)\n",
            "Epoch: [2][160/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6166 (0.7096)\tD(fake)1 0.2215 (0.2917)\tD(fake)2 0.1961 (0.2338)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1558)\n",
            "Epoch: [2][170/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6681 (0.7090)\tD(fake)1 0.2406 (0.2920)\tD(fake)2 0.2829 (0.2353)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1557)\n",
            "Epoch: [2][180/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6199 (0.7088)\tD(fake)1 0.2253 (0.2921)\tD(fake)2 0.2958 (0.2359)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1563)\n",
            "Epoch: [2][190/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8064 (0.7081)\tD(fake)1 0.4566 (0.2934)\tD(fake)2 0.2071 (0.2368)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1279 (-0.1562)\n",
            "Epoch: [3][  0/195]\tTime  0.609 ( 0.609)\tData  0.206 ( 0.206)\tD(real) 0.7696 (0.7696)\tD(fake)1 0.3872 (0.3872)\tD(fake)2 0.1992 (0.1992)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1286 (-0.1286)\n",
            "Epoch: [3][ 10/195]\tTime  0.350 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.8217 (0.7295)\tD(fake)1 0.3199 (0.2840)\tD(fake)2 0.1454 (0.2242)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1505)\n",
            "Epoch: [3][ 20/195]\tTime  0.345 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.6771 (0.7336)\tD(fake)1 0.2244 (0.2711)\tD(fake)2 0.2713 (0.2229)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1567 (-0.1503)\n",
            "Epoch: [3][ 30/195]\tTime  0.352 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.8275 (0.7347)\tD(fake)1 0.3433 (0.2750)\tD(fake)2 0.1204 (0.2208)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1456 (-0.1495)\n",
            "Epoch: [3][ 40/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7329 (0.7343)\tD(fake)1 0.2514 (0.2743)\tD(fake)2 0.2051 (0.2240)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1535 (-0.1521)\n",
            "Epoch: [3][ 50/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8705 (0.7361)\tD(fake)1 0.4664 (0.2750)\tD(fake)2 0.1915 (0.2233)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1535)\n",
            "Epoch: [3][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6640 (0.7232)\tD(fake)1 0.3156 (0.2822)\tD(fake)2 0.2219 (0.2287)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1543)\n",
            "Epoch: [3][ 70/195]\tTime  0.342 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6251 (0.7206)\tD(fake)1 0.1024 (0.2804)\tD(fake)2 0.3586 (0.2294)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1237 (-0.1542)\n",
            "Epoch: [3][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7241 (0.7219)\tD(fake)1 0.3068 (0.2811)\tD(fake)2 0.1947 (0.2271)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1546)\n",
            "Epoch: [3][ 90/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7352 (0.7213)\tD(fake)1 0.2757 (0.2809)\tD(fake)2 0.1515 (0.2277)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1519 (-0.1552)\n",
            "Epoch: [3][100/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7686 (0.7196)\tD(fake)1 0.3603 (0.2831)\tD(fake)2 0.1829 (0.2285)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1555)\n",
            "Epoch: [3][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6898 (0.7238)\tD(fake)1 0.3393 (0.2798)\tD(fake)2 0.1652 (0.2220)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1519 (-0.1555)\n",
            "Epoch: [3][120/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6392 (0.7197)\tD(fake)1 0.2853 (0.2829)\tD(fake)2 0.3326 (0.2256)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1552)\n",
            "Epoch: [3][130/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7287 (0.7191)\tD(fake)1 0.3849 (0.2842)\tD(fake)2 0.1806 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1552)\n",
            "Epoch: [3][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7905 (0.7174)\tD(fake)1 0.3269 (0.2857)\tD(fake)2 0.1191 (0.2259)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1431 (-0.1555)\n",
            "Epoch: [3][150/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6856 (0.7168)\tD(fake)1 0.3425 (0.2855)\tD(fake)2 0.2575 (0.2266)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1559)\n",
            "Epoch: [3][160/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6808 (0.7139)\tD(fake)1 0.3084 (0.2882)\tD(fake)2 0.2774 (0.2301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1565)\n",
            "Epoch: [3][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5880 (0.7121)\tD(fake)1 0.2730 (0.2901)\tD(fake)2 0.2834 (0.2321)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1568)\n",
            "Epoch: [3][180/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6031 (0.7101)\tD(fake)1 0.2539 (0.2919)\tD(fake)2 0.2524 (0.2337)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1569)\n",
            "Epoch: [3][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6262 (0.7079)\tD(fake)1 0.2567 (0.2927)\tD(fake)2 0.2653 (0.2347)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1572)\n",
            "Epoch: [4][  0/195]\tTime  0.617 ( 0.617)\tData  0.215 ( 0.215)\tD(real) 0.7991 (0.7991)\tD(fake)1 0.3814 (0.3814)\tD(fake)2 0.0653 (0.0653)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1560)\n",
            "Epoch: [4][ 10/195]\tTime  0.348 ( 0.375)\tData  0.000 ( 0.020)\tD(real) 0.7799 (0.7226)\tD(fake)1 0.2950 (0.2837)\tD(fake)2 0.1628 (0.2167)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1449 (-0.1510)\n",
            "Epoch: [4][ 20/195]\tTime  0.350 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.7540 (0.7302)\tD(fake)1 0.3068 (0.2754)\tD(fake)2 0.2110 (0.2163)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1567 (-0.1545)\n",
            "Epoch: [4][ 30/195]\tTime  0.350 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.8758 (0.7335)\tD(fake)1 0.3917 (0.2768)\tD(fake)2 0.0882 (0.2139)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1533)\n",
            "Epoch: [4][ 40/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.5867 (0.7339)\tD(fake)1 0.1085 (0.2674)\tD(fake)2 0.4005 (0.2138)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1556)\n",
            "Epoch: [4][ 50/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7049 (0.7268)\tD(fake)1 0.3430 (0.2791)\tD(fake)2 0.2070 (0.2178)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1157 (-0.1550)\n",
            "Epoch: [4][ 60/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7385 (0.7247)\tD(fake)1 0.3173 (0.2813)\tD(fake)2 0.2149 (0.2224)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1567)\n",
            "Epoch: [4][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6053 (0.7131)\tD(fake)1 0.2990 (0.2883)\tD(fake)2 0.3087 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1572)\n",
            "Epoch: [4][ 80/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6934 (0.7101)\tD(fake)1 0.2949 (0.2902)\tD(fake)2 0.1671 (0.2296)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1733 (-0.1586)\n",
            "Epoch: [4][ 90/195]\tTime  0.351 ( 0.352)\tData  0.001 ( 0.003)\tD(real) 0.7850 (0.7109)\tD(fake)1 0.3463 (0.2886)\tD(fake)2 0.2020 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1063 (-0.1586)\n",
            "Epoch: [4][100/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6840 (0.7134)\tD(fake)1 0.1478 (0.2857)\tD(fake)2 0.2613 (0.2253)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1580)\n",
            "Epoch: [4][110/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8975 (0.7199)\tD(fake)1 0.4318 (0.2831)\tD(fake)2 0.0669 (0.2193)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1586)\n",
            "Epoch: [4][120/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7086 (0.7216)\tD(fake)1 0.2239 (0.2806)\tD(fake)2 0.2499 (0.2184)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1586)\n",
            "Epoch: [4][130/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5633 (0.7186)\tD(fake)1 0.2906 (0.2833)\tD(fake)2 0.3336 (0.2203)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1578)\n",
            "Epoch: [4][140/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7514 (0.7176)\tD(fake)1 0.3125 (0.2852)\tD(fake)2 0.1676 (0.2209)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1553 (-0.1575)\n",
            "Epoch: [4][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7894 (0.7165)\tD(fake)1 0.3857 (0.2860)\tD(fake)2 0.0960 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1574)\n",
            "Epoch: [4][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6695 (0.7158)\tD(fake)1 0.2653 (0.2853)\tD(fake)2 0.2703 (0.2218)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1577)\n",
            "Epoch: [4][170/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5783 (0.7154)\tD(fake)1 0.1177 (0.2855)\tD(fake)2 0.4004 (0.2236)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1226 (-0.1574)\n",
            "Epoch: [4][180/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6430 (0.7152)\tD(fake)1 0.2000 (0.2861)\tD(fake)2 0.2883 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1575)\n",
            "Epoch: [4][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6254 (0.7138)\tD(fake)1 0.1743 (0.2872)\tD(fake)2 0.3215 (0.2243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1333 (-0.1575)\n",
            "Epoch: [5][  0/195]\tTime  0.604 ( 0.604)\tData  0.208 ( 0.208)\tD(real) 0.8582 (0.8582)\tD(fake)1 0.3634 (0.3634)\tD(fake)2 0.1068 (0.1068)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1670)\n",
            "Epoch: [5][ 10/195]\tTime  0.352 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.9643 (0.7568)\tD(fake)1 0.4834 (0.2767)\tD(fake)2 0.0116 (0.1862)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1732 (-0.1614)\n",
            "Epoch: [5][ 20/195]\tTime  0.349 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6635 (0.7340)\tD(fake)1 0.2162 (0.2721)\tD(fake)2 0.2535 (0.2108)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1590)\n",
            "Epoch: [5][ 30/195]\tTime  0.349 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7099 (0.7322)\tD(fake)1 0.3507 (0.2780)\tD(fake)2 0.2147 (0.2153)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1593)\n",
            "Epoch: [5][ 40/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.5955 (0.7147)\tD(fake)1 0.2231 (0.2897)\tD(fake)2 0.3144 (0.2244)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1590)\n",
            "Epoch: [5][ 50/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.8915 (0.7310)\tD(fake)1 0.2813 (0.2773)\tD(fake)2 0.0681 (0.2094)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1571)\n",
            "Epoch: [5][ 60/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7769 (0.7386)\tD(fake)1 0.2479 (0.2670)\tD(fake)2 0.0974 (0.2013)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1558)\n",
            "Epoch: [5][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7435 (0.7384)\tD(fake)1 0.2874 (0.2666)\tD(fake)2 0.1564 (0.2023)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1547)\n",
            "Epoch: [5][ 80/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7161 (0.7340)\tD(fake)1 0.2986 (0.2705)\tD(fake)2 0.1917 (0.2059)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1540 (-0.1549)\n",
            "Epoch: [5][ 90/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7890 (0.7275)\tD(fake)1 0.4268 (0.2772)\tD(fake)2 0.1730 (0.2129)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1540)\n",
            "Epoch: [5][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7025 (0.7259)\tD(fake)1 0.1812 (0.2760)\tD(fake)2 0.2212 (0.2133)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1543)\n",
            "Epoch: [5][110/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8165 (0.7313)\tD(fake)1 0.3026 (0.2712)\tD(fake)2 0.1170 (0.2082)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1549)\n",
            "Epoch: [5][120/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7249 (0.7326)\tD(fake)1 0.2880 (0.2696)\tD(fake)2 0.2182 (0.2081)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1445 (-0.1547)\n",
            "Epoch: [5][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7880 (0.7322)\tD(fake)1 0.3109 (0.2700)\tD(fake)2 0.1797 (0.2087)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1240 (-0.1552)\n",
            "Epoch: [5][140/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5746 (0.7301)\tD(fake)1 0.1506 (0.2705)\tD(fake)2 0.4546 (0.2105)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1556)\n",
            "Epoch: [5][150/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6688 (0.7288)\tD(fake)1 0.2412 (0.2722)\tD(fake)2 0.2611 (0.2111)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1555)\n",
            "Epoch: [5][160/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6915 (0.7295)\tD(fake)1 0.2375 (0.2722)\tD(fake)2 0.1956 (0.2105)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1558)\n",
            "Epoch: [5][170/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6230 (0.7307)\tD(fake)1 0.1745 (0.2712)\tD(fake)2 0.2904 (0.2100)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1608 (-0.1561)\n",
            "Epoch: [5][180/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.5380 (0.7292)\tD(fake)1 0.0454 (0.2713)\tD(fake)2 0.6249 (0.2116)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1561)\n",
            "Epoch: [5][190/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7018 (0.7278)\tD(fake)1 0.2903 (0.2740)\tD(fake)2 0.2402 (0.2124)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1566)\n",
            "Epoch: [6][  0/195]\tTime  0.609 ( 0.609)\tData  0.202 ( 0.202)\tD(real) 0.6603 (0.6603)\tD(fake)1 0.2097 (0.2097)\tD(fake)2 0.2817 (0.2817)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1655)\n",
            "Epoch: [6][ 10/195]\tTime  0.348 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.6933 (0.7004)\tD(fake)1 0.2876 (0.2947)\tD(fake)2 0.2637 (0.2525)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1605 (-0.1579)\n",
            "Epoch: [6][ 20/195]\tTime  0.348 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7809 (0.7018)\tD(fake)1 0.3027 (0.2937)\tD(fake)2 0.2157 (0.2433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1486 (-0.1598)\n",
            "Epoch: [6][ 30/195]\tTime  0.344 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.8880 (0.7131)\tD(fake)1 0.4185 (0.2896)\tD(fake)2 0.0983 (0.2322)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1593)\n",
            "Epoch: [6][ 40/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8837 (0.7238)\tD(fake)1 0.3235 (0.2813)\tD(fake)2 0.0666 (0.2235)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1599)\n",
            "Epoch: [6][ 50/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6934 (0.7219)\tD(fake)1 0.2700 (0.2785)\tD(fake)2 0.1801 (0.2212)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1614)\n",
            "Epoch: [6][ 60/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6369 (0.7140)\tD(fake)1 0.3121 (0.2838)\tD(fake)2 0.2835 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1602)\n",
            "Epoch: [6][ 70/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7596 (0.7144)\tD(fake)1 0.2399 (0.2849)\tD(fake)2 0.1736 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1604)\n",
            "Epoch: [6][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7309 (0.7199)\tD(fake)1 0.3172 (0.2805)\tD(fake)2 0.2161 (0.2175)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1559 (-0.1597)\n",
            "Epoch: [6][ 90/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.9656 (0.7224)\tD(fake)1 0.4748 (0.2812)\tD(fake)2 0.0750 (0.2173)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1492 (-0.1593)\n",
            "Epoch: [6][100/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7768 (0.7210)\tD(fake)1 0.3461 (0.2809)\tD(fake)2 0.1013 (0.2178)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1588)\n",
            "Epoch: [6][110/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7249 (0.7183)\tD(fake)1 0.2509 (0.2835)\tD(fake)2 0.2106 (0.2220)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1741 (-0.1585)\n",
            "Epoch: [6][120/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6229 (0.7189)\tD(fake)1 0.2722 (0.2830)\tD(fake)2 0.2366 (0.2219)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1585)\n",
            "Epoch: [6][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5230 (0.7153)\tD(fake)1 0.0944 (0.2843)\tD(fake)2 0.3386 (0.2226)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1574)\n",
            "Epoch: [6][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8981 (0.7198)\tD(fake)1 0.3251 (0.2821)\tD(fake)2 0.0445 (0.2182)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1571)\n",
            "Epoch: [6][150/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9186 (0.7226)\tD(fake)1 0.4182 (0.2805)\tD(fake)2 0.0743 (0.2174)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1572)\n",
            "Epoch: [6][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8250 (0.7218)\tD(fake)1 0.3945 (0.2813)\tD(fake)2 0.1035 (0.2182)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1576)\n",
            "Epoch: [6][170/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6671 (0.7182)\tD(fake)1 0.3525 (0.2836)\tD(fake)2 0.2504 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1563 (-0.1570)\n",
            "Epoch: [6][180/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7213 (0.7160)\tD(fake)1 0.3262 (0.2857)\tD(fake)2 0.1674 (0.2229)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1442 (-0.1572)\n",
            "Epoch: [6][190/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7689 (0.7152)\tD(fake)1 0.4276 (0.2869)\tD(fake)2 0.1393 (0.2246)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1411 (-0.1570)\n",
            "Epoch: [7][  0/195]\tTime  0.613 ( 0.613)\tData  0.204 ( 0.204)\tD(real) 0.7794 (0.7794)\tD(fake)1 0.4084 (0.4084)\tD(fake)2 0.0990 (0.0990)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1486 (-0.1486)\n",
            "Epoch: [7][ 10/195]\tTime  0.342 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.7984 (0.7031)\tD(fake)1 0.3194 (0.3008)\tD(fake)2 0.1375 (0.2368)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1613)\n",
            "Epoch: [7][ 20/195]\tTime  0.345 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7091 (0.7156)\tD(fake)1 0.2904 (0.2884)\tD(fake)2 0.2019 (0.2292)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1604)\n",
            "Epoch: [7][ 30/195]\tTime  0.349 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7180 (0.7274)\tD(fake)1 0.1155 (0.2755)\tD(fake)2 0.2099 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1192 (-0.1576)\n",
            "Epoch: [7][ 40/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7989 (0.7326)\tD(fake)1 0.5138 (0.2769)\tD(fake)2 0.1107 (0.2091)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1578)\n",
            "Epoch: [7][ 50/195]\tTime  0.343 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7558 (0.7215)\tD(fake)1 0.3152 (0.2806)\tD(fake)2 0.1349 (0.2132)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1535 (-0.1565)\n",
            "Epoch: [7][ 60/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7054 (0.7199)\tD(fake)1 0.2825 (0.2798)\tD(fake)2 0.2981 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1545)\n",
            "Epoch: [7][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6626 (0.7168)\tD(fake)1 0.2384 (0.2826)\tD(fake)2 0.3143 (0.2210)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1544)\n",
            "Epoch: [7][ 80/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7363 (0.7176)\tD(fake)1 0.2695 (0.2829)\tD(fake)2 0.2049 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1549)\n",
            "Epoch: [7][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6330 (0.7181)\tD(fake)1 0.2636 (0.2812)\tD(fake)2 0.3104 (0.2202)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1726 (-0.1556)\n",
            "Epoch: [7][100/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6058 (0.7129)\tD(fake)1 0.2470 (0.2864)\tD(fake)2 0.2563 (0.2231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1561)\n",
            "Epoch: [7][110/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.4884 (0.7118)\tD(fake)1 0.0842 (0.2861)\tD(fake)2 0.3820 (0.2233)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1509 (-0.1559)\n",
            "Epoch: [7][120/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7925 (0.7122)\tD(fake)1 0.4051 (0.2891)\tD(fake)2 0.1548 (0.2247)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1564)\n",
            "Epoch: [7][130/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5813 (0.7098)\tD(fake)1 0.1710 (0.2892)\tD(fake)2 0.4254 (0.2273)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1330 (-0.1567)\n",
            "Epoch: [7][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6841 (0.7095)\tD(fake)1 0.2529 (0.2910)\tD(fake)2 0.2488 (0.2278)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1591 (-0.1570)\n",
            "Epoch: [7][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6306 (0.7111)\tD(fake)1 0.1958 (0.2893)\tD(fake)2 0.3220 (0.2267)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1576)\n",
            "Epoch: [7][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7077 (0.7115)\tD(fake)1 0.2946 (0.2896)\tD(fake)2 0.2670 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1573)\n",
            "Epoch: [7][170/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7173 (0.7120)\tD(fake)1 0.2708 (0.2893)\tD(fake)2 0.1877 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1531 (-0.1571)\n",
            "Epoch: [7][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7012 (0.7124)\tD(fake)1 0.3106 (0.2888)\tD(fake)2 0.2751 (0.2283)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1547 (-0.1570)\n",
            "Epoch: [7][190/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7228 (0.7122)\tD(fake)1 0.2942 (0.2889)\tD(fake)2 0.2584 (0.2284)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1175 (-0.1564)\n",
            "Epoch: [8][  0/195]\tTime  0.594 ( 0.594)\tData  0.209 ( 0.209)\tD(real) 0.6678 (0.6678)\tD(fake)1 0.3128 (0.3128)\tD(fake)2 0.3150 (0.3150)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1573)\n",
            "Epoch: [8][ 10/195]\tTime  0.349 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.7012 (0.7329)\tD(fake)1 0.2912 (0.2781)\tD(fake)2 0.2653 (0.2294)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1581)\n",
            "Epoch: [8][ 20/195]\tTime  0.352 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6178 (0.7192)\tD(fake)1 0.2627 (0.2837)\tD(fake)2 0.3282 (0.2362)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1591)\n",
            "Epoch: [8][ 30/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7451 (0.7027)\tD(fake)1 0.3818 (0.3024)\tD(fake)2 0.2234 (0.2505)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1564)\n",
            "Epoch: [8][ 40/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6320 (0.6978)\tD(fake)1 0.1783 (0.3006)\tD(fake)2 0.3389 (0.2513)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1217 (-0.1577)\n",
            "Epoch: [8][ 50/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6520 (0.6967)\tD(fake)1 0.2929 (0.3030)\tD(fake)2 0.2657 (0.2494)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1582)\n",
            "Epoch: [8][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6269 (0.6945)\tD(fake)1 0.2590 (0.3057)\tD(fake)2 0.2443 (0.2509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1583)\n",
            "Epoch: [8][ 70/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8215 (0.6985)\tD(fake)1 0.3444 (0.3033)\tD(fake)2 0.1236 (0.2497)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1397 (-0.1570)\n",
            "Epoch: [8][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5023 (0.7002)\tD(fake)1 0.0102 (0.2971)\tD(fake)2 0.4440 (0.2481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1576)\n",
            "Epoch: [8][ 90/195]\tTime  0.359 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7784 (0.7022)\tD(fake)1 0.4072 (0.2998)\tD(fake)2 0.1813 (0.2474)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1573)\n",
            "Epoch: [8][100/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6496 (0.7013)\tD(fake)1 0.1602 (0.2980)\tD(fake)2 0.3450 (0.2468)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1575)\n",
            "Epoch: [8][110/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7233 (0.7012)\tD(fake)1 0.3291 (0.2995)\tD(fake)2 0.2501 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1581)\n",
            "Epoch: [8][120/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5477 (0.7006)\tD(fake)1 0.1625 (0.2994)\tD(fake)2 0.3677 (0.2465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1639 (-0.1587)\n",
            "Epoch: [8][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6098 (0.6980)\tD(fake)1 0.3157 (0.3024)\tD(fake)2 0.3361 (0.2484)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1584)\n",
            "Epoch: [8][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7936 (0.6964)\tD(fake)1 0.3622 (0.3041)\tD(fake)2 0.0575 (0.2481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1581)\n",
            "Epoch: [8][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6451 (0.6965)\tD(fake)1 0.2695 (0.3033)\tD(fake)2 0.2830 (0.2490)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1583)\n",
            "Epoch: [8][160/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6743 (0.6980)\tD(fake)1 0.2393 (0.3020)\tD(fake)2 0.2613 (0.2475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1584)\n",
            "Epoch: [8][170/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6756 (0.6977)\tD(fake)1 0.2974 (0.3025)\tD(fake)2 0.2737 (0.2484)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1584)\n",
            "Epoch: [8][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.8336 (0.6988)\tD(fake)1 0.4343 (0.3020)\tD(fake)2 0.1923 (0.2476)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1580)\n",
            "Epoch: [8][190/195]\tTime  0.358 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6765 (0.6978)\tD(fake)1 0.2558 (0.3021)\tD(fake)2 0.2867 (0.2481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1579)\n",
            "Epoch: [9][  0/195]\tTime  0.619 ( 0.619)\tData  0.220 ( 0.220)\tD(real) 0.8056 (0.8056)\tD(fake)1 0.2928 (0.2928)\tD(fake)2 0.1041 (0.1041)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1619)\n",
            "Epoch: [9][ 10/195]\tTime  0.350 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.6966 (0.7440)\tD(fake)1 0.1794 (0.2497)\tD(fake)2 0.2732 (0.1893)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1501)\n",
            "Epoch: [9][ 20/195]\tTime  0.345 ( 0.361)\tData  0.000 ( 0.011)\tD(real) 0.6361 (0.7433)\tD(fake)1 0.1950 (0.2519)\tD(fake)2 0.3096 (0.1900)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1549)\n",
            "Epoch: [9][ 30/195]\tTime  0.344 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6002 (0.7264)\tD(fake)1 0.1795 (0.2692)\tD(fake)2 0.3481 (0.2088)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1555)\n",
            "Epoch: [9][ 40/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.5917 (0.7211)\tD(fake)1 0.2818 (0.2763)\tD(fake)2 0.3669 (0.2141)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1565)\n",
            "Epoch: [9][ 50/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.7532 (0.7141)\tD(fake)1 0.3583 (0.2850)\tD(fake)2 0.2223 (0.2220)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1563)\n",
            "Epoch: [9][ 60/195]\tTime  0.354 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7573 (0.7135)\tD(fake)1 0.3515 (0.2861)\tD(fake)2 0.2315 (0.2259)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1557)\n",
            "Epoch: [9][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.9353 (0.7161)\tD(fake)1 0.4632 (0.2870)\tD(fake)2 0.0006 (0.2239)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1559)\n",
            "Epoch: [9][ 80/195]\tTime  0.342 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6993 (0.7162)\tD(fake)1 0.2004 (0.2836)\tD(fake)2 0.2542 (0.2245)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1170 (-0.1565)\n",
            "Epoch: [9][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7557 (0.7173)\tD(fake)1 0.3078 (0.2847)\tD(fake)2 0.2191 (0.2234)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1568)\n",
            "Epoch: [9][100/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6445 (0.7219)\tD(fake)1 0.1687 (0.2815)\tD(fake)2 0.2479 (0.2190)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1508 (-0.1561)\n",
            "Epoch: [9][110/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7472 (0.7222)\tD(fake)1 0.3726 (0.2821)\tD(fake)2 0.1488 (0.2168)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1560)\n",
            "Epoch: [9][120/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8401 (0.7206)\tD(fake)1 0.3792 (0.2826)\tD(fake)2 0.1275 (0.2169)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1564)\n",
            "Epoch: [9][130/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6538 (0.7198)\tD(fake)1 0.1887 (0.2815)\tD(fake)2 0.3838 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1378 (-0.1565)\n",
            "Epoch: [9][140/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6545 (0.7184)\tD(fake)1 0.3097 (0.2834)\tD(fake)2 0.2840 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1568)\n",
            "Epoch: [9][150/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.9131 (0.7205)\tD(fake)1 0.3888 (0.2825)\tD(fake)2 0.0583 (0.2188)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1567)\n",
            "Epoch: [9][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7900 (0.7206)\tD(fake)1 0.3707 (0.2817)\tD(fake)2 0.1443 (0.2194)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1568)\n",
            "Epoch: [9][170/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7422 (0.7192)\tD(fake)1 0.2674 (0.2827)\tD(fake)2 0.2194 (0.2212)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1569)\n",
            "Epoch: [9][180/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7238 (0.7191)\tD(fake)1 0.3454 (0.2831)\tD(fake)2 0.1644 (0.2214)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1149 (-0.1567)\n",
            "Epoch: [9][190/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6041 (0.7173)\tD(fake)1 0.1621 (0.2834)\tD(fake)2 0.3902 (0.2219)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1565)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdIo707ZyUic",
        "outputId": "8541e536-1439-43c9-d6a3-0b8f2974453b"
      },
      "source": [
        "run(10)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.616 ( 0.616)\tData  0.214 ( 0.214)\tD(real) 0.6749 (0.6749)\tD(fake)1 0.2603 (0.2603)\tD(fake)2 0.2092 (0.2092)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1730)\n",
            "Epoch: [0][ 10/195]\tTime  0.353 ( 0.377)\tData  0.000 ( 0.020)\tD(real) 0.8813 (0.7180)\tD(fake)1 0.4626 (0.2861)\tD(fake)2 0.1036 (0.2131)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1600)\n",
            "Epoch: [0][ 20/195]\tTime  0.377 ( 0.366)\tData  0.000 ( 0.011)\tD(real) 0.7437 (0.7133)\tD(fake)1 0.2883 (0.2807)\tD(fake)2 0.2119 (0.2202)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1596)\n",
            "Epoch: [0][ 30/195]\tTime  0.355 ( 0.361)\tData  0.000 ( 0.007)\tD(real) 0.8491 (0.7333)\tD(fake)1 0.2697 (0.2644)\tD(fake)2 0.1640 (0.2033)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1579)\n",
            "Epoch: [0][ 40/195]\tTime  0.346 ( 0.357)\tData  0.000 ( 0.006)\tD(real) 0.6082 (0.7375)\tD(fake)1 0.1904 (0.2621)\tD(fake)2 0.2286 (0.2003)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1241 (-0.1556)\n",
            "Epoch: [0][ 50/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7105 (0.7355)\tD(fake)1 0.2616 (0.2675)\tD(fake)2 0.2587 (0.2076)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1576)\n",
            "Epoch: [0][ 60/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7423 (0.7322)\tD(fake)1 0.3327 (0.2697)\tD(fake)2 0.2099 (0.2092)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1600 (-0.1580)\n",
            "Epoch: [0][ 70/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7664 (0.7304)\tD(fake)1 0.4015 (0.2713)\tD(fake)2 0.2297 (0.2107)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1582)\n",
            "Epoch: [0][ 80/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6515 (0.7231)\tD(fake)1 0.2428 (0.2774)\tD(fake)2 0.2585 (0.2150)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1579)\n",
            "Epoch: [0][ 90/195]\tTime  0.355 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7899 (0.7207)\tD(fake)1 0.4101 (0.2813)\tD(fake)2 0.2033 (0.2171)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1709 (-0.1588)\n",
            "Epoch: [0][100/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7429 (0.7203)\tD(fake)1 0.2380 (0.2808)\tD(fake)2 0.1891 (0.2180)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1498 (-0.1585)\n",
            "Epoch: [0][110/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7224 (0.7189)\tD(fake)1 0.3171 (0.2826)\tD(fake)2 0.1789 (0.2190)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1598 (-0.1584)\n",
            "Epoch: [0][120/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6066 (0.7155)\tD(fake)1 0.2190 (0.2843)\tD(fake)2 0.3300 (0.2222)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1579)\n",
            "Epoch: [0][130/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7222 (0.7155)\tD(fake)1 0.3183 (0.2849)\tD(fake)2 0.1961 (0.2218)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1578)\n",
            "Epoch: [0][140/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7583 (0.7160)\tD(fake)1 0.2982 (0.2845)\tD(fake)2 0.2162 (0.2224)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1187 (-0.1571)\n",
            "Epoch: [0][150/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5751 (0.7169)\tD(fake)1 0.0764 (0.2822)\tD(fake)2 0.3207 (0.2214)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1303 (-0.1571)\n",
            "Epoch: [0][160/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7884 (0.7187)\tD(fake)1 0.2470 (0.2825)\tD(fake)2 0.1973 (0.2206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1340 (-0.1570)\n",
            "Epoch: [0][170/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8022 (0.7206)\tD(fake)1 0.3641 (0.2815)\tD(fake)2 0.1688 (0.2195)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1571)\n",
            "Epoch: [0][180/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7038 (0.7195)\tD(fake)1 0.3614 (0.2820)\tD(fake)2 0.1805 (0.2205)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1239 (-0.1559)\n",
            "Epoch: [0][190/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7072 (0.7179)\tD(fake)1 0.3152 (0.2834)\tD(fake)2 0.2276 (0.2221)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1562)\n",
            "Epoch: [1][  0/195]\tTime  0.587 ( 0.587)\tData  0.203 ( 0.203)\tD(real) 0.7114 (0.7114)\tD(fake)1 0.3122 (0.3122)\tD(fake)2 0.2283 (0.2283)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1446 (-0.1446)\n",
            "Epoch: [1][ 10/195]\tTime  0.347 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.7077 (0.7131)\tD(fake)1 0.2470 (0.3002)\tD(fake)2 0.2110 (0.2137)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1542 (-0.1576)\n",
            "Epoch: [1][ 20/195]\tTime  0.348 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.6700 (0.6993)\tD(fake)1 0.3347 (0.3107)\tD(fake)2 0.1993 (0.2307)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1441 (-0.1580)\n",
            "Epoch: [1][ 30/195]\tTime  0.350 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6456 (0.6954)\tD(fake)1 0.1999 (0.3031)\tD(fake)2 0.2808 (0.2384)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1571)\n",
            "Epoch: [1][ 40/195]\tTime  0.343 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.5966 (0.7011)\tD(fake)1 0.1987 (0.2962)\tD(fake)2 0.2864 (0.2348)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1568)\n",
            "Epoch: [1][ 50/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6416 (0.7046)\tD(fake)1 0.1721 (0.2906)\tD(fake)2 0.3807 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1572)\n",
            "Epoch: [1][ 60/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7558 (0.7137)\tD(fake)1 0.2532 (0.2851)\tD(fake)2 0.2046 (0.2259)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1567)\n",
            "Epoch: [1][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7289 (0.7136)\tD(fake)1 0.3414 (0.2853)\tD(fake)2 0.3079 (0.2273)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1502 (-0.1553)\n",
            "Epoch: [1][ 80/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7922 (0.7171)\tD(fake)1 0.3272 (0.2825)\tD(fake)2 0.0983 (0.2241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1590 (-0.1546)\n",
            "Epoch: [1][ 90/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6822 (0.7152)\tD(fake)1 0.3542 (0.2833)\tD(fake)2 0.2075 (0.2255)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1549)\n",
            "Epoch: [1][100/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6927 (0.7120)\tD(fake)1 0.3151 (0.2863)\tD(fake)2 0.2886 (0.2297)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1555)\n",
            "Epoch: [1][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6447 (0.7123)\tD(fake)1 0.1630 (0.2854)\tD(fake)2 0.3400 (0.2306)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1558)\n",
            "Epoch: [1][120/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7657 (0.7147)\tD(fake)1 0.3047 (0.2843)\tD(fake)2 0.2231 (0.2296)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1509 (-0.1552)\n",
            "Epoch: [1][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8215 (0.7172)\tD(fake)1 0.3669 (0.2830)\tD(fake)2 0.2046 (0.2277)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1555)\n",
            "Epoch: [1][140/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7391 (0.7203)\tD(fake)1 0.2732 (0.2811)\tD(fake)2 0.2121 (0.2256)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1559)\n",
            "Epoch: [1][150/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6687 (0.7206)\tD(fake)1 0.2423 (0.2806)\tD(fake)2 0.2218 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1566)\n",
            "Epoch: [1][160/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.4896 (0.7191)\tD(fake)1 0.1534 (0.2811)\tD(fake)2 0.3265 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1566)\n",
            "Epoch: [1][170/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7935 (0.7177)\tD(fake)1 0.3613 (0.2836)\tD(fake)2 0.0995 (0.2273)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1566)\n",
            "Epoch: [1][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6520 (0.7180)\tD(fake)1 0.1664 (0.2819)\tD(fake)2 0.3010 (0.2264)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1567)\n",
            "Epoch: [1][190/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6860 (0.7189)\tD(fake)1 0.1337 (0.2809)\tD(fake)2 0.2112 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1567)\n",
            "Epoch: [2][  0/195]\tTime  0.604 ( 0.604)\tData  0.203 ( 0.203)\tD(real) 0.7894 (0.7894)\tD(fake)1 0.3575 (0.3575)\tD(fake)2 0.1066 (0.1066)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1675)\n",
            "Epoch: [2][ 10/195]\tTime  0.347 ( 0.371)\tData  0.000 ( 0.019)\tD(real) 0.6540 (0.7375)\tD(fake)1 0.1626 (0.2715)\tD(fake)2 0.1858 (0.1885)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1607)\n",
            "Epoch: [2][ 20/195]\tTime  0.347 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7257 (0.7310)\tD(fake)1 0.3380 (0.2777)\tD(fake)2 0.2230 (0.2049)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1617)\n",
            "Epoch: [2][ 30/195]\tTime  0.346 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6899 (0.7220)\tD(fake)1 0.2665 (0.2837)\tD(fake)2 0.2165 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1495 (-0.1568)\n",
            "Epoch: [2][ 40/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7063 (0.7190)\tD(fake)1 0.2582 (0.2881)\tD(fake)2 0.2180 (0.2237)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1550 (-0.1582)\n",
            "Epoch: [2][ 50/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7474 (0.7193)\tD(fake)1 0.3863 (0.2889)\tD(fake)2 0.2167 (0.2246)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1584)\n",
            "Epoch: [2][ 60/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6712 (0.7122)\tD(fake)1 0.3185 (0.2923)\tD(fake)2 0.2724 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1284 (-0.1584)\n",
            "Epoch: [2][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8389 (0.7114)\tD(fake)1 0.4289 (0.2963)\tD(fake)2 0.2285 (0.2309)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1166 (-0.1584)\n",
            "Epoch: [2][ 80/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6871 (0.7143)\tD(fake)1 0.1692 (0.2910)\tD(fake)2 0.3071 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1579 (-0.1579)\n",
            "Epoch: [2][ 90/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6106 (0.7114)\tD(fake)1 0.3150 (0.2931)\tD(fake)2 0.3178 (0.2279)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1581)\n",
            "Epoch: [2][100/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6953 (0.7079)\tD(fake)1 0.3071 (0.2964)\tD(fake)2 0.2121 (0.2303)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1573)\n",
            "Epoch: [2][110/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6776 (0.7059)\tD(fake)1 0.2852 (0.2963)\tD(fake)2 0.2328 (0.2306)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1572)\n",
            "Epoch: [2][120/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8143 (0.7066)\tD(fake)1 0.4673 (0.2965)\tD(fake)2 0.1445 (0.2289)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1572)\n",
            "Epoch: [2][130/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7276 (0.7039)\tD(fake)1 0.3576 (0.2995)\tD(fake)2 0.2247 (0.2328)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1575)\n",
            "Epoch: [2][140/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6569 (0.7034)\tD(fake)1 0.2561 (0.2988)\tD(fake)2 0.2875 (0.2330)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1456 (-0.1574)\n",
            "Epoch: [2][150/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7391 (0.7056)\tD(fake)1 0.2850 (0.2965)\tD(fake)2 0.2259 (0.2309)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1577)\n",
            "Epoch: [2][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6623 (0.7089)\tD(fake)1 0.0401 (0.2921)\tD(fake)2 0.2734 (0.2270)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1571)\n",
            "Epoch: [2][170/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7185 (0.7139)\tD(fake)1 0.1781 (0.2888)\tD(fake)2 0.2450 (0.2228)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1546 (-0.1570)\n",
            "Epoch: [2][180/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.8379 (0.7187)\tD(fake)1 0.1803 (0.2850)\tD(fake)2 0.0915 (0.2185)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1570)\n",
            "Epoch: [2][190/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6789 (0.7209)\tD(fake)1 0.3180 (0.2819)\tD(fake)2 0.2224 (0.2155)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1497 (-0.1568)\n",
            "Epoch: [3][  0/195]\tTime  0.619 ( 0.619)\tData  0.215 ( 0.215)\tD(real) 0.9175 (0.9175)\tD(fake)1 0.5294 (0.5294)\tD(fake)2 0.0064 (0.0064)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1527 (-0.1527)\n",
            "Epoch: [3][ 10/195]\tTime  0.349 ( 0.375)\tData  0.000 ( 0.020)\tD(real) 0.7162 (0.7315)\tD(fake)1 0.2030 (0.2930)\tD(fake)2 0.2222 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1608)\n",
            "Epoch: [3][ 20/195]\tTime  0.345 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.8259 (0.7352)\tD(fake)1 0.4649 (0.2837)\tD(fake)2 0.2830 (0.2189)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1586)\n",
            "Epoch: [3][ 30/195]\tTime  0.348 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7589 (0.7229)\tD(fake)1 0.3294 (0.2873)\tD(fake)2 0.1587 (0.2242)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1555 (-0.1562)\n",
            "Epoch: [3][ 40/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7843 (0.7222)\tD(fake)1 0.3627 (0.2851)\tD(fake)2 0.0482 (0.2186)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1225 (-0.1546)\n",
            "Epoch: [3][ 50/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6837 (0.7171)\tD(fake)1 0.2945 (0.2848)\tD(fake)2 0.2736 (0.2222)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1574 (-0.1552)\n",
            "Epoch: [3][ 60/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7369 (0.7197)\tD(fake)1 0.3259 (0.2829)\tD(fake)2 0.2447 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1567)\n",
            "Epoch: [3][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5899 (0.7178)\tD(fake)1 0.2163 (0.2841)\tD(fake)2 0.3188 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1299 (-0.1568)\n",
            "Epoch: [3][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7857 (0.7200)\tD(fake)1 0.3161 (0.2843)\tD(fake)2 0.1294 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1573)\n",
            "Epoch: [3][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6876 (0.7165)\tD(fake)1 0.2634 (0.2866)\tD(fake)2 0.2720 (0.2304)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1567)\n",
            "Epoch: [3][100/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8595 (0.7204)\tD(fake)1 0.3587 (0.2854)\tD(fake)2 0.0530 (0.2268)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1570)\n",
            "Epoch: [3][110/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6775 (0.7175)\tD(fake)1 0.2933 (0.2865)\tD(fake)2 0.2953 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1346 (-0.1572)\n",
            "Epoch: [3][120/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8991 (0.7189)\tD(fake)1 0.4252 (0.2851)\tD(fake)2 0.0224 (0.2254)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1570)\n",
            "Epoch: [3][130/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6627 (0.7147)\tD(fake)1 0.3468 (0.2868)\tD(fake)2 0.2340 (0.2277)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1574)\n",
            "Epoch: [3][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6912 (0.7143)\tD(fake)1 0.2675 (0.2874)\tD(fake)2 0.2545 (0.2296)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1576)\n",
            "Epoch: [3][150/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6474 (0.7128)\tD(fake)1 0.2459 (0.2888)\tD(fake)2 0.3100 (0.2324)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1578)\n",
            "Epoch: [3][160/195]\tTime  0.357 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7352 (0.7116)\tD(fake)1 0.3451 (0.2903)\tD(fake)2 0.2481 (0.2343)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1397 (-0.1579)\n",
            "Epoch: [3][170/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7382 (0.7122)\tD(fake)1 0.3418 (0.2897)\tD(fake)2 0.2058 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1384 (-0.1580)\n",
            "Epoch: [3][180/195]\tTime  0.350 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7168 (0.7102)\tD(fake)1 0.3190 (0.2926)\tD(fake)2 0.2509 (0.2367)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1581)\n",
            "Epoch: [3][190/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6864 (0.7135)\tD(fake)1 0.1709 (0.2894)\tD(fake)2 0.2420 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1576)\n",
            "Epoch: [4][  0/195]\tTime  0.609 ( 0.609)\tData  0.212 ( 0.212)\tD(real) 0.7303 (0.7303)\tD(fake)1 0.2348 (0.2348)\tD(fake)2 0.2381 (0.2381)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1640)\n",
            "Epoch: [4][ 10/195]\tTime  0.350 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.6944 (0.7287)\tD(fake)1 0.3096 (0.2737)\tD(fake)2 0.2531 (0.2245)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1571)\n",
            "Epoch: [4][ 20/195]\tTime  0.343 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.8599 (0.7118)\tD(fake)1 0.5275 (0.2991)\tD(fake)2 -0.0011 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1596)\n",
            "Epoch: [4][ 30/195]\tTime  0.350 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6652 (0.6968)\tD(fake)1 0.2976 (0.2993)\tD(fake)2 0.2586 (0.2464)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1626)\n",
            "Epoch: [4][ 40/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6718 (0.6951)\tD(fake)1 0.2418 (0.2991)\tD(fake)2 0.2737 (0.2466)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1608)\n",
            "Epoch: [4][ 50/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6646 (0.7036)\tD(fake)1 0.2369 (0.2930)\tD(fake)2 0.3576 (0.2417)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1612)\n",
            "Epoch: [4][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6975 (0.7047)\tD(fake)1 0.2767 (0.2949)\tD(fake)2 0.2508 (0.2412)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1614)\n",
            "Epoch: [4][ 70/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7257 (0.7095)\tD(fake)1 0.2618 (0.2889)\tD(fake)2 0.3197 (0.2342)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1613)\n",
            "Epoch: [4][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7327 (0.7155)\tD(fake)1 0.2735 (0.2851)\tD(fake)2 0.2171 (0.2298)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1193 (-0.1599)\n",
            "Epoch: [4][ 90/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.5800 (0.7084)\tD(fake)1 0.3162 (0.2902)\tD(fake)2 0.3655 (0.2349)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1604)\n",
            "Epoch: [4][100/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8021 (0.7063)\tD(fake)1 0.3873 (0.2935)\tD(fake)2 0.0612 (0.2361)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1590 (-0.1601)\n",
            "Epoch: [4][110/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6936 (0.7034)\tD(fake)1 0.3429 (0.2944)\tD(fake)2 0.2618 (0.2380)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1605)\n",
            "Epoch: [4][120/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8364 (0.7034)\tD(fake)1 0.4475 (0.2962)\tD(fake)2 0.0888 (0.2387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1600 (-0.1596)\n",
            "Epoch: [4][130/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7364 (0.7031)\tD(fake)1 0.2611 (0.2963)\tD(fake)2 0.2282 (0.2402)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1594)\n",
            "Epoch: [4][140/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8700 (0.7074)\tD(fake)1 0.3413 (0.2932)\tD(fake)2 0.0827 (0.2357)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1598)\n",
            "Epoch: [4][150/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5510 (0.7073)\tD(fake)1 0.1610 (0.2911)\tD(fake)2 0.3996 (0.2346)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1401 (-0.1591)\n",
            "Epoch: [4][160/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8253 (0.7078)\tD(fake)1 0.3331 (0.2920)\tD(fake)2 0.0683 (0.2342)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1251 (-0.1586)\n",
            "Epoch: [4][170/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7559 (0.7109)\tD(fake)1 0.1892 (0.2881)\tD(fake)2 0.2030 (0.2320)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1593 (-0.1585)\n",
            "Epoch: [4][180/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6649 (0.7125)\tD(fake)1 0.2653 (0.2868)\tD(fake)2 0.2970 (0.2310)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1295 (-0.1583)\n",
            "Epoch: [4][190/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7730 (0.7112)\tD(fake)1 0.4046 (0.2882)\tD(fake)2 0.1498 (0.2317)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1579)\n",
            "Epoch: [5][  0/195]\tTime  0.609 ( 0.609)\tData  0.211 ( 0.211)\tD(real) 0.7333 (0.7333)\tD(fake)1 0.4089 (0.4089)\tD(fake)2 0.1775 (0.1775)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1674)\n",
            "Epoch: [5][ 10/195]\tTime  0.349 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.7789 (0.7202)\tD(fake)1 0.3516 (0.2911)\tD(fake)2 0.1405 (0.2056)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1527 (-0.1613)\n",
            "Epoch: [5][ 20/195]\tTime  0.350 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7222 (0.7185)\tD(fake)1 0.3071 (0.2847)\tD(fake)2 0.1928 (0.2112)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1612)\n",
            "Epoch: [5][ 30/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7040 (0.7026)\tD(fake)1 0.3614 (0.2972)\tD(fake)2 0.2620 (0.2259)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1599)\n",
            "Epoch: [5][ 40/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6560 (0.7077)\tD(fake)1 0.1918 (0.2895)\tD(fake)2 0.3761 (0.2203)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1191 (-0.1592)\n",
            "Epoch: [5][ 50/195]\tTime  0.342 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7078 (0.7099)\tD(fake)1 0.2477 (0.2912)\tD(fake)2 0.1979 (0.2189)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1591)\n",
            "Epoch: [5][ 60/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7361 (0.7186)\tD(fake)1 0.1817 (0.2829)\tD(fake)2 0.1300 (0.2118)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1591)\n",
            "Epoch: [5][ 70/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6755 (0.7273)\tD(fake)1 0.1278 (0.2725)\tD(fake)2 0.2450 (0.2000)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1588)\n",
            "Epoch: [5][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6392 (0.7304)\tD(fake)1 0.1441 (0.2715)\tD(fake)2 0.2813 (0.1966)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1589)\n",
            "Epoch: [5][ 90/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7988 (0.7319)\tD(fake)1 0.4093 (0.2724)\tD(fake)2 0.0883 (0.1959)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1587)\n",
            "Epoch: [5][100/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8191 (0.7255)\tD(fake)1 0.5662 (0.2780)\tD(fake)2 0.2723 (0.2025)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1596)\n",
            "Epoch: [5][110/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7247 (0.7190)\tD(fake)1 0.2997 (0.2835)\tD(fake)2 0.2196 (0.2093)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1591 (-0.1596)\n",
            "Epoch: [5][120/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7413 (0.7183)\tD(fake)1 0.3631 (0.2847)\tD(fake)2 0.2467 (0.2122)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1598)\n",
            "Epoch: [5][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6203 (0.7155)\tD(fake)1 0.1198 (0.2855)\tD(fake)2 0.3593 (0.2152)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1598)\n",
            "Epoch: [5][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7291 (0.7178)\tD(fake)1 0.3435 (0.2851)\tD(fake)2 0.2778 (0.2143)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1567 (-0.1595)\n",
            "Epoch: [5][150/195]\tTime  0.355 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5675 (0.7183)\tD(fake)1 0.1254 (0.2847)\tD(fake)2 0.3904 (0.2154)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1593)\n",
            "Epoch: [5][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6802 (0.7199)\tD(fake)1 0.2361 (0.2840)\tD(fake)2 0.3390 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1595)\n",
            "Epoch: [5][170/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7601 (0.7180)\tD(fake)1 0.4145 (0.2859)\tD(fake)2 0.1833 (0.2171)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1593)\n",
            "Epoch: [5][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7316 (0.7171)\tD(fake)1 0.2532 (0.2867)\tD(fake)2 0.1767 (0.2181)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1544 (-0.1590)\n",
            "Epoch: [5][190/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7933 (0.7162)\tD(fake)1 0.4141 (0.2883)\tD(fake)2 0.1608 (0.2197)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1583)\n",
            "Epoch: [6][  0/195]\tTime  0.610 ( 0.610)\tData  0.215 ( 0.215)\tD(real) 0.7487 (0.7487)\tD(fake)1 0.3397 (0.3397)\tD(fake)2 0.1956 (0.1956)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1569)\n",
            "Epoch: [6][ 10/195]\tTime  0.345 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.8729 (0.7085)\tD(fake)1 0.4395 (0.3115)\tD(fake)2 0.0416 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1000 (-0.1519)\n",
            "Epoch: [6][ 20/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.011)\tD(real) 0.7777 (0.7088)\tD(fake)1 0.3542 (0.2930)\tD(fake)2 0.1791 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1535 (-0.1542)\n",
            "Epoch: [6][ 30/195]\tTime  0.345 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7264 (0.7193)\tD(fake)1 0.1648 (0.2805)\tD(fake)2 0.2269 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1679 (-0.1567)\n",
            "Epoch: [6][ 40/195]\tTime  0.346 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7470 (0.7203)\tD(fake)1 0.3948 (0.2809)\tD(fake)2 0.1920 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1553 (-0.1564)\n",
            "Epoch: [6][ 50/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6292 (0.7177)\tD(fake)1 0.2129 (0.2804)\tD(fake)2 0.2648 (0.2246)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1554)\n",
            "Epoch: [6][ 60/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8755 (0.7208)\tD(fake)1 0.4331 (0.2804)\tD(fake)2 0.1767 (0.2223)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1564)\n",
            "Epoch: [6][ 70/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6476 (0.7218)\tD(fake)1 0.1679 (0.2772)\tD(fake)2 0.2896 (0.2203)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1257 (-0.1555)\n",
            "Epoch: [6][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7728 (0.7210)\tD(fake)1 0.3963 (0.2803)\tD(fake)2 0.2042 (0.2221)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1561)\n",
            "Epoch: [6][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6672 (0.7154)\tD(fake)1 0.2750 (0.2845)\tD(fake)2 0.2260 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1559)\n",
            "Epoch: [6][100/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7605 (0.7162)\tD(fake)1 0.3155 (0.2841)\tD(fake)2 0.1966 (0.2265)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1434 (-0.1556)\n",
            "Epoch: [6][110/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8851 (0.7185)\tD(fake)1 0.4232 (0.2832)\tD(fake)2 0.0723 (0.2262)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1519 (-0.1553)\n",
            "Epoch: [6][120/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7174 (0.7172)\tD(fake)1 0.2986 (0.2830)\tD(fake)2 0.2680 (0.2271)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1552)\n",
            "Epoch: [6][130/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7702 (0.7194)\tD(fake)1 0.1627 (0.2801)\tD(fake)2 0.2149 (0.2238)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1593 (-0.1549)\n",
            "Epoch: [6][140/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7464 (0.7235)\tD(fake)1 0.2832 (0.2762)\tD(fake)2 0.2361 (0.2201)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1544)\n",
            "Epoch: [6][150/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7649 (0.7231)\tD(fake)1 0.3301 (0.2781)\tD(fake)2 0.2311 (0.2215)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1549)\n",
            "Epoch: [6][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5363 (0.7211)\tD(fake)1 0.1122 (0.2784)\tD(fake)2 0.4459 (0.2226)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1554)\n",
            "Epoch: [6][170/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6488 (0.7188)\tD(fake)1 0.2503 (0.2811)\tD(fake)2 0.2979 (0.2243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1555)\n",
            "Epoch: [6][180/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.5610 (0.7175)\tD(fake)1 0.1336 (0.2819)\tD(fake)2 0.3770 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1557)\n",
            "Epoch: [6][190/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6734 (0.7178)\tD(fake)1 0.2068 (0.2825)\tD(fake)2 0.2802 (0.2243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1743 (-0.1563)\n",
            "Epoch: [7][  0/195]\tTime  0.599 ( 0.599)\tData  0.204 ( 0.204)\tD(real) 0.8467 (0.8467)\tD(fake)1 0.3579 (0.3579)\tD(fake)2 0.1166 (0.1166)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1657)\n",
            "Epoch: [7][ 10/195]\tTime  0.353 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.6678 (0.7342)\tD(fake)1 0.2373 (0.2688)\tD(fake)2 0.2244 (0.2004)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1051 (-0.1569)\n",
            "Epoch: [7][ 20/195]\tTime  0.346 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.6089 (0.7025)\tD(fake)1 0.2979 (0.3113)\tD(fake)2 0.3244 (0.2432)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1638 (-0.1561)\n",
            "Epoch: [7][ 30/195]\tTime  0.350 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.6865 (0.6978)\tD(fake)1 0.2249 (0.3120)\tD(fake)2 0.3012 (0.2481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1562)\n",
            "Epoch: [7][ 40/195]\tTime  0.346 ( 0.357)\tData  0.000 ( 0.005)\tD(real) 0.6662 (0.6896)\tD(fake)1 0.3292 (0.3121)\tD(fake)2 0.2476 (0.2498)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1580)\n",
            "Epoch: [7][ 50/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7720 (0.6885)\tD(fake)1 0.4327 (0.3124)\tD(fake)2 0.1044 (0.2490)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1563)\n",
            "Epoch: [7][ 60/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7641 (0.6855)\tD(fake)1 0.3997 (0.3140)\tD(fake)2 0.2234 (0.2537)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1575)\n",
            "Epoch: [7][ 70/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.5950 (0.6850)\tD(fake)1 0.2204 (0.3120)\tD(fake)2 0.3004 (0.2538)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1575)\n",
            "Epoch: [7][ 80/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7139 (0.6887)\tD(fake)1 0.2295 (0.3085)\tD(fake)2 0.2550 (0.2504)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1583)\n",
            "Epoch: [7][ 90/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7795 (0.6938)\tD(fake)1 0.2872 (0.3043)\tD(fake)2 0.1697 (0.2467)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1579)\n",
            "Epoch: [7][100/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7657 (0.6986)\tD(fake)1 0.2886 (0.2997)\tD(fake)2 0.2539 (0.2433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1584)\n",
            "Epoch: [7][110/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.8928 (0.7067)\tD(fake)1 0.4574 (0.2934)\tD(fake)2 0.1181 (0.2359)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1579)\n",
            "Epoch: [7][120/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7251 (0.7078)\tD(fake)1 0.2343 (0.2925)\tD(fake)2 0.2506 (0.2355)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1570)\n",
            "Epoch: [7][130/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6637 (0.7112)\tD(fake)1 0.2144 (0.2901)\tD(fake)2 0.3250 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1495 (-0.1570)\n",
            "Epoch: [7][140/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5565 (0.7095)\tD(fake)1 0.2271 (0.2913)\tD(fake)2 0.3703 (0.2346)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1565 (-0.1568)\n",
            "Epoch: [7][150/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6243 (0.7047)\tD(fake)1 0.3669 (0.2963)\tD(fake)2 0.2701 (0.2384)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1573)\n",
            "Epoch: [7][160/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7464 (0.7042)\tD(fake)1 0.3018 (0.2969)\tD(fake)2 0.1843 (0.2387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1575)\n",
            "Epoch: [7][170/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7220 (0.7063)\tD(fake)1 0.2779 (0.2952)\tD(fake)2 0.1843 (0.2371)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1509 (-0.1577)\n",
            "Epoch: [7][180/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7103 (0.7068)\tD(fake)1 0.2663 (0.2943)\tD(fake)2 0.3047 (0.2370)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1548 (-0.1582)\n",
            "Epoch: [7][190/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6684 (0.7066)\tD(fake)1 0.3426 (0.2948)\tD(fake)2 0.2993 (0.2377)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1267 (-0.1582)\n",
            "Epoch: [8][  0/195]\tTime  0.617 ( 0.617)\tData  0.216 ( 0.216)\tD(real) 0.7050 (0.7050)\tD(fake)1 0.2914 (0.2914)\tD(fake)2 0.2250 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1263 (-0.1263)\n",
            "Epoch: [8][ 10/195]\tTime  0.351 ( 0.374)\tData  0.000 ( 0.020)\tD(real) 0.8795 (0.7489)\tD(fake)1 0.3629 (0.2616)\tD(fake)2 0.0811 (0.2032)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1580)\n",
            "Epoch: [8][ 20/195]\tTime  0.348 ( 0.363)\tData  0.000 ( 0.011)\tD(real) 0.6875 (0.7384)\tD(fake)1 0.1845 (0.2544)\tD(fake)2 0.3228 (0.2097)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1623)\n",
            "Epoch: [8][ 30/195]\tTime  0.345 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6806 (0.7292)\tD(fake)1 0.3172 (0.2701)\tD(fake)2 0.2344 (0.2140)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1592)\n",
            "Epoch: [8][ 40/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.7613 (0.7251)\tD(fake)1 0.3721 (0.2743)\tD(fake)2 0.1569 (0.2180)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1585)\n",
            "Epoch: [8][ 50/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7010 (0.7195)\tD(fake)1 0.2806 (0.2767)\tD(fake)2 0.2666 (0.2247)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1588)\n",
            "Epoch: [8][ 60/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7681 (0.7185)\tD(fake)1 0.3118 (0.2786)\tD(fake)2 0.1450 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1584)\n",
            "Epoch: [8][ 70/195]\tTime  0.353 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7081 (0.7206)\tD(fake)1 0.2722 (0.2766)\tD(fake)2 0.2715 (0.2242)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1400 (-0.1579)\n",
            "Epoch: [8][ 80/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7067 (0.7214)\tD(fake)1 0.2390 (0.2767)\tD(fake)2 0.1908 (0.2233)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1579)\n",
            "Epoch: [8][ 90/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7611 (0.7186)\tD(fake)1 0.4301 (0.2813)\tD(fake)2 0.2086 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1343 (-0.1565)\n",
            "Epoch: [8][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6783 (0.7150)\tD(fake)1 0.2466 (0.2833)\tD(fake)2 0.2632 (0.2280)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1510 (-0.1564)\n",
            "Epoch: [8][110/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.9425 (0.7186)\tD(fake)1 0.4432 (0.2814)\tD(fake)2 0.1283 (0.2257)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1562)\n",
            "Epoch: [8][120/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6894 (0.7180)\tD(fake)1 0.2406 (0.2805)\tD(fake)2 0.2041 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1565)\n",
            "Epoch: [8][130/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7989 (0.7199)\tD(fake)1 0.3154 (0.2794)\tD(fake)2 0.1321 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1565)\n",
            "Epoch: [8][140/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9040 (0.7247)\tD(fake)1 0.2682 (0.2757)\tD(fake)2 0.0024 (0.2212)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1567)\n",
            "Epoch: [8][150/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7588 (0.7273)\tD(fake)1 0.3135 (0.2727)\tD(fake)2 0.1787 (0.2199)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1569)\n",
            "Epoch: [8][160/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8178 (0.7263)\tD(fake)1 0.4059 (0.2746)\tD(fake)2 0.0830 (0.2210)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1570)\n",
            "Epoch: [8][170/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7442 (0.7245)\tD(fake)1 0.3505 (0.2756)\tD(fake)2 0.2007 (0.2229)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1574)\n",
            "Epoch: [8][180/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6642 (0.7230)\tD(fake)1 0.2447 (0.2763)\tD(fake)2 0.2487 (0.2241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1578)\n",
            "Epoch: [8][190/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6376 (0.7230)\tD(fake)1 0.2141 (0.2761)\tD(fake)2 0.2792 (0.2243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1579)\n",
            "Epoch: [9][  0/195]\tTime  0.592 ( 0.592)\tData  0.209 ( 0.209)\tD(real) 0.7677 (0.7677)\tD(fake)1 0.3546 (0.3546)\tD(fake)2 0.1384 (0.1384)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1406 (-0.1406)\n",
            "Epoch: [9][ 10/195]\tTime  0.345 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.8791 (0.7467)\tD(fake)1 0.4317 (0.2683)\tD(fake)2 0.1731 (0.2072)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1639 (-0.1518)\n",
            "Epoch: [9][ 20/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.8352 (0.7374)\tD(fake)1 0.3912 (0.2750)\tD(fake)2 0.0663 (0.2154)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1562)\n",
            "Epoch: [9][ 30/195]\tTime  0.348 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6269 (0.7224)\tD(fake)1 0.2544 (0.2798)\tD(fake)2 0.3064 (0.2301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1679 (-0.1578)\n",
            "Epoch: [9][ 40/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7058 (0.7144)\tD(fake)1 0.3025 (0.2864)\tD(fake)2 0.2246 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1567)\n",
            "Epoch: [9][ 50/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7253 (0.7163)\tD(fake)1 0.2956 (0.2842)\tD(fake)2 0.1989 (0.2301)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1408 (-0.1567)\n",
            "Epoch: [9][ 60/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6834 (0.7176)\tD(fake)1 0.2509 (0.2846)\tD(fake)2 0.2247 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1367 (-0.1572)\n",
            "Epoch: [9][ 70/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5979 (0.7155)\tD(fake)1 0.1956 (0.2848)\tD(fake)2 0.4066 (0.2314)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1605 (-0.1574)\n",
            "Epoch: [9][ 80/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7477 (0.7141)\tD(fake)1 0.3055 (0.2872)\tD(fake)2 0.2019 (0.2322)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1572)\n",
            "Epoch: [9][ 90/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7875 (0.7150)\tD(fake)1 0.3426 (0.2864)\tD(fake)2 0.1579 (0.2307)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1479 (-0.1569)\n",
            "Epoch: [9][100/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6870 (0.7166)\tD(fake)1 0.1999 (0.2826)\tD(fake)2 0.2757 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1494 (-0.1574)\n",
            "Epoch: [9][110/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6901 (0.7190)\tD(fake)1 0.2372 (0.2802)\tD(fake)2 0.2410 (0.2267)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1573)\n",
            "Epoch: [9][120/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6855 (0.7181)\tD(fake)1 0.3412 (0.2825)\tD(fake)2 0.2703 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1575)\n",
            "Epoch: [9][130/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7342 (0.7184)\tD(fake)1 0.2032 (0.2837)\tD(fake)2 0.2067 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1573)\n",
            "Epoch: [9][140/195]\tTime  0.355 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7459 (0.7200)\tD(fake)1 0.3319 (0.2819)\tD(fake)2 0.2754 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1520 (-0.1575)\n",
            "Epoch: [9][150/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5782 (0.7185)\tD(fake)1 0.1479 (0.2816)\tD(fake)2 0.3901 (0.2276)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1578)\n",
            "Epoch: [9][160/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7654 (0.7186)\tD(fake)1 0.3430 (0.2829)\tD(fake)2 0.1568 (0.2272)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1581)\n",
            "Epoch: [9][170/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6027 (0.7165)\tD(fake)1 0.1947 (0.2836)\tD(fake)2 0.3625 (0.2290)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1477 (-0.1582)\n",
            "Epoch: [9][180/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7245 (0.7180)\tD(fake)1 0.2113 (0.2827)\tD(fake)2 0.2602 (0.2283)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1576)\n",
            "Epoch: [9][190/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7048 (0.7191)\tD(fake)1 0.2858 (0.2821)\tD(fake)2 0.2413 (0.2276)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1579)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9naW-A2OGLMg",
        "outputId": "5fd8cd9c-1c6a-4565-d696-505a13f3b063"
      },
      "source": [
        "run(10)\n",
        "save_vid()\n",
        "save()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.601 ( 0.601)\tData  0.208 ( 0.208)\tD(real) 0.6716 (0.6716)\tD(fake)1 0.2358 (0.2358)\tD(fake)2 0.3084 (0.3084)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1493 (-0.1493)\n",
            "Epoch: [0][ 10/195]\tTime  0.349 ( 0.375)\tData  0.000 ( 0.019)\tD(real) 0.5043 (0.7087)\tD(fake)1 0.0872 (0.2803)\tD(fake)2 0.3296 (0.2363)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1586)\n",
            "Epoch: [0][ 20/195]\tTime  0.367 ( 0.365)\tData  0.000 ( 0.010)\tD(real) 0.8672 (0.7161)\tD(fake)1 0.5236 (0.2952)\tD(fake)2 0.0763 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1298 (-0.1597)\n",
            "Epoch: [0][ 30/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.007)\tD(real) 0.7266 (0.7031)\tD(fake)1 0.2953 (0.2949)\tD(fake)2 0.2204 (0.2393)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1603)\n",
            "Epoch: [0][ 40/195]\tTime  0.342 ( 0.357)\tData  0.000 ( 0.005)\tD(real) 0.8067 (0.7063)\tD(fake)1 0.3836 (0.2944)\tD(fake)2 0.1275 (0.2372)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0856 (-0.1589)\n",
            "Epoch: [0][ 50/195]\tTime  0.353 ( 0.356)\tData  0.000 ( 0.004)\tD(real) 0.7321 (0.7092)\tD(fake)1 0.2635 (0.2896)\tD(fake)2 0.2060 (0.2324)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1591)\n",
            "Epoch: [0][ 60/195]\tTime  0.355 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7402 (0.7156)\tD(fake)1 0.2113 (0.2858)\tD(fake)2 0.2122 (0.2300)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1585)\n",
            "Epoch: [0][ 70/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.8398 (0.7260)\tD(fake)1 0.3060 (0.2783)\tD(fake)2 0.0326 (0.2213)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1589)\n",
            "Epoch: [0][ 80/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7574 (0.7281)\tD(fake)1 0.2095 (0.2736)\tD(fake)2 0.2113 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1595)\n",
            "Epoch: [0][ 90/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7333 (0.7279)\tD(fake)1 0.3208 (0.2738)\tD(fake)2 0.2019 (0.2192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1600)\n",
            "Epoch: [0][100/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.5518 (0.7258)\tD(fake)1 0.0866 (0.2732)\tD(fake)2 0.4010 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1512 (-0.1603)\n",
            "Epoch: [0][110/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6363 (0.7233)\tD(fake)1 0.2718 (0.2770)\tD(fake)2 0.3126 (0.2241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1596)\n",
            "Epoch: [0][120/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6646 (0.7189)\tD(fake)1 0.3117 (0.2820)\tD(fake)2 0.2768 (0.2284)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1493 (-0.1589)\n",
            "Epoch: [0][130/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7873 (0.7184)\tD(fake)1 0.3018 (0.2827)\tD(fake)2 0.1628 (0.2295)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1586)\n",
            "Epoch: [0][140/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7145 (0.7172)\tD(fake)1 0.3290 (0.2843)\tD(fake)2 0.1932 (0.2300)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1589)\n",
            "Epoch: [0][150/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7417 (0.7168)\tD(fake)1 0.2937 (0.2843)\tD(fake)2 0.1800 (0.2297)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1589)\n",
            "Epoch: [0][160/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7443 (0.7155)\tD(fake)1 0.3274 (0.2848)\tD(fake)2 0.1662 (0.2290)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1428 (-0.1587)\n",
            "Epoch: [0][170/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6101 (0.7175)\tD(fake)1 0.0542 (0.2817)\tD(fake)2 0.3233 (0.2266)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1586)\n",
            "Epoch: [0][180/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.8054 (0.7189)\tD(fake)1 0.3180 (0.2821)\tD(fake)2 0.1012 (0.2251)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1586)\n",
            "Epoch: [0][190/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7078 (0.7186)\tD(fake)1 0.3597 (0.2821)\tD(fake)2 0.2423 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1225 (-0.1581)\n",
            "Epoch: [1][  0/195]\tTime  0.621 ( 0.621)\tData  0.213 ( 0.213)\tD(real) 0.6525 (0.6525)\tD(fake)1 0.2429 (0.2429)\tD(fake)2 0.3206 (0.3206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1520 (-0.1520)\n",
            "Epoch: [1][ 10/195]\tTime  0.347 ( 0.374)\tData  0.000 ( 0.020)\tD(real) 0.7895 (0.7278)\tD(fake)1 0.3418 (0.2778)\tD(fake)2 0.1903 (0.2312)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1606)\n",
            "Epoch: [1][ 20/195]\tTime  0.349 ( 0.363)\tData  0.000 ( 0.011)\tD(real) 0.7568 (0.7155)\tD(fake)1 0.3538 (0.2867)\tD(fake)2 0.2201 (0.2396)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1437 (-0.1548)\n",
            "Epoch: [1][ 30/195]\tTime  0.349 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6106 (0.7055)\tD(fake)1 0.1305 (0.2873)\tD(fake)2 0.4001 (0.2452)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1582)\n",
            "Epoch: [1][ 40/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.6928 (0.7091)\tD(fake)1 0.2675 (0.2898)\tD(fake)2 0.1637 (0.2351)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1585)\n",
            "Epoch: [1][ 50/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8361 (0.7132)\tD(fake)1 0.3578 (0.2857)\tD(fake)2 0.1466 (0.2259)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1354 (-0.1572)\n",
            "Epoch: [1][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6064 (0.7133)\tD(fake)1 0.1991 (0.2847)\tD(fake)2 0.3138 (0.2264)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1442 (-0.1573)\n",
            "Epoch: [1][ 70/195]\tTime  0.355 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.8923 (0.7146)\tD(fake)1 0.5085 (0.2883)\tD(fake)2 0.1375 (0.2290)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1538 (-0.1564)\n",
            "Epoch: [1][ 80/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7945 (0.7122)\tD(fake)1 0.2352 (0.2878)\tD(fake)2 0.1551 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1567)\n",
            "Epoch: [1][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7611 (0.7209)\tD(fake)1 0.1976 (0.2801)\tD(fake)2 0.1749 (0.2216)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1423 (-0.1563)\n",
            "Epoch: [1][100/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7448 (0.7259)\tD(fake)1 0.1656 (0.2745)\tD(fake)2 0.2377 (0.2160)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1568)\n",
            "Epoch: [1][110/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7175 (0.7310)\tD(fake)1 0.1315 (0.2690)\tD(fake)2 0.2320 (0.2112)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1567)\n",
            "Epoch: [1][120/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7582 (0.7343)\tD(fake)1 0.2769 (0.2660)\tD(fake)2 0.2179 (0.2093)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1575)\n",
            "Epoch: [1][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7068 (0.7346)\tD(fake)1 0.2745 (0.2671)\tD(fake)2 0.1546 (0.2099)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1570)\n",
            "Epoch: [1][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5715 (0.7303)\tD(fake)1 0.2403 (0.2703)\tD(fake)2 0.3082 (0.2134)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1500 (-0.1574)\n",
            "Epoch: [1][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8723 (0.7292)\tD(fake)1 0.3985 (0.2718)\tD(fake)2 0.1733 (0.2150)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1575)\n",
            "Epoch: [1][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7561 (0.7290)\tD(fake)1 0.2859 (0.2717)\tD(fake)2 0.1480 (0.2152)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1507 (-0.1575)\n",
            "Epoch: [1][170/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9063 (0.7293)\tD(fake)1 0.4689 (0.2735)\tD(fake)2 0.0864 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1497 (-0.1576)\n",
            "Epoch: [1][180/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7312 (0.7276)\tD(fake)1 0.4141 (0.2751)\tD(fake)2 0.1211 (0.2171)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1573)\n",
            "Epoch: [1][190/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6900 (0.7247)\tD(fake)1 0.1814 (0.2756)\tD(fake)2 0.2779 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1568)\n",
            "Epoch: [2][  0/195]\tTime  0.604 ( 0.604)\tData  0.213 ( 0.213)\tD(real) 0.6395 (0.6395)\tD(fake)1 0.2209 (0.2209)\tD(fake)2 0.3124 (0.3124)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1694)\n",
            "Epoch: [2][ 10/195]\tTime  0.349 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.7008 (0.6916)\tD(fake)1 0.2676 (0.3024)\tD(fake)2 0.2693 (0.2602)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1665)\n",
            "Epoch: [2][ 20/195]\tTime  0.345 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6685 (0.6981)\tD(fake)1 0.3024 (0.3007)\tD(fake)2 0.2977 (0.2564)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1616)\n",
            "Epoch: [2][ 30/195]\tTime  0.342 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6869 (0.6959)\tD(fake)1 0.2822 (0.3026)\tD(fake)2 0.2814 (0.2558)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1606 (-0.1615)\n",
            "Epoch: [2][ 40/195]\tTime  0.352 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7502 (0.6959)\tD(fake)1 0.3593 (0.3037)\tD(fake)2 0.2336 (0.2540)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1600)\n",
            "Epoch: [2][ 50/195]\tTime  0.353 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6531 (0.6914)\tD(fake)1 0.3071 (0.3074)\tD(fake)2 0.3342 (0.2575)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1594)\n",
            "Epoch: [2][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8090 (0.6991)\tD(fake)1 0.2361 (0.3038)\tD(fake)2 0.1198 (0.2509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1483 (-0.1597)\n",
            "Epoch: [2][ 70/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.9117 (0.7112)\tD(fake)1 0.3834 (0.2947)\tD(fake)2 0.0025 (0.2413)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1601 (-0.1603)\n",
            "Epoch: [2][ 80/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6498 (0.7085)\tD(fake)1 0.2556 (0.2925)\tD(fake)2 0.3195 (0.2427)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1603)\n",
            "Epoch: [2][ 90/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6509 (0.7067)\tD(fake)1 0.3264 (0.2939)\tD(fake)2 0.3143 (0.2434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1601)\n",
            "Epoch: [2][100/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6172 (0.7033)\tD(fake)1 0.2661 (0.2966)\tD(fake)2 0.2475 (0.2456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1598)\n",
            "Epoch: [2][110/195]\tTime  0.355 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6427 (0.7014)\tD(fake)1 0.3237 (0.2991)\tD(fake)2 0.3285 (0.2483)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1530 (-0.1597)\n",
            "Epoch: [2][120/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7008 (0.7012)\tD(fake)1 0.2032 (0.2996)\tD(fake)2 0.2445 (0.2481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1601)\n",
            "Epoch: [2][130/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5998 (0.7024)\tD(fake)1 0.2156 (0.2971)\tD(fake)2 0.2917 (0.2452)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1600)\n",
            "Epoch: [2][140/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7062 (0.7025)\tD(fake)1 0.2186 (0.2958)\tD(fake)2 0.2711 (0.2438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1603)\n",
            "Epoch: [2][150/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6708 (0.7025)\tD(fake)1 0.3587 (0.2968)\tD(fake)2 0.2898 (0.2437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1599)\n",
            "Epoch: [2][160/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.9171 (0.7037)\tD(fake)1 0.5017 (0.2976)\tD(fake)2 0.0286 (0.2426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1596)\n",
            "Epoch: [2][170/195]\tTime  0.358 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6868 (0.7013)\tD(fake)1 0.3695 (0.2987)\tD(fake)2 0.2137 (0.2439)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1453 (-0.1592)\n",
            "Epoch: [2][180/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7014 (0.6996)\tD(fake)1 0.3270 (0.3004)\tD(fake)2 0.2881 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1591)\n",
            "Epoch: [2][190/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7637 (0.6997)\tD(fake)1 0.3591 (0.3004)\tD(fake)2 0.0917 (0.2457)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1592)\n",
            "Epoch: [3][  0/195]\tTime  0.605 ( 0.605)\tData  0.215 ( 0.215)\tD(real) 0.7319 (0.7319)\tD(fake)1 0.3069 (0.3069)\tD(fake)2 0.2122 (0.2122)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1689)\n",
            "Epoch: [3][ 10/195]\tTime  0.346 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.6414 (0.7069)\tD(fake)1 0.2520 (0.2892)\tD(fake)2 0.2986 (0.2332)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1468 (-0.1542)\n",
            "Epoch: [3][ 20/195]\tTime  0.346 ( 0.361)\tData  0.000 ( 0.011)\tD(real) 0.8874 (0.7255)\tD(fake)1 0.2708 (0.2812)\tD(fake)2 0.0547 (0.2161)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1394 (-0.1502)\n",
            "Epoch: [3][ 30/195]\tTime  0.349 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7375 (0.7416)\tD(fake)1 0.1807 (0.2616)\tD(fake)2 0.2297 (0.2070)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1540)\n",
            "Epoch: [3][ 40/195]\tTime  0.351 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.6997 (0.7421)\tD(fake)1 0.2501 (0.2601)\tD(fake)2 0.2666 (0.2049)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1531)\n",
            "Epoch: [3][ 50/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6686 (0.7419)\tD(fake)1 0.1704 (0.2629)\tD(fake)2 0.2942 (0.2076)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1558)\n",
            "Epoch: [3][ 60/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6188 (0.7347)\tD(fake)1 0.3560 (0.2717)\tD(fake)2 0.2256 (0.2132)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1300 (-0.1567)\n",
            "Epoch: [3][ 70/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6237 (0.7245)\tD(fake)1 0.2281 (0.2775)\tD(fake)2 0.3699 (0.2223)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1566)\n",
            "Epoch: [3][ 80/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6401 (0.7198)\tD(fake)1 0.3534 (0.2833)\tD(fake)2 0.2505 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1746 (-0.1576)\n",
            "Epoch: [3][ 90/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8194 (0.7178)\tD(fake)1 0.3900 (0.2851)\tD(fake)2 0.2473 (0.2282)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1570)\n",
            "Epoch: [3][100/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7267 (0.7174)\tD(fake)1 0.3087 (0.2864)\tD(fake)2 0.1602 (0.2280)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1573)\n",
            "Epoch: [3][110/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.9116 (0.7225)\tD(fake)1 0.3537 (0.2830)\tD(fake)2 0.0926 (0.2247)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1570)\n",
            "Epoch: [3][120/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6940 (0.7221)\tD(fake)1 0.2879 (0.2830)\tD(fake)2 0.2020 (0.2255)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1578)\n",
            "Epoch: [3][130/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6836 (0.7179)\tD(fake)1 0.3542 (0.2861)\tD(fake)2 0.2183 (0.2287)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1581)\n",
            "Epoch: [3][140/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8293 (0.7164)\tD(fake)1 0.3751 (0.2870)\tD(fake)2 0.1212 (0.2297)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1578)\n",
            "Epoch: [3][150/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8502 (0.7181)\tD(fake)1 0.3499 (0.2851)\tD(fake)2 0.1325 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1482 (-0.1580)\n",
            "Epoch: [3][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7753 (0.7191)\tD(fake)1 0.3716 (0.2833)\tD(fake)2 0.2935 (0.2269)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1580)\n",
            "Epoch: [3][170/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6380 (0.7171)\tD(fake)1 0.2489 (0.2843)\tD(fake)2 0.3283 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1375 (-0.1580)\n",
            "Epoch: [3][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7249 (0.7174)\tD(fake)1 0.2226 (0.2842)\tD(fake)2 0.2714 (0.2278)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1146 (-0.1574)\n",
            "Epoch: [3][190/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7031 (0.7176)\tD(fake)1 0.2916 (0.2841)\tD(fake)2 0.2846 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1573)\n",
            "Epoch: [4][  0/195]\tTime  0.616 ( 0.616)\tData  0.204 ( 0.204)\tD(real) 0.7458 (0.7458)\tD(fake)1 0.2900 (0.2900)\tD(fake)2 0.2075 (0.2075)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1621)\n",
            "Epoch: [4][ 10/195]\tTime  0.347 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.8335 (0.7357)\tD(fake)1 0.4068 (0.2714)\tD(fake)2 0.2196 (0.2192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1544 (-0.1528)\n",
            "Epoch: [4][ 20/195]\tTime  0.351 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.8223 (0.7353)\tD(fake)1 0.3339 (0.2716)\tD(fake)2 0.0591 (0.2123)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1526)\n",
            "Epoch: [4][ 30/195]\tTime  0.345 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7003 (0.7296)\tD(fake)1 0.2482 (0.2681)\tD(fake)2 0.2118 (0.2142)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1530 (-0.1553)\n",
            "Epoch: [4][ 40/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7728 (0.7294)\tD(fake)1 0.3334 (0.2696)\tD(fake)2 0.1483 (0.2143)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1564 (-0.1558)\n",
            "Epoch: [4][ 50/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6981 (0.7291)\tD(fake)1 0.1577 (0.2662)\tD(fake)2 0.2394 (0.2148)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1605 (-0.1558)\n",
            "Epoch: [4][ 60/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8450 (0.7332)\tD(fake)1 0.3565 (0.2660)\tD(fake)2 0.0422 (0.2111)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1565)\n",
            "Epoch: [4][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7319 (0.7278)\tD(fake)1 0.3124 (0.2709)\tD(fake)2 0.2223 (0.2189)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1555)\n",
            "Epoch: [4][ 80/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7978 (0.7300)\tD(fake)1 0.3356 (0.2725)\tD(fake)2 0.2095 (0.2201)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1519 (-0.1545)\n",
            "Epoch: [4][ 90/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7158 (0.7270)\tD(fake)1 0.2958 (0.2751)\tD(fake)2 0.2339 (0.2224)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1550)\n",
            "Epoch: [4][100/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6318 (0.7241)\tD(fake)1 0.2845 (0.2767)\tD(fake)2 0.2400 (0.2239)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1555)\n",
            "Epoch: [4][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7721 (0.7183)\tD(fake)1 0.4464 (0.2830)\tD(fake)2 0.1636 (0.2291)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1562)\n",
            "Epoch: [4][120/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7095 (0.7122)\tD(fake)1 0.3775 (0.2883)\tD(fake)2 0.2018 (0.2349)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1566)\n",
            "Epoch: [4][130/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8263 (0.7118)\tD(fake)1 0.3868 (0.2884)\tD(fake)2 0.1284 (0.2350)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1600 (-0.1566)\n",
            "Epoch: [4][140/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7096 (0.7140)\tD(fake)1 0.1580 (0.2853)\tD(fake)2 0.3058 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1568)\n",
            "Epoch: [4][150/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8729 (0.7153)\tD(fake)1 0.3968 (0.2860)\tD(fake)2 0.0391 (0.2318)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1570)\n",
            "Epoch: [4][160/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6419 (0.7122)\tD(fake)1 0.3813 (0.2878)\tD(fake)2 0.2950 (0.2338)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1243 (-0.1570)\n",
            "Epoch: [4][170/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8135 (0.7130)\tD(fake)1 0.2660 (0.2881)\tD(fake)2 0.1467 (0.2329)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1025 (-0.1573)\n",
            "Epoch: [4][180/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7395 (0.7133)\tD(fake)1 0.3904 (0.2880)\tD(fake)2 0.2420 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1758 (-0.1574)\n",
            "Epoch: [4][190/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7708 (0.7108)\tD(fake)1 0.2776 (0.2895)\tD(fake)2 0.1770 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1387 (-0.1570)\n",
            "Epoch: [5][  0/195]\tTime  0.624 ( 0.624)\tData  0.228 ( 0.228)\tD(real) 0.7370 (0.7370)\tD(fake)1 0.2119 (0.2119)\tD(fake)2 0.1976 (0.1976)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1526 (-0.1526)\n",
            "Epoch: [5][ 10/195]\tTime  0.349 ( 0.376)\tData  0.000 ( 0.021)\tD(real) 0.6719 (0.7260)\tD(fake)1 0.2602 (0.2756)\tD(fake)2 0.2043 (0.2165)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1549)\n",
            "Epoch: [5][ 20/195]\tTime  0.345 ( 0.364)\tData  0.000 ( 0.011)\tD(real) 0.7168 (0.7115)\tD(fake)1 0.2442 (0.2906)\tD(fake)2 0.2024 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1565)\n",
            "Epoch: [5][ 30/195]\tTime  0.348 ( 0.359)\tData  0.000 ( 0.008)\tD(real) 0.6417 (0.7108)\tD(fake)1 0.3613 (0.2972)\tD(fake)2 0.2974 (0.2270)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1568)\n",
            "Epoch: [5][ 40/195]\tTime  0.349 ( 0.357)\tData  0.000 ( 0.006)\tD(real) 0.7148 (0.7102)\tD(fake)1 0.2894 (0.2981)\tD(fake)2 0.2314 (0.2335)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1745 (-0.1591)\n",
            "Epoch: [5][ 50/195]\tTime  0.348 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.6392 (0.7019)\tD(fake)1 0.4127 (0.3052)\tD(fake)2 0.2330 (0.2381)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1584)\n",
            "Epoch: [5][ 60/195]\tTime  0.354 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7801 (0.6957)\tD(fake)1 0.3341 (0.3053)\tD(fake)2 0.1659 (0.2404)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1583)\n",
            "Epoch: [5][ 70/195]\tTime  0.343 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6714 (0.6986)\tD(fake)1 0.3004 (0.3016)\tD(fake)2 0.3044 (0.2384)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1587)\n",
            "Epoch: [5][ 80/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7083 (0.6940)\tD(fake)1 0.3857 (0.3098)\tD(fake)2 0.1868 (0.2438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1588)\n",
            "Epoch: [5][ 90/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6351 (0.6928)\tD(fake)1 0.2837 (0.3094)\tD(fake)2 0.3082 (0.2457)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1591)\n",
            "Epoch: [5][100/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7241 (0.6910)\tD(fake)1 0.3857 (0.3106)\tD(fake)2 0.2577 (0.2470)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1595)\n",
            "Epoch: [5][110/195]\tTime  0.358 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7377 (0.6919)\tD(fake)1 0.3076 (0.3097)\tD(fake)2 0.2358 (0.2469)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1515 (-0.1593)\n",
            "Epoch: [5][120/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6198 (0.6937)\tD(fake)1 0.1489 (0.3074)\tD(fake)2 0.2825 (0.2465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1497 (-0.1582)\n",
            "Epoch: [5][130/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5710 (0.6934)\tD(fake)1 0.3149 (0.3088)\tD(fake)2 0.3903 (0.2477)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1600 (-0.1586)\n",
            "Epoch: [5][140/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6924 (0.6944)\tD(fake)1 0.1360 (0.3078)\tD(fake)2 0.3163 (0.2476)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1587)\n",
            "Epoch: [5][150/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7923 (0.6975)\tD(fake)1 0.3613 (0.3065)\tD(fake)2 0.1622 (0.2454)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1579)\n",
            "Epoch: [5][160/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6266 (0.6994)\tD(fake)1 0.2017 (0.3029)\tD(fake)2 0.4259 (0.2436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1581)\n",
            "Epoch: [5][170/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7196 (0.6995)\tD(fake)1 0.2677 (0.3040)\tD(fake)2 0.2229 (0.2436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1582)\n",
            "Epoch: [5][180/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6264 (0.6986)\tD(fake)1 0.3062 (0.3037)\tD(fake)2 0.2526 (0.2428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1585)\n",
            "Epoch: [5][190/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7201 (0.6972)\tD(fake)1 0.2664 (0.3055)\tD(fake)2 0.2331 (0.2440)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1580)\n",
            "Epoch: [6][  0/195]\tTime  0.604 ( 0.604)\tData  0.216 ( 0.216)\tD(real) 0.8495 (0.8495)\tD(fake)1 0.3683 (0.3683)\tD(fake)2 0.0924 (0.0924)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1679 (-0.1679)\n",
            "Epoch: [6][ 10/195]\tTime  0.349 ( 0.375)\tData  0.000 ( 0.020)\tD(real) 0.5661 (0.7217)\tD(fake)1 0.0608 (0.2632)\tD(fake)2 0.3409 (0.2124)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1598 (-0.1621)\n",
            "Epoch: [6][ 20/195]\tTime  0.351 ( 0.363)\tData  0.000 ( 0.011)\tD(real) 0.7782 (0.7288)\tD(fake)1 0.3695 (0.2728)\tD(fake)2 0.2245 (0.2184)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1614)\n",
            "Epoch: [6][ 30/195]\tTime  0.348 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.7209 (0.7276)\tD(fake)1 0.3110 (0.2755)\tD(fake)2 0.2610 (0.2235)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1582)\n",
            "Epoch: [6][ 40/195]\tTime  0.350 ( 0.357)\tData  0.000 ( 0.006)\tD(real) 0.7156 (0.7172)\tD(fake)1 0.3315 (0.2878)\tD(fake)2 0.2168 (0.2290)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1584)\n",
            "Epoch: [6][ 50/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.6647 (0.7139)\tD(fake)1 0.2185 (0.2864)\tD(fake)2 0.3263 (0.2272)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1679 (-0.1591)\n",
            "Epoch: [6][ 60/195]\tTime  0.343 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.6643 (0.7112)\tD(fake)1 0.3776 (0.2915)\tD(fake)2 0.3617 (0.2338)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1597)\n",
            "Epoch: [6][ 70/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.003)\tD(real) 0.7371 (0.7092)\tD(fake)1 0.3027 (0.2942)\tD(fake)2 0.1746 (0.2355)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1600)\n",
            "Epoch: [6][ 80/195]\tTime  0.353 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.6948 (0.7082)\tD(fake)1 0.2650 (0.2927)\tD(fake)2 0.2487 (0.2343)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1422 (-0.1601)\n",
            "Epoch: [6][ 90/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7659 (0.7101)\tD(fake)1 0.3466 (0.2911)\tD(fake)2 0.1353 (0.2319)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1605)\n",
            "Epoch: [6][100/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6064 (0.7076)\tD(fake)1 0.2329 (0.2921)\tD(fake)2 0.3044 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1053 (-0.1598)\n",
            "Epoch: [6][110/195]\tTime  0.358 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7707 (0.7097)\tD(fake)1 0.3123 (0.2909)\tD(fake)2 0.1451 (0.2330)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1511 (-0.1598)\n",
            "Epoch: [6][120/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7337 (0.7120)\tD(fake)1 0.2434 (0.2879)\tD(fake)2 0.2477 (0.2318)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1597)\n",
            "Epoch: [6][130/195]\tTime  0.352 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.8040 (0.7158)\tD(fake)1 0.3875 (0.2869)\tD(fake)2 0.1407 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1594)\n",
            "Epoch: [6][140/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7377 (0.7148)\tD(fake)1 0.3276 (0.2872)\tD(fake)2 0.1787 (0.2303)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1552 (-0.1596)\n",
            "Epoch: [6][150/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7000 (0.7127)\tD(fake)1 0.3764 (0.2892)\tD(fake)2 0.2586 (0.2329)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1595)\n",
            "Epoch: [6][160/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7992 (0.7119)\tD(fake)1 0.3916 (0.2898)\tD(fake)2 0.0841 (0.2325)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1593)\n",
            "Epoch: [6][170/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6811 (0.7105)\tD(fake)1 0.3788 (0.2902)\tD(fake)2 0.2579 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1063 (-0.1590)\n",
            "Epoch: [6][180/195]\tTime  0.342 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.8299 (0.7097)\tD(fake)1 0.3867 (0.2914)\tD(fake)2 0.1302 (0.2334)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1556 (-0.1586)\n",
            "Epoch: [6][190/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.001)\tD(real) 0.8657 (0.7116)\tD(fake)1 0.3835 (0.2899)\tD(fake)2 0.0507 (0.2322)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1581)\n",
            "Epoch: [7][  0/195]\tTime  0.594 ( 0.594)\tData  0.211 ( 0.211)\tD(real) 0.7606 (0.7606)\tD(fake)1 0.3594 (0.3594)\tD(fake)2 0.2467 (0.2467)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1566 (-0.1566)\n",
            "Epoch: [7][ 10/195]\tTime  0.345 ( 0.375)\tData  0.000 ( 0.020)\tD(real) 0.7936 (0.7288)\tD(fake)1 0.3631 (0.2984)\tD(fake)2 0.0732 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1656)\n",
            "Epoch: [7][ 20/195]\tTime  0.352 ( 0.368)\tData  0.000 ( 0.011)\tD(real) 0.6233 (0.6963)\tD(fake)1 0.3437 (0.3113)\tD(fake)2 0.3171 (0.2520)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1270 (-0.1620)\n",
            "Epoch: [7][ 30/195]\tTime  0.348 ( 0.362)\tData  0.000 ( 0.007)\tD(real) 0.6119 (0.6890)\tD(fake)1 0.2297 (0.3148)\tD(fake)2 0.3392 (0.2597)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1725 (-0.1618)\n",
            "Epoch: [7][ 40/195]\tTime  0.357 ( 0.360)\tData  0.000 ( 0.006)\tD(real) 0.7484 (0.6873)\tD(fake)1 0.3661 (0.3144)\tD(fake)2 0.2404 (0.2551)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1614)\n",
            "Epoch: [7][ 50/195]\tTime  0.347 ( 0.358)\tData  0.000 ( 0.005)\tD(real) 0.6700 (0.6888)\tD(fake)1 0.2546 (0.3129)\tD(fake)2 0.2759 (0.2515)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1421 (-0.1592)\n",
            "Epoch: [7][ 60/195]\tTime  0.350 ( 0.357)\tData  0.001 ( 0.004)\tD(real) 0.6288 (0.6929)\tD(fake)1 0.1582 (0.3078)\tD(fake)2 0.2930 (0.2502)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1459 (-0.1574)\n",
            "Epoch: [7][ 70/195]\tTime  0.350 ( 0.356)\tData  0.000 ( 0.003)\tD(real) 0.6350 (0.6956)\tD(fake)1 0.2974 (0.3058)\tD(fake)2 0.3098 (0.2484)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1576)\n",
            "Epoch: [7][ 80/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.003)\tD(real) 0.7713 (0.6992)\tD(fake)1 0.3015 (0.3025)\tD(fake)2 0.1921 (0.2450)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1581)\n",
            "Epoch: [7][ 90/195]\tTime  0.351 ( 0.355)\tData  0.000 ( 0.003)\tD(real) 0.7021 (0.6987)\tD(fake)1 0.3246 (0.3035)\tD(fake)2 0.2417 (0.2457)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1582)\n",
            "Epoch: [7][100/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.002)\tD(real) 0.7905 (0.7014)\tD(fake)1 0.4009 (0.3022)\tD(fake)2 0.0921 (0.2430)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1587)\n",
            "Epoch: [7][110/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.002)\tD(real) 0.6754 (0.6996)\tD(fake)1 0.3145 (0.3013)\tD(fake)2 0.2355 (0.2429)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1639 (-0.1591)\n",
            "Epoch: [7][120/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.002)\tD(real) 0.6518 (0.6986)\tD(fake)1 0.2762 (0.3012)\tD(fake)2 0.2579 (0.2431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1564 (-0.1588)\n",
            "Epoch: [7][130/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.002)\tD(real) 0.6990 (0.6970)\tD(fake)1 0.3054 (0.3021)\tD(fake)2 0.2362 (0.2447)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1583 (-0.1589)\n",
            "Epoch: [7][140/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6754 (0.6973)\tD(fake)1 0.2807 (0.3023)\tD(fake)2 0.2373 (0.2454)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1587)\n",
            "Epoch: [7][150/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.8598 (0.6982)\tD(fake)1 0.3724 (0.3021)\tD(fake)2 0.1062 (0.2456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1586)\n",
            "Epoch: [7][160/195]\tTime  0.342 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.8479 (0.7006)\tD(fake)1 0.3476 (0.3001)\tD(fake)2 0.1174 (0.2437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1467 (-0.1583)\n",
            "Epoch: [7][170/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7999 (0.7036)\tD(fake)1 0.3717 (0.2982)\tD(fake)2 0.0821 (0.2416)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1581)\n",
            "Epoch: [7][180/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5736 (0.7019)\tD(fake)1 0.2268 (0.2995)\tD(fake)2 0.3892 (0.2438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1711 (-0.1580)\n",
            "Epoch: [7][190/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.001)\tD(real) 0.6186 (0.6991)\tD(fake)1 0.2440 (0.3009)\tD(fake)2 0.3428 (0.2442)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1699 (-0.1584)\n",
            "Epoch: [8][  0/195]\tTime  0.611 ( 0.611)\tData  0.208 ( 0.208)\tD(real) 0.6780 (0.6780)\tD(fake)1 0.3177 (0.3177)\tD(fake)2 0.2754 (0.2754)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1657)\n",
            "Epoch: [8][ 10/195]\tTime  0.351 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.6952 (0.7048)\tD(fake)1 0.2894 (0.2941)\tD(fake)2 0.2653 (0.2417)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1163 (-0.1579)\n",
            "Epoch: [8][ 20/195]\tTime  0.346 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.6753 (0.7041)\tD(fake)1 0.1448 (0.2870)\tD(fake)2 0.2715 (0.2300)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1574)\n",
            "Epoch: [8][ 30/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.5602 (0.7169)\tD(fake)1 0.1213 (0.2732)\tD(fake)2 0.3826 (0.2173)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1581)\n",
            "Epoch: [8][ 40/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7946 (0.7198)\tD(fake)1 0.2931 (0.2790)\tD(fake)2 0.1281 (0.2192)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1582)\n",
            "Epoch: [8][ 50/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7475 (0.7216)\tD(fake)1 0.2726 (0.2797)\tD(fake)2 0.2203 (0.2226)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1437 (-0.1587)\n",
            "Epoch: [8][ 60/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6414 (0.7193)\tD(fake)1 0.2563 (0.2811)\tD(fake)2 0.3117 (0.2239)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1592)\n",
            "Epoch: [8][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6302 (0.7138)\tD(fake)1 0.2352 (0.2839)\tD(fake)2 0.3080 (0.2269)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1601 (-0.1594)\n",
            "Epoch: [8][ 80/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7790 (0.7139)\tD(fake)1 0.2527 (0.2854)\tD(fake)2 0.1509 (0.2248)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1431 (-0.1590)\n",
            "Epoch: [8][ 90/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6408 (0.7190)\tD(fake)1 0.2059 (0.2798)\tD(fake)2 0.2882 (0.2199)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1736 (-0.1591)\n",
            "Epoch: [8][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7175 (0.7175)\tD(fake)1 0.2738 (0.2826)\tD(fake)2 0.1436 (0.2193)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1588)\n",
            "Epoch: [8][110/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8476 (0.7253)\tD(fake)1 0.2856 (0.2762)\tD(fake)2 0.0821 (0.2110)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1591)\n",
            "Epoch: [8][120/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6847 (0.7255)\tD(fake)1 0.2827 (0.2756)\tD(fake)2 0.2291 (0.2111)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1587)\n",
            "Epoch: [8][130/195]\tTime  0.354 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6480 (0.7246)\tD(fake)1 0.2170 (0.2756)\tD(fake)2 0.2793 (0.2127)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1581)\n",
            "Epoch: [8][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7598 (0.7235)\tD(fake)1 0.4053 (0.2784)\tD(fake)2 0.2795 (0.2160)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0973 (-0.1569)\n",
            "Epoch: [8][150/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7244 (0.7232)\tD(fake)1 0.2556 (0.2786)\tD(fake)2 0.2906 (0.2177)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1571)\n",
            "Epoch: [8][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6835 (0.7235)\tD(fake)1 0.2332 (0.2779)\tD(fake)2 0.3075 (0.2184)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1568)\n",
            "Epoch: [8][170/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8230 (0.7225)\tD(fake)1 0.4140 (0.2792)\tD(fake)2 0.2048 (0.2195)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1715 (-0.1572)\n",
            "Epoch: [8][180/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.8783 (0.7212)\tD(fake)1 0.4584 (0.2807)\tD(fake)2 0.1121 (0.2206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1576)\n",
            "Epoch: [8][190/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6587 (0.7207)\tD(fake)1 0.1778 (0.2794)\tD(fake)2 0.3489 (0.2211)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1578)\n",
            "Epoch: [9][  0/195]\tTime  0.601 ( 0.601)\tData  0.222 ( 0.222)\tD(real) 0.7102 (0.7102)\tD(fake)1 0.2384 (0.2384)\tD(fake)2 0.2341 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1649)\n",
            "Epoch: [9][ 10/195]\tTime  0.353 ( 0.372)\tData  0.000 ( 0.021)\tD(real) 0.8428 (0.7248)\tD(fake)1 0.3908 (0.2943)\tD(fake)2 0.1575 (0.2252)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1178 (-0.1579)\n",
            "Epoch: [9][ 20/195]\tTime  0.357 ( 0.363)\tData  0.000 ( 0.011)\tD(real) 0.6759 (0.7281)\tD(fake)1 0.1995 (0.2758)\tD(fake)2 0.2904 (0.2251)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1556)\n",
            "Epoch: [9][ 30/195]\tTime  0.347 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7288 (0.7251)\tD(fake)1 0.3268 (0.2792)\tD(fake)2 0.1603 (0.2234)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1542)\n",
            "Epoch: [9][ 40/195]\tTime  0.353 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.8137 (0.7212)\tD(fake)1 0.3789 (0.2784)\tD(fake)2 0.2278 (0.2237)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1563)\n",
            "Epoch: [9][ 50/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.5698 (0.7192)\tD(fake)1 0.1274 (0.2752)\tD(fake)2 0.4121 (0.2243)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1576)\n",
            "Epoch: [9][ 60/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6859 (0.7194)\tD(fake)1 0.2821 (0.2801)\tD(fake)2 0.2547 (0.2254)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1577)\n",
            "Epoch: [9][ 70/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.9043 (0.7269)\tD(fake)1 0.3303 (0.2769)\tD(fake)2 -0.0400 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1586)\n",
            "Epoch: [9][ 80/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6526 (0.7278)\tD(fake)1 0.2055 (0.2714)\tD(fake)2 0.2964 (0.2165)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1477 (-0.1580)\n",
            "Epoch: [9][ 90/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8140 (0.7305)\tD(fake)1 0.2962 (0.2703)\tD(fake)2 0.0566 (0.2134)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1574 (-0.1578)\n",
            "Epoch: [9][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8025 (0.7318)\tD(fake)1 0.3352 (0.2684)\tD(fake)2 0.0932 (0.2132)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1575)\n",
            "Epoch: [9][110/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6838 (0.7299)\tD(fake)1 0.2397 (0.2682)\tD(fake)2 0.2637 (0.2157)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1574)\n",
            "Epoch: [9][120/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7729 (0.7286)\tD(fake)1 0.3798 (0.2705)\tD(fake)2 0.2111 (0.2181)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1576)\n",
            "Epoch: [9][130/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8118 (0.7273)\tD(fake)1 0.4002 (0.2732)\tD(fake)2 0.2026 (0.2213)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1576)\n",
            "Epoch: [9][140/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6520 (0.7256)\tD(fake)1 0.1930 (0.2729)\tD(fake)2 0.3203 (0.2218)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1578)\n",
            "Epoch: [9][150/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7184 (0.7244)\tD(fake)1 0.2709 (0.2740)\tD(fake)2 0.2286 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1574)\n",
            "Epoch: [9][160/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6841 (0.7246)\tD(fake)1 0.2185 (0.2738)\tD(fake)2 0.2585 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1569)\n",
            "Epoch: [9][170/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8662 (0.7245)\tD(fake)1 0.4743 (0.2753)\tD(fake)2 0.1729 (0.2232)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1570)\n",
            "Epoch: [9][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7190 (0.7233)\tD(fake)1 0.2940 (0.2758)\tD(fake)2 0.2478 (0.2248)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1247 (-0.1569)\n",
            "Epoch: [9][190/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7933 (0.7254)\tD(fake)1 0.2179 (0.2735)\tD(fake)2 0.1862 (0.2229)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1570)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzUaCS1tS8YV",
        "outputId": "b5a195c4-e41c-4d93-9ccc-04c2d6b5b88b"
      },
      "source": [
        "run(15)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.602 ( 0.602)\tData  0.202 ( 0.202)\tD(real) 0.9245 (0.9245)\tD(fake)1 0.3555 (0.3555)\tD(fake)2 -0.0108 (-0.0108)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1610)\n",
            "Epoch: [0][ 10/195]\tTime  0.348 ( 0.375)\tData  0.000 ( 0.019)\tD(real) 0.5855 (0.7314)\tD(fake)1 0.1728 (0.2600)\tD(fake)2 0.4532 (0.2276)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1559 (-0.1594)\n",
            "Epoch: [0][ 20/195]\tTime  0.380 ( 0.364)\tData  0.000 ( 0.010)\tD(real) 0.7247 (0.7151)\tD(fake)1 0.3265 (0.2893)\tD(fake)2 0.2485 (0.2404)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1718 (-0.1572)\n",
            "Epoch: [0][ 30/195]\tTime  0.347 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.7099 (0.7142)\tD(fake)1 0.2364 (0.2898)\tD(fake)2 0.2530 (0.2431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1551 (-0.1571)\n",
            "Epoch: [0][ 40/195]\tTime  0.353 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7307 (0.7171)\tD(fake)1 0.3343 (0.2898)\tD(fake)2 0.2446 (0.2445)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1565)\n",
            "Epoch: [0][ 50/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7441 (0.7071)\tD(fake)1 0.4378 (0.2994)\tD(fake)2 0.1777 (0.2500)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1584 (-0.1578)\n",
            "Epoch: [0][ 60/195]\tTime  0.354 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7916 (0.7083)\tD(fake)1 0.3404 (0.2981)\tD(fake)2 0.1763 (0.2482)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1578)\n",
            "Epoch: [0][ 70/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.5873 (0.7120)\tD(fake)1 0.0965 (0.2913)\tD(fake)2 0.2818 (0.2425)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1569)\n",
            "Epoch: [0][ 80/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.8520 (0.7144)\tD(fake)1 0.4598 (0.2919)\tD(fake)2 0.1525 (0.2414)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1567 (-0.1554)\n",
            "Epoch: [0][ 90/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6826 (0.7130)\tD(fake)1 0.2421 (0.2916)\tD(fake)2 0.3339 (0.2432)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1551)\n",
            "Epoch: [0][100/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.8553 (0.7172)\tD(fake)1 0.3877 (0.2902)\tD(fake)2 0.1029 (0.2391)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1555)\n",
            "Epoch: [0][110/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5837 (0.7134)\tD(fake)1 0.2341 (0.2909)\tD(fake)2 0.3570 (0.2412)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1562)\n",
            "Epoch: [0][120/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.8464 (0.7113)\tD(fake)1 0.4327 (0.2935)\tD(fake)2 0.2038 (0.2422)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1267 (-0.1562)\n",
            "Epoch: [0][130/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8164 (0.7107)\tD(fake)1 0.4337 (0.2939)\tD(fake)2 0.1921 (0.2433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1559)\n",
            "Epoch: [0][140/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6454 (0.7084)\tD(fake)1 0.2275 (0.2952)\tD(fake)2 0.3565 (0.2458)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1608 (-0.1562)\n",
            "Epoch: [0][150/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6934 (0.7076)\tD(fake)1 0.2756 (0.2954)\tD(fake)2 0.2401 (0.2440)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1503 (-0.1560)\n",
            "Epoch: [0][160/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5748 (0.7073)\tD(fake)1 0.1621 (0.2955)\tD(fake)2 0.1271 (0.2421)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1463 (-0.1558)\n",
            "Epoch: [0][170/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7179 (0.7062)\tD(fake)1 0.2639 (0.2967)\tD(fake)2 0.2209 (0.2440)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1551 (-0.1555)\n",
            "Epoch: [0][180/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7601 (0.7085)\tD(fake)1 0.2978 (0.2945)\tD(fake)2 0.1786 (0.2421)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1451 (-0.1551)\n",
            "Epoch: [0][190/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6480 (0.7087)\tD(fake)1 0.2305 (0.2936)\tD(fake)2 0.2981 (0.2420)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1185 (-0.1550)\n",
            "Epoch: [1][  0/195]\tTime  0.610 ( 0.610)\tData  0.218 ( 0.218)\tD(real) 0.6266 (0.6266)\tD(fake)1 0.2524 (0.2524)\tD(fake)2 0.3545 (0.3545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1680)\n",
            "Epoch: [1][ 10/195]\tTime  0.344 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.7455 (0.7142)\tD(fake)1 0.2692 (0.2758)\tD(fake)2 0.2136 (0.2363)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1626)\n",
            "Epoch: [1][ 20/195]\tTime  0.354 ( 0.363)\tData  0.000 ( 0.011)\tD(real) 0.7683 (0.7231)\tD(fake)1 0.2976 (0.2730)\tD(fake)2 0.2100 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1287 (-0.1565)\n",
            "Epoch: [1][ 30/195]\tTime  0.346 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.7699 (0.7265)\tD(fake)1 0.3304 (0.2743)\tD(fake)2 0.2028 (0.2337)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1565)\n",
            "Epoch: [1][ 40/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.6667 (0.7252)\tD(fake)1 0.2292 (0.2738)\tD(fake)2 0.2684 (0.2342)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1576)\n",
            "Epoch: [1][ 50/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.8151 (0.7256)\tD(fake)1 0.4155 (0.2769)\tD(fake)2 0.1390 (0.2318)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1573)\n",
            "Epoch: [1][ 60/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7672 (0.7225)\tD(fake)1 0.3656 (0.2788)\tD(fake)2 0.1627 (0.2318)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1598 (-0.1567)\n",
            "Epoch: [1][ 70/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.8981 (0.7260)\tD(fake)1 0.2870 (0.2758)\tD(fake)2 0.0773 (0.2281)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1573)\n",
            "Epoch: [1][ 80/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6383 (0.7308)\tD(fake)1 0.0935 (0.2673)\tD(fake)2 0.3206 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1579)\n",
            "Epoch: [1][ 90/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8944 (0.7346)\tD(fake)1 0.4507 (0.2664)\tD(fake)2 0.1225 (0.2170)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1124 (-0.1568)\n",
            "Epoch: [1][100/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7652 (0.7323)\tD(fake)1 0.2655 (0.2682)\tD(fake)2 0.1713 (0.2175)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1553)\n",
            "Epoch: [1][110/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7408 (0.7344)\tD(fake)1 0.2400 (0.2658)\tD(fake)2 0.2310 (0.2163)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1472 (-0.1552)\n",
            "Epoch: [1][120/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5989 (0.7346)\tD(fake)1 0.1307 (0.2648)\tD(fake)2 0.2963 (0.2155)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1554)\n",
            "Epoch: [1][130/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8182 (0.7311)\tD(fake)1 0.5112 (0.2699)\tD(fake)2 0.1853 (0.2191)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1474 (-0.1553)\n",
            "Epoch: [1][140/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6863 (0.7257)\tD(fake)1 0.2612 (0.2731)\tD(fake)2 0.2587 (0.2233)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1549)\n",
            "Epoch: [1][150/195]\tTime  0.356 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8169 (0.7257)\tD(fake)1 0.3540 (0.2740)\tD(fake)2 0.1428 (0.2236)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1131 (-0.1546)\n",
            "Epoch: [1][160/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6328 (0.7242)\tD(fake)1 0.1633 (0.2742)\tD(fake)2 0.3164 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1549)\n",
            "Epoch: [1][170/195]\tTime  0.355 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7573 (0.7254)\tD(fake)1 0.3008 (0.2743)\tD(fake)2 0.2051 (0.2244)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1552)\n",
            "Epoch: [1][180/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7007 (0.7244)\tD(fake)1 0.2987 (0.2753)\tD(fake)2 0.2250 (0.2255)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1553)\n",
            "Epoch: [1][190/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6166 (0.7252)\tD(fake)1 0.0771 (0.2743)\tD(fake)2 0.1626 (0.2244)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1542 (-0.1553)\n",
            "Epoch: [2][  0/195]\tTime  0.611 ( 0.611)\tData  0.211 ( 0.211)\tD(real) 0.7799 (0.7799)\tD(fake)1 0.2592 (0.2592)\tD(fake)2 0.1834 (0.1834)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1417 (-0.1417)\n",
            "Epoch: [2][ 10/195]\tTime  0.344 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.7735 (0.7501)\tD(fake)1 0.3515 (0.2640)\tD(fake)2 0.1505 (0.2044)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1385 (-0.1525)\n",
            "Epoch: [2][ 20/195]\tTime  0.346 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.8257 (0.7374)\tD(fake)1 0.3963 (0.2764)\tD(fake)2 0.2083 (0.2233)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1557)\n",
            "Epoch: [2][ 30/195]\tTime  0.351 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7978 (0.7308)\tD(fake)1 0.3780 (0.2831)\tD(fake)2 0.0657 (0.2264)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1556)\n",
            "Epoch: [2][ 40/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.7895 (0.7193)\tD(fake)1 0.3721 (0.2886)\tD(fake)2 0.1669 (0.2327)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1565)\n",
            "Epoch: [2][ 50/195]\tTime  0.351 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7484 (0.7174)\tD(fake)1 0.4424 (0.2904)\tD(fake)2 0.1436 (0.2330)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1505 (-0.1573)\n",
            "Epoch: [2][ 60/195]\tTime  0.354 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.6658 (0.7093)\tD(fake)1 0.3178 (0.2963)\tD(fake)2 0.2396 (0.2397)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1485 (-0.1576)\n",
            "Epoch: [2][ 70/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.5720 (0.7039)\tD(fake)1 0.2416 (0.2970)\tD(fake)2 0.4093 (0.2422)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1461 (-0.1574)\n",
            "Epoch: [2][ 80/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6491 (0.7029)\tD(fake)1 0.1714 (0.2980)\tD(fake)2 0.3488 (0.2431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1573)\n",
            "Epoch: [2][ 90/195]\tTime  0.353 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7062 (0.7060)\tD(fake)1 0.2676 (0.2981)\tD(fake)2 0.2281 (0.2412)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1575)\n",
            "Epoch: [2][100/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7441 (0.7121)\tD(fake)1 0.2141 (0.2928)\tD(fake)2 0.2137 (0.2367)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1577)\n",
            "Epoch: [2][110/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6474 (0.7171)\tD(fake)1 0.1738 (0.2882)\tD(fake)2 0.2100 (0.2323)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1535 (-0.1579)\n",
            "Epoch: [2][120/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6545 (0.7181)\tD(fake)1 0.2335 (0.2876)\tD(fake)2 0.3419 (0.2313)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1582)\n",
            "Epoch: [2][130/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6810 (0.7159)\tD(fake)1 0.2945 (0.2895)\tD(fake)2 0.2513 (0.2325)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1581)\n",
            "Epoch: [2][140/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7332 (0.7149)\tD(fake)1 0.3008 (0.2901)\tD(fake)2 0.2253 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1580)\n",
            "Epoch: [2][150/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6830 (0.7137)\tD(fake)1 0.2594 (0.2911)\tD(fake)2 0.2615 (0.2338)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1580)\n",
            "Epoch: [2][160/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5921 (0.7127)\tD(fake)1 0.1962 (0.2907)\tD(fake)2 0.3190 (0.2331)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1583)\n",
            "Epoch: [2][170/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6798 (0.7115)\tD(fake)1 0.2814 (0.2910)\tD(fake)2 0.2974 (0.2332)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1577)\n",
            "Epoch: [2][180/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.5800 (0.7108)\tD(fake)1 0.1871 (0.2912)\tD(fake)2 0.2646 (0.2330)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1580)\n",
            "Epoch: [2][190/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7979 (0.7103)\tD(fake)1 0.3664 (0.2921)\tD(fake)2 0.1924 (0.2338)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1577)\n",
            "Epoch: [3][  0/195]\tTime  0.590 ( 0.590)\tData  0.210 ( 0.210)\tD(real) 0.7348 (0.7348)\tD(fake)1 0.2309 (0.2309)\tD(fake)2 0.2300 (0.2300)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1652)\n",
            "Epoch: [3][ 10/195]\tTime  0.352 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.7787 (0.7701)\tD(fake)1 0.2811 (0.2360)\tD(fake)2 0.1885 (0.1869)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1556 (-0.1574)\n",
            "Epoch: [3][ 20/195]\tTime  0.349 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7529 (0.7522)\tD(fake)1 0.3040 (0.2529)\tD(fake)2 0.2516 (0.2050)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1404 (-0.1570)\n",
            "Epoch: [3][ 30/195]\tTime  0.350 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7676 (0.7402)\tD(fake)1 0.3547 (0.2672)\tD(fake)2 0.1504 (0.2151)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1367 (-0.1587)\n",
            "Epoch: [3][ 40/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6202 (0.7311)\tD(fake)1 0.1657 (0.2700)\tD(fake)2 0.3113 (0.2250)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1596)\n",
            "Epoch: [3][ 50/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7761 (0.7274)\tD(fake)1 0.3487 (0.2753)\tD(fake)2 0.1478 (0.2263)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1604)\n",
            "Epoch: [3][ 60/195]\tTime  0.359 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7243 (0.7238)\tD(fake)1 0.3103 (0.2782)\tD(fake)2 0.2101 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1601)\n",
            "Epoch: [3][ 70/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6482 (0.7191)\tD(fake)1 0.1805 (0.2807)\tD(fake)2 0.3305 (0.2337)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1579 (-0.1608)\n",
            "Epoch: [3][ 80/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6543 (0.7197)\tD(fake)1 0.1485 (0.2795)\tD(fake)2 0.3690 (0.2334)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1609)\n",
            "Epoch: [3][ 90/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7932 (0.7218)\tD(fake)1 0.3619 (0.2802)\tD(fake)2 0.1874 (0.2321)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1609)\n",
            "Epoch: [3][100/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6629 (0.7189)\tD(fake)1 0.2885 (0.2812)\tD(fake)2 0.3349 (0.2349)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1605)\n",
            "Epoch: [3][110/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7049 (0.7184)\tD(fake)1 0.3019 (0.2826)\tD(fake)2 0.2863 (0.2355)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1606)\n",
            "Epoch: [3][120/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7720 (0.7175)\tD(fake)1 0.3878 (0.2847)\tD(fake)2 0.1823 (0.2366)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1599)\n",
            "Epoch: [3][130/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5550 (0.7130)\tD(fake)1 0.2285 (0.2881)\tD(fake)2 0.3774 (0.2409)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1253 (-0.1600)\n",
            "Epoch: [3][140/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.4828 (0.7097)\tD(fake)1 0.1499 (0.2910)\tD(fake)2 0.3840 (0.2436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1708 (-0.1595)\n",
            "Epoch: [3][150/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7618 (0.7074)\tD(fake)1 0.3937 (0.2941)\tD(fake)2 0.1691 (0.2454)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1370 (-0.1590)\n",
            "Epoch: [3][160/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7418 (0.7067)\tD(fake)1 0.2782 (0.2942)\tD(fake)2 0.1632 (0.2458)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1589)\n",
            "Epoch: [3][170/195]\tTime  0.354 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7471 (0.7086)\tD(fake)1 0.2291 (0.2918)\tD(fake)2 0.1646 (0.2438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1585 (-0.1588)\n",
            "Epoch: [3][180/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7488 (0.7099)\tD(fake)1 0.4229 (0.2916)\tD(fake)2 0.2058 (0.2430)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1565 (-0.1587)\n",
            "Epoch: [3][190/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.5756 (0.7070)\tD(fake)1 0.2962 (0.2947)\tD(fake)2 0.3546 (0.2454)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1555 (-0.1585)\n",
            "Epoch: [4][  0/195]\tTime  0.611 ( 0.611)\tData  0.213 ( 0.213)\tD(real) 0.6110 (0.6110)\tD(fake)1 0.2472 (0.2472)\tD(fake)2 0.3109 (0.3109)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1485 (-0.1485)\n",
            "Epoch: [4][ 10/195]\tTime  0.351 ( 0.376)\tData  0.000 ( 0.020)\tD(real) 0.7005 (0.6921)\tD(fake)1 0.2749 (0.2981)\tD(fake)2 0.2655 (0.2552)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1155 (-0.1533)\n",
            "Epoch: [4][ 20/195]\tTime  0.352 ( 0.364)\tData  0.000 ( 0.011)\tD(real) 0.6748 (0.6742)\tD(fake)1 0.2995 (0.3128)\tD(fake)2 0.2818 (0.2681)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1563)\n",
            "Epoch: [4][ 30/195]\tTime  0.351 ( 0.360)\tData  0.000 ( 0.007)\tD(real) 0.7666 (0.6892)\tD(fake)1 0.3683 (0.3066)\tD(fake)2 0.2149 (0.2598)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1506 (-0.1573)\n",
            "Epoch: [4][ 40/195]\tTime  0.348 ( 0.357)\tData  0.000 ( 0.006)\tD(real) 0.7128 (0.6952)\tD(fake)1 0.3309 (0.3032)\tD(fake)2 0.2836 (0.2586)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1587)\n",
            "Epoch: [4][ 50/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.6812 (0.6916)\tD(fake)1 0.3333 (0.3078)\tD(fake)2 0.2118 (0.2597)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1596 (-0.1600)\n",
            "Epoch: [4][ 60/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8028 (0.6964)\tD(fake)1 0.3791 (0.3025)\tD(fake)2 0.2443 (0.2533)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1528 (-0.1605)\n",
            "Epoch: [4][ 70/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7892 (0.6962)\tD(fake)1 0.3988 (0.3024)\tD(fake)2 0.1716 (0.2509)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1497 (-0.1601)\n",
            "Epoch: [4][ 80/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.6590 (0.7006)\tD(fake)1 0.0768 (0.2939)\tD(fake)2 0.3435 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1119 (-0.1587)\n",
            "Epoch: [4][ 90/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7564 (0.7066)\tD(fake)1 0.2681 (0.2924)\tD(fake)2 0.2127 (0.2415)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1588)\n",
            "Epoch: [4][100/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6236 (0.7082)\tD(fake)1 0.2599 (0.2916)\tD(fake)2 0.3569 (0.2417)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1583)\n",
            "Epoch: [4][110/195]\tTime  0.352 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.5063 (0.7033)\tD(fake)1 0.1808 (0.2964)\tD(fake)2 0.4117 (0.2461)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1582)\n",
            "Epoch: [4][120/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.8543 (0.7027)\tD(fake)1 0.4409 (0.2982)\tD(fake)2 0.1744 (0.2467)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1457 (-0.1586)\n",
            "Epoch: [4][130/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6587 (0.7031)\tD(fake)1 0.3034 (0.2973)\tD(fake)2 0.3192 (0.2469)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1587)\n",
            "Epoch: [4][140/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5484 (0.7014)\tD(fake)1 0.1366 (0.2985)\tD(fake)2 0.3617 (0.2484)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1113 (-0.1579)\n",
            "Epoch: [4][150/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5819 (0.7007)\tD(fake)1 0.1617 (0.2988)\tD(fake)2 0.3663 (0.2494)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1699 (-0.1582)\n",
            "Epoch: [4][160/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6800 (0.6998)\tD(fake)1 0.2582 (0.2994)\tD(fake)2 0.3145 (0.2498)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1582)\n",
            "Epoch: [4][170/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7972 (0.7014)\tD(fake)1 0.2630 (0.2981)\tD(fake)2 0.1348 (0.2470)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1569 (-0.1577)\n",
            "Epoch: [4][180/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7054 (0.7047)\tD(fake)1 0.2171 (0.2953)\tD(fake)2 0.2359 (0.2447)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1550 (-0.1579)\n",
            "Epoch: [4][190/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6432 (0.7059)\tD(fake)1 0.2409 (0.2948)\tD(fake)2 0.2976 (0.2442)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1578)\n",
            "Epoch: [5][  0/195]\tTime  0.605 ( 0.605)\tData  0.194 ( 0.194)\tD(real) 0.8131 (0.8131)\tD(fake)1 0.3725 (0.3725)\tD(fake)2 0.0727 (0.0727)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1561 (-0.1561)\n",
            "Epoch: [5][ 10/195]\tTime  0.351 ( 0.374)\tData  0.000 ( 0.018)\tD(real) 0.7183 (0.6890)\tD(fake)1 0.2917 (0.3059)\tD(fake)2 0.2640 (0.2548)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1558)\n",
            "Epoch: [5][ 20/195]\tTime  0.346 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.6587 (0.6975)\tD(fake)1 0.2548 (0.2970)\tD(fake)2 0.2684 (0.2513)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1453 (-0.1572)\n",
            "Epoch: [5][ 30/195]\tTime  0.348 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6427 (0.6968)\tD(fake)1 0.2774 (0.3031)\tD(fake)2 0.2967 (0.2597)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1562)\n",
            "Epoch: [5][ 40/195]\tTime  0.351 ( 0.357)\tData  0.000 ( 0.005)\tD(real) 0.6904 (0.6980)\tD(fake)1 0.3590 (0.3069)\tD(fake)2 0.2537 (0.2627)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1213 (-0.1568)\n",
            "Epoch: [5][ 50/195]\tTime  0.351 ( 0.356)\tData  0.000 ( 0.004)\tD(real) 0.7950 (0.6960)\tD(fake)1 0.4029 (0.3088)\tD(fake)2 0.2226 (0.2638)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1590 (-0.1568)\n",
            "Epoch: [5][ 60/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8553 (0.6998)\tD(fake)1 0.4572 (0.3052)\tD(fake)2 0.2250 (0.2608)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1558)\n",
            "Epoch: [5][ 70/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.5192 (0.6983)\tD(fake)1 0.1474 (0.3013)\tD(fake)2 0.4472 (0.2599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1451 (-0.1560)\n",
            "Epoch: [5][ 80/195]\tTime  0.354 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7234 (0.6993)\tD(fake)1 0.2999 (0.3034)\tD(fake)2 0.2343 (0.2596)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1584 (-0.1561)\n",
            "Epoch: [5][ 90/195]\tTime  0.350 ( 0.354)\tData  0.000 ( 0.002)\tD(real) 0.8380 (0.7019)\tD(fake)1 0.3519 (0.3020)\tD(fake)2 0.0921 (0.2571)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1555)\n",
            "Epoch: [5][100/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7602 (0.7025)\tD(fake)1 0.3311 (0.2997)\tD(fake)2 0.2302 (0.2567)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1558)\n",
            "Epoch: [5][110/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7118 (0.7018)\tD(fake)1 0.3303 (0.2995)\tD(fake)2 0.2546 (0.2560)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1553)\n",
            "Epoch: [5][120/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7118 (0.7038)\tD(fake)1 0.1306 (0.2969)\tD(fake)2 0.2385 (0.2519)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1526 (-0.1553)\n",
            "Epoch: [5][130/195]\tTime  0.354 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.7244 (0.7113)\tD(fake)1 0.0725 (0.2887)\tD(fake)2 0.2664 (0.2443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1556)\n",
            "Epoch: [5][140/195]\tTime  0.352 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6880 (0.7166)\tD(fake)1 0.2139 (0.2840)\tD(fake)2 0.2315 (0.2390)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1447 (-0.1555)\n",
            "Epoch: [5][150/195]\tTime  0.354 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7299 (0.7186)\tD(fake)1 0.2380 (0.2825)\tD(fake)2 0.2410 (0.2372)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1555)\n",
            "Epoch: [5][160/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7734 (0.7204)\tD(fake)1 0.3444 (0.2816)\tD(fake)2 0.1666 (0.2357)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1556)\n",
            "Epoch: [5][170/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.001)\tD(real) 0.7466 (0.7186)\tD(fake)1 0.2973 (0.2836)\tD(fake)2 0.1900 (0.2362)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1537 (-0.1558)\n",
            "Epoch: [5][180/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.001)\tD(real) 0.8166 (0.7194)\tD(fake)1 0.4585 (0.2839)\tD(fake)2 0.1733 (0.2356)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1559)\n",
            "Epoch: [5][190/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.001)\tD(real) 0.6570 (0.7158)\tD(fake)1 0.3530 (0.2863)\tD(fake)2 0.2250 (0.2367)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1525 (-0.1560)\n",
            "Epoch: [6][  0/195]\tTime  0.599 ( 0.599)\tData  0.204 ( 0.204)\tD(real) 0.7064 (0.7064)\tD(fake)1 0.1391 (0.1391)\tD(fake)2 0.2197 (0.2197)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1537 (-0.1537)\n",
            "Epoch: [6][ 10/195]\tTime  0.347 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.7987 (0.7521)\tD(fake)1 0.2983 (0.2470)\tD(fake)2 0.0931 (0.1814)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1556)\n",
            "Epoch: [6][ 20/195]\tTime  0.346 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.6965 (0.7290)\tD(fake)1 0.3502 (0.2698)\tD(fake)2 0.1857 (0.2041)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1582)\n",
            "Epoch: [6][ 30/195]\tTime  0.350 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6998 (0.7179)\tD(fake)1 0.2849 (0.2796)\tD(fake)2 0.2355 (0.2196)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1572)\n",
            "Epoch: [6][ 40/195]\tTime  0.352 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.6033 (0.7198)\tD(fake)1 0.1474 (0.2768)\tD(fake)2 0.4760 (0.2241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1604 (-0.1567)\n",
            "Epoch: [6][ 50/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.6200 (0.7119)\tD(fake)1 0.2726 (0.2865)\tD(fake)2 0.3270 (0.2287)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1567)\n",
            "Epoch: [6][ 60/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6658 (0.7053)\tD(fake)1 0.2833 (0.2933)\tD(fake)2 0.3183 (0.2365)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1574)\n",
            "Epoch: [6][ 70/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.5957 (0.7015)\tD(fake)1 0.2864 (0.2959)\tD(fake)2 0.2905 (0.2382)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1600 (-0.1574)\n",
            "Epoch: [6][ 80/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7684 (0.7016)\tD(fake)1 0.2545 (0.2966)\tD(fake)2 0.2208 (0.2389)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1573)\n",
            "Epoch: [6][ 90/195]\tTime  0.352 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.8156 (0.7042)\tD(fake)1 0.4523 (0.2956)\tD(fake)2 0.2106 (0.2382)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1561)\n",
            "Epoch: [6][100/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.5994 (0.7006)\tD(fake)1 0.2918 (0.2984)\tD(fake)2 0.3134 (0.2427)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1586 (-0.1563)\n",
            "Epoch: [6][110/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6929 (0.6993)\tD(fake)1 0.2696 (0.2997)\tD(fake)2 0.2249 (0.2443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1560)\n",
            "Epoch: [6][120/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6751 (0.7017)\tD(fake)1 0.2478 (0.2972)\tD(fake)2 0.2364 (0.2423)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1563)\n",
            "Epoch: [6][130/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6533 (0.7032)\tD(fake)1 0.2685 (0.2967)\tD(fake)2 0.3221 (0.2428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1560)\n",
            "Epoch: [6][140/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5519 (0.7029)\tD(fake)1 0.2075 (0.2973)\tD(fake)2 0.3006 (0.2424)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1361 (-0.1559)\n",
            "Epoch: [6][150/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7422 (0.7016)\tD(fake)1 0.3294 (0.2992)\tD(fake)2 0.1659 (0.2430)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1555)\n",
            "Epoch: [6][160/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6739 (0.7012)\tD(fake)1 0.3388 (0.2991)\tD(fake)2 0.2532 (0.2432)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1558)\n",
            "Epoch: [6][170/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6003 (0.6997)\tD(fake)1 0.2484 (0.2999)\tD(fake)2 0.3687 (0.2448)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1556)\n",
            "Epoch: [6][180/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6783 (0.7008)\tD(fake)1 0.2212 (0.2998)\tD(fake)2 0.2131 (0.2445)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1561)\n",
            "Epoch: [6][190/195]\tTime  0.356 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6287 (0.7024)\tD(fake)1 0.1839 (0.2977)\tD(fake)2 0.3550 (0.2435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1284 (-0.1562)\n",
            "Epoch: [7][  0/195]\tTime  0.590 ( 0.590)\tData  0.202 ( 0.202)\tD(real) 0.6392 (0.6392)\tD(fake)1 0.2360 (0.2360)\tD(fake)2 0.2794 (0.2794)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1666)\n",
            "Epoch: [7][ 10/195]\tTime  0.358 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.7329 (0.7147)\tD(fake)1 0.3271 (0.2735)\tD(fake)2 0.1987 (0.2196)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1479 (-0.1529)\n",
            "Epoch: [7][ 20/195]\tTime  0.351 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.6946 (0.7113)\tD(fake)1 0.2394 (0.2723)\tD(fake)2 0.2697 (0.2206)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1545)\n",
            "Epoch: [7][ 30/195]\tTime  0.356 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.7384 (0.7152)\tD(fake)1 0.2851 (0.2758)\tD(fake)2 0.1996 (0.2203)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1566)\n",
            "Epoch: [7][ 40/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.005)\tD(real) 0.7414 (0.7243)\tD(fake)1 0.1956 (0.2680)\tD(fake)2 0.1781 (0.2143)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1587)\n",
            "Epoch: [7][ 50/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8988 (0.7311)\tD(fake)1 0.4200 (0.2663)\tD(fake)2 -0.0041 (0.2107)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1591)\n",
            "Epoch: [7][ 60/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7282 (0.7259)\tD(fake)1 0.3271 (0.2691)\tD(fake)2 0.2072 (0.2183)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1593)\n",
            "Epoch: [7][ 70/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7253 (0.7233)\tD(fake)1 0.2855 (0.2737)\tD(fake)2 0.2437 (0.2251)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1596)\n",
            "Epoch: [7][ 80/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7426 (0.7247)\tD(fake)1 0.2838 (0.2736)\tD(fake)2 0.1747 (0.2249)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1584)\n",
            "Epoch: [7][ 90/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7700 (0.7232)\tD(fake)1 0.3468 (0.2750)\tD(fake)2 0.1677 (0.2258)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1583)\n",
            "Epoch: [7][100/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.8325 (0.7210)\tD(fake)1 0.3534 (0.2776)\tD(fake)2 0.1383 (0.2285)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1558 (-0.1581)\n",
            "Epoch: [7][110/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6852 (0.7207)\tD(fake)1 0.2448 (0.2764)\tD(fake)2 0.2827 (0.2289)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1584)\n",
            "Epoch: [7][120/195]\tTime  0.356 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6156 (0.7220)\tD(fake)1 0.2285 (0.2755)\tD(fake)2 0.3137 (0.2282)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1588)\n",
            "Epoch: [7][130/195]\tTime  0.357 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7572 (0.7223)\tD(fake)1 0.3516 (0.2777)\tD(fake)2 0.2037 (0.2298)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1469 (-0.1588)\n",
            "Epoch: [7][140/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7243 (0.7213)\tD(fake)1 0.3221 (0.2781)\tD(fake)2 0.2417 (0.2306)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1585)\n",
            "Epoch: [7][150/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7754 (0.7207)\tD(fake)1 0.3388 (0.2781)\tD(fake)2 0.2577 (0.2305)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1738 (-0.1585)\n",
            "Epoch: [7][160/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6181 (0.7202)\tD(fake)1 0.1727 (0.2777)\tD(fake)2 0.3438 (0.2304)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1586)\n",
            "Epoch: [7][170/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8156 (0.7193)\tD(fake)1 0.4801 (0.2800)\tD(fake)2 0.1999 (0.2304)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1475 (-0.1587)\n",
            "Epoch: [7][180/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7343 (0.7212)\tD(fake)1 0.1427 (0.2775)\tD(fake)2 0.2684 (0.2285)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1585)\n",
            "Epoch: [7][190/195]\tTime  0.356 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7588 (0.7233)\tD(fake)1 0.3208 (0.2763)\tD(fake)2 0.2149 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1504 (-0.1582)\n",
            "Epoch: [8][  0/195]\tTime  0.588 ( 0.588)\tData  0.199 ( 0.199)\tD(real) 0.7386 (0.7386)\tD(fake)1 0.2297 (0.2297)\tD(fake)2 0.2286 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1616)\n",
            "Epoch: [8][ 10/195]\tTime  0.352 ( 0.372)\tData  0.000 ( 0.018)\tD(real) 0.7250 (0.7257)\tD(fake)1 0.3776 (0.2752)\tD(fake)2 0.1626 (0.2107)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1581)\n",
            "Epoch: [8][ 20/195]\tTime  0.354 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.7325 (0.7095)\tD(fake)1 0.2426 (0.2850)\tD(fake)2 0.2581 (0.2313)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1593)\n",
            "Epoch: [8][ 30/195]\tTime  0.351 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6816 (0.7185)\tD(fake)1 0.2762 (0.2806)\tD(fake)2 0.2231 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1586)\n",
            "Epoch: [8][ 40/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7096 (0.7174)\tD(fake)1 0.2874 (0.2833)\tD(fake)2 0.1944 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1380 (-0.1569)\n",
            "Epoch: [8][ 50/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8071 (0.7218)\tD(fake)1 0.2723 (0.2791)\tD(fake)2 0.1594 (0.2269)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1560)\n",
            "Epoch: [8][ 60/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8042 (0.7282)\tD(fake)1 0.3558 (0.2747)\tD(fake)2 0.1266 (0.2225)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1570)\n",
            "Epoch: [8][ 70/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7666 (0.7270)\tD(fake)1 0.2705 (0.2755)\tD(fake)2 0.1431 (0.2202)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1580)\n",
            "Epoch: [8][ 80/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.5351 (0.7308)\tD(fake)1 0.0920 (0.2689)\tD(fake)2 0.3940 (0.2157)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1587)\n",
            "Epoch: [8][ 90/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6316 (0.7292)\tD(fake)1 0.2176 (0.2726)\tD(fake)2 0.3019 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1720 (-0.1574)\n",
            "Epoch: [8][100/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6793 (0.7268)\tD(fake)1 0.2788 (0.2746)\tD(fake)2 0.2909 (0.2188)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1578)\n",
            "Epoch: [8][110/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7218 (0.7288)\tD(fake)1 0.1730 (0.2736)\tD(fake)2 0.1637 (0.2173)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1571)\n",
            "Epoch: [8][120/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6407 (0.7306)\tD(fake)1 0.1858 (0.2717)\tD(fake)2 0.3626 (0.2168)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1581)\n",
            "Epoch: [8][130/195]\tTime  0.355 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6539 (0.7298)\tD(fake)1 0.2223 (0.2734)\tD(fake)2 0.2865 (0.2175)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1588)\n",
            "Epoch: [8][140/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7377 (0.7276)\tD(fake)1 0.3613 (0.2762)\tD(fake)2 0.1690 (0.2191)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1593)\n",
            "Epoch: [8][150/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6429 (0.7243)\tD(fake)1 0.2540 (0.2777)\tD(fake)2 0.2986 (0.2218)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1595)\n",
            "Epoch: [8][160/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6519 (0.7218)\tD(fake)1 0.2725 (0.2796)\tD(fake)2 0.2888 (0.2242)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1594)\n",
            "Epoch: [8][170/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7014 (0.7204)\tD(fake)1 0.3456 (0.2812)\tD(fake)2 0.2120 (0.2257)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1597)\n",
            "Epoch: [8][180/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.7159 (0.7189)\tD(fake)1 0.2132 (0.2821)\tD(fake)2 0.2749 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1597)\n",
            "Epoch: [8][190/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6706 (0.7190)\tD(fake)1 0.2844 (0.2820)\tD(fake)2 0.2529 (0.2277)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1598)\n",
            "Epoch: [9][  0/195]\tTime  0.606 ( 0.606)\tData  0.209 ( 0.209)\tD(real) 0.5843 (0.5843)\tD(fake)1 0.1446 (0.1446)\tD(fake)2 0.3993 (0.3993)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1681)\n",
            "Epoch: [9][ 10/195]\tTime  0.350 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.6632 (0.6856)\tD(fake)1 0.3644 (0.3158)\tD(fake)2 0.2440 (0.2624)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1697 (-0.1637)\n",
            "Epoch: [9][ 20/195]\tTime  0.348 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.7950 (0.6914)\tD(fake)1 0.3223 (0.3082)\tD(fake)2 0.0917 (0.2482)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1621)\n",
            "Epoch: [9][ 30/195]\tTime  0.349 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6970 (0.6944)\tD(fake)1 0.3467 (0.2999)\tD(fake)2 0.1614 (0.2391)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1619 (-0.1606)\n",
            "Epoch: [9][ 40/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7813 (0.6968)\tD(fake)1 0.3635 (0.2988)\tD(fake)2 0.1466 (0.2410)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1616)\n",
            "Epoch: [9][ 50/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.4859 (0.6989)\tD(fake)1 0.0534 (0.2899)\tD(fake)2 0.4376 (0.2401)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1608)\n",
            "Epoch: [9][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7748 (0.7019)\tD(fake)1 0.3294 (0.2940)\tD(fake)2 0.1845 (0.2395)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1602)\n",
            "Epoch: [9][ 70/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6092 (0.7043)\tD(fake)1 0.1010 (0.2888)\tD(fake)2 0.3720 (0.2368)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1604)\n",
            "Epoch: [9][ 80/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7087 (0.7093)\tD(fake)1 0.1788 (0.2888)\tD(fake)2 0.2147 (0.2335)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1395 (-0.1596)\n",
            "Epoch: [9][ 90/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7143 (0.7185)\tD(fake)1 0.2071 (0.2815)\tD(fake)2 0.2353 (0.2279)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1603)\n",
            "Epoch: [9][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8072 (0.7238)\tD(fake)1 0.1576 (0.2805)\tD(fake)2 0.1137 (0.2208)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1601)\n",
            "Epoch: [9][110/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6403 (0.7281)\tD(fake)1 0.2419 (0.2758)\tD(fake)2 0.3269 (0.2172)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1601)\n",
            "Epoch: [9][120/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6686 (0.7245)\tD(fake)1 0.3310 (0.2798)\tD(fake)2 0.2461 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1598)\n",
            "Epoch: [9][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6713 (0.7216)\tD(fake)1 0.2919 (0.2814)\tD(fake)2 0.2820 (0.2226)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1601)\n",
            "Epoch: [9][140/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6304 (0.7171)\tD(fake)1 0.3313 (0.2862)\tD(fake)2 0.2308 (0.2271)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1597)\n",
            "Epoch: [9][150/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7428 (0.7145)\tD(fake)1 0.3340 (0.2884)\tD(fake)2 0.1894 (0.2289)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1602)\n",
            "Epoch: [9][160/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5389 (0.7134)\tD(fake)1 0.1773 (0.2884)\tD(fake)2 0.3082 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1602)\n",
            "Epoch: [9][170/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7877 (0.7125)\tD(fake)1 0.3679 (0.2909)\tD(fake)2 0.1676 (0.2313)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1602)\n",
            "Epoch: [9][180/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6599 (0.7116)\tD(fake)1 0.3144 (0.2912)\tD(fake)2 0.2678 (0.2314)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1529 (-0.1603)\n",
            "Epoch: [9][190/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6465 (0.7099)\tD(fake)1 0.2201 (0.2922)\tD(fake)2 0.1975 (0.2311)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1453 (-0.1603)\n",
            "Epoch: [10][  0/195]\tTime  0.579 ( 0.579)\tData  0.203 ( 0.203)\tD(real) 0.7565 (0.7565)\tD(fake)1 0.2912 (0.2912)\tD(fake)2 0.1708 (0.1708)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1621)\n",
            "Epoch: [10][ 10/195]\tTime  0.349 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.6849 (0.7269)\tD(fake)1 0.2338 (0.2715)\tD(fake)2 0.2600 (0.2252)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1597)\n",
            "Epoch: [10][ 20/195]\tTime  0.346 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.6564 (0.7189)\tD(fake)1 0.1939 (0.2798)\tD(fake)2 0.2759 (0.2334)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1565 (-0.1607)\n",
            "Epoch: [10][ 30/195]\tTime  0.352 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.9009 (0.7285)\tD(fake)1 0.3363 (0.2770)\tD(fake)2 0.0777 (0.2213)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1605)\n",
            "Epoch: [10][ 40/195]\tTime  0.342 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7552 (0.7416)\tD(fake)1 0.2644 (0.2624)\tD(fake)2 0.1746 (0.2093)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1165 (-0.1589)\n",
            "Epoch: [10][ 50/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.5702 (0.7379)\tD(fake)1 0.2048 (0.2634)\tD(fake)2 0.3115 (0.2124)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1587)\n",
            "Epoch: [10][ 60/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7116 (0.7222)\tD(fake)1 0.3544 (0.2779)\tD(fake)2 0.2107 (0.2228)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1592)\n",
            "Epoch: [10][ 70/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.8155 (0.7220)\tD(fake)1 0.3708 (0.2786)\tD(fake)2 0.2228 (0.2241)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1590 (-0.1592)\n",
            "Epoch: [10][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6899 (0.7219)\tD(fake)1 0.1991 (0.2768)\tD(fake)2 0.2865 (0.2244)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1554 (-0.1594)\n",
            "Epoch: [10][ 90/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7581 (0.7248)\tD(fake)1 0.3037 (0.2760)\tD(fake)2 0.1910 (0.2228)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1445 (-0.1584)\n",
            "Epoch: [10][100/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6574 (0.7234)\tD(fake)1 0.2360 (0.2776)\tD(fake)2 0.2573 (0.2257)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1513 (-0.1585)\n",
            "Epoch: [10][110/195]\tTime  0.358 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8122 (0.7208)\tD(fake)1 0.4863 (0.2805)\tD(fake)2 0.2389 (0.2288)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1518 (-0.1587)\n",
            "Epoch: [10][120/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7767 (0.7174)\tD(fake)1 0.3147 (0.2823)\tD(fake)2 0.1372 (0.2308)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1587)\n",
            "Epoch: [10][130/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7500 (0.7172)\tD(fake)1 0.3730 (0.2817)\tD(fake)2 0.1946 (0.2307)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1593)\n",
            "Epoch: [10][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7033 (0.7146)\tD(fake)1 0.3859 (0.2844)\tD(fake)2 0.2720 (0.2333)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1593)\n",
            "Epoch: [10][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7260 (0.7138)\tD(fake)1 0.2279 (0.2861)\tD(fake)2 0.2041 (0.2348)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1594)\n",
            "Epoch: [10][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6318 (0.7154)\tD(fake)1 0.1627 (0.2841)\tD(fake)2 0.2950 (0.2334)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1466 (-0.1593)\n",
            "Epoch: [10][170/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7045 (0.7134)\tD(fake)1 0.3131 (0.2859)\tD(fake)2 0.2288 (0.2339)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1437 (-0.1591)\n",
            "Epoch: [10][180/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6972 (0.7136)\tD(fake)1 0.3301 (0.2855)\tD(fake)2 0.2318 (0.2335)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1590)\n",
            "Epoch: [10][190/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.8610 (0.7119)\tD(fake)1 0.4785 (0.2878)\tD(fake)2 0.0309 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1588)\n",
            "Epoch: [11][  0/195]\tTime  0.618 ( 0.618)\tData  0.218 ( 0.218)\tD(real) 0.7760 (0.7760)\tD(fake)1 0.3241 (0.3241)\tD(fake)2 0.2493 (0.2493)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1020 (-0.1020)\n",
            "Epoch: [11][ 10/195]\tTime  0.348 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.7359 (0.7385)\tD(fake)1 0.2724 (0.2703)\tD(fake)2 0.1997 (0.2068)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1504)\n",
            "Epoch: [11][ 20/195]\tTime  0.348 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.8973 (0.7497)\tD(fake)1 0.3317 (0.2644)\tD(fake)2 0.1580 (0.2008)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1513)\n",
            "Epoch: [11][ 30/195]\tTime  0.354 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.7577 (0.7636)\tD(fake)1 0.1688 (0.2492)\tD(fake)2 0.2226 (0.1914)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1572 (-0.1526)\n",
            "Epoch: [11][ 40/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.006)\tD(real) 0.8245 (0.7617)\tD(fake)1 0.3817 (0.2508)\tD(fake)2 0.1298 (0.1894)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1601 (-0.1543)\n",
            "Epoch: [11][ 50/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6853 (0.7452)\tD(fake)1 0.2982 (0.2613)\tD(fake)2 0.2049 (0.2011)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1546)\n",
            "Epoch: [11][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7412 (0.7391)\tD(fake)1 0.3070 (0.2658)\tD(fake)2 0.1745 (0.2063)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1553)\n",
            "Epoch: [11][ 70/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7058 (0.7371)\tD(fake)1 0.2883 (0.2672)\tD(fake)2 0.2551 (0.2095)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1289 (-0.1562)\n",
            "Epoch: [11][ 80/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.9036 (0.7374)\tD(fake)1 0.3874 (0.2702)\tD(fake)2 0.0948 (0.2111)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1570)\n",
            "Epoch: [11][ 90/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7929 (0.7341)\tD(fake)1 0.4239 (0.2732)\tD(fake)2 0.0656 (0.2132)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1575)\n",
            "Epoch: [11][100/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6097 (0.7259)\tD(fake)1 0.2540 (0.2771)\tD(fake)2 0.3264 (0.2210)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1584)\n",
            "Epoch: [11][110/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7448 (0.7234)\tD(fake)1 0.3449 (0.2803)\tD(fake)2 0.2192 (0.2242)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1586)\n",
            "Epoch: [11][120/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8447 (0.7257)\tD(fake)1 0.2359 (0.2795)\tD(fake)2 0.1806 (0.2229)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1454 (-0.1581)\n",
            "Epoch: [11][130/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8660 (0.7323)\tD(fake)1 0.2984 (0.2744)\tD(fake)2 0.0448 (0.2178)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1576)\n",
            "Epoch: [11][140/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6646 (0.7303)\tD(fake)1 0.2484 (0.2745)\tD(fake)2 0.3048 (0.2198)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1291 (-0.1571)\n",
            "Epoch: [11][150/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7133 (0.7287)\tD(fake)1 0.2643 (0.2754)\tD(fake)2 0.2375 (0.2209)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1575)\n",
            "Epoch: [11][160/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7274 (0.7266)\tD(fake)1 0.3218 (0.2767)\tD(fake)2 0.2802 (0.2225)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1571 (-0.1570)\n",
            "Epoch: [11][170/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6239 (0.7250)\tD(fake)1 0.2447 (0.2776)\tD(fake)2 0.3802 (0.2245)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1608 (-0.1569)\n",
            "Epoch: [11][180/195]\tTime  0.356 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7255 (0.7239)\tD(fake)1 0.3196 (0.2791)\tD(fake)2 0.2753 (0.2260)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1570)\n",
            "Epoch: [11][190/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6044 (0.7231)\tD(fake)1 0.2045 (0.2794)\tD(fake)2 0.3734 (0.2275)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1571)\n",
            "Epoch: [12][  0/195]\tTime  0.598 ( 0.598)\tData  0.203 ( 0.203)\tD(real) 0.7115 (0.7115)\tD(fake)1 0.2974 (0.2974)\tD(fake)2 0.2756 (0.2756)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1625 (-0.1625)\n",
            "Epoch: [12][ 10/195]\tTime  0.350 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.7016 (0.7106)\tD(fake)1 0.2933 (0.2825)\tD(fake)2 0.3148 (0.2437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1526 (-0.1597)\n",
            "Epoch: [12][ 20/195]\tTime  0.350 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7753 (0.7064)\tD(fake)1 0.3490 (0.2927)\tD(fake)2 0.1667 (0.2418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1473 (-0.1594)\n",
            "Epoch: [12][ 30/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.8099 (0.7147)\tD(fake)1 0.3570 (0.2888)\tD(fake)2 0.1468 (0.2354)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1599)\n",
            "Epoch: [12][ 40/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6791 (0.7116)\tD(fake)1 0.2981 (0.2902)\tD(fake)2 0.2267 (0.2391)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1603)\n",
            "Epoch: [12][ 50/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8108 (0.7067)\tD(fake)1 0.4396 (0.2957)\tD(fake)2 0.2086 (0.2434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1526 (-0.1598)\n",
            "Epoch: [12][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7034 (0.7069)\tD(fake)1 0.2637 (0.2936)\tD(fake)2 0.2270 (0.2443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1590)\n",
            "Epoch: [12][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7443 (0.7080)\tD(fake)1 0.3146 (0.2932)\tD(fake)2 0.2192 (0.2458)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1569)\n",
            "Epoch: [12][ 80/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7093 (0.7115)\tD(fake)1 0.2112 (0.2895)\tD(fake)2 0.2822 (0.2442)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1390 (-0.1570)\n",
            "Epoch: [12][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6357 (0.7132)\tD(fake)1 0.2179 (0.2875)\tD(fake)2 0.4038 (0.2438)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1571)\n",
            "Epoch: [12][100/195]\tTime  0.355 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7537 (0.7111)\tD(fake)1 0.3315 (0.2904)\tD(fake)2 0.2112 (0.2443)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1025 (-0.1567)\n",
            "Epoch: [12][110/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6999 (0.7100)\tD(fake)1 0.3011 (0.2908)\tD(fake)2 0.2078 (0.2451)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1726 (-0.1571)\n",
            "Epoch: [12][120/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5919 (0.7103)\tD(fake)1 0.1445 (0.2893)\tD(fake)2 0.3137 (0.2445)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1577)\n",
            "Epoch: [12][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7559 (0.7110)\tD(fake)1 0.3137 (0.2899)\tD(fake)2 0.1919 (0.2447)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1576)\n",
            "Epoch: [12][140/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6265 (0.7120)\tD(fake)1 0.2189 (0.2880)\tD(fake)2 0.3385 (0.2440)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1574)\n",
            "Epoch: [12][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8032 (0.7136)\tD(fake)1 0.3118 (0.2887)\tD(fake)2 0.1644 (0.2435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1747 (-0.1574)\n",
            "Epoch: [12][160/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8591 (0.7151)\tD(fake)1 0.3887 (0.2888)\tD(fake)2 0.0209 (0.2417)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1749 (-0.1578)\n",
            "Epoch: [12][170/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6467 (0.7134)\tD(fake)1 0.3178 (0.2883)\tD(fake)2 0.3076 (0.2422)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1594 (-0.1578)\n",
            "Epoch: [12][180/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7456 (0.7128)\tD(fake)1 0.2975 (0.2880)\tD(fake)2 0.1758 (0.2409)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1765 (-0.1583)\n",
            "Epoch: [12][190/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6639 (0.7122)\tD(fake)1 0.2551 (0.2883)\tD(fake)2 0.3255 (0.2413)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1566 (-0.1582)\n",
            "Epoch: [13][  0/195]\tTime  0.585 ( 0.585)\tData  0.204 ( 0.204)\tD(real) 0.7314 (0.7314)\tD(fake)1 0.3534 (0.3534)\tD(fake)2 0.2545 (0.2545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1632)\n",
            "Epoch: [13][ 10/195]\tTime  0.354 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.7606 (0.7072)\tD(fake)1 0.3331 (0.2945)\tD(fake)2 0.2019 (0.2397)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1651 (-0.1550)\n",
            "Epoch: [13][ 20/195]\tTime  0.347 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7439 (0.7193)\tD(fake)1 0.2280 (0.2887)\tD(fake)2 0.2301 (0.2334)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1557)\n",
            "Epoch: [13][ 30/195]\tTime  0.345 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7726 (0.7420)\tD(fake)1 0.2365 (0.2688)\tD(fake)2 0.2282 (0.2187)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1538)\n",
            "Epoch: [13][ 40/195]\tTime  0.353 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6678 (0.7436)\tD(fake)1 0.3364 (0.2639)\tD(fake)2 0.3324 (0.2159)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1539)\n",
            "Epoch: [13][ 50/195]\tTime  0.353 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6529 (0.7259)\tD(fake)1 0.3506 (0.2799)\tD(fake)2 0.3030 (0.2289)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1324 (-0.1547)\n",
            "Epoch: [13][ 60/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.4925 (0.7158)\tD(fake)1 0.1354 (0.2855)\tD(fake)2 0.3734 (0.2372)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1567)\n",
            "Epoch: [13][ 70/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7801 (0.7144)\tD(fake)1 0.2994 (0.2900)\tD(fake)2 0.1856 (0.2395)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1582)\n",
            "Epoch: [13][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7440 (0.7192)\tD(fake)1 0.2444 (0.2847)\tD(fake)2 0.2241 (0.2358)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1754 (-0.1585)\n",
            "Epoch: [13][ 90/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.4272 (0.7197)\tD(fake)1 0.0468 (0.2810)\tD(fake)2 0.3593 (0.2341)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1412 (-0.1578)\n",
            "Epoch: [13][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6720 (0.7182)\tD(fake)1 0.3135 (0.2854)\tD(fake)2 0.2929 (0.2384)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1745 (-0.1586)\n",
            "Epoch: [13][110/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6737 (0.7161)\tD(fake)1 0.2628 (0.2872)\tD(fake)2 0.2709 (0.2408)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1588)\n",
            "Epoch: [13][120/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6799 (0.7152)\tD(fake)1 0.3113 (0.2890)\tD(fake)2 0.1830 (0.2414)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1373 (-0.1591)\n",
            "Epoch: [13][130/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6753 (0.7133)\tD(fake)1 0.1908 (0.2887)\tD(fake)2 0.2789 (0.2421)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1594)\n",
            "Epoch: [13][140/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6662 (0.7139)\tD(fake)1 0.2365 (0.2881)\tD(fake)2 0.2875 (0.2414)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1593)\n",
            "Epoch: [13][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7183 (0.7146)\tD(fake)1 0.2376 (0.2874)\tD(fake)2 0.2572 (0.2406)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1595)\n",
            "Epoch: [13][160/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7181 (0.7166)\tD(fake)1 0.1688 (0.2849)\tD(fake)2 0.3107 (0.2388)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1594)\n",
            "Epoch: [13][170/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6764 (0.7176)\tD(fake)1 0.3374 (0.2846)\tD(fake)2 0.2742 (0.2379)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1599)\n",
            "Epoch: [13][180/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.8289 (0.7161)\tD(fake)1 0.3841 (0.2868)\tD(fake)2 0.1540 (0.2396)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1598)\n",
            "Epoch: [13][190/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7738 (0.7153)\tD(fake)1 0.4170 (0.2874)\tD(fake)2 0.1547 (0.2403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1548 (-0.1598)\n",
            "Epoch: [14][  0/195]\tTime  0.588 ( 0.588)\tData  0.201 ( 0.201)\tD(real) 0.8288 (0.8288)\tD(fake)1 0.4013 (0.4013)\tD(fake)2 0.1152 (0.1152)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1378 (-0.1378)\n",
            "Epoch: [14][ 10/195]\tTime  0.345 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.7736 (0.7117)\tD(fake)1 0.3816 (0.3287)\tD(fake)2 0.1200 (0.2513)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1597)\n",
            "Epoch: [14][ 20/195]\tTime  0.348 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.6887 (0.6852)\tD(fake)1 0.4288 (0.3298)\tD(fake)2 0.2603 (0.2697)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1616)\n",
            "Epoch: [14][ 30/195]\tTime  0.353 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6734 (0.6787)\tD(fake)1 0.3700 (0.3267)\tD(fake)2 0.3152 (0.2754)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1607)\n",
            "Epoch: [14][ 40/195]\tTime  0.343 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6356 (0.6749)\tD(fake)1 0.2758 (0.3267)\tD(fake)2 0.3367 (0.2772)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1610)\n",
            "Epoch: [14][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7091 (0.6777)\tD(fake)1 0.3283 (0.3249)\tD(fake)2 0.2138 (0.2745)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1591)\n",
            "Epoch: [14][ 60/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8232 (0.6824)\tD(fake)1 0.3752 (0.3205)\tD(fake)2 0.1285 (0.2710)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1681 (-0.1600)\n",
            "Epoch: [14][ 70/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7820 (0.6911)\tD(fake)1 0.2625 (0.3114)\tD(fake)2 0.1867 (0.2636)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1587)\n",
            "Epoch: [14][ 80/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.9099 (0.7007)\tD(fake)1 0.4008 (0.3057)\tD(fake)2 0.1745 (0.2560)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1476 (-0.1587)\n",
            "Epoch: [14][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7353 (0.7024)\tD(fake)1 0.3856 (0.3038)\tD(fake)2 0.2176 (0.2537)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1288 (-0.1586)\n",
            "Epoch: [14][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6979 (0.6980)\tD(fake)1 0.3324 (0.3063)\tD(fake)2 0.2213 (0.2561)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1583)\n",
            "Epoch: [14][110/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6436 (0.6946)\tD(fake)1 0.3966 (0.3088)\tD(fake)2 0.2759 (0.2589)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1584)\n",
            "Epoch: [14][120/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6397 (0.6915)\tD(fake)1 0.2936 (0.3113)\tD(fake)2 0.2836 (0.2617)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1094 (-0.1579)\n",
            "Epoch: [14][130/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7211 (0.6916)\tD(fake)1 0.3586 (0.3106)\tD(fake)2 0.2805 (0.2615)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1586)\n",
            "Epoch: [14][140/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6176 (0.6916)\tD(fake)1 0.2133 (0.3104)\tD(fake)2 0.3283 (0.2613)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1590)\n",
            "Epoch: [14][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6364 (0.6926)\tD(fake)1 0.2073 (0.3104)\tD(fake)2 0.3943 (0.2622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1592)\n",
            "Epoch: [14][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7455 (0.6943)\tD(fake)1 0.3473 (0.3094)\tD(fake)2 0.1944 (0.2602)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1595 (-0.1595)\n",
            "Epoch: [14][170/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7055 (0.6961)\tD(fake)1 0.2266 (0.3067)\tD(fake)2 0.1875 (0.2580)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1596)\n",
            "Epoch: [14][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7413 (0.6967)\tD(fake)1 0.3470 (0.3064)\tD(fake)2 0.2062 (0.2574)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1511 (-0.1593)\n",
            "Epoch: [14][190/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7329 (0.6980)\tD(fake)1 0.3369 (0.3049)\tD(fake)2 0.2187 (0.2555)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1463 (-0.1590)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKWZPniqS5uX",
        "outputId": "97ed42d0-2ae8-48f3-eaf0-a8f5ce221457"
      },
      "source": [
        "run(15)\n",
        "save_vid()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.602 ( 0.602)\tData  0.208 ( 0.208)\tD(real) 0.6636 (0.6636)\tD(fake)1 0.2361 (0.2361)\tD(fake)2 0.2663 (0.2663)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1189 (-0.1189)\n",
            "Epoch: [0][ 10/195]\tTime  0.348 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.7482 (0.7355)\tD(fake)1 0.3027 (0.2668)\tD(fake)2 0.1909 (0.2253)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1521)\n",
            "Epoch: [0][ 20/195]\tTime  0.349 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6340 (0.7181)\tD(fake)1 0.2882 (0.2804)\tD(fake)2 0.2562 (0.2364)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1539)\n",
            "Epoch: [0][ 30/195]\tTime  0.346 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7872 (0.7090)\tD(fake)1 0.2794 (0.2858)\tD(fake)2 0.1917 (0.2403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1548)\n",
            "Epoch: [0][ 40/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.7688 (0.7125)\tD(fake)1 0.3657 (0.2835)\tD(fake)2 0.1675 (0.2343)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1563 (-0.1566)\n",
            "Epoch: [0][ 50/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7976 (0.7090)\tD(fake)1 0.3293 (0.2869)\tD(fake)2 0.1377 (0.2346)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1457 (-0.1564)\n",
            "Epoch: [0][ 60/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6358 (0.7127)\tD(fake)1 0.2724 (0.2839)\tD(fake)2 0.3315 (0.2325)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1508 (-0.1576)\n",
            "Epoch: [0][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8177 (0.7112)\tD(fake)1 0.4563 (0.2906)\tD(fake)2 0.1837 (0.2370)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1730 (-0.1575)\n",
            "Epoch: [0][ 80/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6743 (0.7085)\tD(fake)1 0.2330 (0.2901)\tD(fake)2 0.2649 (0.2392)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1578)\n",
            "Epoch: [0][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7406 (0.7089)\tD(fake)1 0.3827 (0.2914)\tD(fake)2 0.1714 (0.2396)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1694 (-0.1583)\n",
            "Epoch: [0][100/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7925 (0.7090)\tD(fake)1 0.3577 (0.2912)\tD(fake)2 0.1700 (0.2400)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1718 (-0.1581)\n",
            "Epoch: [0][110/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6896 (0.7076)\tD(fake)1 0.2730 (0.2914)\tD(fake)2 0.2373 (0.2412)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1598 (-0.1581)\n",
            "Epoch: [0][120/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6398 (0.7042)\tD(fake)1 0.2993 (0.2940)\tD(fake)2 0.3273 (0.2446)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1537 (-0.1578)\n",
            "Epoch: [0][130/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8033 (0.7034)\tD(fake)1 0.3846 (0.2956)\tD(fake)2 0.1613 (0.2455)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1581)\n",
            "Epoch: [0][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7450 (0.7035)\tD(fake)1 0.3071 (0.2953)\tD(fake)2 0.2354 (0.2467)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1522 (-0.1585)\n",
            "Epoch: [0][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6140 (0.7038)\tD(fake)1 0.2255 (0.2951)\tD(fake)2 0.3093 (0.2474)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1521 (-0.1590)\n",
            "Epoch: [0][160/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5770 (0.7010)\tD(fake)1 0.2902 (0.2980)\tD(fake)2 0.3290 (0.2497)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1591)\n",
            "Epoch: [0][170/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7053 (0.7003)\tD(fake)1 0.3058 (0.2991)\tD(fake)2 0.2114 (0.2506)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1591)\n",
            "Epoch: [0][180/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6980 (0.7013)\tD(fake)1 0.2424 (0.2986)\tD(fake)2 0.1752 (0.2496)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1592)\n",
            "Epoch: [0][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6298 (0.7035)\tD(fake)1 0.1675 (0.2958)\tD(fake)2 0.3587 (0.2475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1213 (-0.1593)\n",
            "Epoch: [1][  0/195]\tTime  0.612 ( 0.612)\tData  0.215 ( 0.215)\tD(real) 0.6668 (0.6668)\tD(fake)1 0.2089 (0.2089)\tD(fake)2 0.2665 (0.2665)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1288 (-0.1288)\n",
            "Epoch: [1][ 10/195]\tTime  0.344 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.6399 (0.7594)\tD(fake)1 0.1367 (0.2429)\tD(fake)2 0.1911 (0.2023)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1632)\n",
            "Epoch: [1][ 20/195]\tTime  0.346 ( 0.362)\tData  0.001 ( 0.011)\tD(real) 0.7279 (0.7429)\tD(fake)1 0.2863 (0.2689)\tD(fake)2 0.2066 (0.2253)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1611)\n",
            "Epoch: [1][ 30/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7884 (0.7411)\tD(fake)1 0.3402 (0.2704)\tD(fake)2 0.1761 (0.2217)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1603)\n",
            "Epoch: [1][ 40/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.006)\tD(real) 0.7002 (0.7317)\tD(fake)1 0.3385 (0.2758)\tD(fake)2 0.1963 (0.2246)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1664 (-0.1615)\n",
            "Epoch: [1][ 50/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.7189 (0.7234)\tD(fake)1 0.2179 (0.2811)\tD(fake)2 0.2071 (0.2282)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1617)\n",
            "Epoch: [1][ 60/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6927 (0.7274)\tD(fake)1 0.3166 (0.2782)\tD(fake)2 0.2601 (0.2223)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1621)\n",
            "Epoch: [1][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5860 (0.7168)\tD(fake)1 0.2827 (0.2852)\tD(fake)2 0.3070 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1621)\n",
            "Epoch: [1][ 80/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7792 (0.7185)\tD(fake)1 0.2481 (0.2827)\tD(fake)2 0.1380 (0.2251)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1614)\n",
            "Epoch: [1][ 90/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6924 (0.7192)\tD(fake)1 0.2976 (0.2820)\tD(fake)2 0.2563 (0.2253)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1607)\n",
            "Epoch: [1][100/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6805 (0.7168)\tD(fake)1 0.2819 (0.2843)\tD(fake)2 0.3002 (0.2293)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1613)\n",
            "Epoch: [1][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6752 (0.7155)\tD(fake)1 0.2926 (0.2858)\tD(fake)2 0.3137 (0.2312)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1307 (-0.1602)\n",
            "Epoch: [1][120/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6592 (0.7126)\tD(fake)1 0.3554 (0.2898)\tD(fake)2 0.2842 (0.2356)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1601)\n",
            "Epoch: [1][130/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7287 (0.7121)\tD(fake)1 0.3863 (0.2919)\tD(fake)2 0.2082 (0.2374)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1182 (-0.1600)\n",
            "Epoch: [1][140/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6683 (0.7099)\tD(fake)1 0.3474 (0.2931)\tD(fake)2 0.2392 (0.2391)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1592)\n",
            "Epoch: [1][150/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.5450 (0.7079)\tD(fake)1 0.1344 (0.2931)\tD(fake)2 0.3593 (0.2405)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1593)\n",
            "Epoch: [1][160/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7320 (0.7071)\tD(fake)1 0.3840 (0.2955)\tD(fake)2 0.2055 (0.2422)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1656 (-0.1592)\n",
            "Epoch: [1][170/195]\tTime  0.354 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6191 (0.7042)\tD(fake)1 0.3003 (0.2977)\tD(fake)2 0.3331 (0.2447)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1593)\n",
            "Epoch: [1][180/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6417 (0.7021)\tD(fake)1 0.2373 (0.2992)\tD(fake)2 0.4013 (0.2466)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1591)\n",
            "Epoch: [1][190/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6569 (0.7001)\tD(fake)1 0.3678 (0.3015)\tD(fake)2 0.2867 (0.2481)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1592)\n",
            "Epoch: [2][  0/195]\tTime  0.599 ( 0.599)\tData  0.197 ( 0.197)\tD(real) 0.7262 (0.7262)\tD(fake)1 0.3676 (0.3676)\tD(fake)2 0.2575 (0.2575)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1671)\n",
            "Epoch: [2][ 10/195]\tTime  0.346 ( 0.371)\tData  0.000 ( 0.018)\tD(real) 0.5208 (0.6832)\tD(fake)1 0.1158 (0.3062)\tD(fake)2 0.3686 (0.2630)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1358 (-0.1618)\n",
            "Epoch: [2][ 20/195]\tTime  0.349 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7469 (0.7054)\tD(fake)1 0.3011 (0.2968)\tD(fake)2 0.1832 (0.2475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1614)\n",
            "Epoch: [2][ 30/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6382 (0.7080)\tD(fake)1 0.2660 (0.2891)\tD(fake)2 0.3310 (0.2439)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1707 (-0.1600)\n",
            "Epoch: [2][ 40/195]\tTime  0.342 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.6616 (0.6982)\tD(fake)1 0.3522 (0.2992)\tD(fake)2 0.2617 (0.2503)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1616)\n",
            "Epoch: [2][ 50/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7119 (0.6899)\tD(fake)1 0.3529 (0.3053)\tD(fake)2 0.2297 (0.2567)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1599)\n",
            "Epoch: [2][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6496 (0.6894)\tD(fake)1 0.2026 (0.3029)\tD(fake)2 0.3445 (0.2579)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1598)\n",
            "Epoch: [2][ 70/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7348 (0.6936)\tD(fake)1 0.3457 (0.3016)\tD(fake)2 0.2800 (0.2559)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1592 (-0.1591)\n",
            "Epoch: [2][ 80/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.7472 (0.6977)\tD(fake)1 0.3107 (0.2994)\tD(fake)2 0.2124 (0.2537)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1589)\n",
            "Epoch: [2][ 90/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6866 (0.6984)\tD(fake)1 0.2954 (0.2980)\tD(fake)2 0.2948 (0.2532)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1596)\n",
            "Epoch: [2][100/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6915 (0.6995)\tD(fake)1 0.2492 (0.2965)\tD(fake)2 0.2763 (0.2514)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1728 (-0.1602)\n",
            "Epoch: [2][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6591 (0.7027)\tD(fake)1 0.2312 (0.2940)\tD(fake)2 0.2489 (0.2483)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1462 (-0.1602)\n",
            "Epoch: [2][120/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7564 (0.7067)\tD(fake)1 0.2198 (0.2923)\tD(fake)2 0.2074 (0.2456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1606)\n",
            "Epoch: [2][130/195]\tTime  0.349 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7031 (0.7082)\tD(fake)1 0.2494 (0.2912)\tD(fake)2 0.2577 (0.2432)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1604)\n",
            "Epoch: [2][140/195]\tTime  0.353 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6348 (0.7076)\tD(fake)1 0.2492 (0.2909)\tD(fake)2 0.3170 (0.2424)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1602)\n",
            "Epoch: [2][150/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7832 (0.7076)\tD(fake)1 0.3684 (0.2920)\tD(fake)2 0.2077 (0.2426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1606)\n",
            "Epoch: [2][160/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8176 (0.7086)\tD(fake)1 0.3900 (0.2923)\tD(fake)2 0.0959 (0.2423)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1607)\n",
            "Epoch: [2][170/195]\tTime  0.351 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7112 (0.7057)\tD(fake)1 0.3490 (0.2944)\tD(fake)2 0.2196 (0.2455)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1751 (-0.1604)\n",
            "Epoch: [2][180/195]\tTime  0.356 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6416 (0.7037)\tD(fake)1 0.2738 (0.2959)\tD(fake)2 0.2677 (0.2474)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1606)\n",
            "Epoch: [2][190/195]\tTime  0.343 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7948 (0.7030)\tD(fake)1 0.3814 (0.2965)\tD(fake)2 0.2419 (0.2482)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1393 (-0.1609)\n",
            "Epoch: [3][  0/195]\tTime  0.603 ( 0.603)\tData  0.196 ( 0.196)\tD(real) 0.7352 (0.7352)\tD(fake)1 0.2729 (0.2729)\tD(fake)2 0.2204 (0.2204)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1683)\n",
            "Epoch: [3][ 10/195]\tTime  0.349 ( 0.373)\tData  0.000 ( 0.018)\tD(real) 0.6273 (0.7072)\tD(fake)1 0.2388 (0.2917)\tD(fake)2 0.2877 (0.2411)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1554)\n",
            "Epoch: [3][ 20/195]\tTime  0.342 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7985 (0.7157)\tD(fake)1 0.4136 (0.2938)\tD(fake)2 0.1203 (0.2380)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1564)\n",
            "Epoch: [3][ 30/195]\tTime  0.348 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6758 (0.7025)\tD(fake)1 0.2874 (0.3010)\tD(fake)2 0.3114 (0.2537)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1569)\n",
            "Epoch: [3][ 40/195]\tTime  0.346 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6471 (0.7025)\tD(fake)1 0.3023 (0.3023)\tD(fake)2 0.2310 (0.2538)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1408 (-0.1559)\n",
            "Epoch: [3][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6189 (0.6938)\tD(fake)1 0.2516 (0.3052)\tD(fake)2 0.3254 (0.2599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1245 (-0.1566)\n",
            "Epoch: [3][ 60/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6918 (0.6939)\tD(fake)1 0.2836 (0.3061)\tD(fake)2 0.2245 (0.2595)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1578)\n",
            "Epoch: [3][ 70/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.8484 (0.6983)\tD(fake)1 0.3796 (0.3042)\tD(fake)2 0.0738 (0.2567)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1582)\n",
            "Epoch: [3][ 80/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6122 (0.6966)\tD(fake)1 0.2613 (0.3026)\tD(fake)2 0.3107 (0.2587)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1740 (-0.1590)\n",
            "Epoch: [3][ 90/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6610 (0.6968)\tD(fake)1 0.1770 (0.3020)\tD(fake)2 0.3384 (0.2584)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1163 (-0.1584)\n",
            "Epoch: [3][100/195]\tTime  0.341 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7200 (0.6960)\tD(fake)1 0.3706 (0.3047)\tD(fake)2 0.2498 (0.2599)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1582)\n",
            "Epoch: [3][110/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7073 (0.6967)\tD(fake)1 0.2525 (0.3036)\tD(fake)2 0.2462 (0.2600)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1578)\n",
            "Epoch: [3][120/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8121 (0.6978)\tD(fake)1 0.4311 (0.3035)\tD(fake)2 0.1960 (0.2603)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1291 (-0.1581)\n",
            "Epoch: [3][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8450 (0.6976)\tD(fake)1 0.4616 (0.3044)\tD(fake)2 0.1325 (0.2611)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1732 (-0.1587)\n",
            "Epoch: [3][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7794 (0.6957)\tD(fake)1 0.4278 (0.3053)\tD(fake)2 0.2217 (0.2635)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1716 (-0.1593)\n",
            "Epoch: [3][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6153 (0.6950)\tD(fake)1 0.2259 (0.3045)\tD(fake)2 0.3444 (0.2640)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1749 (-0.1593)\n",
            "Epoch: [3][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6133 (0.6955)\tD(fake)1 0.2139 (0.3042)\tD(fake)2 0.3103 (0.2632)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1532 (-0.1593)\n",
            "Epoch: [3][170/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7121 (0.6963)\tD(fake)1 0.3759 (0.3039)\tD(fake)2 0.2130 (0.2622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1593)\n",
            "Epoch: [3][180/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6980 (0.6956)\tD(fake)1 0.3267 (0.3045)\tD(fake)2 0.2636 (0.2627)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1713 (-0.1595)\n",
            "Epoch: [3][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6791 (0.6962)\tD(fake)1 0.2589 (0.3037)\tD(fake)2 0.3213 (0.2626)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1231 (-0.1598)\n",
            "Epoch: [4][  0/195]\tTime  0.586 ( 0.586)\tData  0.209 ( 0.209)\tD(real) 0.6690 (0.6690)\tD(fake)1 0.2682 (0.2682)\tD(fake)2 0.3017 (0.3017)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1631)\n",
            "Epoch: [4][ 10/195]\tTime  0.349 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.6443 (0.7024)\tD(fake)1 0.2162 (0.2941)\tD(fake)2 0.2067 (0.2583)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1574)\n",
            "Epoch: [4][ 20/195]\tTime  0.349 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.6928 (0.6978)\tD(fake)1 0.3286 (0.3018)\tD(fake)2 0.2485 (0.2674)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1709 (-0.1614)\n",
            "Epoch: [4][ 30/195]\tTime  0.346 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.5534 (0.6937)\tD(fake)1 0.2828 (0.3050)\tD(fake)2 0.3872 (0.2702)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1607)\n",
            "Epoch: [4][ 40/195]\tTime  0.350 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6786 (0.6912)\tD(fake)1 0.3914 (0.3130)\tD(fake)2 0.2442 (0.2720)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1729 (-0.1615)\n",
            "Epoch: [4][ 50/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7203 (0.6871)\tD(fake)1 0.3060 (0.3139)\tD(fake)2 0.1922 (0.2716)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1132 (-0.1606)\n",
            "Epoch: [4][ 60/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7895 (0.6894)\tD(fake)1 0.3540 (0.3121)\tD(fake)2 0.1889 (0.2683)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1613)\n",
            "Epoch: [4][ 70/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5805 (0.6932)\tD(fake)1 0.1486 (0.3077)\tD(fake)2 0.3383 (0.2658)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1618)\n",
            "Epoch: [4][ 80/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6255 (0.6978)\tD(fake)1 0.1964 (0.3058)\tD(fake)2 0.2855 (0.2626)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1531 (-0.1619)\n",
            "Epoch: [4][ 90/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6988 (0.6955)\tD(fake)1 0.3833 (0.3081)\tD(fake)2 0.2124 (0.2626)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1497 (-0.1615)\n",
            "Epoch: [4][100/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7952 (0.6936)\tD(fake)1 0.3692 (0.3086)\tD(fake)2 0.1018 (0.2621)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1524 (-0.1610)\n",
            "Epoch: [4][110/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7926 (0.6937)\tD(fake)1 0.3860 (0.3081)\tD(fake)2 0.2435 (0.2638)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1611)\n",
            "Epoch: [4][120/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6754 (0.6931)\tD(fake)1 0.3111 (0.3083)\tD(fake)2 0.2764 (0.2649)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1609)\n",
            "Epoch: [4][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6726 (0.6945)\tD(fake)1 0.2072 (0.3063)\tD(fake)2 0.3034 (0.2644)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1610)\n",
            "Epoch: [4][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6727 (0.6970)\tD(fake)1 0.2709 (0.3042)\tD(fake)2 0.3189 (0.2628)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1260 (-0.1610)\n",
            "Epoch: [4][150/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8418 (0.6990)\tD(fake)1 0.3846 (0.3040)\tD(fake)2 -0.0110 (0.2608)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1724 (-0.1607)\n",
            "Epoch: [4][160/195]\tTime  0.346 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6494 (0.6977)\tD(fake)1 0.2723 (0.3039)\tD(fake)2 0.2877 (0.2625)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1611)\n",
            "Epoch: [4][170/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6095 (0.6970)\tD(fake)1 0.2482 (0.3039)\tD(fake)2 0.3438 (0.2636)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1614)\n",
            "Epoch: [4][180/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.9263 (0.6987)\tD(fake)1 0.4862 (0.3042)\tD(fake)2 0.1053 (0.2629)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1615)\n",
            "Epoch: [4][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7349 (0.6992)\tD(fake)1 0.2792 (0.3036)\tD(fake)2 0.2109 (0.2625)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1580 (-0.1618)\n",
            "Epoch: [5][  0/195]\tTime  0.614 ( 0.614)\tData  0.216 ( 0.216)\tD(real) 0.5889 (0.5889)\tD(fake)1 0.1757 (0.1757)\tD(fake)2 0.3361 (0.3361)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1564 (-0.1564)\n",
            "Epoch: [5][ 10/195]\tTime  0.347 ( 0.374)\tData  0.000 ( 0.020)\tD(real) 0.6365 (0.7032)\tD(fake)1 0.2277 (0.2732)\tD(fake)2 0.3045 (0.2472)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1626)\n",
            "Epoch: [5][ 20/195]\tTime  0.347 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.6019 (0.7025)\tD(fake)1 0.2254 (0.2788)\tD(fake)2 0.3318 (0.2462)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1651)\n",
            "Epoch: [5][ 30/195]\tTime  0.345 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7337 (0.6951)\tD(fake)1 0.3877 (0.2946)\tD(fake)2 0.2413 (0.2529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1748 (-0.1609)\n",
            "Epoch: [5][ 40/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.6862 (0.6926)\tD(fake)1 0.3086 (0.2981)\tD(fake)2 0.2035 (0.2545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1459 (-0.1609)\n",
            "Epoch: [5][ 50/195]\tTime  0.343 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7649 (0.6929)\tD(fake)1 0.3857 (0.3006)\tD(fake)2 0.1701 (0.2553)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1613)\n",
            "Epoch: [5][ 60/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.9407 (0.7019)\tD(fake)1 0.3511 (0.2961)\tD(fake)2 0.0228 (0.2492)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1609)\n",
            "Epoch: [5][ 70/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7057 (0.7079)\tD(fake)1 0.3005 (0.2890)\tD(fake)2 0.2351 (0.2456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1604)\n",
            "Epoch: [5][ 80/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7035 (0.7071)\tD(fake)1 0.3256 (0.2892)\tD(fake)2 0.2706 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1714 (-0.1602)\n",
            "Epoch: [5][ 90/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7110 (0.7054)\tD(fake)1 0.3378 (0.2917)\tD(fake)2 0.1902 (0.2474)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1604)\n",
            "Epoch: [5][100/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8569 (0.7053)\tD(fake)1 0.4913 (0.2938)\tD(fake)2 0.0652 (0.2486)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1203 (-0.1599)\n",
            "Epoch: [5][110/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8034 (0.7066)\tD(fake)1 0.3529 (0.2918)\tD(fake)2 0.1436 (0.2478)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1601)\n",
            "Epoch: [5][120/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8178 (0.7087)\tD(fake)1 0.3609 (0.2907)\tD(fake)2 0.0881 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1601)\n",
            "Epoch: [5][130/195]\tTime  0.355 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6892 (0.7095)\tD(fake)1 0.2597 (0.2892)\tD(fake)2 0.2669 (0.2465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1483 (-0.1596)\n",
            "Epoch: [5][140/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.9149 (0.7105)\tD(fake)1 0.4389 (0.2898)\tD(fake)2 0.0864 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1599)\n",
            "Epoch: [5][150/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7987 (0.7103)\tD(fake)1 0.3971 (0.2892)\tD(fake)2 0.1700 (0.2462)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1596)\n",
            "Epoch: [5][160/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7856 (0.7107)\tD(fake)1 0.3058 (0.2883)\tD(fake)2 0.1881 (0.2460)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1362 (-0.1598)\n",
            "Epoch: [5][170/195]\tTime  0.357 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7268 (0.7130)\tD(fake)1 0.2380 (0.2856)\tD(fake)2 0.2045 (0.2433)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1534 (-0.1595)\n",
            "Epoch: [5][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6733 (0.7139)\tD(fake)1 0.2832 (0.2853)\tD(fake)2 0.2725 (0.2427)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1570 (-0.1592)\n",
            "Epoch: [5][190/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6009 (0.7127)\tD(fake)1 0.2136 (0.2863)\tD(fake)2 0.3548 (0.2439)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1591)\n",
            "Epoch: [6][  0/195]\tTime  0.610 ( 0.610)\tData  0.212 ( 0.212)\tD(real) 0.6712 (0.6712)\tD(fake)1 0.3012 (0.3012)\tD(fake)2 0.3046 (0.3046)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1674)\n",
            "Epoch: [6][ 10/195]\tTime  0.345 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.6964 (0.6913)\tD(fake)1 0.3038 (0.3043)\tD(fake)2 0.2531 (0.2654)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1591 (-0.1577)\n",
            "Epoch: [6][ 20/195]\tTime  0.350 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7315 (0.6984)\tD(fake)1 0.3614 (0.3008)\tD(fake)2 0.2076 (0.2579)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1256 (-0.1572)\n",
            "Epoch: [6][ 30/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6193 (0.6865)\tD(fake)1 0.2515 (0.3051)\tD(fake)2 0.3342 (0.2668)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1286 (-0.1557)\n",
            "Epoch: [6][ 40/195]\tTime  0.345 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7848 (0.6963)\tD(fake)1 0.3125 (0.3001)\tD(fake)2 0.1872 (0.2590)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1552 (-0.1569)\n",
            "Epoch: [6][ 50/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8405 (0.7033)\tD(fake)1 0.4291 (0.2965)\tD(fake)2 0.2220 (0.2556)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1674 (-0.1550)\n",
            "Epoch: [6][ 60/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6021 (0.7010)\tD(fake)1 0.2044 (0.2977)\tD(fake)2 0.3552 (0.2587)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1117 (-0.1545)\n",
            "Epoch: [6][ 70/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5522 (0.7014)\tD(fake)1 0.2032 (0.2981)\tD(fake)2 0.3698 (0.2597)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1614 (-0.1550)\n",
            "Epoch: [6][ 80/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7092 (0.6984)\tD(fake)1 0.4049 (0.3022)\tD(fake)2 0.1528 (0.2597)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1559)\n",
            "Epoch: [6][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7317 (0.6957)\tD(fake)1 0.3058 (0.3031)\tD(fake)2 0.2097 (0.2603)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1560)\n",
            "Epoch: [6][100/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8096 (0.6991)\tD(fake)1 0.3789 (0.3008)\tD(fake)2 0.1711 (0.2570)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1565)\n",
            "Epoch: [6][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8325 (0.6986)\tD(fake)1 0.4407 (0.3024)\tD(fake)2 0.0832 (0.2564)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1564)\n",
            "Epoch: [6][120/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8428 (0.6994)\tD(fake)1 0.3516 (0.3021)\tD(fake)2 0.1029 (0.2556)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1567)\n",
            "Epoch: [6][130/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8803 (0.7074)\tD(fake)1 0.2547 (0.2953)\tD(fake)2 0.0501 (0.2492)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1566)\n",
            "Epoch: [6][140/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8669 (0.7131)\tD(fake)1 0.3757 (0.2906)\tD(fake)2 0.0827 (0.2452)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1520 (-0.1569)\n",
            "Epoch: [6][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5842 (0.7125)\tD(fake)1 0.1495 (0.2886)\tD(fake)2 0.4570 (0.2454)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1569)\n",
            "Epoch: [6][160/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7701 (0.7128)\tD(fake)1 0.3555 (0.2893)\tD(fake)2 0.2081 (0.2450)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1419 (-0.1570)\n",
            "Epoch: [6][170/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8122 (0.7120)\tD(fake)1 0.4411 (0.2901)\tD(fake)2 0.2572 (0.2462)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1598 (-0.1572)\n",
            "Epoch: [6][180/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6494 (0.7112)\tD(fake)1 0.3144 (0.2912)\tD(fake)2 0.2554 (0.2463)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1574)\n",
            "Epoch: [6][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6555 (0.7119)\tD(fake)1 0.2984 (0.2907)\tD(fake)2 0.3150 (0.2444)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1437 (-0.1576)\n",
            "Epoch: [7][  0/195]\tTime  0.612 ( 0.612)\tData  0.212 ( 0.212)\tD(real) 0.6608 (0.6608)\tD(fake)1 0.3383 (0.3383)\tD(fake)2 0.2619 (0.2619)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1615)\n",
            "Epoch: [7][ 10/195]\tTime  0.344 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.7408 (0.6674)\tD(fake)1 0.3959 (0.3351)\tD(fake)2 0.2453 (0.2885)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1329 (-0.1555)\n",
            "Epoch: [7][ 20/195]\tTime  0.350 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.6070 (0.6715)\tD(fake)1 0.2308 (0.3240)\tD(fake)2 0.3284 (0.2833)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1544)\n",
            "Epoch: [7][ 30/195]\tTime  0.346 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6111 (0.6727)\tD(fake)1 0.2870 (0.3258)\tD(fake)2 0.3709 (0.2839)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1553)\n",
            "Epoch: [7][ 40/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7605 (0.6791)\tD(fake)1 0.2957 (0.3225)\tD(fake)2 0.2086 (0.2756)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1565 (-0.1554)\n",
            "Epoch: [7][ 50/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.9464 (0.6929)\tD(fake)1 0.4760 (0.3116)\tD(fake)2 0.0465 (0.2616)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1552)\n",
            "Epoch: [7][ 60/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7207 (0.6935)\tD(fake)1 0.3675 (0.3072)\tD(fake)2 0.2518 (0.2607)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1471 (-0.1548)\n",
            "Epoch: [7][ 70/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6901 (0.6892)\tD(fake)1 0.3319 (0.3113)\tD(fake)2 0.2592 (0.2638)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1546 (-0.1546)\n",
            "Epoch: [7][ 80/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6177 (0.6896)\tD(fake)1 0.2165 (0.3102)\tD(fake)2 0.2605 (0.2642)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.1544)\n",
            "Epoch: [7][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7055 (0.6931)\tD(fake)1 0.2578 (0.3070)\tD(fake)2 0.2923 (0.2629)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1395 (-0.1550)\n",
            "Epoch: [7][100/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8946 (0.6976)\tD(fake)1 0.4912 (0.3049)\tD(fake)2 0.2049 (0.2597)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1709 (-0.1554)\n",
            "Epoch: [7][110/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7929 (0.6965)\tD(fake)1 0.4163 (0.3049)\tD(fake)2 0.1561 (0.2593)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1563)\n",
            "Epoch: [7][120/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6163 (0.6952)\tD(fake)1 0.1906 (0.3034)\tD(fake)2 0.3738 (0.2598)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1566 (-0.1562)\n",
            "Epoch: [7][130/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6863 (0.6944)\tD(fake)1 0.3593 (0.3055)\tD(fake)2 0.2612 (0.2606)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1565)\n",
            "Epoch: [7][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6458 (0.6932)\tD(fake)1 0.2895 (0.3061)\tD(fake)2 0.3157 (0.2622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1566)\n",
            "Epoch: [7][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8690 (0.6941)\tD(fake)1 0.4399 (0.3067)\tD(fake)2 0.0888 (0.2622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1567)\n",
            "Epoch: [7][160/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8208 (0.6951)\tD(fake)1 0.3914 (0.3049)\tD(fake)2 0.1630 (0.2616)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1574)\n",
            "Epoch: [7][170/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6950 (0.6952)\tD(fake)1 0.2671 (0.3038)\tD(fake)2 0.2398 (0.2612)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1465 (-0.1573)\n",
            "Epoch: [7][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7506 (0.6962)\tD(fake)1 0.3767 (0.3035)\tD(fake)2 0.2203 (0.2610)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1485 (-0.1571)\n",
            "Epoch: [7][190/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6475 (0.6951)\tD(fake)1 0.3151 (0.3045)\tD(fake)2 0.3327 (0.2622)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1574)\n",
            "Epoch: [8][  0/195]\tTime  0.616 ( 0.616)\tData  0.208 ( 0.208)\tD(real) 0.7425 (0.7425)\tD(fake)1 0.3033 (0.3033)\tD(fake)2 0.2737 (0.2737)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1728 (-0.1728)\n",
            "Epoch: [8][ 10/195]\tTime  0.346 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.8364 (0.7581)\tD(fake)1 0.3463 (0.2582)\tD(fake)2 0.2027 (0.2179)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1616)\n",
            "Epoch: [8][ 20/195]\tTime  0.342 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.7569 (0.7364)\tD(fake)1 0.3750 (0.2752)\tD(fake)2 0.1730 (0.2285)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1628)\n",
            "Epoch: [8][ 30/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7770 (0.7245)\tD(fake)1 0.3701 (0.2806)\tD(fake)2 0.1907 (0.2361)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1610)\n",
            "Epoch: [8][ 40/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7480 (0.7201)\tD(fake)1 0.3475 (0.2836)\tD(fake)2 0.2108 (0.2388)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1259 (-0.1580)\n",
            "Epoch: [8][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6867 (0.7113)\tD(fake)1 0.2491 (0.2908)\tD(fake)2 0.2819 (0.2465)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1304 (-0.1560)\n",
            "Epoch: [8][ 60/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.7180 (0.7124)\tD(fake)1 0.2879 (0.2892)\tD(fake)2 0.1950 (0.2418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1566)\n",
            "Epoch: [8][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6375 (0.7076)\tD(fake)1 0.2577 (0.2898)\tD(fake)2 0.3155 (0.2434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1411 (-0.1564)\n",
            "Epoch: [8][ 80/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6610 (0.7071)\tD(fake)1 0.2514 (0.2896)\tD(fake)2 0.2945 (0.2434)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1407 (-0.1561)\n",
            "Epoch: [8][ 90/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7155 (0.7062)\tD(fake)1 0.4045 (0.2914)\tD(fake)2 0.2948 (0.2436)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1557)\n",
            "Epoch: [8][100/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7128 (0.7074)\tD(fake)1 0.2376 (0.2911)\tD(fake)2 0.2536 (0.2446)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1577 (-0.1558)\n",
            "Epoch: [8][110/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6654 (0.7098)\tD(fake)1 0.2199 (0.2895)\tD(fake)2 0.2605 (0.2435)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1564)\n",
            "Epoch: [8][120/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5612 (0.7090)\tD(fake)1 0.1949 (0.2900)\tD(fake)2 0.3675 (0.2449)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1564)\n",
            "Epoch: [8][130/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7025 (0.7079)\tD(fake)1 0.2576 (0.2924)\tD(fake)2 0.2370 (0.2469)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1666 (-0.1567)\n",
            "Epoch: [8][140/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8005 (0.7087)\tD(fake)1 0.3655 (0.2922)\tD(fake)2 0.2130 (0.2469)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1571)\n",
            "Epoch: [8][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6374 (0.7078)\tD(fake)1 0.2278 (0.2918)\tD(fake)2 0.3011 (0.2475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1572)\n",
            "Epoch: [8][160/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8105 (0.7084)\tD(fake)1 0.3621 (0.2921)\tD(fake)2 0.1567 (0.2475)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1723 (-0.1573)\n",
            "Epoch: [8][170/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7038 (0.7070)\tD(fake)1 0.3377 (0.2928)\tD(fake)2 0.2154 (0.2486)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1574)\n",
            "Epoch: [8][180/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6831 (0.7073)\tD(fake)1 0.2514 (0.2921)\tD(fake)2 0.2809 (0.2480)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1580)\n",
            "Epoch: [8][190/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6857 (0.7070)\tD(fake)1 0.3183 (0.2926)\tD(fake)2 0.2790 (0.2486)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1507 (-0.1580)\n",
            "Epoch: [9][  0/195]\tTime  0.619 ( 0.619)\tData  0.225 ( 0.225)\tD(real) 0.5454 (0.5454)\tD(fake)1 0.1943 (0.1943)\tD(fake)2 0.4121 (0.4121)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1517 (-0.1517)\n",
            "Epoch: [9][ 10/195]\tTime  0.349 ( 0.374)\tData  0.000 ( 0.021)\tD(real) 0.6029 (0.6656)\tD(fake)1 0.2446 (0.3206)\tD(fake)2 0.3428 (0.3028)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1617)\n",
            "Epoch: [9][ 20/195]\tTime  0.351 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.5997 (0.6792)\tD(fake)1 0.2021 (0.3119)\tD(fake)2 0.3273 (0.2849)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1618)\n",
            "Epoch: [9][ 30/195]\tTime  0.343 ( 0.357)\tData  0.000 ( 0.008)\tD(real) 0.7517 (0.6929)\tD(fake)1 0.3156 (0.3038)\tD(fake)2 0.1675 (0.2693)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1710 (-0.1601)\n",
            "Epoch: [9][ 40/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.6796 (0.6947)\tD(fake)1 0.2535 (0.3005)\tD(fake)2 0.3174 (0.2681)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1573 (-0.1599)\n",
            "Epoch: [9][ 50/195]\tTime  0.353 ( 0.353)\tData  0.001 ( 0.005)\tD(real) 0.6606 (0.6935)\tD(fake)1 0.2478 (0.3030)\tD(fake)2 0.3306 (0.2699)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1596)\n",
            "Epoch: [9][ 60/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6743 (0.6976)\tD(fake)1 0.2422 (0.2996)\tD(fake)2 0.3389 (0.2664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1608)\n",
            "Epoch: [9][ 70/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7971 (0.7010)\tD(fake)1 0.3339 (0.2989)\tD(fake)2 0.1570 (0.2624)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1617)\n",
            "Epoch: [9][ 80/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7495 (0.7027)\tD(fake)1 0.3243 (0.2962)\tD(fake)2 0.1942 (0.2604)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1627 (-0.1604)\n",
            "Epoch: [9][ 90/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7713 (0.7020)\tD(fake)1 0.3545 (0.2975)\tD(fake)2 0.1974 (0.2618)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1660 (-0.1602)\n",
            "Epoch: [9][100/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6683 (0.7019)\tD(fake)1 0.2667 (0.2974)\tD(fake)2 0.3511 (0.2630)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1314 (-0.1599)\n",
            "Epoch: [9][110/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8058 (0.7012)\tD(fake)1 0.4610 (0.2999)\tD(fake)2 0.1718 (0.2636)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1324 (-0.1599)\n",
            "Epoch: [9][120/195]\tTime  0.358 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7820 (0.6986)\tD(fake)1 0.4213 (0.3017)\tD(fake)2 0.1849 (0.2656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1578 (-0.1597)\n",
            "Epoch: [9][130/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7234 (0.6970)\tD(fake)1 0.3224 (0.3024)\tD(fake)2 0.2317 (0.2665)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1595)\n",
            "Epoch: [9][140/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7456 (0.6979)\tD(fake)1 0.3057 (0.3015)\tD(fake)2 0.2472 (0.2664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1599)\n",
            "Epoch: [9][150/195]\tTime  0.342 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7303 (0.6994)\tD(fake)1 0.3039 (0.3006)\tD(fake)2 0.2597 (0.2652)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1333 (-0.1599)\n",
            "Epoch: [9][160/195]\tTime  0.353 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.8426 (0.7005)\tD(fake)1 0.4078 (0.3003)\tD(fake)2 0.1188 (0.2640)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1588 (-0.1595)\n",
            "Epoch: [9][170/195]\tTime  0.345 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7906 (0.7010)\tD(fake)1 0.3324 (0.2990)\tD(fake)2 0.2245 (0.2635)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1587)\n",
            "Epoch: [9][180/195]\tTime  0.344 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.7020 (0.7012)\tD(fake)1 0.3118 (0.2989)\tD(fake)2 0.2268 (0.2630)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1584)\n",
            "Epoch: [9][190/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.6897 (0.7016)\tD(fake)1 0.2552 (0.2984)\tD(fake)2 0.2410 (0.2629)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1583)\n",
            "Epoch: [10][  0/195]\tTime  0.610 ( 0.610)\tData  0.205 ( 0.205)\tD(real) 0.6437 (0.6437)\tD(fake)1 0.2472 (0.2472)\tD(fake)2 0.3154 (0.3154)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1673)\n",
            "Epoch: [10][ 10/195]\tTime  0.344 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.5708 (0.7111)\tD(fake)1 0.1557 (0.2770)\tD(fake)2 0.3027 (0.2528)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1249 (-0.1533)\n",
            "Epoch: [10][ 20/195]\tTime  0.352 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.7558 (0.7180)\tD(fake)1 0.2568 (0.2917)\tD(fake)2 0.1559 (0.2407)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1565)\n",
            "Epoch: [10][ 30/195]\tTime  0.350 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.8711 (0.7406)\tD(fake)1 0.2406 (0.2645)\tD(fake)2 0.1296 (0.2132)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1588)\n",
            "Epoch: [10][ 40/195]\tTime  0.350 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7075 (0.7424)\tD(fake)1 0.2813 (0.2681)\tD(fake)2 0.1777 (0.2145)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1448 (-0.1595)\n",
            "Epoch: [10][ 50/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8334 (0.7402)\tD(fake)1 0.3553 (0.2698)\tD(fake)2 0.1465 (0.2209)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1594)\n",
            "Epoch: [10][ 60/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.8430 (0.7350)\tD(fake)1 0.4821 (0.2742)\tD(fake)2 0.1711 (0.2261)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1592)\n",
            "Epoch: [10][ 70/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.5771 (0.7227)\tD(fake)1 0.2590 (0.2807)\tD(fake)2 0.3602 (0.2359)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1580)\n",
            "Epoch: [10][ 80/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.5845 (0.7106)\tD(fake)1 0.3444 (0.2924)\tD(fake)2 0.3617 (0.2483)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1431 (-0.1568)\n",
            "Epoch: [10][ 90/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7333 (0.7037)\tD(fake)1 0.4248 (0.3004)\tD(fake)2 0.2538 (0.2557)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1580)\n",
            "Epoch: [10][100/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5633 (0.7001)\tD(fake)1 0.1724 (0.3013)\tD(fake)2 0.4559 (0.2588)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1585)\n",
            "Epoch: [10][110/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6459 (0.6988)\tD(fake)1 0.3360 (0.3040)\tD(fake)2 0.3661 (0.2606)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1640 (-0.1585)\n",
            "Epoch: [10][120/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7006 (0.6966)\tD(fake)1 0.3678 (0.3070)\tD(fake)2 0.2461 (0.2627)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1588)\n",
            "Epoch: [10][130/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6305 (0.6921)\tD(fake)1 0.3164 (0.3107)\tD(fake)2 0.3395 (0.2665)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1592)\n",
            "Epoch: [10][140/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7691 (0.6907)\tD(fake)1 0.4665 (0.3128)\tD(fake)2 0.1644 (0.2671)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1591)\n",
            "Epoch: [10][150/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5987 (0.6866)\tD(fake)1 0.2501 (0.3149)\tD(fake)2 0.3736 (0.2704)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1596)\n",
            "Epoch: [10][160/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5869 (0.6870)\tD(fake)1 0.2000 (0.3147)\tD(fake)2 0.3453 (0.2703)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1600)\n",
            "Epoch: [10][170/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7297 (0.6885)\tD(fake)1 0.3471 (0.3145)\tD(fake)2 0.3228 (0.2699)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1605)\n",
            "Epoch: [10][180/195]\tTime  0.358 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7495 (0.6880)\tD(fake)1 0.3307 (0.3160)\tD(fake)2 0.2256 (0.2705)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1737 (-0.1603)\n",
            "Epoch: [10][190/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7748 (0.6889)\tD(fake)1 0.3726 (0.3150)\tD(fake)2 0.2768 (0.2694)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1565 (-0.1602)\n",
            "Epoch: [11][  0/195]\tTime  0.611 ( 0.611)\tData  0.210 ( 0.210)\tD(real) 0.6657 (0.6657)\tD(fake)1 0.2120 (0.2120)\tD(fake)2 0.2920 (0.2920)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1696)\n",
            "Epoch: [11][ 10/195]\tTime  0.348 ( 0.375)\tData  0.000 ( 0.020)\tD(real) 0.6453 (0.6767)\tD(fake)1 0.3349 (0.3105)\tD(fake)2 0.2453 (0.2565)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1644)\n",
            "Epoch: [11][ 20/195]\tTime  0.348 ( 0.364)\tData  0.000 ( 0.010)\tD(real) 0.6745 (0.6844)\tD(fake)1 0.2956 (0.3045)\tD(fake)2 0.2769 (0.2507)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1602)\n",
            "Epoch: [11][ 30/195]\tTime  0.343 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.6342 (0.6892)\tD(fake)1 0.2230 (0.3072)\tD(fake)2 0.1935 (0.2547)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1575 (-0.1617)\n",
            "Epoch: [11][ 40/195]\tTime  0.355 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.5828 (0.6835)\tD(fake)1 0.2485 (0.3132)\tD(fake)2 0.3853 (0.2676)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1639)\n",
            "Epoch: [11][ 50/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.004)\tD(real) 0.7947 (0.6800)\tD(fake)1 0.4454 (0.3191)\tD(fake)2 0.2110 (0.2681)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1643)\n",
            "Epoch: [11][ 60/195]\tTime  0.358 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8135 (0.6819)\tD(fake)1 0.4732 (0.3169)\tD(fake)2 0.1058 (0.2651)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1630)\n",
            "Epoch: [11][ 70/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.6474 (0.6779)\tD(fake)1 0.3344 (0.3178)\tD(fake)2 0.3210 (0.2697)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1376 (-0.1623)\n",
            "Epoch: [11][ 80/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6450 (0.6805)\tD(fake)1 0.2086 (0.3174)\tD(fake)2 0.2807 (0.2701)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1612)\n",
            "Epoch: [11][ 90/195]\tTime  0.343 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7968 (0.6854)\tD(fake)1 0.4009 (0.3139)\tD(fake)2 0.2603 (0.2676)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1594)\n",
            "Epoch: [11][100/195]\tTime  0.353 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6826 (0.6878)\tD(fake)1 0.2605 (0.3109)\tD(fake)2 0.2720 (0.2652)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1419 (-0.1595)\n",
            "Epoch: [11][110/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6585 (0.6871)\tD(fake)1 0.3836 (0.3123)\tD(fake)2 0.3443 (0.2677)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1449 (-0.1595)\n",
            "Epoch: [11][120/195]\tTime  0.359 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6137 (0.6846)\tD(fake)1 0.2306 (0.3145)\tD(fake)2 0.4011 (0.2714)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1159 (-0.1586)\n",
            "Epoch: [11][130/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5633 (0.6840)\tD(fake)1 0.2015 (0.3150)\tD(fake)2 0.4124 (0.2719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1449 (-0.1582)\n",
            "Epoch: [11][140/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6715 (0.6828)\tD(fake)1 0.3293 (0.3157)\tD(fake)2 0.3029 (0.2724)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1584)\n",
            "Epoch: [11][150/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6867 (0.6830)\tD(fake)1 0.2881 (0.3152)\tD(fake)2 0.2663 (0.2719)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1590)\n",
            "Epoch: [11][160/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6189 (0.6838)\tD(fake)1 0.1804 (0.3140)\tD(fake)2 0.2847 (0.2706)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1506 (-0.1589)\n",
            "Epoch: [11][170/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7378 (0.6852)\tD(fake)1 0.3260 (0.3135)\tD(fake)2 0.2286 (0.2695)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1589)\n",
            "Epoch: [11][180/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6423 (0.6862)\tD(fake)1 0.2434 (0.3128)\tD(fake)2 0.3355 (0.2699)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1590)\n",
            "Epoch: [11][190/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.001)\tD(real) 0.5509 (0.6876)\tD(fake)1 0.1240 (0.3121)\tD(fake)2 0.2631 (0.2689)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1663 (-0.1592)\n",
            "Epoch: [12][  0/195]\tTime  0.575 ( 0.575)\tData  0.197 ( 0.197)\tD(real) 0.7673 (0.7673)\tD(fake)1 0.3619 (0.3619)\tD(fake)2 0.2152 (0.2152)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1311 (-0.1311)\n",
            "Epoch: [12][ 10/195]\tTime  0.355 ( 0.369)\tData  0.000 ( 0.018)\tD(real) 0.6402 (0.7175)\tD(fake)1 0.1995 (0.2934)\tD(fake)2 0.2721 (0.2535)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1449)\n",
            "Epoch: [12][ 20/195]\tTime  0.352 ( 0.359)\tData  0.000 ( 0.010)\tD(real) 0.8661 (0.7217)\tD(fake)1 0.4697 (0.2977)\tD(fake)2 -0.0276 (0.2418)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1542)\n",
            "Epoch: [12][ 30/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.6482 (0.7032)\tD(fake)1 0.2783 (0.2976)\tD(fake)2 0.3021 (0.2579)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1567)\n",
            "Epoch: [12][ 40/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.6474 (0.6981)\tD(fake)1 0.3111 (0.3032)\tD(fake)2 0.2919 (0.2627)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1560)\n",
            "Epoch: [12][ 50/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6627 (0.6964)\tD(fake)1 0.2875 (0.3051)\tD(fake)2 0.3161 (0.2648)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1722 (-0.1578)\n",
            "Epoch: [12][ 60/195]\tTime  0.343 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.4514 (0.6923)\tD(fake)1 0.0828 (0.3042)\tD(fake)2 0.4861 (0.2669)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1617 (-0.1577)\n",
            "Epoch: [12][ 70/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6378 (0.6904)\tD(fake)1 0.3139 (0.3098)\tD(fake)2 0.3175 (0.2706)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1403 (-0.1574)\n",
            "Epoch: [12][ 80/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6431 (0.6870)\tD(fake)1 0.3145 (0.3121)\tD(fake)2 0.3862 (0.2745)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1748 (-0.1573)\n",
            "Epoch: [12][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6058 (0.6850)\tD(fake)1 0.2233 (0.3141)\tD(fake)2 0.3626 (0.2766)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1628 (-0.1582)\n",
            "Epoch: [12][100/195]\tTime  0.351 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7500 (0.6844)\tD(fake)1 0.4174 (0.3155)\tD(fake)2 0.3052 (0.2771)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1588)\n",
            "Epoch: [12][110/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8541 (0.6864)\tD(fake)1 0.3814 (0.3138)\tD(fake)2 0.1312 (0.2740)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1611 (-0.1591)\n",
            "Epoch: [12][120/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7856 (0.6901)\tD(fake)1 0.3006 (0.3100)\tD(fake)2 0.1385 (0.2705)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1677 (-0.1594)\n",
            "Epoch: [12][130/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7094 (0.6916)\tD(fake)1 0.3237 (0.3078)\tD(fake)2 0.2410 (0.2694)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1414 (-0.1591)\n",
            "Epoch: [12][140/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7013 (0.6933)\tD(fake)1 0.2285 (0.3057)\tD(fake)2 0.3058 (0.2681)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1539 (-0.1591)\n",
            "Epoch: [12][150/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7155 (0.6956)\tD(fake)1 0.2656 (0.3037)\tD(fake)2 0.2659 (0.2664)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1644 (-0.1591)\n",
            "Epoch: [12][160/195]\tTime  0.356 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6410 (0.6966)\tD(fake)1 0.2635 (0.3030)\tD(fake)2 0.3087 (0.2656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1596)\n",
            "Epoch: [12][170/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7145 (0.6958)\tD(fake)1 0.3181 (0.3050)\tD(fake)2 0.2208 (0.2672)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1596)\n",
            "Epoch: [12][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6732 (0.6950)\tD(fake)1 0.3663 (0.3056)\tD(fake)2 0.2862 (0.2678)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1719 (-0.1600)\n",
            "Epoch: [12][190/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6718 (0.6932)\tD(fake)1 0.3510 (0.3065)\tD(fake)2 0.3098 (0.2682)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1703 (-0.1601)\n",
            "Epoch: [13][  0/195]\tTime  0.605 ( 0.605)\tData  0.199 ( 0.199)\tD(real) 0.7525 (0.7525)\tD(fake)1 0.4389 (0.4389)\tD(fake)2 0.2461 (0.2461)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1637 (-0.1637)\n",
            "Epoch: [13][ 10/195]\tTime  0.351 ( 0.374)\tData  0.000 ( 0.018)\tD(real) 0.8810 (0.6993)\tD(fake)1 0.3892 (0.3199)\tD(fake)2 0.0534 (0.2472)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1742 (-0.1581)\n",
            "Epoch: [13][ 20/195]\tTime  0.358 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.6560 (0.7114)\tD(fake)1 0.2168 (0.2898)\tD(fake)2 0.2891 (0.2431)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1574)\n",
            "Epoch: [13][ 30/195]\tTime  0.344 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.6969 (0.7098)\tD(fake)1 0.2911 (0.2955)\tD(fake)2 0.2541 (0.2490)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1267 (-0.1555)\n",
            "Epoch: [13][ 40/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7945 (0.7079)\tD(fake)1 0.4229 (0.2995)\tD(fake)2 0.2141 (0.2530)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1582)\n",
            "Epoch: [13][ 50/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.8494 (0.7031)\tD(fake)1 0.4354 (0.3043)\tD(fake)2 0.1140 (0.2564)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1587)\n",
            "Epoch: [13][ 60/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7124 (0.7002)\tD(fake)1 0.3208 (0.3032)\tD(fake)2 0.2818 (0.2598)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1590)\n",
            "Epoch: [13][ 70/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7555 (0.7002)\tD(fake)1 0.3359 (0.3034)\tD(fake)2 0.2241 (0.2601)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1125 (-0.1588)\n",
            "Epoch: [13][ 80/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6874 (0.7014)\tD(fake)1 0.2759 (0.3011)\tD(fake)2 0.3014 (0.2593)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1557 (-0.1587)\n",
            "Epoch: [13][ 90/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6621 (0.7033)\tD(fake)1 0.2338 (0.2991)\tD(fake)2 0.3603 (0.2594)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1098 (-0.1575)\n",
            "Epoch: [13][100/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7000 (0.7039)\tD(fake)1 0.2853 (0.3000)\tD(fake)2 0.2419 (0.2593)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1570)\n",
            "Epoch: [13][110/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7701 (0.7071)\tD(fake)1 0.3157 (0.2973)\tD(fake)2 0.1695 (0.2565)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1570)\n",
            "Epoch: [13][120/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6987 (0.7082)\tD(fake)1 0.2854 (0.2944)\tD(fake)2 0.3180 (0.2542)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1570)\n",
            "Epoch: [13][130/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7087 (0.7079)\tD(fake)1 0.2972 (0.2948)\tD(fake)2 0.2464 (0.2544)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1473 (-0.1567)\n",
            "Epoch: [13][140/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6410 (0.7084)\tD(fake)1 0.1660 (0.2936)\tD(fake)2 0.2238 (0.2534)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1465 (-0.1570)\n",
            "Epoch: [13][150/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7286 (0.7110)\tD(fake)1 0.2301 (0.2913)\tD(fake)2 0.2320 (0.2514)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1518 (-0.1572)\n",
            "Epoch: [13][160/195]\tTime  0.353 ( 0.349)\tData  0.000 ( 0.002)\tD(real) 0.6688 (0.7113)\tD(fake)1 0.2692 (0.2911)\tD(fake)2 0.2310 (0.2514)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1541 (-0.1571)\n",
            "Epoch: [13][170/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7270 (0.7106)\tD(fake)1 0.3223 (0.2915)\tD(fake)2 0.2222 (0.2522)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1566)\n",
            "Epoch: [13][180/195]\tTime  0.348 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7256 (0.7107)\tD(fake)1 0.3348 (0.2917)\tD(fake)2 0.2224 (0.2526)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1567)\n",
            "Epoch: [13][190/195]\tTime  0.347 ( 0.349)\tData  0.000 ( 0.001)\tD(real) 0.7789 (0.7108)\tD(fake)1 0.3021 (0.2917)\tD(fake)2 0.2097 (0.2529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1670 (-0.1573)\n",
            "Epoch: [14][  0/195]\tTime  0.607 ( 0.607)\tData  0.208 ( 0.208)\tD(real) 0.5937 (0.5937)\tD(fake)1 0.2206 (0.2206)\tD(fake)2 0.2328 (0.2328)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1620)\n",
            "Epoch: [14][ 10/195]\tTime  0.346 ( 0.370)\tData  0.000 ( 0.019)\tD(real) 0.7595 (0.6745)\tD(fake)1 0.3839 (0.3092)\tD(fake)2 0.1755 (0.2656)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1305 (-0.1558)\n",
            "Epoch: [14][ 20/195]\tTime  0.345 ( 0.360)\tData  0.000 ( 0.010)\tD(real) 0.6254 (0.6792)\tD(fake)1 0.2548 (0.3055)\tD(fake)2 0.3477 (0.2746)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1598 (-0.1597)\n",
            "Epoch: [14][ 30/195]\tTime  0.355 ( 0.356)\tData  0.000 ( 0.007)\tD(real) 0.7476 (0.6823)\tD(fake)1 0.3189 (0.3076)\tD(fake)2 0.2253 (0.2716)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1657 (-0.1596)\n",
            "Epoch: [14][ 40/195]\tTime  0.352 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.7699 (0.6864)\tD(fake)1 0.4115 (0.3086)\tD(fake)2 0.1840 (0.2707)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1582)\n",
            "Epoch: [14][ 50/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.6841 (0.6855)\tD(fake)1 0.3294 (0.3077)\tD(fake)2 0.2922 (0.2724)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1582)\n",
            "Epoch: [14][ 60/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.6196 (0.6849)\tD(fake)1 0.2633 (0.3094)\tD(fake)2 0.3069 (0.2738)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1652 (-0.1581)\n",
            "Epoch: [14][ 70/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.5714 (0.6849)\tD(fake)1 0.1305 (0.3080)\tD(fake)2 0.3827 (0.2734)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1027 (-0.1572)\n",
            "Epoch: [14][ 80/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6104 (0.6890)\tD(fake)1 0.1870 (0.3073)\tD(fake)2 0.3236 (0.2725)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1624 (-0.1574)\n",
            "Epoch: [14][ 90/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.003)\tD(real) 0.6738 (0.6923)\tD(fake)1 0.2098 (0.3045)\tD(fake)2 0.3664 (0.2706)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1389 (-0.1575)\n",
            "Epoch: [14][100/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7082 (0.6954)\tD(fake)1 0.2679 (0.3020)\tD(fake)2 0.2030 (0.2661)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1587 (-0.1577)\n",
            "Epoch: [14][110/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7489 (0.6951)\tD(fake)1 0.3085 (0.3019)\tD(fake)2 0.1791 (0.2645)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1470 (-0.1571)\n",
            "Epoch: [14][120/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7275 (0.6954)\tD(fake)1 0.3378 (0.3022)\tD(fake)2 0.1830 (0.2632)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1635 (-0.1576)\n",
            "Epoch: [14][130/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7141 (0.7007)\tD(fake)1 0.1847 (0.2977)\tD(fake)2 0.2278 (0.2588)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1577)\n",
            "Epoch: [14][140/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7967 (0.7048)\tD(fake)1 0.2947 (0.2951)\tD(fake)2 0.1320 (0.2551)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1582)\n",
            "Epoch: [14][150/195]\tTime  0.354 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6615 (0.7066)\tD(fake)1 0.2382 (0.2931)\tD(fake)2 0.2552 (0.2540)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1587)\n",
            "Epoch: [14][160/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7636 (0.7063)\tD(fake)1 0.4051 (0.2939)\tD(fake)2 0.2176 (0.2544)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1456 (-0.1584)\n",
            "Epoch: [14][170/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6997 (0.7039)\tD(fake)1 0.3798 (0.2956)\tD(fake)2 0.2464 (0.2561)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1735 (-0.1584)\n",
            "Epoch: [14][180/195]\tTime  0.344 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.5488 (0.7031)\tD(fake)1 0.0841 (0.2952)\tD(fake)2 0.3294 (0.2562)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1653 (-0.1590)\n",
            "Epoch: [14][190/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7464 (0.7043)\tD(fake)1 0.2785 (0.2955)\tD(fake)2 0.2429 (0.2557)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1591)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYyP-fb7S-WE",
        "outputId": "ef369b24-ff99-4bf9-a4a8-effdb8106a10"
      },
      "source": [
        "run(10)\n",
        "save_vid()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][  0/195]\tTime  0.850 ( 0.850)\tData  0.435 ( 0.435)\tD(real) 0.7838 (0.7838)\tD(fake)1 0.3152 (0.3152)\tD(fake)2 0.2404 (0.2404)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1629)\n",
            "Epoch: [0][ 10/195]\tTime  0.348 ( 0.397)\tData  0.000 ( 0.040)\tD(real) 0.6343 (0.7004)\tD(fake)1 0.2174 (0.2914)\tD(fake)2 0.3600 (0.2503)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1612 (-0.1603)\n",
            "Epoch: [0][ 20/195]\tTime  0.345 ( 0.381)\tData  0.000 ( 0.021)\tD(real) 0.7671 (0.7017)\tD(fake)1 0.3950 (0.2983)\tD(fake)2 0.2035 (0.2487)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1584)\n",
            "Epoch: [0][ 30/195]\tTime  0.349 ( 0.371)\tData  0.000 ( 0.014)\tD(real) 0.6859 (0.6969)\tD(fake)1 0.2445 (0.2975)\tD(fake)2 0.2567 (0.2541)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1727 (-0.1575)\n",
            "Epoch: [0][ 40/195]\tTime  0.349 ( 0.366)\tData  0.000 ( 0.011)\tD(real) 0.7120 (0.7068)\tD(fake)1 0.2733 (0.2884)\tD(fake)2 0.3356 (0.2482)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1615 (-0.1592)\n",
            "Epoch: [0][ 50/195]\tTime  0.352 ( 0.363)\tData  0.000 ( 0.009)\tD(real) 0.6115 (0.7061)\tD(fake)1 0.2500 (0.2922)\tD(fake)2 0.3663 (0.2511)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1427 (-0.1578)\n",
            "Epoch: [0][ 60/195]\tTime  0.348 ( 0.360)\tData  0.000 ( 0.007)\tD(real) 0.7716 (0.7032)\tD(fake)1 0.4353 (0.2966)\tD(fake)2 0.2150 (0.2525)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1589)\n",
            "Epoch: [0][ 70/195]\tTime  0.347 ( 0.359)\tData  0.000 ( 0.006)\tD(real) 0.7244 (0.7014)\tD(fake)1 0.3438 (0.2972)\tD(fake)2 0.2322 (0.2538)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1593)\n",
            "Epoch: [0][ 80/195]\tTime  0.345 ( 0.358)\tData  0.000 ( 0.006)\tD(real) 0.6418 (0.7009)\tD(fake)1 0.2507 (0.2967)\tD(fake)2 0.3255 (0.2550)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1597)\n",
            "Epoch: [0][ 90/195]\tTime  0.348 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.5702 (0.7005)\tD(fake)1 0.2114 (0.2992)\tD(fake)2 0.2486 (0.2553)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1683 (-0.1606)\n",
            "Epoch: [0][100/195]\tTime  0.347 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7840 (0.6997)\tD(fake)1 0.4324 (0.3028)\tD(fake)2 0.1662 (0.2562)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1427 (-0.1605)\n",
            "Epoch: [0][110/195]\tTime  0.346 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.7729 (0.6988)\tD(fake)1 0.2847 (0.3015)\tD(fake)2 0.1567 (0.2560)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1217 (-0.1599)\n",
            "Epoch: [0][120/195]\tTime  0.346 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.6705 (0.7024)\tD(fake)1 0.2090 (0.2980)\tD(fake)2 0.2134 (0.2524)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1320 (-0.1599)\n",
            "Epoch: [0][130/195]\tTime  0.351 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.6602 (0.7040)\tD(fake)1 0.2684 (0.2966)\tD(fake)2 0.2243 (0.2505)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1598)\n",
            "Epoch: [0][140/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.8012 (0.7039)\tD(fake)1 0.3697 (0.2969)\tD(fake)2 0.1581 (0.2504)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1645 (-0.1600)\n",
            "Epoch: [0][150/195]\tTime  0.344 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.6325 (0.7023)\tD(fake)1 0.2797 (0.2980)\tD(fake)2 0.3184 (0.2522)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1699 (-0.1601)\n",
            "Epoch: [0][160/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7395 (0.7012)\tD(fake)1 0.3774 (0.2994)\tD(fake)2 0.2682 (0.2533)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1610 (-0.1599)\n",
            "Epoch: [0][170/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7728 (0.7011)\tD(fake)1 0.3192 (0.2989)\tD(fake)2 0.2213 (0.2533)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1436 (-0.1599)\n",
            "Epoch: [0][180/195]\tTime  0.351 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7983 (0.7024)\tD(fake)1 0.3308 (0.2982)\tD(fake)2 0.1187 (0.2520)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1113 (-0.1593)\n",
            "Epoch: [0][190/195]\tTime  0.347 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6068 (0.7022)\tD(fake)1 0.2366 (0.2982)\tD(fake)2 0.3523 (0.2529)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1467 (-0.1589)\n",
            "Epoch: [1][  0/195]\tTime  0.624 ( 0.624)\tData  0.216 ( 0.216)\tD(real) 0.6705 (0.6705)\tD(fake)1 0.2417 (0.2417)\tD(fake)2 0.3072 (0.3072)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1673 (-0.1673)\n",
            "Epoch: [1][ 10/195]\tTime  0.347 ( 0.374)\tData  0.000 ( 0.020)\tD(real) 0.7216 (0.7013)\tD(fake)1 0.2792 (0.2954)\tD(fake)2 0.2623 (0.2720)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1722 (-0.1588)\n",
            "Epoch: [1][ 20/195]\tTime  0.353 ( 0.365)\tData  0.000 ( 0.011)\tD(real) 0.6308 (0.7036)\tD(fake)1 0.2144 (0.2972)\tD(fake)2 0.3310 (0.2718)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1732 (-0.1620)\n",
            "Epoch: [1][ 30/195]\tTime  0.352 ( 0.360)\tData  0.000 ( 0.007)\tD(real) 0.7600 (0.7018)\tD(fake)1 0.3980 (0.3005)\tD(fake)2 0.2811 (0.2684)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1631)\n",
            "Epoch: [1][ 40/195]\tTime  0.348 ( 0.357)\tData  0.000 ( 0.006)\tD(real) 0.7169 (0.7018)\tD(fake)1 0.3473 (0.2996)\tD(fake)2 0.1811 (0.2621)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1633)\n",
            "Epoch: [1][ 50/195]\tTime  0.348 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7711 (0.7019)\tD(fake)1 0.4047 (0.2990)\tD(fake)2 0.1792 (0.2604)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1603 (-0.1611)\n",
            "Epoch: [1][ 60/195]\tTime  0.349 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7473 (0.6968)\tD(fake)1 0.3571 (0.3021)\tD(fake)2 0.1338 (0.2616)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1611)\n",
            "Epoch: [1][ 70/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7433 (0.7009)\tD(fake)1 0.2672 (0.2980)\tD(fake)2 0.2010 (0.2590)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1606)\n",
            "Epoch: [1][ 80/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7808 (0.7029)\tD(fake)1 0.3062 (0.2987)\tD(fake)2 0.1467 (0.2581)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1600)\n",
            "Epoch: [1][ 90/195]\tTime  0.357 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6838 (0.7038)\tD(fake)1 0.3791 (0.2978)\tD(fake)2 0.2821 (0.2581)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1528 (-0.1590)\n",
            "Epoch: [1][100/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.002)\tD(real) 0.6572 (0.6995)\tD(fake)1 0.2697 (0.3008)\tD(fake)2 0.2743 (0.2611)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1433 (-0.1585)\n",
            "Epoch: [1][110/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7816 (0.7011)\tD(fake)1 0.3066 (0.3000)\tD(fake)2 0.1856 (0.2604)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1556 (-0.1589)\n",
            "Epoch: [1][120/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7534 (0.7033)\tD(fake)1 0.3624 (0.2981)\tD(fake)2 0.3061 (0.2580)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1692 (-0.1593)\n",
            "Epoch: [1][130/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5916 (0.7021)\tD(fake)1 0.2396 (0.2993)\tD(fake)2 0.2419 (0.2572)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1576 (-0.1591)\n",
            "Epoch: [1][140/195]\tTime  0.356 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7017 (0.6990)\tD(fake)1 0.3454 (0.3011)\tD(fake)2 0.2555 (0.2588)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1595)\n",
            "Epoch: [1][150/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7403 (0.6998)\tD(fake)1 0.3374 (0.3002)\tD(fake)2 0.2081 (0.2575)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1176 (-0.1591)\n",
            "Epoch: [1][160/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6596 (0.6993)\tD(fake)1 0.2596 (0.3001)\tD(fake)2 0.3138 (0.2580)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1595)\n",
            "Epoch: [1][170/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7211 (0.6989)\tD(fake)1 0.3027 (0.3007)\tD(fake)2 0.2503 (0.2581)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1708 (-0.1598)\n",
            "Epoch: [1][180/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7330 (0.7002)\tD(fake)1 0.2545 (0.2998)\tD(fake)2 0.1425 (0.2569)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1139 (-0.1598)\n",
            "Epoch: [1][190/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6728 (0.7015)\tD(fake)1 0.2379 (0.2982)\tD(fake)2 0.2873 (0.2560)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1596)\n",
            "Epoch: [2][  0/195]\tTime  0.611 ( 0.611)\tData  0.212 ( 0.212)\tD(real) 0.8231 (0.8231)\tD(fake)1 0.4094 (0.4094)\tD(fake)2 0.2007 (0.2007)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1594 (-0.1594)\n",
            "Epoch: [2][ 10/195]\tTime  0.349 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.6653 (0.7050)\tD(fake)1 0.2951 (0.3062)\tD(fake)2 0.2677 (0.2292)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1588)\n",
            "Epoch: [2][ 20/195]\tTime  0.346 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.6567 (0.7008)\tD(fake)1 0.2739 (0.3037)\tD(fake)2 0.2263 (0.2371)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1569)\n",
            "Epoch: [2][ 30/195]\tTime  0.351 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.6497 (0.7052)\tD(fake)1 0.1691 (0.2937)\tD(fake)2 0.3719 (0.2410)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1480 (-0.1582)\n",
            "Epoch: [2][ 40/195]\tTime  0.346 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.8024 (0.7111)\tD(fake)1 0.3912 (0.2957)\tD(fake)2 0.2014 (0.2407)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1594)\n",
            "Epoch: [2][ 50/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.005)\tD(real) 0.7351 (0.7155)\tD(fake)1 0.2374 (0.2902)\tD(fake)2 0.2426 (0.2387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1622 (-0.1598)\n",
            "Epoch: [2][ 60/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7711 (0.7166)\tD(fake)1 0.3789 (0.2894)\tD(fake)2 0.2177 (0.2378)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1721 (-0.1601)\n",
            "Epoch: [2][ 70/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6758 (0.7121)\tD(fake)1 0.2008 (0.2911)\tD(fake)2 0.2868 (0.2387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1554 (-0.1603)\n",
            "Epoch: [2][ 80/195]\tTime  0.352 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7349 (0.7155)\tD(fake)1 0.3113 (0.2893)\tD(fake)2 0.2394 (0.2364)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1676 (-0.1612)\n",
            "Epoch: [2][ 90/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6850 (0.7157)\tD(fake)1 0.3095 (0.2889)\tD(fake)2 0.2774 (0.2381)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1597)\n",
            "Epoch: [2][100/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7156 (0.7145)\tD(fake)1 0.2552 (0.2904)\tD(fake)2 0.2692 (0.2402)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1705 (-0.1598)\n",
            "Epoch: [2][110/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6688 (0.7174)\tD(fake)1 0.2480 (0.2879)\tD(fake)2 0.3006 (0.2390)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.0973 (-0.1599)\n",
            "Epoch: [2][120/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7047 (0.7184)\tD(fake)1 0.2485 (0.2871)\tD(fake)2 0.2175 (0.2386)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1647 (-0.1603)\n",
            "Epoch: [2][130/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6334 (0.7169)\tD(fake)1 0.2406 (0.2872)\tD(fake)2 0.2661 (0.2391)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1701 (-0.1600)\n",
            "Epoch: [2][140/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6193 (0.7160)\tD(fake)1 0.2597 (0.2872)\tD(fake)2 0.3237 (0.2390)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1636 (-0.1598)\n",
            "Epoch: [2][150/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7450 (0.7151)\tD(fake)1 0.2227 (0.2887)\tD(fake)2 0.2195 (0.2402)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1319 (-0.1595)\n",
            "Epoch: [2][160/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7557 (0.7204)\tD(fake)1 0.2143 (0.2841)\tD(fake)2 0.1743 (0.2361)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1668 (-0.1596)\n",
            "Epoch: [2][170/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.8572 (0.7215)\tD(fake)1 0.4121 (0.2843)\tD(fake)2 0.0446 (0.2351)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1599)\n",
            "Epoch: [2][180/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6392 (0.7176)\tD(fake)1 0.3370 (0.2861)\tD(fake)2 0.3196 (0.2387)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1582 (-0.1598)\n",
            "Epoch: [2][190/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6482 (0.7167)\tD(fake)1 0.2303 (0.2864)\tD(fake)2 0.3441 (0.2399)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1658 (-0.1595)\n",
            "Epoch: [3][  0/195]\tTime  0.590 ( 0.590)\tData  0.205 ( 0.205)\tD(real) 0.7235 (0.7235)\tD(fake)1 0.3730 (0.3730)\tD(fake)2 0.2982 (0.2982)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1643 (-0.1643)\n",
            "Epoch: [3][ 10/195]\tTime  0.347 ( 0.372)\tData  0.000 ( 0.019)\tD(real) 0.6151 (0.6803)\tD(fake)1 0.2284 (0.3218)\tD(fake)2 0.2526 (0.2764)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1603)\n",
            "Epoch: [3][ 20/195]\tTime  0.351 ( 0.361)\tData  0.000 ( 0.010)\tD(real) 0.6640 (0.6894)\tD(fake)1 0.2380 (0.3107)\tD(fake)2 0.2233 (0.2674)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1629 (-0.1598)\n",
            "Epoch: [3][ 30/195]\tTime  0.351 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7319 (0.6925)\tD(fake)1 0.3615 (0.3096)\tD(fake)2 0.1766 (0.2663)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1700 (-0.1608)\n",
            "Epoch: [3][ 40/195]\tTime  0.345 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6841 (0.6944)\tD(fake)1 0.2593 (0.3047)\tD(fake)2 0.2754 (0.2647)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1167 (-0.1594)\n",
            "Epoch: [3][ 50/195]\tTime  0.350 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7407 (0.6999)\tD(fake)1 0.2959 (0.3005)\tD(fake)2 0.2180 (0.2607)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1744 (-0.1609)\n",
            "Epoch: [3][ 60/195]\tTime  0.351 ( 0.352)\tData  0.000 ( 0.004)\tD(real) 0.8551 (0.7042)\tD(fake)1 0.4224 (0.2995)\tD(fake)2 0.1873 (0.2583)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1564 (-0.1598)\n",
            "Epoch: [3][ 70/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7789 (0.7112)\tD(fake)1 0.2332 (0.2924)\tD(fake)2 0.2012 (0.2528)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1712 (-0.1599)\n",
            "Epoch: [3][ 80/195]\tTime  0.357 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7829 (0.7235)\tD(fake)1 0.1486 (0.2800)\tD(fake)2 0.1993 (0.2411)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1595)\n",
            "Epoch: [3][ 90/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7917 (0.7329)\tD(fake)1 0.2293 (0.2711)\tD(fake)2 0.1465 (0.2325)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1474 (-0.1592)\n",
            "Epoch: [3][100/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7976 (0.7348)\tD(fake)1 0.4022 (0.2694)\tD(fake)2 0.1075 (0.2286)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1583)\n",
            "Epoch: [3][110/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7645 (0.7305)\tD(fake)1 0.3528 (0.2728)\tD(fake)2 0.1589 (0.2316)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1587)\n",
            "Epoch: [3][120/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6853 (0.7267)\tD(fake)1 0.3231 (0.2759)\tD(fake)2 0.2575 (0.2343)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1567 (-0.1585)\n",
            "Epoch: [3][130/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7441 (0.7257)\tD(fake)1 0.2876 (0.2764)\tD(fake)2 0.1832 (0.2340)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1586)\n",
            "Epoch: [3][140/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7461 (0.7253)\tD(fake)1 0.3735 (0.2779)\tD(fake)2 0.2621 (0.2354)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1634 (-0.1585)\n",
            "Epoch: [3][150/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7041 (0.7217)\tD(fake)1 0.3492 (0.2810)\tD(fake)2 0.2158 (0.2380)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1632 (-0.1583)\n",
            "Epoch: [3][160/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7940 (0.7201)\tD(fake)1 0.3696 (0.2830)\tD(fake)2 0.2122 (0.2399)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1579)\n",
            "Epoch: [3][170/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6560 (0.7196)\tD(fake)1 0.3165 (0.2834)\tD(fake)2 0.3358 (0.2404)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1568 (-0.1579)\n",
            "Epoch: [3][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7880 (0.7185)\tD(fake)1 0.4085 (0.2855)\tD(fake)2 0.1046 (0.2403)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1579)\n",
            "Epoch: [3][190/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6950 (0.7169)\tD(fake)1 0.3013 (0.2857)\tD(fake)2 0.2289 (0.2416)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1580)\n",
            "Epoch: [4][  0/195]\tTime  0.592 ( 0.592)\tData  0.213 ( 0.213)\tD(real) 0.5421 (0.5421)\tD(fake)1 0.1616 (0.1616)\tD(fake)2 0.4829 (0.4829)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1500 (-0.1500)\n",
            "Epoch: [4][ 10/195]\tTime  0.345 ( 0.373)\tData  0.000 ( 0.020)\tD(real) 0.7238 (0.6783)\tD(fake)1 0.3154 (0.3177)\tD(fake)2 0.2188 (0.2854)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1679 (-0.1596)\n",
            "Epoch: [4][ 20/195]\tTime  0.347 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.8963 (0.7072)\tD(fake)1 0.3985 (0.3066)\tD(fake)2 0.0988 (0.2617)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1646 (-0.1582)\n",
            "Epoch: [4][ 30/195]\tTime  0.343 ( 0.357)\tData  0.000 ( 0.007)\tD(real) 0.7250 (0.7119)\tD(fake)1 0.3245 (0.3051)\tD(fake)2 0.1528 (0.2544)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1732 (-0.1601)\n",
            "Epoch: [4][ 40/195]\tTime  0.353 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.7945 (0.7325)\tD(fake)1 0.1004 (0.2838)\tD(fake)2 0.0962 (0.2212)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1507 (-0.1596)\n",
            "Epoch: [4][ 50/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8478 (0.7513)\tD(fake)1 0.2358 (0.2627)\tD(fake)2 0.1428 (0.2066)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1492 (-0.1600)\n",
            "Epoch: [4][ 60/195]\tTime  0.349 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.8626 (0.7622)\tD(fake)1 0.2643 (0.2513)\tD(fake)2 0.1237 (0.1986)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1696 (-0.1600)\n",
            "Epoch: [4][ 70/195]\tTime  0.344 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.5879 (0.7563)\tD(fake)1 0.1783 (0.2555)\tD(fake)2 0.3292 (0.2025)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1602 (-0.1605)\n",
            "Epoch: [4][ 80/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6620 (0.7462)\tD(fake)1 0.3847 (0.2650)\tD(fake)2 0.3298 (0.2135)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1603)\n",
            "Epoch: [4][ 90/195]\tTime  0.349 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7100 (0.7357)\tD(fake)1 0.3556 (0.2735)\tD(fake)2 0.2271 (0.2231)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1230 (-0.1608)\n",
            "Epoch: [4][100/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6815 (0.7267)\tD(fake)1 0.3724 (0.2811)\tD(fake)2 0.2926 (0.2326)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1551 (-0.1617)\n",
            "Epoch: [4][110/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6090 (0.7209)\tD(fake)1 0.2819 (0.2855)\tD(fake)2 0.3478 (0.2394)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1546 (-0.1612)\n",
            "Epoch: [4][120/195]\tTime  0.345 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6746 (0.7174)\tD(fake)1 0.3192 (0.2882)\tD(fake)2 0.3296 (0.2437)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1642 (-0.1610)\n",
            "Epoch: [4][130/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6823 (0.7136)\tD(fake)1 0.3873 (0.2912)\tD(fake)2 0.2571 (0.2476)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1478 (-0.1610)\n",
            "Epoch: [4][140/195]\tTime  0.358 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6759 (0.7104)\tD(fake)1 0.3390 (0.2936)\tD(fake)2 0.2675 (0.2511)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.1607)\n",
            "Epoch: [4][150/195]\tTime  0.351 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6571 (0.7070)\tD(fake)1 0.3033 (0.2963)\tD(fake)2 0.2817 (0.2545)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1606)\n",
            "Epoch: [4][160/195]\tTime  0.342 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6554 (0.7045)\tD(fake)1 0.3786 (0.2983)\tD(fake)2 0.2641 (0.2567)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1605 (-0.1600)\n",
            "Epoch: [4][170/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7537 (0.7009)\tD(fake)1 0.4494 (0.3013)\tD(fake)2 0.1867 (0.2592)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1590 (-0.1603)\n",
            "Epoch: [4][180/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.8036 (0.6998)\tD(fake)1 0.3816 (0.3021)\tD(fake)2 0.1523 (0.2600)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1469 (-0.1604)\n",
            "Epoch: [4][190/195]\tTime  0.346 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.5478 (0.6997)\tD(fake)1 0.1395 (0.3011)\tD(fake)2 0.3193 (0.2602)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1659 (-0.1605)\n",
            "Epoch: [5][  0/195]\tTime  0.600 ( 0.600)\tData  0.220 ( 0.220)\tD(real) 0.6954 (0.6954)\tD(fake)1 0.2830 (0.2830)\tD(fake)2 0.2572 (0.2572)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1427 (-0.1427)\n",
            "Epoch: [5][ 10/195]\tTime  0.345 ( 0.372)\tData  0.000 ( 0.020)\tD(real) 0.6393 (0.7144)\tD(fake)1 0.1830 (0.2845)\tD(fake)2 0.3366 (0.2498)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1623 (-0.1603)\n",
            "Epoch: [5][ 20/195]\tTime  0.346 ( 0.362)\tData  0.000 ( 0.011)\tD(real) 0.6213 (0.7116)\tD(fake)1 0.3326 (0.2950)\tD(fake)2 0.3566 (0.2519)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1752 (-0.1585)\n",
            "Epoch: [5][ 30/195]\tTime  0.347 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.7643 (0.6949)\tD(fake)1 0.3923 (0.3138)\tD(fake)2 0.2041 (0.2653)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1237 (-0.1577)\n",
            "Epoch: [5][ 40/195]\tTime  0.344 ( 0.355)\tData  0.000 ( 0.006)\tD(real) 0.6004 (0.6894)\tD(fake)1 0.2392 (0.3144)\tD(fake)2 0.2980 (0.2698)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1587)\n",
            "Epoch: [5][ 50/195]\tTime  0.345 ( 0.354)\tData  0.000 ( 0.005)\tD(real) 0.8704 (0.6909)\tD(fake)1 0.5072 (0.3146)\tD(fake)2 0.2191 (0.2693)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1602)\n",
            "Epoch: [5][ 60/195]\tTime  0.344 ( 0.353)\tData  0.000 ( 0.004)\tD(real) 0.7060 (0.6890)\tD(fake)1 0.3136 (0.3125)\tD(fake)2 0.2591 (0.2690)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1457 (-0.1607)\n",
            "Epoch: [5][ 70/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6325 (0.6886)\tD(fake)1 0.2526 (0.3115)\tD(fake)2 0.2959 (0.2694)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1602)\n",
            "Epoch: [5][ 80/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.6450 (0.6869)\tD(fake)1 0.3296 (0.3142)\tD(fake)2 0.3500 (0.2729)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1715 (-0.1600)\n",
            "Epoch: [5][ 90/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.003)\tD(real) 0.7003 (0.6860)\tD(fake)1 0.3734 (0.3172)\tD(fake)2 0.2466 (0.2753)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1608)\n",
            "Epoch: [5][100/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5612 (0.6798)\tD(fake)1 0.2821 (0.3203)\tD(fake)2 0.4294 (0.2800)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1600)\n",
            "Epoch: [5][110/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6820 (0.6781)\tD(fake)1 0.3751 (0.3224)\tD(fake)2 0.2635 (0.2805)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1631 (-0.1595)\n",
            "Epoch: [5][120/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7351 (0.6787)\tD(fake)1 0.3247 (0.3217)\tD(fake)2 0.1834 (0.2791)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1599 (-0.1595)\n",
            "Epoch: [5][130/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7479 (0.6802)\tD(fake)1 0.3646 (0.3206)\tD(fake)2 0.2521 (0.2788)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1678 (-0.1590)\n",
            "Epoch: [5][140/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6793 (0.6790)\tD(fake)1 0.3482 (0.3208)\tD(fake)2 0.2874 (0.2793)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1688 (-0.1593)\n",
            "Epoch: [5][150/195]\tTime  0.347 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7713 (0.6804)\tD(fake)1 0.3327 (0.3201)\tD(fake)2 0.1868 (0.2783)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1733 (-0.1594)\n",
            "Epoch: [5][160/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5900 (0.6806)\tD(fake)1 0.2385 (0.3194)\tD(fake)2 0.3446 (0.2784)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1597)\n",
            "Epoch: [5][170/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7381 (0.6802)\tD(fake)1 0.3563 (0.3200)\tD(fake)2 0.3251 (0.2787)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1745 (-0.1597)\n",
            "Epoch: [5][180/195]\tTime  0.352 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.7503 (0.6801)\tD(fake)1 0.3670 (0.3204)\tD(fake)2 0.2189 (0.2785)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1598)\n",
            "Epoch: [5][190/195]\tTime  0.355 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.5805 (0.6795)\tD(fake)1 0.2343 (0.3199)\tD(fake)2 0.3823 (0.2789)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1549 (-0.1599)\n",
            "Epoch: [6][  0/195]\tTime  0.616 ( 0.616)\tData  0.207 ( 0.207)\tD(real) 0.6386 (0.6386)\tD(fake)1 0.2709 (0.2709)\tD(fake)2 0.2982 (0.2982)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1689 (-0.1689)\n",
            "Epoch: [6][ 10/195]\tTime  0.347 ( 0.376)\tData  0.000 ( 0.019)\tD(real) 0.6248 (0.7015)\tD(fake)1 0.2264 (0.2881)\tD(fake)2 0.2883 (0.2507)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1562 (-0.1571)\n",
            "Epoch: [6][ 20/195]\tTime  0.348 ( 0.364)\tData  0.000 ( 0.010)\tD(real) 0.6036 (0.7081)\tD(fake)1 0.2272 (0.2836)\tD(fake)2 0.4276 (0.2575)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1527 (-0.1579)\n",
            "Epoch: [6][ 30/195]\tTime  0.347 ( 0.359)\tData  0.000 ( 0.007)\tD(real) 0.6873 (0.7029)\tD(fake)1 0.3641 (0.2974)\tD(fake)2 0.2932 (0.2654)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1690 (-0.1569)\n",
            "Epoch: [6][ 40/195]\tTime  0.349 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7552 (0.7031)\tD(fake)1 0.3808 (0.3016)\tD(fake)2 0.2061 (0.2677)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1630 (-0.1584)\n",
            "Epoch: [6][ 50/195]\tTime  0.348 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.6524 (0.7020)\tD(fake)1 0.2649 (0.2994)\tD(fake)2 0.2914 (0.2672)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1648 (-0.1607)\n",
            "Epoch: [6][ 60/195]\tTime  0.358 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.5914 (0.7013)\tD(fake)1 0.1428 (0.2975)\tD(fake)2 0.4041 (0.2673)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1611)\n",
            "Epoch: [6][ 70/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.7975 (0.7056)\tD(fake)1 0.3857 (0.2966)\tD(fake)2 0.2084 (0.2634)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1654 (-0.1623)\n",
            "Epoch: [6][ 80/195]\tTime  0.356 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7290 (0.7053)\tD(fake)1 0.3247 (0.2966)\tD(fake)2 0.2074 (0.2640)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1593 (-0.1628)\n",
            "Epoch: [6][ 90/195]\tTime  0.346 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7145 (0.7020)\tD(fake)1 0.3875 (0.2991)\tD(fake)2 0.2420 (0.2669)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1621 (-0.1624)\n",
            "Epoch: [6][100/195]\tTime  0.354 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6771 (0.6977)\tD(fake)1 0.3898 (0.3020)\tD(fake)2 0.2966 (0.2697)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1698 (-0.1620)\n",
            "Epoch: [6][110/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6939 (0.6974)\tD(fake)1 0.2689 (0.3022)\tD(fake)2 0.3067 (0.2701)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1669 (-0.1619)\n",
            "Epoch: [6][120/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6883 (0.7003)\tD(fake)1 0.2492 (0.3000)\tD(fake)2 0.2822 (0.2676)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1619)\n",
            "Epoch: [6][130/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7567 (0.7003)\tD(fake)1 0.3538 (0.3009)\tD(fake)2 0.1918 (0.2663)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1597 (-0.1619)\n",
            "Epoch: [6][140/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5969 (0.6979)\tD(fake)1 0.3052 (0.3026)\tD(fake)2 0.3253 (0.2676)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1400 (-0.1618)\n",
            "Epoch: [6][150/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7956 (0.6981)\tD(fake)1 0.4326 (0.3041)\tD(fake)2 0.1851 (0.2676)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1099 (-0.1616)\n",
            "Epoch: [6][160/195]\tTime  0.352 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6309 (0.6971)\tD(fake)1 0.3156 (0.3044)\tD(fake)2 0.3346 (0.2687)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1717 (-0.1619)\n",
            "Epoch: [6][170/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6598 (0.6958)\tD(fake)1 0.3331 (0.3062)\tD(fake)2 0.3151 (0.2697)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1650 (-0.1616)\n",
            "Epoch: [6][180/195]\tTime  0.345 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7197 (0.6941)\tD(fake)1 0.4120 (0.3079)\tD(fake)2 0.2502 (0.2704)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1615)\n",
            "Epoch: [6][190/195]\tTime  0.353 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6431 (0.6923)\tD(fake)1 0.3160 (0.3088)\tD(fake)2 0.3081 (0.2709)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1615)\n",
            "Epoch: [7][  0/195]\tTime  0.606 ( 0.606)\tData  0.207 ( 0.207)\tD(real) 0.8734 (0.8734)\tD(fake)1 0.5223 (0.5223)\tD(fake)2 0.1736 (0.1736)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1680 (-0.1680)\n",
            "Epoch: [7][ 10/195]\tTime  0.346 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.7286 (0.7081)\tD(fake)1 0.2357 (0.3244)\tD(fake)2 0.2118 (0.2531)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1502 (-0.1618)\n",
            "Epoch: [7][ 20/195]\tTime  0.356 ( 0.364)\tData  0.000 ( 0.010)\tD(real) 0.7949 (0.7362)\tD(fake)1 0.2446 (0.2848)\tD(fake)2 0.1917 (0.2305)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1684 (-0.1607)\n",
            "Epoch: [7][ 30/195]\tTime  0.347 ( 0.360)\tData  0.000 ( 0.007)\tD(real) 0.6621 (0.7363)\tD(fake)1 0.3071 (0.2800)\tD(fake)2 0.2706 (0.2299)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1661 (-0.1609)\n",
            "Epoch: [7][ 40/195]\tTime  0.347 ( 0.357)\tData  0.000 ( 0.005)\tD(real) 0.6352 (0.7256)\tD(fake)1 0.2330 (0.2858)\tD(fake)2 0.2607 (0.2352)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1665 (-0.1611)\n",
            "Epoch: [7][ 50/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.6531 (0.7207)\tD(fake)1 0.2423 (0.2888)\tD(fake)2 0.3002 (0.2380)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1672 (-0.1613)\n",
            "Epoch: [7][ 60/195]\tTime  0.346 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7443 (0.7206)\tD(fake)1 0.2879 (0.2870)\tD(fake)2 0.3011 (0.2362)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1252 (-0.1608)\n",
            "Epoch: [7][ 70/195]\tTime  0.348 ( 0.354)\tData  0.000 ( 0.003)\tD(real) 0.6635 (0.7191)\tD(fake)1 0.2374 (0.2890)\tD(fake)2 0.2768 (0.2383)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1610)\n",
            "Epoch: [7][ 80/195]\tTime  0.348 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7903 (0.7207)\tD(fake)1 0.3555 (0.2887)\tD(fake)2 0.1399 (0.2382)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1620 (-0.1607)\n",
            "Epoch: [7][ 90/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7603 (0.7179)\tD(fake)1 0.3630 (0.2902)\tD(fake)2 0.1607 (0.2409)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1529 (-0.1598)\n",
            "Epoch: [7][100/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6689 (0.7130)\tD(fake)1 0.3289 (0.2925)\tD(fake)2 0.2924 (0.2456)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1607 (-0.1597)\n",
            "Epoch: [7][110/195]\tTime  0.345 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5740 (0.7095)\tD(fake)1 0.1781 (0.2944)\tD(fake)2 0.3467 (0.2488)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1597)\n",
            "Epoch: [7][120/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.7847 (0.7114)\tD(fake)1 0.3442 (0.2935)\tD(fake)2 0.1389 (0.2471)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1591)\n",
            "Epoch: [7][130/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7461 (0.7116)\tD(fake)1 0.2901 (0.2922)\tD(fake)2 0.2359 (0.2466)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1649 (-0.1589)\n",
            "Epoch: [7][140/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5956 (0.7118)\tD(fake)1 0.1988 (0.2913)\tD(fake)2 0.4141 (0.2471)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1314 (-0.1578)\n",
            "Epoch: [7][150/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.5993 (0.7101)\tD(fake)1 0.2482 (0.2935)\tD(fake)2 0.3395 (0.2488)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1682 (-0.1585)\n",
            "Epoch: [7][160/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6551 (0.7069)\tD(fake)1 0.2498 (0.2963)\tD(fake)2 0.3053 (0.2518)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1609 (-0.1587)\n",
            "Epoch: [7][170/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6074 (0.7058)\tD(fake)1 0.1979 (0.2972)\tD(fake)2 0.3610 (0.2528)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1589 (-0.1589)\n",
            "Epoch: [7][180/195]\tTime  0.353 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6513 (0.7055)\tD(fake)1 0.2181 (0.2978)\tD(fake)2 0.2859 (0.2538)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1691 (-0.1592)\n",
            "Epoch: [7][190/195]\tTime  0.355 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6924 (0.7057)\tD(fake)1 0.3354 (0.2982)\tD(fake)2 0.2133 (0.2538)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1616 (-0.1590)\n",
            "Epoch: [8][  0/195]\tTime  0.601 ( 0.601)\tData  0.201 ( 0.201)\tD(real) 0.6907 (0.6907)\tD(fake)1 0.3534 (0.3534)\tD(fake)2 0.2294 (0.2294)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1671)\n",
            "Epoch: [8][ 10/195]\tTime  0.355 ( 0.374)\tData  0.000 ( 0.019)\tD(real) 0.7568 (0.6927)\tD(fake)1 0.2962 (0.3095)\tD(fake)2 0.1835 (0.2499)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1699 (-0.1610)\n",
            "Epoch: [8][ 20/195]\tTime  0.347 ( 0.362)\tData  0.000 ( 0.010)\tD(real) 0.7022 (0.6977)\tD(fake)1 0.3894 (0.3091)\tD(fake)2 0.1918 (0.2426)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1429 (-0.1589)\n",
            "Epoch: [8][ 30/195]\tTime  0.349 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.8433 (0.7157)\tD(fake)1 0.2280 (0.2919)\tD(fake)2 0.1219 (0.2214)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1729 (-0.1601)\n",
            "Epoch: [8][ 40/195]\tTime  0.346 ( 0.356)\tData  0.000 ( 0.005)\tD(real) 0.7577 (0.7414)\tD(fake)1 0.0595 (0.2606)\tD(fake)2 0.1560 (0.1994)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1608)\n",
            "Epoch: [8][ 50/195]\tTime  0.347 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8227 (0.7598)\tD(fake)1 0.1812 (0.2422)\tD(fake)2 0.1392 (0.1872)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1693 (-0.1624)\n",
            "Epoch: [8][ 60/195]\tTime  0.354 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7327 (0.7671)\tD(fake)1 0.2356 (0.2351)\tD(fake)2 0.2157 (0.1838)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1581 (-0.1627)\n",
            "Epoch: [8][ 70/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.7377 (0.7597)\tD(fake)1 0.4030 (0.2448)\tD(fake)2 0.1921 (0.1917)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1503 (-0.1621)\n",
            "Epoch: [8][ 80/195]\tTime  0.348 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6934 (0.7474)\tD(fake)1 0.4036 (0.2563)\tD(fake)2 0.2599 (0.2053)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1613 (-0.1626)\n",
            "Epoch: [8][ 90/195]\tTime  0.346 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.7059 (0.7354)\tD(fake)1 0.4047 (0.2677)\tD(fake)2 0.2154 (0.2177)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1706 (-0.1630)\n",
            "Epoch: [8][100/195]\tTime  0.353 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.5719 (0.7269)\tD(fake)1 0.2592 (0.2743)\tD(fake)2 0.3631 (0.2274)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1723 (-0.1629)\n",
            "Epoch: [8][110/195]\tTime  0.343 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6989 (0.7198)\tD(fake)1 0.3841 (0.2827)\tD(fake)2 0.2080 (0.2358)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1662 (-0.1631)\n",
            "Epoch: [8][120/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6538 (0.7142)\tD(fake)1 0.3471 (0.2872)\tD(fake)2 0.2855 (0.2428)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1723 (-0.1627)\n",
            "Epoch: [8][130/195]\tTime  0.347 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.8232 (0.7102)\tD(fake)1 0.4923 (0.2910)\tD(fake)2 0.3383 (0.2479)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1618 (-0.1626)\n",
            "Epoch: [8][140/195]\tTime  0.350 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6264 (0.7052)\tD(fake)1 0.3603 (0.2953)\tD(fake)2 0.3407 (0.2533)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1560 (-0.1628)\n",
            "Epoch: [8][150/195]\tTime  0.349 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.6583 (0.7007)\tD(fake)1 0.3801 (0.3000)\tD(fake)2 0.3096 (0.2586)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1731 (-0.1631)\n",
            "Epoch: [8][160/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5939 (0.6978)\tD(fake)1 0.3066 (0.3027)\tD(fake)2 0.3762 (0.2625)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1545 (-0.1630)\n",
            "Epoch: [8][170/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.002)\tD(real) 0.5624 (0.6954)\tD(fake)1 0.2069 (0.3049)\tD(fake)2 0.4426 (0.2652)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1497 (-0.1629)\n",
            "Epoch: [8][180/195]\tTime  0.348 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.7572 (0.6963)\tD(fake)1 0.3295 (0.3065)\tD(fake)2 0.2043 (0.2657)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1685 (-0.1628)\n",
            "Epoch: [8][190/195]\tTime  0.350 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6681 (0.6972)\tD(fake)1 0.2984 (0.3062)\tD(fake)2 0.2102 (0.2654)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1675 (-0.1630)\n",
            "Epoch: [9][  0/195]\tTime  0.594 ( 0.594)\tData  0.209 ( 0.209)\tD(real) 0.6607 (0.6607)\tD(fake)1 0.3840 (0.3840)\tD(fake)2 0.3026 (0.3026)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1626 (-0.1626)\n",
            "Epoch: [9][ 10/195]\tTime  0.349 ( 0.373)\tData  0.000 ( 0.019)\tD(real) 0.4957 (0.6418)\tD(fake)1 0.1975 (0.3413)\tD(fake)2 0.3228 (0.3014)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1726 (-0.1566)\n",
            "Epoch: [9][ 20/195]\tTime  0.351 ( 0.363)\tData  0.000 ( 0.010)\tD(real) 0.6795 (0.6499)\tD(fake)1 0.3672 (0.3437)\tD(fake)2 0.2567 (0.3021)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1704 (-0.1593)\n",
            "Epoch: [9][ 30/195]\tTime  0.350 ( 0.358)\tData  0.000 ( 0.007)\tD(real) 0.5620 (0.6494)\tD(fake)1 0.2207 (0.3393)\tD(fake)2 0.3926 (0.3030)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1444 (-0.1585)\n",
            "Epoch: [9][ 40/195]\tTime  0.349 ( 0.355)\tData  0.000 ( 0.005)\tD(real) 0.6227 (0.6521)\tD(fake)1 0.3139 (0.3435)\tD(fake)2 0.3667 (0.3053)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1641 (-0.1581)\n",
            "Epoch: [9][ 50/195]\tTime  0.351 ( 0.355)\tData  0.000 ( 0.004)\tD(real) 0.8356 (0.6588)\tD(fake)1 0.4493 (0.3412)\tD(fake)2 0.1960 (0.3009)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1702 (-0.1599)\n",
            "Epoch: [9][ 60/195]\tTime  0.347 ( 0.354)\tData  0.000 ( 0.004)\tD(real) 0.7875 (0.6623)\tD(fake)1 0.3954 (0.3365)\tD(fake)2 0.1156 (0.2957)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1695 (-0.1599)\n",
            "Epoch: [9][ 70/195]\tTime  0.345 ( 0.353)\tData  0.000 ( 0.003)\tD(real) 0.6594 (0.6611)\tD(fake)1 0.2985 (0.3340)\tD(fake)2 0.2902 (0.2955)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1734 (-0.1603)\n",
            "Epoch: [9][ 80/195]\tTime  0.345 ( 0.352)\tData  0.001 ( 0.003)\tD(real) 0.7289 (0.6652)\tD(fake)1 0.3509 (0.3304)\tD(fake)2 0.2624 (0.2928)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1733 (-0.1612)\n",
            "Epoch: [9][ 90/195]\tTime  0.350 ( 0.352)\tData  0.000 ( 0.003)\tD(real) 0.6771 (0.6661)\tD(fake)1 0.3332 (0.3300)\tD(fake)2 0.2733 (0.2925)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1711 (-0.1613)\n",
            "Epoch: [9][100/195]\tTime  0.347 ( 0.352)\tData  0.000 ( 0.002)\tD(real) 0.6603 (0.6659)\tD(fake)1 0.3190 (0.3306)\tD(fake)2 0.2833 (0.2929)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1655 (-0.1618)\n",
            "Epoch: [9][110/195]\tTime  0.346 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6298 (0.6663)\tD(fake)1 0.2568 (0.3294)\tD(fake)2 0.3682 (0.2927)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1633 (-0.1614)\n",
            "Epoch: [9][120/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6924 (0.6692)\tD(fake)1 0.3026 (0.3275)\tD(fake)2 0.2409 (0.2902)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1728 (-0.1611)\n",
            "Epoch: [9][130/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6836 (0.6704)\tD(fake)1 0.3002 (0.3258)\tD(fake)2 0.2619 (0.2885)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1667 (-0.1612)\n",
            "Epoch: [9][140/195]\tTime  0.344 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6333 (0.6725)\tD(fake)1 0.2903 (0.3248)\tD(fake)2 0.2961 (0.2868)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1508 (-0.1615)\n",
            "Epoch: [9][150/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7468 (0.6748)\tD(fake)1 0.3222 (0.3251)\tD(fake)2 0.1757 (0.2863)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1357 (-0.1607)\n",
            "Epoch: [9][160/195]\tTime  0.348 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.7298 (0.6759)\tD(fake)1 0.4100 (0.3248)\tD(fake)2 0.1980 (0.2849)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1671 (-0.1610)\n",
            "Epoch: [9][170/195]\tTime  0.349 ( 0.351)\tData  0.000 ( 0.002)\tD(real) 0.6413 (0.6748)\tD(fake)1 0.3198 (0.3252)\tD(fake)2 0.3423 (0.2855)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1687 (-0.1613)\n",
            "Epoch: [9][180/195]\tTime  0.363 ( 0.351)\tData  0.000 ( 0.001)\tD(real) 0.6494 (0.6745)\tD(fake)1 0.2931 (0.3254)\tD(fake)2 0.3017 (0.2858)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1724 (-0.1614)\n",
            "Epoch: [9][190/195]\tTime  0.343 ( 0.350)\tData  0.000 ( 0.001)\tD(real) 0.6583 (0.6744)\tD(fake)1 0.3057 (0.3253)\tD(fake)2 0.2766 (0.2863)\tgrad(D) 0.0000 (0.0000)\trepr loss -0.1686 (-0.1614)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMSlrEvie7Pa"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "mvYdbtKQe_2-",
        "outputId": "b8b73ea9-a862-45d1-f5d6-ce5ee4dc60aa"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def show_sample(x, num_samples=16, show_x=False):\n",
        "    x = x.cuda(args.gpu)[:num_samples]\n",
        "    if show_x:\n",
        "        x_grid = vutils.make_grid(inv_normalize(x).cpu(), padding=2, nrow=4)\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(x_grid.permute(1,2,0))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = sample_latent(num_samples).cuda(args.gpu)\n",
        "        repr = simsiam.encoder(x)\n",
        "        repr = F.normalize(repr + args.repr_noise * torch.randn_like(repr))\n",
        "        z = latent_transform(repr, noise)\n",
        "        x_fake = model.G(z)\n",
        "    im_grid = vutils.make_grid(x_fake.cpu(), padding=2, nrow=4, normalize=True, range=(-1,1))\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(im_grid.permute(1,2,0))\n",
        "\n",
        "x, _ = next(iter(train_loader))\n",
        "show_sample(x, show_x=True)\n",
        "show_sample(x)\n",
        "show_sample(x)\n",
        "show_sample(x)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b92b4a072e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gfx3T5m2wah"
      },
      "source": [
        "save_vid()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5P0BestcMER"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}