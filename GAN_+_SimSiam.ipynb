{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN + SimSiam",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeligism/ConGAN/blob/main/GAN_%2B_SimSiam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxx3Jy_8qsPE"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFx20xTNkpQ",
        "outputId": "7fbfbacc-9c70-4b8c-ecb9-92c0f66f2356"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QNzdq01hSb"
      },
      "source": [
        "# Header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlF68ff2K8L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_Qrpq7z3iJ"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import log2\n",
        "from pprint import pformat\n",
        "from collections import defaultdict"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDduLe1Qkd9"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRxrufxw1cm"
      },
      "source": [
        "### Report Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmEyNG58w2kJ"
      },
      "source": [
        "def plot_lines(losses_dict, filename=None, title=\"\"):\n",
        "    \"\"\"\n",
        "    Plots the losses of the discriminator and the generator.\n",
        "\n",
        "    Args:\n",
        "        filename: The plot's filename. If None, plot won't be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(title)\n",
        "    for label, losses in losses_dict.items():\n",
        "        plt.plot(losses, label=label)\n",
        "    plt.xlabel(\"t\")\n",
        "    plt.legend()\n",
        "    \n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def create_progress_animation(frames, filename):\n",
        "    \"\"\"\n",
        "    Creates a video of the progress of the generator on a fixed latent vector.\n",
        "\n",
        "    Args:\n",
        "        filename: The animation's filename.\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    ims = [[plt.imshow(img.permute(1,2,0), animated=True)]\n",
        "           for img in frames]\n",
        "    ani = animation.ArtistAnimation(fig, ims, blit=True)\n",
        "    \n",
        "    ani.save(filename)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def generate_grid(generator, latent):\n",
        "    \"\"\"\n",
        "    Check generator's output on latent vectors and return it.\n",
        "\n",
        "    Args:\n",
        "        generator: The generator.\n",
        "        latent: Latent vector from which an image grid will be generated.\n",
        "\n",
        "    Returns:\n",
        "        A grid of images generated by `generator` from `latent`.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(latent).detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(fake.cpu(), padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n",
        "\n",
        "def generate_G_grid(generator, before):\n",
        "    \"\"\"\n",
        "    Generate a grid of pairs of images, where each pair shows a before-after\n",
        "    transition when applying G on before.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(before.size()) == 3:\n",
        "        before.unsqueeze(0)\n",
        "\n",
        "    batch_size = before.size()[0]\n",
        "    img_dim = before.size()[1:]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        after = generator(before)\n",
        "\n",
        "    row = torch.zeros([2 * batch_size, *img_dim])\n",
        "    row[0::2] = before.detach()\n",
        "    row[1::2] = after.detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(row.cpu(), nrow=8, padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n",
        "\n",
        "\n",
        "def generate_makeup_grid(applier_ref, remover, before, after_ref):\n",
        "    \"\"\"\n",
        "    Generate a grid, 8 images per row, as follows:\n",
        "      Image #1: real photo of a face WITHOUT makeup (call it face #1).\n",
        "      Image #2: real (makeup reference) photo of a face WITH makeup (call it face #2).\n",
        "      Image #3: fake photo of face #1 WITH makeup style from face #2 (applied).\n",
        "      Image #4: fake photo of face #2 WITHOUT makeup (removed).\n",
        "      Image #5: Repeat the same pattern from Image #1...\n",
        "\n",
        "    In case only 4 images are needed per row, change `nrow` below to 4.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(before.size()) == 3:\n",
        "        before.unsqueeze(0)\n",
        "\n",
        "    batch_size = before.size()[0]\n",
        "    img_dim = before.size()[1:]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_after = applier_ref(before, after_ref)\n",
        "        fake_before_ref = remover(after_ref)\n",
        "\n",
        "\n",
        "    row = torch.zeros([4 * batch_size, *img_dim])\n",
        "    row[0::4] = before.detach()\n",
        "    row[1::4] = after_ref.detach()\n",
        "    row[2::4] = fake_after.detach()\n",
        "    row[3::4] = fake_before_ref.detach()\n",
        "\n",
        "    image_grid = vutils.make_grid(row.cpu(), nrow=8, padding=2, normalize=True, range=(-1,1))\n",
        "\n",
        "    return image_grid\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzwGurc1qOx"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPhc2oS53G4e"
      },
      "source": [
        "## PyTorch Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU7HFc6t5N8w"
      },
      "source": [
        "### DCGAN-style"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHPo8w13JmH"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding half the size of features,\n",
        "    e.g. if input is [in_channels, 64, 64], output will be [out_channels, 32, 32].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.conv = nn.utils.spectral_norm(self.conv)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.LeakyReLU(0.2, inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Default stride and padding double the size of features,\n",
        "    e.g. if input is [in_channels, 32, 32], output will be [out_channels, 64, 64].\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1,\n",
        "                 use_batchnorm=True, use_spectralnorm=False, activation=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convT = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, bias=False)\n",
        "        if use_spectralnorm:\n",
        "            self.convT = nn.utils.spectral_norm(self.convT)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels) if use_batchnorm else None\n",
        "        self.activation = nn.ReLU(inplace=True) if activation is None else activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convT(x)\n",
        "        if self.batchnorm:\n",
        "            x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=16,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 D_block=ConvBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        using_grad_penalty = gan_type in (\"gan-gp\", \"wgan-gp\")\n",
        "        output_sigmoid = gan_type in (\"gan\", \"gan-gp\")\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm and not using_grad_penalty,\n",
        "            \"use_spectralnorm\": use_spectralnorm,\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Input layer\n",
        "        self.input_layer = D_block(image_channels, features[0], **block_config)\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            D_block(in_features, out_features, **block_config)\n",
        "            for in_features, out_features in zip(features, features[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer (feature_size = 3, 4, or 5 -> 1)\n",
        "        if fully_convolutional:\n",
        "            self.output_layer = nn.Sequential(\n",
        "                nn.Conv2d(features[-1], num_latents, latent_kernel, bias=False),\n",
        "                nn.Flatten(),\n",
        "            )\n",
        "        else:\n",
        "            self.output_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(features[-1] * latent_kernel**2, num_latents, bias=False)\n",
        "            )\n",
        "\n",
        "        # Add sigmoid activation if using regular GAN loss\n",
        "        self.output_activation = nn.Sigmoid() if output_sigmoid else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        if self.output_activation:\n",
        "            x = self.output_activation(x)\n",
        "        # Remove H and W dimensions, infer channels dim (remove if 1)\n",
        "        x = x.view(x.size(0), -1).squeeze(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_latents=100,\n",
        "                 num_features=64,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 max_features=512,\n",
        "                 gan_type=\"gan\",\n",
        "                 fully_convolutional=True,\n",
        "                 activation=None,\n",
        "                 use_batchnorm=True,\n",
        "                 use_spectralnorm=False,\n",
        "                 G_block=ConvTBlock):\n",
        "        super().__init__()\n",
        "\n",
        "        block_config = {\n",
        "            \"activation\": activation,\n",
        "            \"use_batchnorm\": use_batchnorm,\n",
        "            \"use_spectralnorm\": use_spectralnorm\n",
        "        }\n",
        "\n",
        "        # Calculate intermediate image sizes\n",
        "        image_sizes = [image_size]\n",
        "        while image_sizes[-1] > 5:\n",
        "            image_sizes.append(image_sizes[-1] // 2)\n",
        "        latent_kernel = image_sizes[-1]  # should be either 3, 4, or 5\n",
        "        num_layers = len(image_sizes) - 1\n",
        "\n",
        "        # Calculate feature sizes\n",
        "        features = [min(max_features, round(num_features * feature_multiplier**i))\n",
        "                    for i in range(num_layers)]\n",
        "\n",
        "        # Reverse order of image sizes and features for generator\n",
        "        image_sizes = image_sizes[::-1]\n",
        "        features = features[::-1]\n",
        "\n",
        "        # Input layer\n",
        "        if fully_convolutional:\n",
        "            self.input_layer = G_block(num_latents, features[0], kernel_size=latent_kernel,\n",
        "                                       stride=1, padding=0, **block_config)\n",
        "        else:\n",
        "            self.input_layer = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(num_latents, features[0] * image_sizes[0]**2, bias=False),\n",
        "                View(features[0], image_sizes[0], image_sizes[0])\n",
        "            )\n",
        "\n",
        "        # Intermediate layers\n",
        "        self.main_layers = nn.Sequential(*[\n",
        "            G_block(in_features, out_features, kernel_size=4+(expected_size%2), **block_config)\n",
        "            for in_features, out_features, expected_size in zip(features, features[1:], image_sizes[1:])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.ConvTranspose2d(features[-1], image_channels, kernel_size=4+(image_size%2),\n",
        "                                               stride=2, padding=1, bias=False)\n",
        "        self.output_activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add H and W dimensions, infer channels dim (add if none)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.main_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "        x = self.output_activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape, including_batch=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.including_batch = including_batch\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.including_batch:\n",
        "            return x.view(*self.shape)\n",
        "        else:\n",
        "            return x.view(x.size(0), *self.shape)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvbfPzWAydEy"
      },
      "source": [
        "### Residual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGyxAEKcyhUe"
      },
      "source": [
        "class ChannelNoise(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel noise injection module.\n",
        "    Adds a linearly transformed noise to a convolution layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, std=0.02):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise_size = [x.size()[0], 1, *x.size()[2:]]  # single channel\n",
        "        noise = self.std * torch.randn(noise_size).to(x)\n",
        "\n",
        "        return x + self.scale * noise\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 dilation=(1,1),\n",
        "                 downsample=None,\n",
        "                 dropout_p=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dilation = dilation\n",
        "        self.downsample = downsample\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            ### Conv 3x3 ###\n",
        "            nn.Conv2d(in_channels, out_channels, 3,\n",
        "                      padding=dilation[0], dilation=dilation[0], bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            ChannelNoise(out_channels),\n",
        "            ### Conv 3x3 ###\n",
        "            nn.Conv2d(out_channels, out_channels, 3,\n",
        "                      padding=dilation[1], dilation=dilation[1], bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x if self.downsample is None else self.downsample(x)\n",
        "\n",
        "        return F.relu(self.main(x) + residual)\n",
        "\n",
        "\n",
        "class ResidualBottleneck(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 downsample=None,\n",
        "                 dilation=1,\n",
        "                 dropout_p=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.dilation = dilation\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "\n",
        "            ### Conv 1x1 ###\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "\n",
        "            ### Conv 3x3 ###\n",
        "            nn.Conv2d(out_channels, out_channels, 3,\n",
        "                      padding=dilation[1], dilation=dilation[1], bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "\n",
        "            ### Conv 1x1 ###\n",
        "            nn.Conv2d(out_channels, out_channels * 4, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * 4),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x if self.downsample is None else self.downsample(x)\n",
        "\n",
        "        return F.relu(self.main(x) + residual)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0zlEhInykFC"
      },
      "source": [
        "### MaskGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2q-crDHyszg"
      },
      "source": [
        "class MaskGAN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_features=64,\n",
        "                 max_features=512,\n",
        "                 image_channels=3,\n",
        "                 image_size=64,\n",
        "                 feature_multiplier=2,\n",
        "                 gan_type=\"gan\",\n",
        "                 with_reference=False):\n",
        "        super().__init__()\n",
        "\n",
        "        D_params = {\n",
        "            \"num_features\": num_features,\n",
        "            \"max_features\": max_features,\n",
        "            \"image_channels\": image_channels,\n",
        "            \"image_size\": image_size,\n",
        "            \"feature_multiplier\": feature_multiplier,\n",
        "            \"gan_type\": gan_type,\n",
        "        }\n",
        "        G_params = {\n",
        "            \"num_features\": num_features,\n",
        "            \"with_reference\": with_reference,\n",
        "        }\n",
        "\n",
        "        self.D = DCGAN_Discriminator(**D_params)\n",
        "        self.G = MaskGenerator(**G_params)\n",
        "\n",
        "\n",
        "class MaskGenerator(nn.Module):\n",
        "    \"\"\"A neural network that generates a mask to apply.\"\"\"\n",
        "    def __init__(self, num_features=64, with_reference=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.with_reference = with_reference\n",
        "\n",
        "        def make_features_extractor(num_features):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(3, num_features, 7, padding=3, bias=False),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "\n",
        "        # Extract features from source\n",
        "        self.source_features_extractor = make_features_extractor(self.num_features)\n",
        "\n",
        "        # Extract features from reference\n",
        "        if self.with_reference:\n",
        "            self.reference_features_extractor = make_features_extractor(self.num_features)\n",
        "\n",
        "\n",
        "        # Double the number of features in the mask generator if with reference\n",
        "        if self.with_reference:\n",
        "            num_features *= 2\n",
        "\n",
        "        self.mask_generator = nn.Sequential(\n",
        "            ResidualBlock(num_features, num_features),\n",
        "            ResidualBlock(num_features, num_features, dilation=(2,2)),\n",
        "            ResidualBlock(num_features, num_features, dilation=(4,4)),\n",
        "            ResidualBlock(num_features, num_features, dilation=(8,8)),\n",
        "            nn.Conv2d(num_features, num_features, 3, padding=2, dilation=2, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(num_features, 3, 3, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, source, reference=None):\n",
        "\n",
        "        assert reference is None or self.with_reference\n",
        "\n",
        "        features = self.source_features_extractor(source)\n",
        "\n",
        "        if self.with_reference:\n",
        "            reference_features = self.reference_features_extractor(reference)\n",
        "            features = torch.cat([features, reference_features], dim=1)\n",
        "\n",
        "        mask = self.mask_generator(features)\n",
        "\n",
        "        return (source + mask).clamp(-1,1) # XXX: range could go outside [-1, 1] !!!\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQcvNDLQ5niT"
      },
      "source": [
        "### ConsistentGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeUqwjQ95mMV"
      },
      "source": [
        "class ConsistentGAN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 base_encoder,\n",
        "                 repr_dim,\n",
        "                 pred_dim,\n",
        "                 latent_dim,\n",
        "                 args*, **kwargs):\n",
        "        \"\"\"\n",
        "        s ~ S is representation/encoding space, e.g. s = Enc(x).\n",
        "        z ~ Z is latent/seed space for G, e.g. x_fake ~ G(z).\n",
        "\n",
        "        Case A:\n",
        "            - Sample x_real ~ X\n",
        "            - s <- Encoder(x_real)\n",
        "            - Sample z ~ Z (coupled with s somehow? e.g. z = f(s) + noise)\n",
        "            - x_fake <- G(z)\n",
        "            - Test D on x_real, x_fake, i.e. test whether x in X}\n",
        "            - Calculate GAN loss\n",
        "            - Calculate SimSiam loss with Predictor(s)\n",
        "\n",
        "        Case B: \n",
        "            - Sample x_real ~ X\n",
        "            - s_real <- Encoder(x_real)\n",
        "            - x_recon <- Decoder(s_real)\n",
        "            - Sample z ~ Z (e.g. N(0,1) or U(-1,1))\n",
        "            - s_fake <- G(z)\n",
        "            - Test D on s_real, s_fake, i.e. test whether Dec(s) in X (how?)\n",
        "            - Calculate GAN loss\n",
        "            - Calculate Contrastive/SimSiam loss with Predictor(s)\n",
        "            - Calculate reconsruction loss, e.g. || Enc(x_recon) - Enc(x_real) ||\n",
        "        \n",
        "        We choose Case B for now.\n",
        "\n",
        "        Adversarial learning:\n",
        "            Case A:\n",
        "                Train D and G so that we can disciminate x based on its representation.\n",
        "                Train G so that representation has enough info for reconstructing x.\n",
        "                Ideally, G would generate different views of x given similar s's.\n",
        "            Case B:\n",
        "                Train D and G so that we can disciminate representations.\n",
        "                Train G so that it produces representations as real (close to Enc(x)) as possible.\n",
        "                This assumes that Enc(x) is the real representation.\n",
        "                (There is no such thing as any random transformation can be real enough, but\n",
        "                we should try to mitigate this problem nonetheless. For example, we can at least\n",
        "                make it stable enough by pre-training Enc/Dec.)\n",
        "                Ideally, G would produce accurate representations that can be decoded later.\n",
        "\n",
        "        Contrastive learning:\n",
        "            If x1 and x2 are views of same x (e.g. x1, x2 = rand_aug(x), rand_aug(x))\n",
        "            Then, Encoder(x1) should be similar to Encoder(x2), so we do this (SimSiam algorithm):\n",
        "            min 0.5*{ sim(Predictor(s1), s2.detach()) + sim(Predictor(s2), s1.detach()) }\n",
        "            where sim = CosineSimilarity(dim=1).\n",
        "        \n",
        "        Reconstruction learning:\n",
        "            We can add a (deterministic) Decoder that learns to decode s to x.\n",
        "            This does not take into account the invariance of representation to augmentations.\n",
        "            It simply learns the inverse of Encoder. G will learn to produce represenations\n",
        "            that are as real as possible, where the Decoder will learn to decode them into their\n",
        "            corresponding x's such that Enc(Dec(s)) = s (do we stop grad at s for this loss?)\n",
        "\n",
        "        Architecture:\n",
        "            We assume x comes from an image dataset, e.g. CIFAR10.\n",
        "            Encoder-Decoder pair can have a DCGAN-style architecture.\n",
        "            The generator can also have an arch similar to the decoder.\n",
        "            Other networks can be simple FCNs.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.repr_dim = repr_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.pred_dim = pred_dim\n",
        "\n",
        "        ### Copied from SimSiam repo >>>>>>>>\n",
        "        # create the encoder\n",
        "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
        "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
        "\n",
        "        # build a 3-layer projector\n",
        "        prev_dim = self.encoder.fc.weight.shape[1]\n",
        "        self.encoder.fc = nn.Sequential(nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # first layer\n",
        "                                        nn.Linear(prev_dim, prev_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(prev_dim),\n",
        "                                        nn.ReLU(inplace=True), # second layer\n",
        "                                        self.encoder.fc,\n",
        "                                        nn.BatchNorm1d(dim, affine=False)) # output layer\n",
        "        self.encoder.fc[6].bias.requires_grad = False # hack: not use bias as it is followed by BN\n",
        "\n",
        "        # build a 2-layer predictor\n",
        "        self.predictor = nn.Sequential(nn.Linear(dim, pred_dim, bias=False),\n",
        "                                        nn.BatchNorm1d(pred_dim),\n",
        "                                        nn.ReLU(inplace=True), # hidden layer\n",
        "                                        nn.Linear(pred_dim, dim)) # output layer\n",
        "        ### <<<<<<<<\n",
        "        \n",
        "        # Make D's architecture kinda similar to predictor @TODO\n",
        "        # @XXX: Shouldn't use batchnorm with grad_penalty\n",
        "        D_hidden_dim = repr_dim // 2\n",
        "        self.D = nn.Sequential(nn.Linear(repr_dim, D_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(D_hidden_dim),\n",
        "                               nn.LeakyRelu(0.2, inplace=True),\n",
        "                               nn.Linear(D_hidden_dim, D_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(D_hidden_dim),\n",
        "                               nn.LeakyRelu(0.2, inplace=True),\n",
        "                               nn.Linear(D_hidden_dim, D_hidden_dim, bias=False),\n",
        "                               nn.BatchNorm1d(D_hidden_dim),\n",
        "                               nn.LeakyRelu(0.2, inplace=True),\n",
        "                               nn.Linear(D_hidden_dim, 1))\n",
        "        \n",
        "        # Same for generator (latent -> representations)\n",
        "        self.G = nn.Sequential(nn.Linear(latent_dim, repr_dim, bias=False),\n",
        "                               nn.BatchNorm1d(repr_dim),\n",
        "                               nn.Relu(inplace=True), # hidden layer\n",
        "                               nn.Linear(repr_dim, repr_dim, bias=False),\n",
        "                               nn.BatchNorm1d(repr_dim),\n",
        "                               nn.Relu(inplace=True), # hidden layer\n",
        "                               nn.Linear(repr_dim, repr_dim, bias=False),\n",
        "                               nn.BatchNorm1d(repr_dim),\n",
        "                               nn.Relu(inplace=True), # hidden layer\n",
        "                               nn.Linear(repr_dim, repr_dim))\n",
        "\n",
        "        # Decoder should be a ConvT net. We'll use DCGAN's G for now\n",
        "        #self.decoder = DCGAN_Generator(num_latents=repr_dim, image_size=image_size) #@XXX\n",
        "    \n",
        "\n",
        "    def sample_latent(self, batch_size):\n",
        "\n",
        "        latent_size = [batch_size, self.latent_dim]\n",
        "        latent = torch.randn(latent_size)\n",
        "\n",
        "        return latent\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x1: first views of images\n",
        "            x2: second views of images\n",
        "        Output:\n",
        "            p1, p2, z1, z2: predictors and targets of the network\n",
        "            See Sec. 3 of https://arxiv.org/abs/2011.10566 for detailed notations\n",
        "        \"\"\"\n",
        "\n",
        "        # compute features for one view\n",
        "        z1 = self.encoder(x1) # NxC\n",
        "        z2 = self.encoder(x2) # NxC\n",
        "\n",
        "        p1 = self.predictor(z1) # NxC\n",
        "        p2 = self.predictor(z2) # NxC\n",
        "\n",
        "        return p1, p2, z1.detach(), z2.detach()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yeJV3M0RxEf"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f53hdfoezWvj"
      },
      "source": [
        "#### Init Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0z8HzWozftW"
      },
      "source": [
        "def create_weights_init(conv_std=0.01, batchnorm_std=0.01):\n",
        "    \"\"\"\n",
        "    A function that returns the weights initialization function for a net,\n",
        "    which can be used as `net.apply(create_weights_init())`, for example.\n",
        "\n",
        "    Args:\n",
        "        conv_std: the standard deviation of the conv/up-conv layers.\n",
        "        batchnorm_std: the standard deviation of the batch-norm layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def weights_init(module):\n",
        "        classname = module.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            nn.init.normal_(module.weight.data, 0.0, conv_std)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(module.weight.data, 1.0, batchnorm_std)\n",
        "            nn.init.constant_(module.bias.data, 0)\n",
        "\n",
        "    def weights_init_kaiming(module):\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            #nn.init.kaiming_normal_(module.weight, nonlinearity=\"leaky_relu\")\n",
        "            nn.init.normal_(module.weight, 0.0, conv_std)\n",
        "        elif isinstance(module, nn.ConvTranspose2d):\n",
        "            nn.init.kaiming_normal_(module.weight, nonlinearity=\"relu\")\n",
        "        elif isinstance(module, nn.BatchNorm2d):\n",
        "            nn.init.constant_(module.weight, 1)\n",
        "            nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    return weights_init_kaiming\n",
        "\n",
        "\n",
        "def init_optim(params, optim_choice=\"sgd\", lr=1e-4, momentum=0.0, betas=(0.9, 0.999)):\n",
        "    \"\"\"\n",
        "    Initializes the optimizer.\n",
        "\n",
        "    Args:\n",
        "        params: Parameters the optimizer will optimize.\n",
        "        choice: The choice of the optimizer.\n",
        "        optim_configs: Configurations for the optimizer.\n",
        "\n",
        "    Returns:\n",
        "        The optimizer (torch.optim).\n",
        "    \"\"\"\n",
        "\n",
        "    if optim_choice == \"adam\":\n",
        "        optim = torch.optim.Adam(params, lr=lr, betas=betas)\n",
        "    elif optim_choice == \"adamw\":\n",
        "        optim = torch.optim.AdamW(params, lr=lr, betas=betas)\n",
        "    elif optim_choice == \"rmsprop\":\n",
        "        optim = torch.optim.RMSprop(params, lr=lr)\n",
        "    elif optim_choice == \"sgd\":\n",
        "        optim = torch.optim.SGD(params, lr=lr, momentum=momentum)\n",
        "    else:\n",
        "        raise ValueError(f\"Optimizer '{optim_choice}' not recognized.\")\n",
        "\n",
        "    return optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UhO2ngDy-Bw"
      },
      "source": [
        "#### GAN Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irQIl-Q7zA6_"
      },
      "source": [
        "def get_D_loss(gan_type=\"gan\"):\n",
        "    if gan_type in (\"gan\", \"gan-gp\"):\n",
        "        return D_loss_GAN\n",
        "    elif gan_type in (\"wgan\", \"wgan-gp\"):\n",
        "        return D_loss_WGAN\n",
        "    else:\n",
        "        raise ValueError(f\"gan_type {gan_type} not supported\")\n",
        "\n",
        "\n",
        "def get_G_loss(gan_type=\"gan\"):\n",
        "    if gan_type in (\"gan\", \"gan-gp\"):\n",
        "        return G_loss_GAN\n",
        "    elif gan_type in (\"wgan\", \"wgan-gp\"):\n",
        "        return G_loss_WGAN\n",
        "    else:\n",
        "        raise ValueError(f\"gan_type {gan_type} not supported\")\n",
        "\n",
        "\n",
        "def D_loss_GAN(D_on_real, D_on_fake, label_smoothing=True):\n",
        "    \n",
        "    # Create (noisy) real and fake labels XXX\n",
        "    if label_smoothing:\n",
        "        real_label = 0.7 + 0.5 * torch.rand_like(D_on_real)\n",
        "    else:\n",
        "        real_label = torch.ones_like(D_on_real) - 0.1\n",
        "    fake_label = torch.zeros_like(D_on_fake)\n",
        "\n",
        "    # Calculate binary cross entropy loss\n",
        "    D_loss_on_real = F.binary_cross_entropy(D_on_real, real_label)\n",
        "    D_loss_on_fake = F.binary_cross_entropy(D_on_fake, fake_label)\n",
        "\n",
        "    # Loss is: - log(D(x)) - log(1 - D(x_g)),\n",
        "    # which is equiv. to maximizing: log(D(x)) + log(1 - D(x_g))\n",
        "    D_loss = D_loss_on_real + D_loss_on_fake\n",
        "\n",
        "    return D_loss.mean()\n",
        "\n",
        "\n",
        "def D_loss_WGAN(D_on_real, D_on_fake, grad_penalty=0.0):\n",
        "\n",
        "    # Maximize: D(x) - D(x_g) - const * (|| grad of D(x_i) wrt x_i || - 1)^2,\n",
        "    # where x_i <- eps * x + (1 - eps) * x_g, and eps ~ rand(0,1)\n",
        "    D_loss = -1 * (D_on_real - D_on_fake - grad_penalty)\n",
        "\n",
        "    return D_loss.mean()\n",
        "\n",
        "\n",
        "def G_loss_GAN(D_on_fake):\n",
        "\n",
        "    # Calculate binary cross entropy loss with a fake binary label\n",
        "    fake_label = torch.zeros_like(D_on_fake)\n",
        "\n",
        "    # Loss is: -log(D(G(z))), which is equiv. to minimizing log(1-D(G(z)))\n",
        "    # We use this loss vs. the original one for stability only.\n",
        "    G_loss = F.binary_cross_entropy(D_on_fake, 1 - fake_label)\n",
        "\n",
        "    return G_loss.mean()\n",
        "\n",
        "\n",
        "def G_loss_WGAN(D_on_fake):\n",
        "\n",
        "    # Minimize: -D(G(z))\n",
        "    G_loss = -D_on_fake\n",
        "    \n",
        "    return G_loss.mean()\n",
        "\n",
        "\"\"\"\n",
        "def get_D_grad_norm(discriminator, real, fake):\n",
        "\n",
        "    batch_size = real.size()[0]\n",
        "    device = real.device\n",
        "\n",
        "    # Calculate gradient penalty\n",
        "    eps = torch.rand([batch_size, 1, 1, 1], device=device)\n",
        "    interpolated = eps * real + (1 - eps) * fake\n",
        "    interpolated.requires_grad_()\n",
        "    D_on_inter = discriminator(interpolated)\n",
        "\n",
        "    # Calculate gradient of D(x_i) wrt x_i for each batch\n",
        "    D_grad = torch.autograd.grad(D_on_inter, interpolated,\n",
        "                                 torch.ones_like(D_on_inter), create_graph=True)\n",
        "\n",
        "    # D_grad will be a 1-tuple, as in: (grad,)\n",
        "    D_grad_norm = D_grad[0].view([batch_size, -1]).norm(dim=1)\n",
        "\n",
        "    return D_grad_norm\n",
        "\n",
        "\n",
        "def get_grad_penalty(grad_norm, gp_coeff=10.):\n",
        "    # D's gradient penalty is `gp_coeff * (|| grad of D(x_i) wrt x_i || - 1)^2`\n",
        "    grad_penalty = (grad_norm - 1).pow(2) * gp_coeff\n",
        "\n",
        "    return grad_penalty\n",
        "\"\"\"\n",
        "\n",
        "def random_interpolate(real, fake):\n",
        "    eps = torch.rand(real.size(0), 1, 1, 1).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "\n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_on_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_on_x, x, torch.ones_like(D_on_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5hkBvc7zIHs"
      },
      "source": [
        "### Base Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl0_-iKQzKl9"
      },
      "source": [
        "class BaseTrainer:\n",
        "    \"\"\"The base trainer class.\"\"\"\n",
        "\n",
        "    def __init__(self, model, dataset,\n",
        "        name=\"trainer\",\n",
        "        results_dir=\"results/\",\n",
        "        load_model_path=None,\n",
        "        num_gpu=1,\n",
        "        num_workers=0,\n",
        "        batch_size=4,\n",
        "        report_interval=10,\n",
        "        save_interval=100000,\n",
        "        use_tensorboard=False,  # XXX: not implemented yet\n",
        "        description=\"no description given\",\n",
        "        **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes BaseTrainer.\n",
        "\n",
        "        Args:\n",
        "            model: The model or net.\n",
        "            dataset: The dataset on which the model will be training.\n",
        "            name: Name of this trainer.\n",
        "            results_dir: Directory in which results will be saved for each run.\n",
        "            load_model_path: Path to the model that will be loaded, if any.\n",
        "            num_gpu: Number of GPUs to use for training.\n",
        "            num_workers: Number of workers sampling from the dataset.\n",
        "            batch_size: Size of the batch. Must be > num_gpu.\n",
        "            report_interval: Report stats every `report_interval` iters.\n",
        "            save_interval: Save model every `save_interval` iters.\n",
        "            description: Description of the experiment the trainer is running.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "\n",
        "        self.name = name\n",
        "        self.results_dir = results_dir\n",
        "        self.load_model_path = load_model_path\n",
        "\n",
        "        self.num_gpu = num_gpu\n",
        "        self.num_workers = num_workers\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.report_interval = report_interval\n",
        "        self.save_interval = save_interval\n",
        "        self.description = description\n",
        "        self.save_results = False\n",
        "\n",
        "        self.start_time = datetime.datetime.now()\n",
        "        self.stop_time = datetime.datetime.now()\n",
        "        self.iters = 1  # current iteration (i.e. # of batches processed so far)\n",
        "        self.batch = 1  # current batch\n",
        "        self.epoch = 1  # current epoch\n",
        "        self.num_batches = 1 + len(self.dataset) // self.batch_size  # num of batches per epoch\n",
        "        self.num_epochs = 0  # number of epochs to run\n",
        "\n",
        "        self._dataset_sampler = iter(())  # generates samples from the dataset\n",
        "        self._data = defaultdict(list)  # contains data of experiment\n",
        "\n",
        "        self.writer = None\n",
        "        self.use_tensorboard = use_tensorboard\n",
        "\n",
        "        # Load model if necessary\n",
        "        if load_model_path is not None:\n",
        "            self.load_model(load_model_path)\n",
        "\n",
        "        # Initialize device\n",
        "        using_cuda = torch.cuda.is_available() and self.num_gpu > 0\n",
        "        self.device = torch.device(\"cuda:0\" if using_cuda else \"cpu\")\n",
        "\n",
        "        # Move model to device and parallelize model if possible\n",
        "        self.model = self.model.to(self.device)\n",
        "        if self.device.type == \"cuda\" and self.num_gpu > 1:\n",
        "            self.model = torch.nn.DistributedDataParallel(self.model, list(range(self.num_gpu)))\n",
        "\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        if not os.path.isfile(model_path):\n",
        "            print(f\"Couldn't load model: file '{model_path}' does not exist\")\n",
        "            print(\"Training model from scratch.\")\n",
        "        else:\n",
        "            print(\"Loading model...\")\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\n",
        "    def save_model(self, model_path):\n",
        "        print(\"Saving model...\")\n",
        "        torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "\n",
        "    def time_since_start(self):\n",
        "        elapsed_time = datetime.datetime.now() - self.start_time\n",
        "        return elapsed_time.total_seconds()\n",
        "\n",
        "\n",
        "    def run(self, num_epochs, save_results=False):\n",
        "        \"\"\"\n",
        "        Runs the trainer. Trainer will train the model and then save it.\n",
        "        Note that running trainer more than once will accumulate the results.\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Number of epochs to run.\n",
        "            save_results: A flag indicating whether we should save the results this run.\n",
        "        \"\"\"\n",
        "        self.start_time = datetime.datetime.now()\n",
        "        self.num_epochs = num_epochs + self.epoch - 1\n",
        "        self.save_results = save_results\n",
        "\n",
        "        # Create experiment directory\n",
        "        experiment_name = self.get_experiment_name()\n",
        "        experiment_dir = os.path.join(self.results_dir, experiment_name)\n",
        "        if self.save_results:\n",
        "            if not os.path.isdir(self.results_dir): os.mkdir(self.results_dir)\n",
        "            if not os.path.isdir(experiment_dir): os.mkdir(experiment_dir)\n",
        "\n",
        "        with tensorboard.SummaryWriter(f\"runs/{experiment_name}\") as self.writer:\n",
        "            # Try training the model, then stop the training when an exception is thrown\n",
        "            try:\n",
        "                self.train()\n",
        "            finally:\n",
        "                self.stop_time = datetime.datetime.now()\n",
        "                self.stop()\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train model on dataset for `num_epochs` epochs.\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Number of epochs to run.\n",
        "        \"\"\"\n",
        "\n",
        "        # Train until dataset sampler is exhausted (i.e. until it throws StopIteration)\n",
        "        self.init_dataset_sampler()\n",
        "\n",
        "        try:\n",
        "            print(f\"Starting training {self.name}...\")\n",
        "            while True:\n",
        "                # One training step/iteration\n",
        "                self.pre_train_step()\n",
        "                self.train_step()\n",
        "                self.post_train_step()\n",
        "                self.iters += 1\n",
        "\n",
        "        except StopIteration:\n",
        "            print(\"Finished training.\")\n",
        "\n",
        "\n",
        "    def init_dataset_sampler(self):\n",
        "        \"\"\"\n",
        "        Initializes the sampler (or iterator) of the dataset.\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Number of epochs.\n",
        "        \"\"\"\n",
        "        loader_config = {\n",
        "            \"batch_size\": self.batch_size,\n",
        "            \"shuffle\": True,\n",
        "            \"num_workers\": self.num_workers,\n",
        "        }\n",
        "        self._dataset_sampler = iter(self.sample_loader(loader_config))\n",
        "\n",
        "\n",
        "    def sample_loader(self, loader_config):\n",
        "        \"\"\"\n",
        "        A generator that yields samples from the dataset, exhausting it `num_epochs` times.\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Number of epochs.\n",
        "            loader_config: Configuration for pytorch's data loader.\n",
        "        \"\"\"\n",
        "\n",
        "        for self.epoch in range(self.epoch, self.num_epochs + 1):\n",
        "            data_loader = torch.utils.data.DataLoader(self.dataset, **loader_config)\n",
        "            for self.batch, sample in enumerate(data_loader, 1):\n",
        "                yield sample\n",
        "\n",
        "        self.epoch += 1\n",
        "\n",
        "\n",
        "    def sample_dataset(self):\n",
        "        \"\"\"\n",
        "        Samples the dataset. To be called by the client.\n",
        "\n",
        "        Returns:\n",
        "            A sample from the dataset.\n",
        "        \"\"\"\n",
        "        return next(self._dataset_sampler)\n",
        "\n",
        "\n",
        "    def pre_train_step(self):\n",
        "        \"\"\"\n",
        "        The training preparation, or what happens before each training step.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def train_step(self):\n",
        "        \"\"\"\n",
        "        Makes one training step.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def post_train_step(self):\n",
        "        \"\"\"\n",
        "        The training checkpoint, or what happens after each training step.\n",
        "        \"\"\"\n",
        "        should_report_stats = self.iters % self.report_interval == 0\n",
        "        should_save_progress = self.iters % self.save_interval == 0\n",
        "        finished_epoch = self.batch == self.num_batches\n",
        "\n",
        "        # Report training stats\n",
        "        if should_report_stats or finished_epoch:\n",
        "            self.report_stats()\n",
        "\n",
        "        if self.save_results and should_save_progress:\n",
        "            model_path = os.path.join(self.results_dir,\n",
        "                                      self.get_experiment_name(),\n",
        "                                      f\"model@{self.iters}.pt\")\n",
        "            self.save_model(model_path)\n",
        "\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"\n",
        "        Stops the trainer, or what happens when the trainer stops.\n",
        "        Note: This will run even on keyboard interrupts.\n",
        "        \"\"\"\n",
        "\n",
        "        # plot losses, if any\n",
        "        plot_lines(self.get_data_containing(\"loss\"), title=\"Losses\")\n",
        "\n",
        "\n",
        "    def get_experiment_name(self, delimiter=\", \"):\n",
        "        \"\"\"\n",
        "        Get the name of trainer's training train...\n",
        "\n",
        "        Args:\n",
        "            delimiter: The delimiter between experiment's parameters. Pretty useless.\n",
        "        \"\"\"\n",
        "        info = {\n",
        "            \"name\": self.name,\n",
        "            \"batch_size\": self.batch_size,\n",
        "        }\n",
        "\n",
        "        timestamp = self.start_time.strftime(\"%y%m%d-%H%M%S\")\n",
        "        experiment = delimiter.join(f\"{k}={v}\" for k,v in info.items())\n",
        "\n",
        "        return \"[{}] {}\".format(timestamp, experiment)\n",
        "\n",
        "\n",
        "    def report_stats(self, precision=3):\n",
        "        \"\"\"\n",
        "        Default training stats report.\n",
        "        Prints the current value of each data list recorded.\n",
        "        \"\"\"\n",
        "\n",
        "        # Progress of training\n",
        "        progress = f\"[{self.epoch}/{self.num_epochs}][{self.batch}/{self.num_batches}]  \"\n",
        "\n",
        "        # Show the stat of an item\n",
        "        item_stat = lambda item: f\"{item[0]} = {item[1][-1]:.{precision}f}\"\n",
        "        # Join the stats separated by tabs\n",
        "        stats = \",  \".join(map(item_stat, self._data.items()))\n",
        "\n",
        "        report = progress + stats\n",
        "\n",
        "        print(report)\n",
        "\n",
        "\n",
        "    def get_current_value(self, label):\n",
        "        \"\"\"\n",
        "        Get the current value of the quantity given by `label`.\n",
        "\n",
        "        Args:\n",
        "            label: Name/label of the data/quantity.\n",
        "\n",
        "        Returns:\n",
        "            The current value of the quantity given by `label`.\n",
        "        \"\"\"\n",
        "        return self._data[label][-1] if len(self._data[label]) > 0 else None\n",
        "\n",
        "\n",
        "    def get_data_containing(self, phrase):\n",
        "        \"\"\"\n",
        "        Get the data lists that contain `phrase` in their names/labels.\n",
        "\n",
        "        Args:\n",
        "            phrase: A phrase to find in the label of the data, such as \"loss\".\n",
        "\n",
        "        Returns:\n",
        "            A dict containing the data lists that contain `phrase` in their labels.\n",
        "        \"\"\"\n",
        "        return {k: v for k, v in self._data.items() if k.find(phrase) != -1}\n",
        "\n",
        "\n",
        "    def add_data(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Adds/appends a value to the list given by `label`.\n",
        "\n",
        "        Args:\n",
        "            kwargs: Dict of values to be added to data lists corresponding to their labels.\n",
        "        \"\"\"\n",
        "        for key, value in kwargs.items():\n",
        "            self._data[key].append(value)\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "\n",
        "        self_dict = dict({k:v for k,v in self.__dict__.items() if k[0] != \"_\"})\n",
        "        pretty_dict = pformat(self_dict)\n",
        "        \n",
        "        return self.__class__.__name__ + \"(**\" + pretty_dict + \")\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1COMEeOjzDJA"
      },
      "source": [
        "### ConGAN Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq9oh2M4Rwin"
      },
      "source": [
        "class ConGANTrainer(BaseTrainer):\n",
        "    \"\"\"The trainer for GAN.\"\"\"\n",
        "\n",
        "    def __init__(self, model, dataset,\n",
        "                 D_optim_config={},\n",
        "                 G_optim_config={},\n",
        "                 D_iters=5,\n",
        "                 clamp=(-0.01, 0.01),\n",
        "                 grad_penalty=10.,\n",
        "                 noise_std=0.01,\n",
        "                 generate_grid_interval=200,\n",
        "                 constants={},\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes GANTrainer.\n",
        "\n",
        "        Note:\n",
        "            Optimizer's configurations/parameters must be passable to the\n",
        "            optimizer (in torch.optim). It should also include a parameter\n",
        "            `optim_choice` for the choice of the optimizer (e.g. \"sgd\" or \"adam\").\n",
        "\n",
        "        Args:\n",
        "            model: The model.\n",
        "            dataset: The dataset.\n",
        "            D_optim_config: Configurations for the discriminator's optimizer.\n",
        "            G_optim_config: Configurations for the generator's optimizer.\n",
        "            D_iters: Number of iterations to train discriminator every batch.\n",
        "            clamp: Range on which the discriminator's weight will be clamped after each update.\n",
        "            generate_grid_interval: Check progress every `generate_grid_interval` batch.\n",
        "        \"\"\"\n",
        "        super().__init__(model, dataset, **kwargs)\n",
        "\n",
        "        self.D_iters = D_iters\n",
        "        self.clamp = clamp\n",
        "        self.noise_std = noise_std\n",
        "        self.generate_grid_interval = generate_grid_interval\n",
        "\n",
        "        # Initialize optimizers for generator and discriminator\n",
        "        self.D_optim = init_optim(self.model.D.parameters(), **D_optim_config)\n",
        "        self.G_optim = init_optim(self.model.G.parameters(), **G_optim_config)\n",
        "\n",
        "        # TODO: Specify loss type instead (minimax or wasserstein)\n",
        "        self.D_loss_fn = get_D_loss(self.model.gan_type)\n",
        "        self.G_loss_fn = get_G_loss(self.model.gan_type)\n",
        "\n",
        "        # Grad penalty\n",
        "        self.grad_prenalty = grad_prenalty\n",
        "        \n",
        "        # Initialize list of image grids generated from a fixed latent variable\n",
        "        grid_size = 8 * 8\n",
        "        self._fixed_latent = torch.randn([grid_size, self.model.num_latents], device=self.device)\n",
        "        self._generated_grids = []\n",
        "\n",
        "\n",
        "    def train_step(self):\n",
        "        \"\"\"\n",
        "        Makes one training step.\n",
        "\n",
        "        GAN:\n",
        "        Throughout this doc, we will denote a sample from the real data\n",
        "        distribution, fake data distribution, and latent variables respectively\n",
        "        as follows:\n",
        "            x ~ real,    x_g ~ fake,    z ~ latent\n",
        "\n",
        "        Now recall that in order to train a GAN, we try to find a solution to\n",
        "        a min-max game of the form `min_G max_D V(G,D)`, where G is the generator,\n",
        "        D is the discriminator, and V(G,D) is the score function.\n",
        "        For a regular GAN, V(G,D) = log(D(x)) + log(1 - D(x_g)),\n",
        "        which is the Jensen-Shannon (JS) divergence between the probability\n",
        "        distributions P(x) and P(x_g), where P(x_g) is parameterized by G.\n",
        "\n",
        "        When it comes to Wasserstein GAN (WGAN), the objective is to minimize\n",
        "        the Wasserstein (or Earth-Mover) distance instead of the JS-divergence.\n",
        "        See Theorem 3 and Algorithm 1 in the original paper for more details.\n",
        "        We can achieve that (thanks to the Kantorovich-Rubinstein duality)\n",
        "        by first maximizing  `D(x) - D(x_g)` in the space of 1-Lipschitz\n",
        "        discriminators D, where x ~ data and x_g ~ fake.\n",
        "        Then, we have the gradient wrt G of the Wasserstein distance equal\n",
        "        to the gradient of -D(G(z)).\n",
        "        Since we assumed that D should be 1-Lipschitz, we can enforce\n",
        "        k-Lipschitzness by clamping the weights of D to be in some fixed box,\n",
        "        which would be approximate up to a scaling factor.\n",
        "\n",
        "        Enforcing Lipschitzness is done more elegantly in WGAN-GP,\n",
        "        which is just WGAN with gradient penalty (GP). The gradient penalty\n",
        "        is used because of the statement that a differentiable function is\n",
        "        1-Lipschitz iff it has gradient norm equal to 1 almost everywhere\n",
        "        under P(x) and P(x_g). Hence, the objective will be similar to WGAN,\n",
        "        which is `min_G max_D of D(x) - D(x_g)`, but now we add the gradient\n",
        "        penalty in the D_step such that it will be minimized.\n",
        "\n",
        "        Links to the papers:\n",
        "        GAN:     https://arxiv.org/pdf/1406.2661.pdf\n",
        "        WGAN:    https://arxiv.org/pdf/1701.07875.pdf\n",
        "        WGAN-GP: https://arxiv.org/pdf/1704.00028.pdf\n",
        "        \"\"\"\n",
        "\n",
        "        for _ in range(self.D_iters):\n",
        "            # Sample real data from the dataset\n",
        "            sample = self.sample_dataset()\n",
        "            real = sample[\"before\"].to(self.device)\n",
        "\n",
        "            # Sample latent and train discriminator\n",
        "            latent = self.sample_latent()\n",
        "            D_results = self.D_step(real, latent)\n",
        "\n",
        "        # Sample latent and train generator\n",
        "        latent = self.sample_latent()\n",
        "        G_results = self.G_step(latent)\n",
        "\n",
        "        # Record data\n",
        "        self.add_data(**D_results, **G_results)\n",
        "        losses = {\"D_loss\": D_results[\"D_loss\"],\n",
        "                  \"G_loss\": G_results[\"G_loss\"]}\n",
        "        D_evals = {\"D_on_real\": D_results[\"D_on_real\"],\n",
        "                   \"D_on_fake\": D_results[\"D_on_fake2\"]}\n",
        "        self.writer.add_scalars(\"Loss\", losses, self.iters)\n",
        "        self.writer.add_scalars(\"D_evals\", D_evals, self.iters)\n",
        "\n",
        "\n",
        "    def D_step(self, real, latent):\n",
        "\n",
        "        # Add noise to real\n",
        "        real += torch.randn_like(real) * self.noise_std\n",
        "\n",
        "        # Sample from generators\n",
        "        with torch.no_grad():\n",
        "            fake = self.model.G(latent)\n",
        "        # Add noise to fake\n",
        "        fake += torch.randn_like(fake) * self.noise_std\n",
        "\n",
        "        # Classify real and fake images\n",
        "        D_on_real = self.model.D(real)\n",
        "        D_on_fake = self.model.D(fake)\n",
        "\n",
        "        # Adversarial loss\n",
        "        adv_loss = self.D_loss_fn(D_on_real, D_on_fake)\n",
        "\n",
        "        # Gradient penalty\n",
        "        D_grad_penalty = torch.tensor(0.0)\n",
        "        if grad_penalty != 0:\n",
        "            D_grad_penalty = simple_gradient_penalty(\n",
        "                self.model.D, random_interpolate(real, fake), center=1.0)\n",
        "        \n",
        "        # Calculate gradients and minimize loss\n",
        "        self.D_optim.zero_grad()\n",
        "        D_loss = adv_loss + grad_penalty * D_grad_penalty\n",
        "        D_loss.backward()\n",
        "        self.D_optim.step()\n",
        "\n",
        "        return {\n",
        "            \"D_on_real\": D_on_real.mean().item(),\n",
        "            \"D_on_fake\": D_on_fake.mean().item(),\n",
        "            \"D_grad_penalty\": D_grad_penalty.item(),\n",
        "            \"D_loss\": D_loss.item(),\n",
        "        }\n",
        "\n",
        "\n",
        "    def G_step(self, latent):\n",
        "\n",
        "        # Sample from generators\n",
        "        fake = self.model.G(latent)\n",
        "        fake += torch.randn_like(fake) * self.noise_std\n",
        "\n",
        "        # Classify fake images\n",
        "        D_on_fake = self.model.D(fake)\n",
        "\n",
        "        # Adversarial loss\n",
        "        adv_loss = self.G_loss_fn(D_on_fake)\n",
        "\n",
        "        # Calculate gradients and minimize loss\n",
        "        self.G_optim.zero_grad()\n",
        "        G_loss = adv_loss\n",
        "        G_loss.backward()\n",
        "        self.G_optim.step()\n",
        "\n",
        "        return {\n",
        "            \"D_on_fake2\": D_on_fake.mean().item(),\n",
        "            \"G_loss\": G_loss.item(),\n",
        "        }\n",
        "\n",
        "    def sample_latent(self):\n",
        "        \"\"\"\n",
        "        Samples from the latent space (i.e. input space of the generator).\n",
        "\n",
        "        Returns:\n",
        "            Sample from the latent space.\n",
        "        \"\"\"\n",
        "\n",
        "        # Calculate latent size and sample from normal distribution\n",
        "        latent_size = [self.batch_size, self.model.latent_dim]\n",
        "        latent = torch.randn(latent_size, device=self.device)\n",
        "\n",
        "        return latent\n",
        "\n",
        "\n",
        "    #################### Reporting and Tracking Methods ####################\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"\n",
        "        Stops the trainer and report the result of the experiment.\n",
        "        \"\"\"\n",
        "\n",
        "        losses = {**self.get_data_containing(\"D_loss\"), **self.get_data_containing(\"G_loss\")}\n",
        "        lines_to_plot = {\"Discriminator Evaluations\": \"D_on\",\n",
        "                         \"Gradient Penalty\": \"grad_penalty\",}\n",
        "\n",
        "        if not self.save_results:\n",
        "            plot_lines(losses, title=\"Losses\")\n",
        "            for title, keyword in lines_to_plot.items():\n",
        "                plot_lines(self.get_data_containing(keyword), title=title)\n",
        "            return\n",
        "\n",
        "        # Create experiment directory in the model's directory\n",
        "        experiment_dir = os.path.join(self.results_dir, self.get_experiment_name())\n",
        "\n",
        "        # Save model\n",
        "        model_path = os.path.join(experiment_dir, \"model.pt\")\n",
        "        self.save_model(model_path)\n",
        "\n",
        "        # Plot losses of D and G\n",
        "        losses_file = os.path.join(experiment_dir, \"losses.png\")\n",
        "        plot_lines(losses, filename=losses_file, title=\"Losses of D and G\")\n",
        "\n",
        "        # Plot evals of D on real and fake data\n",
        "        evals_file = os.path.join(experiment_dir, \"evals.png\")\n",
        "        plot_lines(evals, filename=evals_file, title=\"Evaluations of D on real and fake data\")\n",
        "\n",
        "        # Create an animation of the generator's progress\n",
        "        animation_file = os.path.join(experiment_dir, \"progress.mp4\")\n",
        "        create_progress_animation(self._generated_grids, animation_file)\n",
        "\n",
        "        # Write details of experiment\n",
        "        details_txt = os.path.join(experiment_dir, \"repr.txt\")\n",
        "        with open(details_txt, \"w\") as f:\n",
        "            f.write(self.__repr__())\n",
        "\n",
        "\n",
        "    def post_train_step(self):\n",
        "        \"\"\"\n",
        "        The post-training step.\n",
        "        \"\"\"\n",
        "        super().post_train_step()\n",
        "\n",
        "        should_generate_grid = self.iters % self.generate_grid_interval == 0\n",
        "\n",
        "        # Check generator's progress by recording its output on a fixed input\n",
        "        if should_generate_grid:\n",
        "            grid = generate_grid(self.model.G, self._fixed_latent)\n",
        "            self._generated_grids.append(grid)\n",
        "            self.writer.add_image(\"grid\", grid, self.iters)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZL4AHP15ZQ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4d9zr8qEhLF"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvDLiovQEiu6"
      },
      "source": [
        "def get_D_loss(gan_type=\"gan\"):\n",
        "    if gan_type in (\"gan\", \"gan-gp\"):\n",
        "        return D_loss_GAN\n",
        "    elif gan_type in (\"wgan\", \"wgan-gp\"):\n",
        "        return D_loss_WGAN\n",
        "    else:\n",
        "        raise ValueError(f\"gan_type {gan_type} not supported\")\n",
        "\n",
        "\n",
        "def get_G_loss(gan_type=\"gan\"):\n",
        "    if gan_type in (\"gan\", \"gan-gp\"):\n",
        "        return G_loss_GAN\n",
        "    elif gan_type in (\"wgan\", \"wgan-gp\"):\n",
        "        return G_loss_WGAN\n",
        "    else:\n",
        "        raise ValueError(f\"gan_type {gan_type} not supported\")\n",
        "\n",
        "\n",
        "def D_loss_GAN(D_real, D_fake, label_smoothing=True):\n",
        "    \n",
        "    # Create (noisy) real and fake labels XXX\n",
        "    if label_smoothing:\n",
        "        real_label = 0.7 + 0.5 * torch.rand_like(D_real)\n",
        "    else:\n",
        "        real_label = torch.ones_like(D_real) - 0.1\n",
        "    fake_label = torch.zeros_like(D_fake)\n",
        "\n",
        "    # Calculate binary cross entropy loss\n",
        "    D_loss_real = F.binary_cross_entropy(D_real, real_label)\n",
        "    D_loss_fake = F.binary_cross_entropy(D_fake, fake_label)\n",
        "\n",
        "    # Loss is: - log(D(x)) - log(1 - D(x_g)),\n",
        "    # which is equiv. to maximizing: log(D(x)) + log(1 - D(x_g))\n",
        "    D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "    return D_loss.mean()\n",
        "\n",
        "\n",
        "def D_loss_WGAN(D_real, D_fake):\n",
        "\n",
        "    # Maximize: D(x) - D(x_g) - const * (|| grad of D(x_i) wrt x_i || - 1)^2,\n",
        "    # where x_i <- eps * x + (1 - eps) * x_g, and eps ~ rand(0,1)\n",
        "    D_loss = -1 * (D_real - D_fake)\n",
        "\n",
        "    return D_loss.mean()\n",
        "\n",
        "\n",
        "def G_loss_GAN(D_fake):\n",
        "\n",
        "    # Calculate binary cross entropy loss with a fake binary label\n",
        "    fake_label = torch.zeros_like(D_fake)\n",
        "\n",
        "    # Loss is: -log(D(G(z))), which is equiv. to minimizing log(1-D(G(z)))\n",
        "    # We use this loss vs. the original one for stability only.\n",
        "    G_loss = F.binary_cross_entropy(D_fake, 1 - fake_label)\n",
        "\n",
        "    return G_loss.mean()\n",
        "\n",
        "\n",
        "def G_loss_WGAN(D_fake):\n",
        "\n",
        "    # Minimize: -D(G(z))\n",
        "    G_loss = -D_fake\n",
        "    \n",
        "    return G_loss.mean()\n",
        "\n",
        "\n",
        "def interpolate(real, fake):\n",
        "    eps = torch.rand(real.size(0), 1, 1, 1).to(real)\n",
        "    return eps * real + (1 - eps) * fake\n",
        "\n",
        "def simple_gradient_penalty(D, x, center=0.):\n",
        "    x.requires_grad_()\n",
        "    D_x = D(x)\n",
        "    D_grad = torch.autograd.grad(D_x, x, torch.ones_like(D_x), create_graph=True)\n",
        "    D_grad_norm = D_grad[0].view(x.size(0), -1).norm(dim=1)\n",
        "    return (D_grad_norm - center).pow(2).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmE3jiqiqVK9"
      },
      "source": [
        "## Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpX6Fwk-WRsS"
      },
      "source": [
        "class Args:\n",
        "    def __init(self):\n",
        "        self.data = \"/content/drive/My Drive/gansiam/dataset/\"\n",
        "        self.arch = \"resnet50\"\n",
        "        self.workers = 32\n",
        "        self.epochs = 100\n",
        "        self.start_epoch = 0\n",
        "        self.batch_size = 512\n",
        "        self.learning_rate = 0.05\n",
        "        self.momentum = 0.9\n",
        "        self.weight_decay = 1e-4\n",
        "        self.print_freq = 10\n",
        "        self.resume = \"\"\n",
        "        self.world_size = -1\n",
        "        self.rank = -1\n",
        "        self.seed = None\n",
        "        self.gpu = None\n",
        "        self.dist_url = None\n",
        "        self.dist_backend = None\n",
        "        self.multiprocessing_distributed = False\n",
        "\n",
        "        # SimSiam\n",
        "        self.dim = 2048\n",
        "        self.repr_dim = self.dim\n",
        "        self.pred_dim = 512\n",
        "        self.fix_pred_lr = False\n",
        "\n",
        "        # GAN\n",
        "        D_iters = 3\n",
        "        grad_penalty = 10.\n",
        "\n",
        "# Copied from SimSiam repo with some adjustments >>>>>>>>\n",
        "import argparse\n",
        "import builtins\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "def simsiam_main(args):\n",
        "\n",
        "    if args.seed is not None:\n",
        "        random.seed(args.seed)\n",
        "        torch.manual_seed(args.seed)\n",
        "        cudnn.deterministic = True\n",
        "        warnings.warn('You have chosen to seed training. '\n",
        "                      'This will turn on the CUDNN deterministic setting, '\n",
        "                      'which can slow down your training considerably! '\n",
        "                      'You may see unexpected behavior when restarting '\n",
        "                      'from checkpoints.')\n",
        "\n",
        "    if args.gpu is not None:\n",
        "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
        "                      'disable data parallelism.')\n",
        "\n",
        "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "\n",
        "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
        "\n",
        "    ngpus_per_node = torch.cuda.device_count()\n",
        "    if args.multiprocessing_distributed:\n",
        "        # Since we have ngpus_per_node processes per node, the total world_size\n",
        "        # needs to be adjusted accordingly\n",
        "        args.world_size = ngpus_per_node * args.world_size\n",
        "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
        "        # main_worker process function\n",
        "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
        "    else:\n",
        "        # Simply call main_worker function\n",
        "        main_worker(args.gpu, ngpus_per_node, args)\n",
        "\n",
        "\n",
        "def main_worker(gpu, ngpus_per_node, args):\n",
        "    args.gpu = gpu\n",
        "\n",
        "    # suppress printing if not master\n",
        "    if args.multiprocessing_distributed and args.gpu != 0:\n",
        "        def print_pass(*args):\n",
        "            pass\n",
        "        builtins.print = print_pass\n",
        "\n",
        "    if args.gpu is not None:\n",
        "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.dist_url == \"env://\" and args.rank == -1:\n",
        "            args.rank = int(os.environ[\"RANK\"])\n",
        "        if args.multiprocessing_distributed:\n",
        "            # For multiprocessing distributed training, rank needs to be the\n",
        "            # global rank among all the processes\n",
        "            args.rank = args.rank * ngpus_per_node + gpu\n",
        "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
        "                                world_size=args.world_size, rank=args.rank)\n",
        "        torch.distributed.barrier()\n",
        "    # create model\n",
        "    print(\"=> creating model '{}'\".format(args.arch))\n",
        "    # <<<<<<<<<<\n",
        "    model = ConsistentGAN(models.__dict__[args.arch],\n",
        "                          args.dim,\n",
        "                          args.pred_dim,\n",
        "                          args.latent_dim)\n",
        "    # >>>>>>>>>>\n",
        "\n",
        "    # infer learning rate before changing batch size\n",
        "    init_lr = args.lr * args.batch_size / 256\n",
        "\n",
        "    if args.distributed:\n",
        "        # Apply SyncBN\n",
        "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
        "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
        "        # should always set the single device scope, otherwise,\n",
        "        # DistributedDataParallel will use all available devices.\n",
        "        if args.gpu is not None:\n",
        "            torch.cuda.set_device(args.gpu)\n",
        "            model.cuda(args.gpu)\n",
        "            # When using a single GPU per process and per\n",
        "            # DistributedDataParallel, we need to divide the batch size\n",
        "            # ourselves based on the total number of GPUs we have\n",
        "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
        "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
        "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
        "        else:\n",
        "            model.cuda()\n",
        "            # DistributedDataParallel will divide and allocate batch_size to all\n",
        "            # available GPUs if device_ids are not set\n",
        "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
        "    elif args.gpu is not None:\n",
        "        torch.cuda.set_device(args.gpu)\n",
        "        model = model.cuda(args.gpu)\n",
        "        # comment out the following line for debugging\n",
        "        raise NotImplementedError(\"Only DistributedDataParallel is supported.\")\n",
        "    else:\n",
        "        # AllGather implementation (batch shuffle, queue update, etc.) in\n",
        "        # this code only supports DistributedDataParallel.\n",
        "        raise NotImplementedError(\"Only DistributedDataParallel is supported.\")\n",
        "    print(model) # print model after SyncBatchNorm\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    criterion = nn.CosineSimilarity(dim=1).cuda(args.gpu)\n",
        "    # <<<<<<<<<<\n",
        "    # Define D and G loss functions\n",
        "    D_criterion = D_loss_WGAN if gan_type == \"wgan\" else D_loss_GAN\n",
        "    G_criterion = G_loss_WGAN if gan_type == \"wgan\" else G_loss_GAN\n",
        "    # >>>>>>>>>>\n",
        "\n",
        "    if args.fix_pred_lr:\n",
        "        optim_params = [{'params': model.module.encoder.parameters(), 'fix_lr': False},\n",
        "                        {'params': model.module.predictor.parameters(), 'fix_lr': True}]\n",
        "    else:\n",
        "        optim_params = model.parameters()\n",
        "\n",
        "    optimizer = torch.optim.SGD(optim_params, init_lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay)\n",
        "    # <<<<<<<<<<\n",
        "    D_optimizer = torch.optim.SGD(model.module.D.parameters(), init_lr,\n",
        "                                  momentum=args.momentum,\n",
        "                                  )#weight_decay=args.weight_decay)\n",
        "    G_optimizer = torch.optim.SGD(model.module.G.parameters(), init_lr,\n",
        "                                  momentum=args.momentum,\n",
        "                                  )#weight_decay=args.weight_decay)\n",
        "    # >>>>>>>>>>\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            if args.gpu is None:\n",
        "                checkpoint = torch.load(args.resume)\n",
        "            else:\n",
        "                # Map model to be loaded to specified single gpu.\n",
        "                loc = 'cuda:{}'.format(args.gpu)\n",
        "                checkpoint = torch.load(args.resume, map_location=loc)\n",
        "            args.start_epoch = checkpoint['epoch']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(args.resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Data loading code\n",
        "    traindir = os.path.join(args.data, 'train')\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    # MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709\n",
        "    augmentation = [\n",
        "        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
        "        transforms.RandomApply([\n",
        "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
        "        ], p=0.8),\n",
        "        transforms.RandomGrayscale(p=0.2),\n",
        "        transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(\n",
        "        traindir,\n",
        "        TwoCropsTransform(transforms.Compose(augmentation)))\n",
        "\n",
        "    if args.distributed:\n",
        "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    else:\n",
        "        train_sampler = None\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
        "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        if args.distributed:\n",
        "            train_sampler.set_epoch(epoch)\n",
        "        adjust_learning_rate(optimizer, init_lr, epoch, args)\n",
        "\n",
        "        # train for one epoch\n",
        "        # <<<<<<<<<<\n",
        "        train(train_loader, model,\n",
        "              criterion, D_criterion, G_criterion,\n",
        "              optimizer, D_optimizer, G_optimizer,\n",
        "              epoch, args)\n",
        "        # >>>>>>>>>>\n",
        "\n",
        "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
        "                and args.rank % ngpus_per_node == 0):\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'arch': args.arch,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer' : optimizer.state_dict(),\n",
        "            }, is_best=False, filename='checkpoint_{:04d}.pth.tar'.format(epoch))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lrlXdSVACvN"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naX0ismeADNi"
      },
      "source": [
        "def train(train_loader, model,\n",
        "          criterion, D_criterion, G_criterion,\n",
        "          optimizer, D_optimizer, G_optimizer,\n",
        "          epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4f')\n",
        "    D_losses = AverageMeter('D Loss', ':.4f')\n",
        "    G_losses = AverageMeter('G Loss', ':.4f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if args.gpu is not None:\n",
        "            images[0] = images[0].cuda(args.gpu, non_blocking=True)\n",
        "            images[1] = images[1].cuda(args.gpu, non_blocking=True)\n",
        "        \n",
        "        x1 = images[0]\n",
        "        x2 = images[1]\n",
        "        batch_size = x1.size(0)\n",
        "\n",
        "        # compute output and loss\n",
        "        # Note: repr are detached\n",
        "        pred1, pred2, repr1, repr2 = model(x1=x1, x2=x2)\n",
        "        loss = -0.5 * args.siam_coeff * \\\n",
        "            (criterion(pred1, repr2).mean() + criterion(pred2, repr1).mean())\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        \n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # train GAN for repr 1\n",
        "        for _ in range(args.D_iters):\n",
        "            latent = model.sample_latent(batch_size)\n",
        "            \n",
        "            # Add noise to real sample\n",
        "            real = repr1 + torch.randn_like(repr1) * noise\n",
        "\n",
        "            # Sample from generator\n",
        "            with torch.no_grad():\n",
        "                fake = model.G(latent)\n",
        "                # Add noise to fake sample as well\n",
        "                fake += torch.randn_like(fake) * noise\n",
        "\n",
        "            # Classify real and fake data\n",
        "            D_real = model.D(real)\n",
        "            D_fake = model.D(fake)\n",
        "\n",
        "            # Calculate loss\n",
        "            D_loss = D_criterion(D_real, D_fake)\n",
        "            # Gradient penalty\n",
        "            if grad_penalty != 0:\n",
        "                D_grad_penalty = simple_gradient_penalty(\n",
        "                    model.D, interpolate(real, fake), center=1.0)\n",
        "                D_loss += grad_penalty * D_grad_penalty\n",
        "\n",
        "            # Calculate gradient and minimize\n",
        "            D_optimizer.zero_grad()\n",
        "            D_loss.backward()\n",
        "            D_optimizer.step()\n",
        "\n",
        "        # Sample from generators\n",
        "        latent = model.sample_latent(batch_size)\n",
        "        fake = model.G(latent)\n",
        "        fake += torch.randn_like(fake) * args.noise\n",
        "        # Classify fake images\n",
        "        D_fake = model.D(fake)\n",
        "        # Calculate loss\n",
        "        G_loss = G_criterion(D_fake)\n",
        "        G_loss += args.recon_coeff * F.mse_loss(fake, repr2)  # note repr2\n",
        "        # Calculate gradient and minimize\n",
        "        G_optimizer.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        # do the same for repr2? @TODO\n",
        "        for _ in range(args.D_iters):\n",
        "            latent = model.sample_latent(batch_size)\n",
        "            \n",
        "            # Add noise to real sample\n",
        "            real = repr2 + torch.randn_like(repr2) * noise\n",
        "\n",
        "            # Sample from generator\n",
        "            with torch.no_grad():\n",
        "                fake = model.G(latent)\n",
        "                # Add noise to fake sample as well\n",
        "                fake += torch.randn_like(fake) * noise\n",
        "\n",
        "            # Classify real and fake data\n",
        "            D_real = model.D(real)\n",
        "            D_fake = model.D(fake)\n",
        "\n",
        "            # Calculate loss\n",
        "            D_loss = D_criterion(D_real, D_fake)\n",
        "            # Gradient penalty\n",
        "            if grad_penalty != 0:\n",
        "                D_grad_penalty = simple_gradient_penalty(\n",
        "                    model.D, interpolate(real, fake), center=1.0)\n",
        "                D_loss += grad_penalty * D_grad_penalty\n",
        "\n",
        "            # Calculate gradient and minimize\n",
        "            D_optimizer.zero_grad()\n",
        "            D_loss.backward()\n",
        "            D_optimizer.step()\n",
        "\n",
        "        # Sample from generators\n",
        "        latent = model.sample_latent(batch_size)\n",
        "        fake = model.G(latent)\n",
        "        fake += torch.randn_like(fake) * args.noise\n",
        "        # Classify fake images\n",
        "        D_fake = model.D(fake)\n",
        "        # Calculate loss\n",
        "        G_loss = G_criterion(D_fake)\n",
        "        G_loss += args.recon_coeff * F.mse_loss(fake, repr1)\n",
        "        # Calculate gradient and minimize\n",
        "        G_optimizer.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        # Adding second loss only @XXX\n",
        "        D_losses.update(D_loss.item(), batch_size)\n",
        "        G_losses.update(G_loss.item(), batch_size)\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.display(i)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, init_lr, epoch, args):\n",
        "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
        "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
        "            param_group['lr'] = init_lr\n",
        "        else:\n",
        "            param_group['lr'] = cur_lr"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}